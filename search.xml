<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>深度学习模型之CNN（三）AlexNet网络结构及数据集下载</title>
    <url>/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/</url>
    <content><![CDATA[<h1>AlexNet详解</h1>
<p>AlexNet时2012年ILSVRC 2012（ImageNet Large Scale Visual Recognition Challenge）竞赛的冠军网络，分类准确率由传统的70%+提升到80%+。它是由Hinton和他的学生Alex Krizhevsky设计的。也是从那年后，深度学习开始迅速发展。</p>
<p>ILSVRC 2012</p>
<ul>
<li>训练集：1,281,167张已标注图片</li>
<li>验证集：50,000张已标注图片</li>
<li>测试集：100,000张未标注图片</li>
</ul>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/AlexNet%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.png" alt="AlexNet网络架构"></p>
<h2 id="网络的亮点">网络的亮点</h2>
<ol>
<li>首次使用GPU进行网络加速训练</li>
<li>使用ReLU激活函数，而不是传统的Sigmoid激活函数以及Tanh激活函数</li>
<li>使用LRN局部响应归一化</li>
<li>在全连接层的前两层中使用了Dropout随机失活神经元操作，以减少过拟合</li>
</ol>
<ul>
<li>高端GPU的提速比可以达到CPU的20-50倍的速度差距</li>
<li>sigmoid激活函数的两个缺点：<strong>1、求导的过程比较麻烦；2、当网络比较深的时候会出现梯度消失的现象</strong>。ReLU能够解决以上问题</li>
<li>dropout操作可以减少过拟合现象</li>
</ul>
<h2 id="过拟合">过拟合</h2>
<p>过拟合：根本原因是特征维度过多，模型假设过于复杂，参数过多，训练数据过少，噪声过多，导致拟合的函数完美的预测训练集，但对新数据的测试集预测结果差。过度的拟合了训练数据，而没有考虑到泛化能力</p>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/%E8%BF%87%E6%8B%9F%E5%90%88.png" alt="过拟合"></p>
<ul>
<li>第一幅图是网络的一个初始状态，随机地划分了一条边界对于样本进行分类</li>
<li>通过不断的训练过程中，网络会慢慢学习出一条分类的边界如第二幅图所示，得到了一个比较好的分类的结果</li>
<li>第三幅图虽然能够将训练样本进行完全正确的分类，但是图中出现了过拟合现象</li>
<li><strong>过拟合的函数能够完美地预测训练集，但是对新数据的测试机预测效果较差，过度的拟合了训练数据，而没有考虑到泛化能力</strong></li>
</ul>
<h2 id="使用dropout减少过拟合现象">使用dropout减少过拟合现象</h2>
<p>使用Dropout的方式在网络正向传播过程中随机失活一部分神经元</p>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/Dropout.png" alt="Dropout"></p>
<ul>
<li>左图是一个正常的全连接的正向传播过程，每一个节点都与下层的节点进行全连接</li>
<li>使用了dropout之后，会在每一层随机地失活一部分神经元，变相地减少了网络中训练的参数，从而达到了减少过拟合现象的作用</li>
</ul>
<h1>AlexNet网络结构</h1>
<p>经卷积后的矩阵尺寸大小计算公式为：</p>
<p>\begin{flalign}<br>
N = (W-F+2P)/S + 1<br>
\end{flalign}</p>
<ul>
<li>输入图片大小：W×W</li>
<li>Filter大小：F×F</li>
<li>步长：S</li>
<li>padding的像素数：P</li>
</ul>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/AlexNet%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.png" alt="AlexNet网络架构"></p>
<ul>
<li>这个图可以看成上下两部分：<strong>作者使用了两块GPU进行了并行运算</strong></li>
<li>上下两部分都是一样的，只用看其中一部分即可</li>
</ul>
<h2 id="Conv1"><strong>Conv1</strong></h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/%E7%AC%AC%E4%B8%80%E5%B1%82%EF%BC%88Conv1%EF%BC%89.png" alt="Conv1"></p>
<ul>
<li>原始图像是一个224*224的channel为3的彩色图像</li>
<li>卷积核大小是11*11</li>
<li>步长为4</li>
<li>卷积核的大小为11</li>
<li>一共有48*2=96个卷积核</li>
<li>可以推理出padding的大小是1和2：表示在特征矩阵的左边加上一列0，右边加上两列0，上面加上一列0，下面加上两列0**（注意代表padding的2p值的是两边padding的像素之和，并不一定要求两边像素一定要一样）**</li>
</ul>
<h2 id="Maxpooling1"><strong>Maxpooling1</strong></h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/Maxpooling1.png" alt="Maxpooling1"></p>
<ul>
<li>最大池化下采样操作</li>
<li>池化核大小等于3</li>
<li>padding为0</li>
<li>步长为2</li>
<li>这一层的输入是第一层卷积层的输出</li>
<li><strong>池化操作只会改变输出矩阵的高度和宽度，不会改变特征矩阵的深度</strong></li>
</ul>
<h2 id="Conv2"><strong>Conv2</strong></h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/%E7%AC%AC%E4%BA%8C%E5%B1%82%EF%BC%88Conv2%EF%BC%89.png" alt="Conv2"></p>
<ul>
<li>卷积核的个数为128*2=256</li>
<li>卷积核的大小为5</li>
<li>padding为 [ 2，2 ]</li>
<li>步长为1</li>
</ul>
<h2 id="Maxpooling2"><strong>Maxpooling2</strong></h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/Maxpooling2.png" alt="Maxpooling2"></p>
<ul>
<li>池化核大小为3</li>
<li>padding为0</li>
<li>步长等于2</li>
</ul>
<h2 id="Conv3"><strong>Conv3</strong></h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/%E7%AC%AC%E4%B8%89%E5%B1%82%EF%BC%88Conv3%EF%BC%89.png" alt="Conv3"></p>
<ul>
<li>卷积核的个数为192*2=384</li>
<li>卷积核的大小为3</li>
<li>padding为 [ 1，1 ]</li>
<li>步长为1</li>
</ul>
<h2 id="Conv4"><strong>Conv4</strong></h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/%E7%AC%AC%E5%9B%9B%E5%B1%82%EF%BC%88Conv4%EF%BC%89.png" alt="Conv4"></p>
<ul>
<li>卷积核的个数为192*2=384</li>
<li>卷积核的大小为3</li>
<li>padding为 [ 1，1 ]</li>
<li>步长为1</li>
</ul>
<h2 id="Conv5"><strong>Conv5</strong></h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/%E7%AC%AC%E4%BA%94%E5%B1%82%EF%BC%88Conv5%EF%BC%89.png" alt="Conv5"></p>
<ul>
<li>卷积核的个数为128*2=256</li>
<li>卷积核的大小为3</li>
<li>padding为 [ 1，1 ]</li>
<li>步长为1</li>
</ul>
<h2 id="Maxpooling3"><strong>Maxpooling3</strong></h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/Maxpooling3.png" alt="Maxpooling3"></p>
<ul>
<li>池化核的大小为3</li>
<li>padding等于0</li>
<li>步长为2</li>
<li>输出的特征矩阵展平之后和三个全连接层进行连接**（注意最后一个全连接层只有1000个节点，对应数据集的1000个类别，如果要将这个网络应用到自己的数据集的话，只需要将最后一层全连接层的节点个数改成和自己数据集的类别数一致即可）**</li>
</ul>
<h2 id="层级参数总结">层级参数总结</h2>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/AlexNet%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%BF%87%E7%A8%8B%E6%80%BB%E7%BB%93.png" alt="AlexNet网络架构过程总结"></p>
<h1><strong>下载花分类数据集</strong></h1>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/%E4%B8%8B%E8%BD%BD%E8%8A%B1%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86.png" alt="下载花分类数据集"></p>
<p>步骤如下：</p>
<ul>
<li>在data_set文件夹下创建新文件夹&quot;flower_data&quot;</li>
<li>点击链接下载花分类数据集 <a href="https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz">https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</a></li>
<li>解压数据集到flower_data文件夹下</li>
<li>执行&quot;split_data.py&quot;脚本(<a href="https://pan.baidu.com/s/1bijzd-8zBjKLlXi5uG9pFA?pwd=1234">网盘下载</a>)自动将数据集划分成训练集train和验证集val（训练集：测试集 = 9 ：1）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── data_set </span><br><span class="line">	├── split_data.py</span><br><span class="line">	└── flower_data   </span><br><span class="line">		├── flower_photos（解压的数据集文件夹，3670个样本）  </span><br><span class="line">		├── train（生成的训练集，3306个样本）  </span><br><span class="line">		└── val（生成的验证集，364个样本） </span><br></pre></td></tr></table></figure>
<p>附split_data.py代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copy, rmtree</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mk_file</span>(<span class="params">file_path: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">        <span class="comment"># 如果文件夹存在，则先删除原文件夹在重新创建</span></span><br><span class="line">        rmtree(file_path)</span><br><span class="line">    os.makedirs(file_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 保证随机可复现</span></span><br><span class="line">    random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将数据集中10%的数据划分到验证集中</span></span><br><span class="line">    split_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 指向你解压后的flower_photos文件夹</span></span><br><span class="line">    cwd = os.getcwd()</span><br><span class="line">    data_root = os.path.join(cwd, <span class="string">&quot;flower_data&quot;</span>)</span><br><span class="line">    origin_flower_path = os.path.join(data_root, <span class="string">&quot;flower_photos&quot;</span>)</span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(origin_flower_path), <span class="string">&quot;path &#x27;&#123;&#125;&#x27; does not exist.&quot;</span>.<span class="built_in">format</span>(origin_flower_path)</span><br><span class="line"></span><br><span class="line">    flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(origin_flower_path)</span><br><span class="line">                    <span class="keyword">if</span> os.path.isdir(os.path.join(origin_flower_path, cla))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立保存训练集的文件夹</span></span><br><span class="line">    train_root = os.path.join(data_root, <span class="string">&quot;train&quot;</span>)</span><br><span class="line">    mk_file(train_root)</span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        <span class="comment"># 建立每个类别对应的文件夹</span></span><br><span class="line">        mk_file(os.path.join(train_root, cla))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立保存验证集的文件夹</span></span><br><span class="line">    val_root = os.path.join(data_root, <span class="string">&quot;val&quot;</span>)</span><br><span class="line">    mk_file(val_root)</span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        <span class="comment"># 建立每个类别对应的文件夹</span></span><br><span class="line">        mk_file(os.path.join(val_root, cla))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        cla_path = os.path.join(origin_flower_path, cla)</span><br><span class="line">        images = os.listdir(cla_path)</span><br><span class="line">        num = <span class="built_in">len</span>(images)</span><br><span class="line">        <span class="comment"># 随机采样验证集的索引</span></span><br><span class="line">        eval_index = random.sample(images, k=<span class="built_in">int</span>(num*split_rate))</span><br><span class="line">        <span class="keyword">for</span> index, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">            <span class="keyword">if</span> image <span class="keyword">in</span> eval_index:</span><br><span class="line">                <span class="comment"># 将分配至验证集中的文件复制到相应目录</span></span><br><span class="line">                image_path = os.path.join(cla_path, image)</span><br><span class="line">                new_path = os.path.join(val_root, cla)</span><br><span class="line">                copy(image_path, new_path)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 将分配至训练集中的文件复制到相应目录</span></span><br><span class="line">                image_path = os.path.join(cla_path, image)</span><br><span class="line">                new_path = os.path.join(train_root, cla)</span><br><span class="line">                copy(image_path, new_path)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(cla, index+<span class="number">1</span>, num), end=<span class="string">&quot;&quot;</span>)  <span class="comment"># processing bar</span></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;processing done!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>运行split_data.py之后，结果如图所示</p>
<p><img src="/2023/05/02/AlexNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD/split_data%E7%BB%93%E6%9E%9C.png" alt="split_data结果"></p>
<h1>总结</h1>
<p>本节课主要讲AlexNet的网络结构，以及需要使用到的数据集，下节课将会使用Pytorch来搭建AlexNet，并用下载好的花分类数据集进行训练。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>AlexNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（七）GoogLeNet网络详解</title>
    <url>/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1>GoogLeNet详解</h1>
<p>GoogLeNet在2014年由Google团队提出，斩获当年ImageNet竞赛中Classification Task (分类任务) 第一名。原论文地址：<a href="https://arxiv.org/abs/1409.4842">Going deeper with convolutions</a></p>
<p>GoogLeNet 的创新点：</p>
<ul>
<li>引入了<strong>Inception结构</strong>（融合不同尺度的特征信息）</li>
<li>使用1x1的卷积核进行降维以及映射处理（虽然VGG网络中也有，但该论文介绍的更详细）</li>
<li>添加两个辅助分类器帮助训练（<strong>AlexNet和VGG都只有一个输出层，GoogLeNet有三个输出层（其中两个辅助分类层）</strong>）</li>
<li>丢弃全连接层，使用平均池化层（大大减少模型参数，除去两个辅助分类器，网络大小只有VGG的1/20）</li>
</ul>
<h2 id="Inception结构">Inception结构</h2>
<p>传统的CNN结构如AlexNet、VggNet（下图）都是<strong>串联的结构</strong>，即将一系列的卷积层和池化层进行串联得到的结构。</p>
<p><img src="/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/VGG%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="VGG网络架构图"></p>
<h3 id="Inception原始结构">Inception原始结构</h3>
<p>GoogLeNet 提出了一种并联结构，下图是论文中提出的Inception原始结构，将特征矩阵<strong>同时输入到多个分支</strong>进行处理，并将输出的特征矩阵<strong>按深度进行拼接</strong>，得到最终输出。</p>
<p><img src="/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Inception%E7%BB%93%E6%9E%84%E5%88%9D%E5%A7%8B%E7%89%88%E6%9C%AC.png" alt="Inception结构初始版本"></p>
<p>在之前所讲的网络中，例如AlexNet和VGG，网络都是串行结构，将一系列的卷积层和最大池化下采样层进行串联得到一个网络结构。而GoogLeNet中的Inception结构是一个并行的结构。</p>
<p>也就是说，在上一层输入之后，将得到的特征矩阵同时输入到四个分支当中进行处理，处理之后将得到的四个分支的特征矩阵按深度进行拼接，得到输出特征矩阵。</p>
<p>在特征分支中，分别为大小是1*1、3*3、5*5的卷积核和大小为3*3的池化核，通过这四个分支能得到不同尺度的特征矩阵。<strong>注意：每个分支所得的特征矩阵高和宽必须相同</strong>，否则无法延深度方向进行拼接。</p>
<h3 id="Inception结构（降维功能）">Inception结构（降维功能）</h3>
<p>在 Inception 的基础上，还可以加上降维功能的结构，如下图所示，在原始 Inception 结构的基础上，在分支2，3，4上加入了<strong>卷积核大小为1x1的卷积层</strong>，目的是为了降维（减小深度），减少模型训练参数，减少计算量。</p>
<p><img src="/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E5%8A%A0%E4%B8%8A%E9%99%8D%E7%BB%B4%E5%8A%9F%E8%83%BD%E7%9A%84Inception%E7%BB%93%E6%9E%84.png" alt="加上降维功能的Inception结构"></p>
<h3 id="1-1卷积核的降维功能">1*1卷积核的降维功能</h3>
<p><img src="/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E9%99%8D%E7%BB%B4%E5%9B%BE%E7%A4%BA.png" alt="降维图示"></p>
<p>假设有一个深度为512的特征矩阵</p>
<p>当不使用1*1的卷积核降维，直接使用64个5*5的卷积核进行卷积的话，需要用到的参数个数：5*5*512*64 = 819200</p>
<p>当先使用24个卷积核大小1*1的卷积核进行卷积时，得出的特征矩阵深度会由原先的512变为24（<strong>由输入的卷积核的个数决定的</strong>），之后再使用64个卷积核大小为5*5的卷积核进行卷积，需要用到的参数个数：1*1*512*24 + 5*5*24*64 = 12288+38400 = 50688。</p>
<p>因此，在添加了3个卷积核大小为1*1的卷积核进行卷积之后，能对特征矩阵进行降维，减少特征矩阵的深度，从而减少所需的卷积参数，也就减少了计算量。</p>
<p>注：<strong>CNN参数个数 = 卷积核尺寸×卷积核深度 × 卷积核组数 = 卷积核尺寸 × 输入特征矩阵深度 × 输出特征矩阵深度</strong></p>
<h2 id="辅助分类器（Auxiliary-Classifier）">辅助分类器（Auxiliary Classifier）</h2>
<p>AlexNet 和 VGG 都只有1个输出层，GoogLeNet 有3个输出层，其中的两个是辅助分类层。如下图所示，网络主干右边的两个分支 就是辅助分类器，其结构一模一样。</p>
<p>网络中的两个辅助分类器分别来自于4a和4d，对照参数表中的数据，4a的特征矩阵输出尺寸为14*14*512，4d输出的特征矩阵的尺寸为14*14*528，这两个特征矩阵高度和宽度都一样，只有深度不同。</p>
<p><img src="/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E8%BE%85%E5%8A%A9%E5%88%86%E7%B1%BB%E5%99%A8.png" alt="辅助分类器"></p>
<p>在训练模型时，将两个辅助分类器的损失乘以权重（论文中是0.3）加到网络的整体损失上，再进行反向传播。</p>
<p>辅助分类器的两个分支有什么用呢？</p>
<ul>
<li>可以把他看做Inception网络中的一个小细节，它确保了即便是隐藏单元和中间层也参与了特征计算，他们也能预测图片的类别，他在Inception网络中起到一种调整的效果，并且能防止网络发生过拟合。</li>
<li>给定深度相对较大的网络，有效传播梯度反向通过所有层的能力是一个问题。通过将辅助分类器添加到这些中间层，可以期望较低阶段分类器的判别力。在训练期间，它们的损失以折扣权重（辅助分类器损失的权重是0.3）加到网络的整个损失上。</li>
</ul>
<p><img src="/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/GoogLeNet%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.png" alt="GoogLeNet网络架构"></p>
<h2 id="GoogLeNet-网络参数">GoogLeNet 网络参数</h2>
<p><img src="/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/GoogLeNet%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0.png" alt="GoogLeNet网络参数"></p>
<p>对于Inception模块，所需要使用到参数有<code>#1x1</code>, <code>#3x3reduce</code>, <code>#3x3</code>, <code>#5x5reduce</code>, <code>#5x5</code>, <code>poolproj</code>，这6个参数，分别对应着所使用的卷积核个数。</p>
<p><img src="/2023/05/09/GoogLeNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/inception%E5%8D%B7%E7%A7%AF%E6%A0%B8%E4%B8%AA%E6%95%B0.png" alt="Inception卷积核个数"></p>
<ul>
<li><code>#1x1</code>对应着分支1上1x1的卷积核个数</li>
<li><code>#3x3reduce</code>对应着分支2上1x1的卷积核个数</li>
<li><code>#3x3</code>对应着分支2上3x3的卷积核个数</li>
<li><code>#5x5reduce</code>对应着分支3上1x1的卷积核个数</li>
<li><code>#5x5</code>对应着分支3上5x5的卷积核个数</li>
<li><code>poolproj</code>对应着分支4上1x1的卷积核个数。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>GoogLeNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十一）ResNeXt网络结构</title>
    <url>/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<p>本堂课讲述根据ResNet网络之后再次升级的ResNeXt网络，对原先ResNet的一些地方做了优化处理，原论文：<a href="https://arxiv.org/abs/1611.05431">img Transformations for Deep Neural Networks</a></p>
<h1>ResNet和ResNeXt的比较</h1>
<img src="/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/50层以上的ResNet和50层以上的ResNeXt残差比较.png" alt="50层以上的ResNet和50层以上的ResNeXt残差比较 " style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p>上图（左）是在ResNet网络中提到的<strong>实线型残差结构</strong>，在主分支中先对channel为256的特征矩阵<strong>降维</strong>到64，之后用3x3的卷积层进行<strong>卷积处理</strong>，再通过1x1的卷积核<strong>升维</strong>到256，以此来减少参数，最后将得到的特征矩阵与shortcut的特征矩阵相加得到输出特征矩阵</p>
<p>在ResNeXt网络中，使用上图（右）的结构替代上图（左）的结构，经下图展示，替换之后的ResNeXt网络结构确实比原先的ResNet在各性能上更优秀</p>
<img src="/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/ResNet和ResNeXt性能对比.png" style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p>下图（左）是ResNet-50与ResNeXt-50在ImageNet上top-1的错误率比较，在对焦验证集中ResNet-50val（蓝色）和ResNeXt-50val（橙色）两条实线的错误率比较，明显的是在计算量相同的情况下，RexNeXt-50比ResNet-50的错误率更低。</p>
<p>下图（右）是ResNet-101与ResNeXt-101在ImageNet上top-1的错误率比较，与50层类似，在计算量相同的情况下，RexNeXt-101比ResNet-101的错误率更低。</p>
<img src="/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/ResNet和ResNeXt的对比.png" alt="ResNet和ResNeXt的对比" style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>Group Convolution对比Convolution</strong></p>
<img src="/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/GroupConvolution解释.png" alt="Group Convolution解释" style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>Convolution</strong></p>
<blockquote>
<p>假设输入特征矩阵size = k x k，channel = 4，那么此时对于每一个卷积核的channel要与输入特征矩阵的channel保持一致，所以卷积核的channel = 4。假设输出特征矩阵channel = n，表示需要输入n个卷积核来进行卷积处理。</p>
<p>综上，需要使用到的参数Parameters = k x k x $C_{in}$ x n（$C_{in}$表示输入特征矩阵的channel，n表示使用卷积核的个数）</p>
</blockquote>
<p><strong>Group Convolution</strong></p>
<blockquote>
<p>假设输入特征矩阵size = k x k，channel = 4，将输入特征矩阵的channel划分为两个组，之后对每一个组分别进行卷积操作。假设对划分的一个组而言，所采用的卷积核的channel要与该组的channel保持一致，因此卷积核channel = 4 / 2 = 2。假设输出特征矩阵channel = n，则经过分成两组之后，其中一组的channel = n / 2，表示需要输入n / 2个卷积核来进行卷积处理。</p>
<p>综上，需要使用到的参数Parameters = ( k x k x $C_{in}$/g x n/g ) / g = k x k x $C_{in}$ x n x 1/g（$C_{in}$表示输入特征矩阵的channel，n表示使用卷积核的个数，g表示分了多少个组）</p>
</blockquote>
<p>注意：<strong>当g = $C_{in}$，n = $C_{in}$，此时就是DW Conv（深度卷积depthwise conv），相当于对输入特征矩阵的每个channel分配了一个channel为1的卷积核进行卷积</strong></p>
<h1>ResNeXt的创新点</h1>
<h2 id="提出Block模块">提出Block模块</h2>
<p>在原论文中，作者提出以下a、b、c三种block模块，它们在数学计算上完全等价</p>
<img src="/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/Block模块.png" alt="Block模块" style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>（c）block模块</strong></p>
<blockquote>
<p>首先通过1 x 1的卷积层进行降维处理，在经过Group Conv进行处理，且卷积核size = 3 x 3，group = 32，之后再通过1 x 1的卷积核进行升维处理，最后将输出与shortcut的输出相加，得到最终输出特征矩阵</p>
</blockquote>
<p><strong>（b）block模块</strong></p>
<blockquote>
<p>通过32个分支进行处理（total 32 paths），对于每个分支都首先采用1 x 1的卷积核进行降维处理，每一个分支都将特征矩阵从channel = 256降维到channel = 4，因分支 = 32，所以<strong>实际上通过这一层的降维处理之后，总体channel = 4 x 32 = 128，同（c）的第一步处理一致</strong>；</p>
<p>之后对每个分支的特征矩阵进行3 x 3的卷积核进行卷积处理，处理之后再通过concatenate拼接，再通过1 x 1的卷积核进行升维处理，最后将输出与shortcut的输出相加，得到最终输出特征矩阵</p>
</blockquote>
<p><strong>（a）block模块</strong></p>
<blockquote>
<p>通过32个分支进行处理（total 32 paths），对于每个分支都首先采用1 x 1的卷积核进行降维处理，每一个分支都将特征矩阵从channel = 256降维到channel = 4；之后对每个分支的特征矩阵进行3 x 3的卷积核进行卷积处理；</p>
<p>然后通过1 x 1的卷积核将特征矩阵升维从channel = 4到channel = 256，之后进行相加，<strong>原理上同（b）的concatenate拼接之后得到的特征矩阵一致</strong>；</p>
<p>最后将输出与shortcut的输出相加，得到最终输出特征矩阵</p>
</blockquote>
<p><strong>（a）block模块的升维和相加步骤</strong></p>
<img src="/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/（a）虚线框图像解释.png" alt="（a）虚线框图像解释" style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224); ">
<blockquote>
<p>假设pants = 2，pants中采用数量为1的1 x 1的卷积核进行卷积。对这两个pants分别进行卷积之后会得到对应的feature map，再将二者的feature map进行相加，最终得到结果的feature map。</p>
</blockquote>
<p><strong>（b）block模块的concatenate步骤</strong></p>
<img src="/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/（b）虚线框图像解释.png" alt="（b）虚线框图像解释" style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224); ">
<blockquote>
<p>将按照pants = 2的feature map进行拼接，得到上图最左边的feature map，此处采用的kernel同样是1 x 1大小，且将对应的4个卷积核参数进行拼接，最终得到的feature map和前面（a）升维且相加之后的feature map的结果一致。</p>
</blockquote>
<h2 id="Block模块仅适用层结构≥3">Block模块仅适用层结构≥3</h2>
<p>对于浅层的18、34层，其Inception的层级仅只有两层，搭建出来的block已经没有意义了。如果进行拆分之后再进行卷积，再进行相加的话，其实并未产生实质的变化，只不过卷积的个数变多了。</p>
<img src="/2023/05/17/ResNeXt%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/Block模块仅适用≥3层的层结构.png" alt="Block模块仅适用≥3层的层结构" style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h1>总结</h1>
<p>本次论文最大创新点就是提出Block模块，再次提高了整体网络的性能。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>ResNeXt</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（九）ResNet网络结构、BN以及迁移学习详解</title>
    <url>/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1>ResNet详解</h1>
<p>ResNet在2015年由微软实验室提出，斩获当年ImageNet竞赛中分类任务第一名，目标检测第一名。获得COCO数据集中目标检测第一名，图像分割第一名（超级NB）。原论文：<a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></p>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/ResNet-34%E5%B1%82%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="ResNet-34层网络结构图"></p>
<h2 id="网络中的创新点">网络中的创新点</h2>
<ul>
<li>超深的网络结构（突破1000层）</li>
<li>提出residual模块（残差模块，因为有了残差模块，才能够搭建层数很深的网络）</li>
<li>使用Batch Normalization加速训练（丢弃dropout）</li>
</ul>
<p>卷积层和池化层不断叠加是否都会导致准确率不断提高？</p>
<p>下图（左）通过简单将卷积层和池化层进行堆叠所搭建的网络结构，橙黄色曲线表示20层的网络结构，最终的训练错误率在[1%, 2%]，红色区县表示56层网络结构，最终的训练错误率在[7%, 8%]，很明显，当仅仅通过简单的把卷积层和最大池化下采样层堆叠网络，并不代表层数越深效果越好。</p>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/%E5%B1%82%E6%95%B0%E5%8A%A0%E6%B7%B1%E5%AF%BC%E8%87%B4%E5%87%86%E7%A1%AE%E7%8E%87%E5%8F%98%E5%8C%96%E6%83%85%E5%86%B5.png" alt="层数加深导致准确率变化情况"></p>
<p>那么是什么原因导致更深的网络造成效果越差呢？</p>
<p>在ResNet论文中，作者给出以下两个结论：</p>
<ul>
<li>梯度消失或梯度爆炸</li>
<li>退化问题（degradation problem）</li>
</ul>
<h3 id="梯度消失或梯度爆炸"><strong>梯度消失或梯度爆炸</strong></h3>
<p>随着网络层级越来越深，梯度消失或梯度爆炸的现象会越来越明显。</p>
<blockquote>
<p>假设每一层误差梯度小于1，那么在反向传播过程中，每向前传播一次，都要乘以这个小于1的系数。当网络越来越深的时候，所乘的小于1的系数越多，那么这个数越趋近于0，梯度就会越来越小，这就是所说的梯度消失现象。</p>
<p>反过来，当每一层误差梯度是一个大于1的数，那么在反向传播过程中，每向前传播一次，都要乘以这个大于1的系数。当网络越来越深的时候，梯度就会越来越大，这就是所说的梯度爆炸现象。</p>
</blockquote>
<p><strong>如何解决梯度消失/爆炸</strong>：通常对数据进行标准化处理、权重初始化、以及这堂课将会讲述的<strong>Batch Normalization标准化处理</strong>来解决</p>
<h3 id="退化问题">退化问题</h3>
<p>在解决了梯度消失或梯度爆炸的问题之后，可能仍然会出现层数深的没有层数小的效果好的问题。也就是网络越深反而识别错误率提高的现象。</p>
<p><strong>那该如何来解决提到的退化问题呢？</strong></p>
<p>在ResNet论文当中，作者提到一个名为<strong>残差的结构</strong>，通过残差结构，即能解决退化问题</p>
<p>上图（右）就是在原论文中所搭建的一系列网络，里面有20、32、44、56、110层的网络。其中实线代表验证集的错误率变化情况，虚线代表测试集的错误率变化情况（主要看验证集中的错误率）</p>
<p>在图中，随着层数的加深，错误率越小，效果越好。对比图左，ResNet确实解决了文中所提到的退化问题，因此，我们即可以使用文中提到的残差结构来不断加深网络，以获得更好的结果</p>
<h2 id="residual模块（残差结构）">residual模块（残差结构）</h2>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/residual%E7%BB%93%E6%9E%84.png" alt="residual结构"></p>
<h3 id="图形结构对比">图形结构对比</h3>
<p>图中代表着两种不同的残差结构，左边的结构主要针对网络层数较少的结构，对应的是32层的网络结构；右边的结构对应的是50、101、152层的网络结构。</p>
<p>左边结构的主分支，将输入特征矩阵通过2个3×3的卷积层得到结果，右边有一个弧线，直接从输入连接到输出，并在输出点有个+符号。意思是：<strong>在主分支上通过一系列卷积层之后所得到的特征矩阵，再与输入特征矩阵进行相加，相加之后再通过ReLU激活函数</strong>。且在主分支上，第一次卷积层之后通过ReLU激活函数激活，但第二层是在与输入特征矩阵相加之后，再通过ReLU激活函数激活的。</p>
<p><strong>注意：主分支与侧分支（shortcut）的输出特征矩阵中shape必须相同</strong></p>
<p>右边结构的主分支，将输入特征矩阵先通过1×1卷积层，再通过3×3的卷积层，最后通过1×1的卷积层之后，与侧分支的输入特征矩阵进行相加，最终得出结果。</p>
<p>相比左边的结构，是在输入及输出分别加入一个1×1的卷积层，目的是用来降维和升维</p>
<blockquote>
<p>在结构中，输入深度为256的特征矩阵，通过1×1卷积层，高宽不变，深度由256变为64，因此第一个卷积层是起到降维的作用。再通过一个3×3卷积层，之后再经过1×1卷积层，高宽不变，深度由64变为256，因此这一个卷积层是起到升维的作用。</p>
</blockquote>
<h3 id="使用参数对比">使用参数对比</h3>
<p>左侧residual结构所需参数：3 × 3 × 256 × 256 + 3 × 3 × 256 × 256 = 1,179,648</p>
<p>右侧residual结构所需参数：1 × 1 × 256 × 64 + 3 × 3 × 64 × 64 + 1 × 1 × 64 × 256 = 69,632</p>
<p>使用的残差结构越多，减少的参数也就越多</p>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/%E5%8E%9F%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8.png" alt="原论文中的参数列表"></p>
<p>上图是原论文给出的不同深度的ResNet网络结构配置，代表着在不同层数下的参数列表，所对应的是18、34、50、101、152层的网络结构。注意表中的残差结构给出了主分支上卷积核的大小与卷积核个数，表中 残差块×N 表示将该残差结构重复N次。</p>
<p>图中显示，这几个网络框架是一致的，同样是通过1个7X7的卷积层，再通过3X3的最大池化下采样层，再分别通过一系列残差结构，最后再接1个平均池化下采样层以及全连接层输出，softmax将输出转化为概率分布。</p>
<h3 id="降维时的shortcut">降维时的shortcut</h3>
<h4 id="34层残差结构">34层残差结构</h4>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/residual%E4%B8%AD%E5%AE%9E%E8%99%9A%E7%BA%BF%E7%9A%84%E5%8C%BA%E5%88%AB-34%E5%B1%82.png" alt="residual中实虚线的区别-34层"></p>
<p>经过对 ResNet34层网络的观察，可以发现有些残差块的shortcut是实线的，而有些则是虚线的。这二者间有什么区别呢？</p>
<p>对于上图左两层3X3卷积层的残差结构来说，输入特征矩阵深度和输出特征矩阵的shape是一致的，所以能够直接进行相加。但是对于上图右虚线的残差结构来说，其输入和输出的shape是不一致的。</p>
<p>上图右对应到参数表中，是ResNet-34层conv3.x第一层，输入特征矩阵shape是[56, 56, 64]，输出特征矩阵shape是[28, 28, 128]</p>
<p><strong>只有通过虚线残差结构，得到输出之后输入到实线对应的残差结构当中，才能够保证输入特征矩阵和输出特征矩阵的shape保持一致。</strong></p>
<h4 id="更高层的残差结构">更高层的残差结构</h4>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/residual%E4%B8%AD%E5%AE%9E%E8%99%9A%E7%BA%BF%E7%9A%84%E5%8C%BA%E5%88%AB-%E6%9B%B4%E9%AB%98%E5%B1%82.png" alt="residual中实虚线的区别-更高层"></p>
<p>上图右虚线对应的参数，也就是参数表中conv3.x对应的一系列残差结构：50,101,152层。输入特征矩阵的shape是[56, 56, 256],输出特征矩阵的shape是[28, 28, 512]</p>
<blockquote>
<p>对于主分支而言，stride=1，所以第一层1X1卷积层只起到降维的作用，不改变高宽，将深度从256改为128；在第二层stride=2，（ 56 - 3 + 1 ）/ 2 + 1 = 28，所以第二层3X3卷积层将特征矩阵的高宽缩减为原本的一半，深度不变；第三层stride=1，所以第三层1X1卷积层只起到升维的作用，不改变高宽，将深度从128升到512。</p>
<p>对于shortcut分支，仅使用1X1，深度为512，stride = 2的卷积层对输入特征矩阵起到升维且改变高宽的目的。深度1X1，将深度从256改为512；stride = 2，将输入特征矩阵高宽56，改为28。<br>
$$<br>
N = （ W-F+2P ）/S+1<br>
$$</p>
</blockquote>
<p>原论文中，作者对于残差结构的shortcut有optionA、B、C三个方法，但作者通过一系列对比之后，得出optionB方法效果最好。</p>
<p>由此得知，虚线残差结构有一个额外的作用，<strong>就是将输入特征矩阵的shape与输出特征矩阵的shape保持一致（变化高宽深）</strong>，而在实线中，输入和输出特征矩阵的shape是完全无变化的</p>
<p>所以在参数表中，50层及以上的深层网络结构，<strong>conv3、conv4、conv5所对应的一系列残差结构的第一层都是虚线残差结构</strong>。因为第一层需要将上一层输出的特征矩阵的高宽深度调整为当前层所需要的特征矩阵的高宽深度。<strong>在conv2中，仅仅改变了深度（所以用的还是实线）</strong></p>
<h2 id="Batch-Normalization标准化处理">Batch Normalization标准化处理</h2>
<p>老师博客：<a href="https://blog.csdn.net/qq_37541097/article/details/104434557">Batch Normalization详解以及pytorch实验</a></p>
<p>Batch Normalization是google团队在2015年论文<a href="https://arxiv.org/abs/1502.03167">《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》</a>提出的。通过该方法能够加速网络的收敛并提升准确率。本文主要分为以下几个部分：</p>
<ul>
<li>BN的原理</li>
<li>使用pytorch验证本文的观点</li>
<li>使用BN需要注意的地方（BN没用好就是个坑）</li>
</ul>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/Batch-Normalization.png" alt="Batch Normalization"></p>
<h3 id="BN原理">BN原理</h3>
<p>在之前搭建网络过程中，通常第一步会对图像进行标准化处理，也就是将图像数据调整到满足某分布规律，这样能够加速网络的收敛。如下图所示，对于conv1而言，输入的就是经过预处理之后满足某分布规律的特征矩阵，但对于conv2而言，输入的feature map就不一定满足某分布规律了，而Batch Normalization目的即是使feature map满足均值为0，方差为1的分布规律。</p>
<p><strong>注意：Batch Normalization的目的是使我们的一批（Batch）feature map满足均值为0，方差为1 分布规律，并不指某一个feature map</strong></p>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/BN%E5%8E%9F%E7%90%86%E5%9B%BE.png" alt="BN原理图"></p>
<p>原论文中有一句：“对于一个拥有d维的输入x，我们将对它的每一个维度进行标准化处理。”</p>
<blockquote>
<p>假设我们输入的x是RGB三通道的彩色图像，那么这里的d就是输入图像的channels即d=3，$x=(x^{(1)}+x^{(2)}+x^{(3)})$，$x^{(1)}$代表我们的R通道所对应的特征矩阵，依此类推。标准化处理也就是<strong>分别</strong>对R通道，G通道，B通道进行处理。</p>
</blockquote>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/%E5%85%AC%E5%BC%8F.png" alt="原论文公式"></p>
<p>γ主要调整数据方差的大小，β主要调整这批数据均值的大小（是否处于中心），如果不通过γ和β进行调整，那么得到的数据是均值为0方差为1的数据分布规律。<strong>γ和β是通过反向传播去学习得到的，均值和方差是根据一批批的数据统计得到的</strong></p>
<p>γ初始值为1，β初始值为0</p>
<p>示例如下</p>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/BN%E6%A0%87%E5%87%86%E5%8C%96%E5%8E%9F%E7%90%86%E7%A4%BA%E4%BE%8B.png" alt="BN标准化原理示例"></p>
<p>上图展示了一个batch size为2（两张图片）的Batch Normalization的计算过程。</p>
<blockquote>
<p>假设feature1、feature2分别是由image1、image2经过一系列卷积池化后得到的特征矩阵，feature的channel为2，那么$x^{(1)}$代表该batch的所有feature的channel1的数据，即$x^{(1)}$={1，1，1，2，0，-1，2，2}，$x^{(2)}$同理。</p>
<p><strong>注意：最终所得到的均值和方差是一个向量，其向量的长度即为特征矩阵的深度</strong></p>
</blockquote>
<h3 id="使用BN需要注意的问题">使用BN需要注意的问题</h3>
<ul>
<li>
<p>训练时要将traning参数设置为True，在验证时将trainning参数设置为False。在pytorch中可通过创建模型的model.train()和model.eval()方法控制。</p>
</li>
<li>
<p>batch size尽可能设置大点，设置小后表现可能很糟糕，设置的越大求的均值和方差越接近整个训练集的均值和方差。</p>
</li>
<li>
<p>建议将bn层放在卷积层（Conv）和激活层（例如Relu）之间，且卷积层不要使用偏置bias，因为没有用，参考下图推理，即使使用了偏置bias求出的结果也是一样的$y^b_i=y_i$</p>
</li>
</ul>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/%E4%BD%BF%E7%94%A8bias%E5%92%8C%E4%B8%8D%E4%BD%BF%E7%94%A8bias%E6%95%88%E6%9E%9C%E4%B8%80%E8%87%B4.png" alt="使用bias和不使用bias效果一致"></p>
<h1>迁移学习简介</h1>
<p>迁移学习是一个比较大的领域，我们这里说的迁移学习是指神经网络训练中使用到的迁移学习。</p>
<p>如下图所示，神经网络逐层提取图像的深层信息，这样，预训练网络就相当于一个特征提取器。</p>
<p>迁移学习，即将学习好了的浅层网络的一些参数，迁移到新的网络当中，这一新的网络中也具备识别底层通用特征的能力了。当新网络拥有了底层通用特征检测识别能力之后，就能更快速去学习新的数据集的高维特征。</p>
<p><img src="/2023/05/11/ResNet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8CBN%E4%BB%A5%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AF%A6%E8%A7%A3/%E7%AE%80%E5%8D%95%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.png" alt="简单的网络模型"></p>
<p>使用迁移学习的优势</p>
<ul>
<li>能够快速的训练出一个理想的结果</li>
<li>当数据集较小时也能训练出理想的效果</li>
</ul>
<p><strong>注意：使用别人预训练模型参数时，要注意别人的预处理方式</strong></p>
<p>常见的迁移学习方式：</p>
<ul>
<li>载入权重后训练所有参数（准确率最高，需要参数最多，硬件要求最高，时间最长）</li>
<li>载入权重后只训练最后几层参数</li>
<li>载入权重后在原网络基础上再添加一层全连接层，仅训练最后一个全连接层</li>
</ul>
<h1>总结</h1>
<p>本节课程讲解ResNet网络结构，针对残差结构做了详细讲解、讲解Batch Normalization标准化处理过程以及迁移学习内容介绍，下节课将会使用pytorch搭建ResNet网络结构。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>ResNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（五）VGG网络详解及感受野的计算</title>
    <url>/2023/05/04/VGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E5%8F%8A%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<p>VGG在2014年由牛津大学著名研究组VGG(Visual GeometryGroup)提出，斩获该年ImageNet竞赛中 Localization Task(定位任务)第一名和 classification Task(分类任务)第二名。</p>
<p>VGG原论文：VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION</p>
<h1>VGG知识介绍</h1>
<p>下图中显示了6个VGG网络的配置，6个配置中作者尝试了不同深度、是否使用LRN，以及卷积核大小为1为3的效果。实际使用过程中，我们常常使用D配置：一共有16层，其中包括13个卷积层，3个全连接层。</p>
<img src="/2023/05/04/VGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E5%8F%8A%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E8%AE%A1%E7%AE%97/VGG网络架构表.png" style="zoom:80%;">
<h2 id="网络的亮点">网络的亮点</h2>
<ul>
<li>通过堆叠多个3×3的卷积核来替代大尺度卷积核（为了减少所需的参数）</li>
</ul>
<p>论文内提到，可以通过堆叠两个3×3的卷积核替代一个5×5的卷积核，堆叠三个3×3的卷积核替代一个7×7的卷积核（拥有相同的感受野）</p>
<h2 id="什么是感受野">什么是感受野</h2>
<p>在卷积神经网络中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野（receptive filed）。通俗解释是：输出feature map上的一个单元对应输入层上的区域大小</p>
<img src="/2023/05/04/VGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E5%8F%8A%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E8%AE%A1%E7%AE%97/感受野.png" style="zoom: 50%;">
<p>例子如图所示，最下面是一个9 × 9 × 1的特征矩阵，首先通过卷积层Conv1（卷积核大小3 × 3，步距为2），通过下方的计算公式：（ 9 - 3 + 0 ）/ 2 + 1 = 4，因此得到第二层的特征矩阵大小为4 × 4 × 1；再通过最大池化下采样层MaxPool1（池化核大小2 × 2，步距为2），通过下方计算公式：（ 4 - 3 + 1 ）/ 2 + 1 = 2，因此得到第三层的特征矩阵大小为2 × 2 × 1。</p>
<p>\begin{flalign}<br>
out_{size} = (in_{size} - F_{size} + 2P)/S + 1<br>
\end{flalign}</p>
<p>那么，在第三层特征层当中的一个单元，在第二层中对应的一个感受野是2 × 2的区域，在第三层图中显示是一个5 × 5的感受野大小。</p>
<h2 id="如何计算感受野？">如何计算感受野？</h2>
<ul>
<li>F（ i ）：第 i 层感受野；</li>
<li>Stride：第 i 层的步距；</li>
<li>Ksize：卷积核或采样核尺寸</li>
</ul>
<img src="/2023/05/04/VGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E5%8F%8A%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E8%AE%A1%E7%AE%97/感受野的计算.png" style="zoom:80%;">
<p>论文内提到，可以通过堆叠两个3×3的卷积核替代一个5×5的卷积核，堆叠三个3×3的卷积核替代一个7×7的卷积核</p>
<p>注意：在VGG网络中，卷积层的步距默认为1</p>
<p>假设：一个特征矩阵通过3 × 3 × 3的卷积层后，所得到的Feature map，Feature map上的一个单位对应上一层的感受野为（ 1 - 1 ）× 1 + 3 = 3；如果再计算上上一层的感受野为（ 3 - 1 ）× 1 + 3 = 5；如果再计算上上上层的感受野为（ 5 - 1 ）× 1 + 3 = 7</p>
<p>也就是说，<strong>我们通过3 × 3 × 3的卷积核卷积之后所得到的的特征矩阵上的一个单位在原图上对应的感受野相当于是一个7 × 7的大小，那么也就与采用一个7 × 7的卷积核的大小所得到的的感受野是相同的</strong></p>
<p>因此，<strong>当我们使用多个小的卷积核去堆叠就可以去替代一个大的卷积核，目的是为了节省网络训练参数的个数</strong></p>
<h2 id="7-×-7卷积核和3-×-3-×-3所需参数对比">7 × 7卷积核和3 × 3 × 3所需参数对比</h2>
<p>假设输入输出channel为C，下方两个C分别表示卷积核的深度和组数</p>
<p>7 × 7卷积核所需参数 ：7 × 7 × C × C = 49CC</p>
<p>3 × 3 × 3卷积核所需参数 ：3 × 3 × C × C <strong>+</strong> 3 × 3 × C × C <strong>+</strong> 3 × 3 × C × C = 27CC</p>
<h1>VGG网络架构</h1>
<ul>
<li>input：224*224的RGB图片</li>
<li>通过2层3 × 3的卷积层、1层最大下采样池化层</li>
<li>再通过2层3 × 3的卷积层、1层最大下采样池化层</li>
<li>再通过3层3 × 3的卷积层、1层最大下采样池化层</li>
<li>再通过3层3 × 3的卷积层、1层最大下采样池化层</li>
<li>再通过3层3 × 3的卷积层、1层最大下采样池化层</li>
<li>连接3个全连接层</li>
<li>经过soft-max处理得到概率分布</li>
</ul>
<img src="/2023/05/04/VGG%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3%E5%8F%8A%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E8%AE%A1%E7%AE%97/VGG网络架构图.png" style="zoom:80%;">
<p>补充参数：</p>
<ul>
<li>表中的卷积核：默认stride为1、padding为1**（这样通过一个3 × 3的卷积核进行卷积之后，其输入输出的特征矩阵的高度和宽度不变）**。公式计算得证：（ 3 - 3 + 2 ）/ 1 + 1 = 3</li>
<li>最大下采样池化核：默认size为2、stride为2**（相当于将特征矩阵的高宽缩小为原来的一半）**</li>
</ul>
<p>对照左边的图，进行更直观的理解</p>
<p>左边的图形，是根据右表中D模型进行绘制。图中黑色框代表：卷积层+激活函数；红色框代表：最大下采样操作；蓝色框代表：全连接层+激活函数；橙色框代表：softmax处理</p>
<ol>
<li>首先，输入224×224×3的RGB彩色图像；</li>
<li>通过两层3×3的卷积核之后，得到224×224×64特征矩阵大小（stride为1、padding为1——长宽不变；表中标注conv3-64——采用卷积核个数为64，因此输出深度也为64）；</li>
<li>紧接着进入到最大下采样操作， 将特征矩阵缩减为原来的一半，得到112×112×64特征矩阵大小；</li>
<li>通过两层3×3的卷积核之后（采用卷积核个数为128），得到112×112×128特征矩阵大小；</li>
<li>进入到最大下采样操作， 将特征矩阵缩减为原来的一半，得到56×56×128特征矩阵大小；</li>
<li>通过三层3×3的卷积核之后（采用卷积核个数为256），得到56×56×256特征矩阵大小；</li>
<li>进入到最大下采样操作， 将特征矩阵缩减为原来的一半，得到28×28×256特征矩阵大小；</li>
<li>通过三层3×3的卷积核之后（采用卷积核个数为512），得到28×28×512特征矩阵大小；</li>
<li>进入到最大下采样操作， 将特征矩阵缩减为原来的一半，得到14×14×512特征矩阵大小；</li>
<li>通过三层3×3的卷积核之后（采用卷积核个数为512），得到14×14×512特征矩阵大小；</li>
<li>进入到最大下采样操作， 将特征矩阵缩减为原来的一半，得到7×7×512特征矩阵大小；</li>
<li>进入全连接层，全连接层1和全连接层2所采用的节点个数都是4096，全连接层3有1000各节点，因为ImageNet的分类任务有1000个类别**（注意：最后一个全连接层不需要加ReLU激活函数，因为最后需要用到softmax函数来激活）**。</li>
<li>最后是一个softmax激活函数，将预测结果转化为概率分布</li>
</ol>
<h1>总结</h1>
<p>本节课主要讲解CGG16的网络结构，以及拓展感受野的知识点，下节课将会使用Pytorch去搭建VGG16网络。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>VGG</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2023/04/21/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="Quick-Start">Quick Start</h2>
<h3 id="Create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>Hello World</category>
      </categories>
      <tags>
        <tag>Hello</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十二）使用pytorch搭建ResNeXt并基于迁移学习训练</title>
    <url>/2023/05/21/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNeXt%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<h1>ResNet-50与ResNeXt-50（32x4d）</h1>
<img src="/2023/05/21/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNeXt%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/ResNet-50与ResNeXt-50（32x4d）参数.png" alt="ResNet-50与ResNeXt-50（32x4d）网络结构参数" style="border-width: 5px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<p>ResNet网络结构中的较深层结构（50层及以上结构）所采用的是上图（最左侧）的block结构，在ResNeXt网络结构中所对应采用的是上图（中间）的block结构。</p>
<p>区别在于结构显示中的第二层的3x3卷积层，对于普通的block结构（如最左侧），采用普通的3x3进行卷积，而对于ResNeXt的block（如中间），第二层是group conv。</p>
<p><strong>ResNet-50和ResNeXt结构</strong></p>
<blockquote>
<p><strong>相同点：</strong></p>
<ul>
<li>整体框架一致。首先经过一个7x7的卷积层将输入的特征矩阵深度从3变为64，高宽不变；之后经过3x3的最大池化下采样层，深度不变，高宽从112变为56；之后重复堆叠block，且堆叠次数一致，图中都是 [ 3，4，6，3 ]；之后是平均池化、全连接层，最后是softmax概率输出。</li>
<li><strong>在每一个网络结构相对应的block中，输出的特征矩阵的深度是一致的。</strong></li>
</ul>
<p><strong>不同点：</strong></p>
<p>以conv2为例，在ResNet网络结构中第一层采用1x1卷积层的个数是64，但在对应ResNeXt网络结构中的个数是普通block结构中采用卷积核个数的2倍，在下一层3x3的卷积层中，ResNet采用64个卷积核，而ResNeXt中分成了32group，每个group采用4个卷积核，所以ResNeXt第二层中采用128个卷积核。</p>
<p>因此，<strong>在每一层block结构中，ResNeXt的第1、2层的卷积核个数的都是ResNet中对应block层数的2倍。</strong></p>
</blockquote>
<h1>工程目录</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test5_resnext</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,resNext.pth）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	├── resnext50_32x4d.pth（用于迁移学习时，提前下载好官方的resNet权重脚本）</span><br><span class="line">	├── batch_predict.py（批量预测图片分类）</span><br><span class="line">	└── data</span><br><span class="line">		└── imgs（批量数据图片）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h1><a href="http://model.py">model.py</a></h1>
<h2 id="修改Bottleneck类">修改Bottleneck类</h2>
<p>在初始化函数中参数传递加入groups和width_per_group</p>
<ul>
<li>groups：分组数（例如上图中的32）</li>
<li>width_per_group：（例如上图conv2中的4：指每个group中卷积核的个数）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             groups=<span class="number">1</span>, width_per_group=<span class="number">64</span></span>):</span><br><span class="line">    <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line"></span><br><span class="line">    width = <span class="built_in">int</span>(out_channel * (width_per_group / <span class="number">64.</span>)) * groups</span><br><span class="line"></span><br><span class="line">    self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width,</span><br><span class="line">                           kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">    self.bn1 = nn.BatchNorm2d(width)</span><br><span class="line">    <span class="comment"># -----------------------------------------</span></span><br><span class="line">    self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups,</span><br><span class="line">                           kernel_size=<span class="number">3</span>, stride=stride, bias=<span class="literal">False</span>, padding=<span class="number">1</span>)</span><br><span class="line">    self.bn2 = nn.BatchNorm2d(width)</span><br><span class="line">    <span class="comment"># -----------------------------------------</span></span><br><span class="line">    self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel*self.expansion,</span><br><span class="line">                           kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">    self.bn3 = nn.BatchNorm2d(out_channel*self.expansion)</span><br><span class="line">    self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    self.downsample = downsample</span><br></pre></td></tr></table></figure>
<p>其中：当group和width_per_group采用默认值时，width输出值为out_channel。当采用ResNeXt结构时，以conv2为例，groups= 32，width_per_group = 128，则<strong>width = （ 4 * （ 128 / 64 ））* 32 = 256</strong>。</p>
<p>因此本句代码意义为<strong>在ResNeXt结构中，输出特征矩阵的channel是输入特征矩阵channel的2倍，因此可以通过本条语句，得出ResNet和ResNeXt网络结构在block中第1，2层卷积层所采用的卷积核的个数。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">width = <span class="built_in">int</span>(out_channel * (width_per_group / <span class="number">64.</span>)) * groups</span><br></pre></td></tr></table></figure>
<p>注意：在conv3中的out_channels=out_channel*self.expansion，以conv2为例，上一层out_channels = 64，因此在本语句中<strong>总体依旧是输出特征矩阵是上一层（block上一层）的4倍。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel*self.expansion,</span><br><span class="line">                           kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="实例化Bottleneck">实例化Bottleneck</h2>
<p>ResNet网络结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">resnet50</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet50-19c8e357.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], </span><br><span class="line">                  num_classes=num_classes, </span><br><span class="line">                  include_top=include_top)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet101</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet101-5d3b4d8f.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], </span><br><span class="line">                  num_classes=num_classes, </span><br><span class="line">                  include_top=include_top)</span><br></pre></td></tr></table></figure>
<p>ResNeXt网络结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">resnext50_32x4d</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth</span></span><br><span class="line">    groups = <span class="number">32</span></span><br><span class="line">    width_per_group = <span class="number">4</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">                  num_classes=num_classes,</span><br><span class="line">                  include_top=include_top,</span><br><span class="line">                  groups=groups,</span><br><span class="line">                  width_per_group=width_per_group)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnext101_32x8d</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth</span></span><br><span class="line">    groups = <span class="number">32</span></span><br><span class="line">    width_per_group = <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>],</span><br><span class="line">                  num_classes=num_classes,</span><br><span class="line">                  include_top=include_top,</span><br><span class="line">                  groups=groups,</span><br><span class="line">                  width_per_group=width_per_group)</span><br></pre></td></tr></table></figure>
<h2 id="修改ResNet类">修改ResNet类</h2>
<p>初始化函数及_make_layer函数的参数传递加入groups和width_per_group</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 block,</span></span><br><span class="line"><span class="params">                 blocks_num,</span></span><br><span class="line"><span class="params">                 num_classes=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 include_top=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 groups=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 width_per_group=<span class="number">64</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.include_top = include_top</span><br><span class="line">        self.in_channel = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.groups = groups</span><br><span class="line">        self.width_per_group = width_per_group</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, self.in_channel, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>,</span><br><span class="line">                               padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(self.in_channel)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">64</span>, blocks_num[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, blocks_num[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, blocks_num[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, blocks_num[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> self.include_top:</span><br><span class="line">            self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))  <span class="comment"># output size = (1, 1)</span></span><br><span class="line">            self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, channel, block_num, stride=<span class="number">1</span></span>):</span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.in_channel != channel * block.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(channel * block.expansion))</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.in_channel,</span><br><span class="line">                            channel,</span><br><span class="line">                            downsample=downsample,</span><br><span class="line">                            stride=stride,</span><br><span class="line">                            groups=self.groups,</span><br><span class="line">                            width_per_group=self.width_per_group))</span><br><span class="line">        self.in_channel = channel * block.expansion</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, block_num):</span><br><span class="line">            layers.append(block(self.in_channel,</span><br><span class="line">                                channel,</span><br><span class="line">                                groups=self.groups,</span><br><span class="line">                                width_per_group=self.width_per_group))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
<h1><a href="http://train.py">train.py</a></h1>
<p>修改调用model.py函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> resnext50_32x4d</span><br><span class="line">net = resnext50_32x4d()</span><br></pre></td></tr></table></figure>
<p>修改调用迁移学习权重路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_weight_path = <span class="string">&quot;./resnext50_32x4d.pth&quot;</span></span><br></pre></td></tr></table></figure>
<p>另：因为机器撑不住，所以我这把batch_size改为4</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                           batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=nw)</span><br><span class="line"></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>),</span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                              batch_size=<span class="number">4</span>, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                              num_workers=nw)</span><br></pre></td></tr></table></figure>
<h2 id="训练结果">训练结果</h2>
<p><img src="/2023/05/21/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNeXt%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/train%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="train训练结果"></p>
<h1><a href="http://predict.py">predict.py</a></h1>
<p>修改调用model.py函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> resnext50_32x4d</span><br><span class="line">model = resnext50_32x4d(num_classes=<span class="number">5</span>).to(device)</span><br></pre></td></tr></table></figure>
<p>修改使用权重路径（train.py中通过迁移学习产生的权重pth文件）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">weights_path = <span class="string">&quot;./resNext50.pth&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="预测结果">预测结果</h2>
<p><img src="/2023/05/21/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNeXt%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
<h1>批量预测batch_predict.py</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> resnext50_32x4d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="number">256</span>),</span><br><span class="line">         transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    <span class="comment"># 指向需要遍历预测的图像文件夹</span></span><br><span class="line">    imgs_root = <span class="string">&quot;data/imgs&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(imgs_root), <span class="string">f&quot;file: &#x27;<span class="subst">&#123;imgs_root&#125;</span>&#x27; dose not exist.&quot;</span></span><br><span class="line">    <span class="comment"># 读取指定文件夹下所有jpg图像路径</span></span><br><span class="line">    img_path_list = [os.path.join(imgs_root, i) <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(imgs_root) <span class="keyword">if</span> i.endswith(<span class="string">&quot;.jpg&quot;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">f&quot;file: &#x27;<span class="subst">&#123;json_path&#125;</span>&#x27; dose not exist.&quot;</span></span><br><span class="line"></span><br><span class="line">    json_file = <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>)</span><br><span class="line">    class_indict = json.load(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = resnext50_32x4d(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    weights_path = <span class="string">&quot;./resnext50.pth&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(weights_path), <span class="string">f&quot;file: &#x27;<span class="subst">&#123;weights_path&#125;</span>&#x27; dose not exist.&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(weights_path, map_location=device))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># prediction</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    batch_size = <span class="number">8</span>  <span class="comment"># 每次预测时将多少张图片打包成一个batch</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> ids <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(img_path_list) // batch_size):</span><br><span class="line">            img_list = []</span><br><span class="line">            <span class="keyword">for</span> img_path <span class="keyword">in</span> img_path_list[ids * batch_size: (ids + <span class="number">1</span>) * batch_size]:</span><br><span class="line">                <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">f&quot;file: &#x27;<span class="subst">&#123;img_path&#125;</span>&#x27; dose not exist.&quot;</span></span><br><span class="line">                img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">                img = data_transform(img)</span><br><span class="line">                img_list.append(img)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># batch img</span></span><br><span class="line">            <span class="comment"># 将img_list列表中的所有图像打包成一个batch</span></span><br><span class="line">            batch_img = torch.stack(img_list, dim=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># predict class</span></span><br><span class="line">            output = model(batch_img.to(device)).cpu()</span><br><span class="line">            predict = torch.softmax(output, dim=<span class="number">1</span>)</span><br><span class="line">            probs, classes = torch.<span class="built_in">max</span>(predict, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> idx, (pro, cla) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(probs, classes)):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;image: &#123;&#125;  class: &#123;&#125;  prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(img_path_list[ids * batch_size + idx],</span><br><span class="line">                                                                 class_indict[<span class="built_in">str</span>(cla.numpy())],</span><br><span class="line">                                                                 pro.numpy()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="批量预测结果">批量预测结果</h2>
<p><img src="/2023/05/21/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNeXt%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/%E6%89%B9%E9%87%8F%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="批量预测结果"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>ResNeXt</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之绪论</title>
    <url>/2023/04/22/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[<h1>第一章绪论</h1>
<h2 id="第一节基本概念">第一节基本概念</h2>
<p>数据：是信息的载体</p>
<p>数据对象：具有<strong>相同性质</strong>的数据元素的集合，是数据的一个子集</p>
<span id="more"></span>
<p>数据元素：是数据的<strong>基本单位</strong>，通常作为一个整体进行考虑和处理</p>
<p>数据项：是构成数据元素的不可分割的<strong>最小单位</strong></p>
<p>数据结构：是指相互之间存在<strong>一种或者多种特定关系</strong>的数据元素的集合</p>
<p>数据类型：原子类型（bool，int…）、结构类型（struct Coordinate{	int x; int y;}; ）</p>
<p>抽象数据类型（ADT）：抽象数据组织及与之相关的操作</p>
<h2 id="第二节三要素">第二节三要素</h2>
<h3 id="1-逻辑结构">1.逻辑结构</h3>
<p>集合结构：各个元素同属于一个集合，并无其他关系</p>
<p>线性结构：一对一关系，除第一个元素，所有元素都有唯一前驱；除最后一个元素，所有元素都有唯一后继</p>
<p>树形结构：一对多关系，例：思维导图、文件夹</p>
<p>网状结构：多对多关系，例：道路信息，朋友圈关系</p>
<h3 id="2-数据的运算">2.数据的运算</h3>
<p>——针对某种逻辑结构，结合实际需求，定义基本运算</p>
<h3 id="3-物理结构（存储结构）">3.物理结构（存储结构）</h3>
<p>——如何用计算机表示数据元素的逻辑关系</p>
<p>顺序存储：把<strong>逻辑上相邻的元素存储在物理位置上也相邻的存储单元</strong>中，元素之间的关系由存储单元的邻接关系来体现</p>
<p>链式存储：<strong>逻辑上相邻的元素在物理位置上可以不相邻</strong>，借助指示元素存储地址的<strong>指针</strong>来表示元素之间的逻辑关系</p>
<p>索引存储：在存储元素信息的同时，还建立附加的索引表。索引表中的每项称为索引项，索引项的一般形式是（关键字，地址）</p>
<p>散列存储：根据元素的关键字直接计算出该元素的存储地址，又称哈希（Hash）存储</p>
<p><em>小结：</em></p>
<p><em>1）若采用<strong>顺序存储</strong>，则各个数据元素在物理上必须是<strong>连续的</strong>；若采用<strong>非顺序存储</strong>，则各个数据元素在物理上可以是<strong>离散的</strong></em></p>
<p><em>2）数据的<strong>存储结构</strong>会<strong>影响存储空间分配的方便程度</strong></em></p>
<p><em>3）数据的<strong>存储结构</strong>会<strong>影响对数据运算的速度</strong>，例：在元素之间插入新元素</em></p>
<h2 id="第三节算法">第三节算法</h2>
<p>——是对特定问题求解步骤的一种描述</p>
<p>五个特性：有穷性、确定性、可行性、输入、输出</p>
<p>“好”算法的特性：正确性、可读性、健壮性、高效率和低存储量需求</p>
<h3 id="1-时间复杂度">1.时间复杂度</h3>
<p>——时间开销与问题规模n之间的关系</p>
<h3 id="2-空间复杂度">2.空间复杂度</h3>
<p>——空间开销（内存开销）与问题规模n之间的关系</p>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之树和二叉树</title>
    <url>/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E4%B8%83%E7%AB%A0%E6%95%B0%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
    <content><![CDATA[<h1>第七章树和二叉树</h1>
<h2 id="第一节树的概念">第一节树的概念</h2>
<h3 id="1-概念">1.概念</h3>
<p>​	是n（n≥0）个节点的有限集。当n=0时，称为空树。在任意一棵非空树中应满足：</p>
<ul>
<li>有且仅有一个特定的称为根的结点；</li>
<li>当n&gt;1时，其余结点可分为m（m＞0）个互不相交的有限集，其中每个集合本身又是一棵树，并且成为根的子树</li>
</ul>
<span id="more"></span>
<h3 id="2-特点">2.特点</h3>
<ul>
<li>树的根结点没有前驱，除根节点外的所有结点有且只有一个前驱；</li>
<li>树中所有结点可以由零个或多个后继</li>
</ul>
<h3 id="3-基本性质">3.基本性质</h3>
<p>\begin{flalign}<br>
&amp;1)树中的结点数等于所有结点的度数之和+1&amp;&amp;\<br>
&amp;2)度为m的树中第i层上至多有m^{i-1}个结点（i≥1）\<br>
&amp;3)高度为h的m叉树至多有(m^h-1)/(m-1)个结点\<br>
&amp;4)n结点m叉树最小高度为\lceil log_m[n(m-1)+1] \rceil \<br>
\end{flalign}</p>
<h3 id="4-存储结构">4.存储结构</h3>
<p>（1）双亲表示法</p>
<pre class="mermaid">graph TB;
R((R))
A((A))
B((B))
C((C))
D((D))
E((E))
F((F))
G((G))
H((H))
K((K))
R-->A
R-->B
R-->C
A-->D
A-->E
C-->F
F-->G
F-->H
F-->K</pre>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">data</th>
<th style="text-align:center">parent</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">R</td>
<td style="text-align:center">-1</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">A</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">B</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">C</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">D</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">E</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">F</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">G</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">H</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">K</td>
<td style="text-align:center">6</td>
</tr>
</tbody>
</table>
<p>（2）孩子表示法</p>
<p>将每个节点的孩子结点都用单链表链接起来形成一个线性结构，此时n个结点就有n个孩子链表（叶子结点链表为空表）；</p>
<p>这种存储方式寻找子女的操作非常直接，而寻找双亲的操作需要遍历n个结点中孩子链表指针域所指向的n个孩子链表。</p>
<p>（3）孩子兄弟表示法</p>
<p>优点：方便地实现树转换为二叉树的操作，易于查找结点的孩子等；</p>
<p>缺点：从当前结点查找其双亲结点比较麻烦</p>
<p>①在兄弟结点之间加一条线；</p>
<p>②对每个结点，只保留它与i一个孩子的连线，而与其他孩子 连线全部抹掉；</p>
<p>③以树根为轴心，顺时针旋转45°。</p>
<h3 id="5-树、森林与二叉树遍历的对应关系">5.树、森林与二叉树遍历的对应关系</h3>
<table>
<thead>
<tr>
<th style="text-align:center">树</th>
<th style="text-align:center">森林</th>
<th style="text-align:center">二叉树</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">先根遍历</td>
<td style="text-align:center">先序遍历</td>
<td style="text-align:center">先序遍历</td>
</tr>
<tr>
<td style="text-align:center">后根遍历</td>
<td style="text-align:center">中序遍历</td>
<td style="text-align:center">中序遍历</td>
</tr>
</tbody>
</table>
<h2 id="第二节二叉树">第二节二叉树</h2>
<h3 id="1-概念和性质">1.概念和性质</h3>
<h4 id="（1）概念">（1）概念</h4>
<p>​	 一棵二叉树是结点的一个有限集合，该集合：</p>
<ul>
<li>​    或者为空；</li>
<li>​    由一个根节点加上两棵别称为左子树和右子树的二叉树组成</li>
</ul>
<p>满二叉树：一个二叉树，如果每一个层的结点数都达到最大值，则这个二叉树就是满二叉树。</p>
<p>完全二叉树：效率很高的数据结构，由满二叉树而引出来的。是一种特殊的完全二叉树。</p>
<p>二叉排序树：左&lt;中&lt;右.</p>
<p>平衡二叉树：左子树与右子树深度之差不超过1。</p>
<h4 id="（2）性质">（2）性质</h4>
<p>\begin{flalign}<br>
&amp;1)n_0 = n_2 +1\<br>
&amp;2)非空二叉树上第k层至多有2^{k-1}个结点（k≥1）\<br>
&amp;3)高度为h的二叉树至少有2^h-1个结点（h≥1）\<br>
&amp;4)对完全二叉树按向上到下、从左到右的顺序依次编号1,2,…,n，则有以下关系：\<br>
&amp;~①当i&gt;1时，结点i的双亲的编号是\lfloor i/2 \rfloor，即当i为偶数时，其双亲的编号是i/2，它是双亲的左孩子。当i为奇数时，其双亲的编号是（i-1）/2，它是双亲的右孩子。\<br>
&amp;~②当2i≤n时，结点i的左孩子编号为2i，否则无左孩子。\<br>
&amp;~③当2i+1≤n时，结点i的右孩子编号为2i+1，否则无右孩子。\<br>
&amp;~④结点i所在层次（深度）为\lfloor log_2i \rfloor+1。\<br>
&amp;5)具有n个（n&gt;0）结点的完全二叉树的高度为\lceil log_2(n+1) \rceil 或\lfloor log_2n \rfloor +1。<br>
\end{flalign}</p>
<h3 id="2-存储结构和基本算法">2.存储结构和基本算法</h3>
<p>（1）顺序存储结构</p>
<p>（2）链式存储结构</p>
<table>
<thead>
<tr>
<th style="text-align:center">lchild</th>
<th style="text-align:center">data</th>
<th style="text-align:center">rchild</th>
</tr>
</thead>
</table>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">BiTree</span>&#123;</span></span><br><span class="line">	ElemType data;  <span class="comment">// 数据域</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">BiTree</span> *<span class="title">lchile</span>,*<span class="title">rchild</span>;</span> <span class="comment">// 左、右孩子指针</span></span><br><span class="line">&#125;BiTNode,*BiTree;</span><br></pre></td></tr></table></figure>
<h2 id="第三节二叉树的遍历算法">第三节二叉树的遍历算法</h2>
<h3 id="1-先序遍历">1.先序遍历</h3>
<p>递归算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PreOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(T)&#123;</span><br><span class="line">        <span class="built_in">visit</span>(T);		<span class="comment">//访问根结点</span></span><br><span class="line">        <span class="built_in">PreOrder</span>(T-&gt;lchild);	<span class="comment">//递归遍历左子树</span></span><br><span class="line">        <span class="built_in">PreOrder</span>(T-&gt;rchild);	<span class="comment">//递归遍历右子树</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>非递归算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PreOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="built_in">InitStack</span>(S);	BiTree p = T;	<span class="comment">//初始化栈；p是遍历指针</span></span><br><span class="line">    <span class="keyword">while</span>(p||!<span class="built_in">IsEmpty</span>(S))&#123;		<span class="comment">//栈不空或p不空时一直循环</span></span><br><span class="line">        <span class="keyword">if</span>(p)&#123;		<span class="comment">//一路向左</span></span><br><span class="line">            <span class="built_in">visit</span>(p);	<span class="built_in">Push</span>(S,p);	<span class="comment">//访问当前结点，并入栈</span></span><br><span class="line">            p = p-&gt;lchild;		<span class="comment">//左孩子不空，一直向左走</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;		<span class="comment">//出栈，并转向出栈结点的右子树</span></span><br><span class="line">            <span class="built_in">Pop</span>(S,p);				<span class="comment">//栈顶元素出栈</span></span><br><span class="line">            p = p-&gt;rchild;			<span class="comment">//向右子树走，p赋值为当前结点的右孩子</span></span><br><span class="line">        &#125;<span class="comment">//else</span></span><br><span class="line">    &#125;<span class="comment">//while</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-中序遍历">2.中序遍历</h3>
<p>递归算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">InOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(T)&#123;</span><br><span class="line">        <span class="built_in">InOrder</span>(T-&gt;lchild);	<span class="comment">//递归遍历左子树</span></span><br><span class="line">        <span class="built_in">visit</span>(T);		<span class="comment">//访问根结点</span></span><br><span class="line">        <span class="built_in">InOrder</span>(T-&gt;rchild);	<span class="comment">//递归遍历右子树</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>非递归算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">InOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="built_in">InitStack</span>(S);	BiTree p = T;	<span class="comment">//初始化栈；p是遍历指针</span></span><br><span class="line">    <span class="keyword">while</span>(p||!<span class="built_in">IsEmpty</span>(S))&#123;		<span class="comment">//栈不空或p不空时一直循环</span></span><br><span class="line">        <span class="keyword">if</span>(p)&#123;		<span class="comment">//一路向左</span></span><br><span class="line">            <span class="built_in">Push</span>(S,p);			<span class="comment">//当前结点入栈</span></span><br><span class="line">            p = p-&gt;lchild;		<span class="comment">//左孩子不空，一直向左走</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;		<span class="comment">//出栈，并转向出栈结点的右子树</span></span><br><span class="line">            <span class="built_in">Pop</span>(S,p);	<span class="built_in">visit</span>(p);	<span class="comment">//栈顶元素出栈，p赋值为当前结点的右孩子</span></span><br><span class="line">            p = p-&gt;rchild;			<span class="comment">//向右子树走，p赋值为当前结点的右孩子</span></span><br><span class="line">        &#125;<span class="comment">//else</span></span><br><span class="line">    &#125;<span class="comment">//while</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-后序遍历">3.后序遍历</h3>
<p>递归算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PostOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(T)&#123;</span><br><span class="line">       	<span class="built_in">PostOrder</span>(T-&gt;lchild);	<span class="comment">//递归遍历左子树</span></span><br><span class="line">        <span class="built_in">PostOrder</span>(T-&gt;rchild);	<span class="comment">//递归遍历右子树</span></span><br><span class="line">        <span class="built_in">visit</span>(T);		<span class="comment">//访问根结点</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>非递归算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PostOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="built_in">InitStack</span>(S);</span><br><span class="line">    BiTree p = T,r = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">while</span>(p||!<span class="built_in">IsEmpty</span>(S))&#123;</span><br><span class="line">        <span class="keyword">if</span>(p)&#123;		<span class="comment">//走到最左边</span></span><br><span class="line">            <span class="built_in">Push</span>(S,p);			<span class="comment">//当前结点入栈</span></span><br><span class="line">            p = p-&gt;lchild;		<span class="comment">//左孩子不空，一直向左走</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;		<span class="comment">//向右</span></span><br><span class="line">            <span class="built_in">GetTop</span>(S,p);		<span class="comment">//读栈顶结点（非出栈）</span></span><br><span class="line">            <span class="keyword">if</span>(p-&gt;rchild&amp;&amp;p-&gt;rchild!=r)		<span class="comment">//若右子树存在，且未被访问过</span></span><br><span class="line">                p = p-&gt;rchild;		<span class="comment">//转向右</span></span><br><span class="line">            <span class="keyword">else</span>&#123;	<span class="comment">//否则，弹出结点并访问</span></span><br><span class="line">                <span class="built_in">Pop</span>(S,p);			 <span class="comment">//将结点弹出</span></span><br><span class="line">                <span class="built_in">visit</span>(p-&gt;data);		 <span class="comment">//访问该结点</span></span><br><span class="line">                r = p;				<span class="comment">//记录最近访问过的结点</span></span><br><span class="line">                p = <span class="literal">NULL</span>;			<span class="comment">//结点访问完后，重置p指针</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="comment">//else</span></span><br><span class="line">    &#125;<span class="comment">//while</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-层次遍历">4.层次遍历</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">LevelOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="built_in">InitQueue</span>(Q);				<span class="comment">//初始化辅助队列</span></span><br><span class="line">    BiTree p;</span><br><span class="line">    <span class="built_in">EnQueue</span>(Q,T);				<span class="comment">//将根结点入队</span></span><br><span class="line">    <span class="keyword">while</span>(!<span class="built_in">IsEmpty</span>(Q))&#123;			<span class="comment">//队列不空则循环</span></span><br><span class="line">        <span class="built_in">DeQueue</span>(Q,p);			<span class="comment">//队头结点出队</span></span><br><span class="line">        <span class="built_in">visit</span>(p);				<span class="comment">//访问出队结点</span></span><br><span class="line">        <span class="keyword">if</span>(p-&gt;lchild!=<span class="literal">NULL</span>)</span><br><span class="line">            <span class="built_in">EnQueue</span>(Q,p-&gt;lchild);	<span class="comment">//左子树不空，则左子树根结点入队</span></span><br><span class="line">        <span class="keyword">if</span>(p-rchild!=<span class="literal">NULL</span>)</span><br><span class="line">            <span class="built_in">EnQueue</span>(Q,p-&gt;rchild);	<span class="comment">//右子树不空，则右子树根结点入队</span></span><br><span class="line">    &#125;<span class="comment">//while</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="第四节线索二叉树">第四节线索二叉树</h2>
<p>是以一定的规则将二叉树中的结点排列成一个线性序列，从而得到集中遍历序列，使得该序列中的每个结点（第一个和最后一个结点除外）都有一个直接前去和直接后继。</p>
<p>目的：为了加快查找结点前驱和后继的速度。</p>
<p>空指针 = 线索数 = n+1</p>
<table>
<thead>
<tr>
<th style="text-align:center">lchild</th>
<th style="text-align:center">ltag</th>
<th style="text-align:center">data</th>
<th style="text-align:center">rtag</th>
<th style="text-align:center">rchild</th>
</tr>
</thead>
</table>
<p>ltag</p>
<ul>
<li>​	0	lchild域指示结点的左孩子</li>
<li>​	1	lchild域指示结点的前驱</li>
</ul>
<p>rtag</p>
<ul>
<li>​	0	rchild域指示结点的右孩子</li>
<li>​	1	rchild域指示结点的前驱</li>
</ul>
<p>存储结构</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">ThreadNode</span>&#123;</span><br><span class="line">    ElemType data;						<span class="comment">//数据元素</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">ThreadNode</span> *lchild,*rchild;		<span class="comment">//左、右孩子指针</span></span><br><span class="line">    <span class="type">int</span> ltag,rtag;						<span class="comment">//左、右线索标志</span></span><br><span class="line">&#125;ThreadNode,*ThreadTree;</span><br></pre></td></tr></table></figure>
<h2 id="第五节哈夫曼树">第五节哈夫曼树</h2>
<h3 id="1-概念-2">1.概念</h3>
<p>树中所有叶结点的带权路径长度之和称为该树的带权路径长度，记作：<br>
$$<br>
WPL = \sum_{i=1}^nw_il_i<br>
$$<br>
举例如下哈夫曼树，WPL = (4+2)<em>3+5</em>2+7*1 = 35</p>
<pre class="mermaid">graph TB;
A((A))
B((B))
C((C))
D((D:7))
E((E:5))
F((F:2))
G((G:4))
A-->D
A-->B
B-->C
B-->E
C-->G
C-->F</pre>
<h3 id="2-编码问题（左0右1）">2.编码问题（左0右1）</h3>
<pre class="mermaid">graph TB;
A((A))
B((B))
C((C))
D((D:7))
E((E:5))
F((F:2))
G((G:4))
A--1-->D
A--0-->B
B--0-->C
B--1-->E
C--0-->G
C--1-->F</pre>
<table>
<thead>
<tr>
<th style="text-align:center">D</th>
<th style="text-align:center">E</th>
<th style="text-align:center">F</th>
<th style="text-align:center">G</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">01</td>
<td style="text-align:center">001</td>
<td style="text-align:center">000</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之栈与队列</title>
    <url>/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<h1>第三章栈与队列</h1>
<h2 id="第三节堆栈和队列的应用">第三节堆栈和队列的应用</h2>
<span id="more"></span>
<h3 id="1-表达式求值">1.表达式求值</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OK 1</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ERROR 0</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">char</span> SElemType;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">int</span> Status;</span><br><span class="line"><span class="comment">//链栈存储结构</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    SElemType data;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">Node</span>* next;</span><br><span class="line">&#125;Node, * LinkStack;</span><br><span class="line"></span><br><span class="line"><span class="comment">//链栈初始化</span></span><br><span class="line"><span class="function">Status <span class="title">InitStack</span><span class="params">(LinkStack &amp;S)</span> </span>&#123;   <span class="comment">//构造空栈，栈顶指针置空</span></span><br><span class="line">    S = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//链栈入栈</span></span><br><span class="line"><span class="function">Status <span class="title">Push</span><span class="params">(LinkStack &amp;S, SElemType e)</span> </span>&#123;<span class="comment">//栈顶插入元素e</span></span><br><span class="line">    LinkStack p = <span class="keyword">new</span> Node;    <span class="comment">//生成新节点</span></span><br><span class="line">    p-&gt;data = e;   <span class="comment">//新节点数据域置为e</span></span><br><span class="line">    p-&gt;next = S;   <span class="comment">//将新节点插入栈顶</span></span><br><span class="line">    S = p; <span class="comment">//修改栈顶指针为p</span></span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//链栈的出栈</span></span><br><span class="line"><span class="function">Status <span class="title">Pop</span><span class="params">(LinkStack &amp;S, SElemType &amp;e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (S == <span class="literal">NULL</span>) <span class="comment">//栈为空</span></span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    LinkStack p;   <span class="comment">//定义临时链栈</span></span><br><span class="line">    e = S-&gt;data;   <span class="comment">//将栈顶元素赋值给e</span></span><br><span class="line">    p = S; <span class="comment">//临时存储栈顶空间，以备释放</span></span><br><span class="line">    S = S-&gt;next;   <span class="comment">//修改栈顶指针</span></span><br><span class="line">    <span class="keyword">delete</span> p;  <span class="comment">//删除栈顶指针</span></span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//取栈顶元素</span></span><br><span class="line"><span class="function">SElemType <span class="title">GetTop</span><span class="params">(LinkStack S)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (S != <span class="literal">NULL</span>) <span class="comment">//栈非空</span></span><br><span class="line">        <span class="keyword">return</span> S-&gt;data;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断读入的字符ch是否为运算符</span></span><br><span class="line"><span class="function">Status <span class="title">In</span><span class="params">(SElemType ch)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (ch == <span class="string">&#x27;+&#x27;</span> || ch == <span class="string">&#x27;-&#x27;</span> || ch == <span class="string">&#x27;*&#x27;</span> || ch == <span class="string">&#x27;/&#x27;</span> || ch == <span class="string">&#x27;(&#x27;</span> || ch == <span class="string">&#x27;)&#x27;</span>||ch==<span class="string">&#x27;#&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> OK;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断运算符栈顶元素与读入运算符ch的优先级</span></span><br><span class="line"><span class="function">SElemType <span class="title">Precede</span><span class="params">(SElemType a, SElemType b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (a == <span class="string">&#x27;+&#x27;</span> || a == <span class="string">&#x27;-&#x27;</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (b == <span class="string">&#x27;+&#x27;</span> || b == <span class="string">&#x27;-&#x27;</span> || b == <span class="string">&#x27;#&#x27;</span> || b == <span class="string">&#x27;)&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&gt;&#x27;</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&lt;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (a == <span class="string">&#x27;*&#x27;</span> || a == <span class="string">&#x27;/&#x27;</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (b == <span class="string">&#x27;(&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&lt;&#x27;</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&gt;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (a == <span class="string">&#x27;(&#x27;</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (b == <span class="string">&#x27;)&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;=&#x27;</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&lt;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (a == <span class="string">&#x27;#&#x27;</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (b == <span class="string">&#x27;#&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;=&#x27;</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&lt;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (a == <span class="string">&#x27;)&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&gt;&#x27;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//运算函数</span></span><br><span class="line"><span class="function">SElemType <span class="title">Operate</span><span class="params">(SElemType a, SElemType t, SElemType b)</span> </span>&#123;<span class="comment">//进行运算的函数</span></span><br><span class="line">    <span class="keyword">switch</span> (t) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;+&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> a + b;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> a - b;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;*&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> a * b;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> a / b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//算法表达式求值的优先算法，设OPTR和OPND分别为运算符栈和操作数栈</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">EvaluateExpression</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    LinkStack OPND, OPTR;  <span class="comment">//定义栈</span></span><br><span class="line">    SElemType ch, t,t1,t2;</span><br><span class="line">    <span class="built_in">InitStack</span>(OPND);   <span class="comment">//初始化操作数栈</span></span><br><span class="line">    <span class="built_in">InitStack</span>(OPTR);   <span class="comment">//初始化运算符栈</span></span><br><span class="line">    <span class="built_in">Push</span>(OPTR,<span class="string">&#x27;#&#x27;</span>);    <span class="comment">//入栈</span></span><br><span class="line">    cin &gt;&gt; ch;</span><br><span class="line">    <span class="keyword">while</span> (ch != <span class="string">&#x27;#&#x27;</span> || <span class="built_in">GetTop</span>(OPTR) != <span class="string">&#x27;#&#x27;</span>) &#123;<span class="comment">//表达式没有扫描完毕或者OPTR栈顶不为‘#’时执行</span></span><br><span class="line">        <span class="keyword">if</span> (!<span class="built_in">In</span>(ch)) &#123; <span class="comment">//ch不是运算符</span></span><br><span class="line">            <span class="built_in">Push</span>(OPND, ch-<span class="string">&#x27;0&#x27;</span>);    <span class="comment">//进入OPND栈</span></span><br><span class="line">            cin &gt;&gt; ch; <span class="comment">//读取下一个字符</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">switch</span> (<span class="built_in">Precede</span>(<span class="built_in">GetTop</span>(OPTR), ch)) &#123;   <span class="comment">//比较OPTR栈顶元素和ch的优先级</span></span><br><span class="line">                <span class="keyword">case</span> <span class="string">&#x27;&lt;&#x27;</span>:</span><br><span class="line">                    <span class="built_in">Push</span>(OPTR, ch);    <span class="comment">//将ch压入OPTR栈</span></span><br><span class="line">                    cin &gt;&gt; ch; <span class="comment">//读取下一个字符</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> <span class="string">&#x27;&gt;&#x27;</span>:</span><br><span class="line">                    <span class="built_in">Pop</span>(OPTR, t);  <span class="comment">//弹出OPTR栈顶运算符，赋值给t</span></span><br><span class="line">                    <span class="built_in">Pop</span>(OPND, t2); <span class="comment">//后进先出</span></span><br><span class="line">                    <span class="built_in">Pop</span>(OPND, t1); <span class="comment">//弹出OPND栈顶两个运算数</span></span><br><span class="line">                    <span class="built_in">Push</span>(OPND, <span class="built_in">Operate</span>(t1, t, t2));    <span class="comment">//将运算结果压入OPND栈</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> <span class="string">&#x27;=&#x27;</span>:  <span class="comment">//OPTR栈顶元素是&#x27;(&#x27;且ch是&#x27;)&#x27;</span></span><br><span class="line">                    <span class="built_in">Pop</span>(OPTR, t);  <span class="comment">//弹出栈顶&#x27;(&#x27;</span></span><br><span class="line">                    cin &gt;&gt; ch; <span class="comment">//读取下一个字符</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;(<span class="type">int</span>)<span class="built_in">GetTop</span>(OPND)&lt;&lt;endl; <span class="comment">//将char转换为int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">EvaluateExpression</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-括号匹配问题">2.括号匹配问题</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义栈</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> max_size 200<span class="comment">//栈的最大容量</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">char</span> datatype;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">    datatype zhan[max_size];</span><br><span class="line">    <span class="type">int</span> top;<span class="comment">//栈顶</span></span><br><span class="line">&#125;stack;</span><br><span class="line"></span><br><span class="line"><span class="comment">//栈的初始化</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(stack &amp;st)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    st.top = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//类型为datatype的x入栈</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(stack &amp;st, datatype x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//当栈顶和max_size相等时，栈满</span></span><br><span class="line">    <span class="keyword">if</span>(st.top == max_size)&#123;</span><br><span class="line">        <span class="comment">// cout&lt;&lt;&quot;This stack has already full!&quot;;</span></span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;no&quot;</span>;</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        st.zhan[st.top] = x;</span><br><span class="line">        st.top++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//出栈</span></span><br><span class="line"><span class="function"><span class="type">char</span> <span class="title">pop</span><span class="params">(stack &amp;st)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(st.top == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="comment">// cout&lt;&lt;&quot;This stack is empty!&quot;;</span></span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;no&quot;</span>;</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        st.top--;</span><br><span class="line">        <span class="keyword">return</span> st.zhan[st.top];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    stack s;</span><br><span class="line">    <span class="built_in">initial</span>(s);</span><br><span class="line">    <span class="comment">/*输入字符串，并将字符串放到字符数组中，</span></span><br><span class="line"><span class="comment">    实现能够逐个扫描字符串中的字符，并且不跳过空格符*/</span></span><br><span class="line">    string str;</span><br><span class="line">    <span class="built_in">getline</span>(cin, str);</span><br><span class="line">    <span class="type">char</span> ch[<span class="number">200</span>]=&#123;<span class="string">&#x27;\0&#x27;</span>&#125;;</span><br><span class="line">    <span class="built_in">strcpy</span>(ch,str.<span class="built_in">c_str</span>());</span><br><span class="line">    <span class="comment">//flag标志状态 1为括号匹配，0为不匹配</span></span><br><span class="line">    <span class="type">int</span> flag=<span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; ch[i]!=<span class="string">&#x27;\0&#x27;</span>; i++)&#123;</span><br><span class="line">        <span class="comment">//元素若为&#123;，(，[则入栈</span></span><br><span class="line">        <span class="keyword">if</span>((ch[i] == <span class="string">&#x27;&#123;&#x27;</span> )|| (ch[i] ==<span class="string">&#x27;[&#x27;</span>) || (ch[i] ==<span class="string">&#x27;(&#x27;</span>))&#123;</span><br><span class="line">            <span class="built_in">push</span>(s, ch[i]);</span><br><span class="line">        &#125;<span class="comment">//元素若为&#125;，)，]则出栈 赋值给a</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>((ch[i] == <span class="string">&#x27;&#125;&#x27;</span>) || (ch[i] ==<span class="string">&#x27;]&#x27;</span>) || (ch[i] ==<span class="string">&#x27;)&#x27;</span>))&#123;</span><br><span class="line">            <span class="type">char</span> a;</span><br><span class="line">            a = <span class="built_in">pop</span>(s);</span><br><span class="line">            <span class="comment">//若a与ch[i]匹配，进行下一个字符扫描</span></span><br><span class="line">            <span class="keyword">if</span>((a == <span class="string">&#x27;&#123;&#x27;</span> &amp;&amp; ch[i] == <span class="string">&#x27;&#125;&#x27;</span>) || (a == <span class="string">&#x27;(&#x27;</span> &amp;&amp; ch[i] == <span class="string">&#x27;)&#x27;</span>) || (a == <span class="string">&#x27;[&#x27;</span> &amp;&amp; ch[i] == <span class="string">&#x27;]&#x27;</span>))&#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> flag = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(s.top != <span class="number">0</span>)&#123;    <span class="comment">//当左括号多出没有与右括号匹配的时候（如：&quot; &#123;() &quot;）</span></span><br><span class="line">        flag = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(flag == <span class="number">0</span>)&#123;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;no&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;yes&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-迷宫问题（栈，深度检索）">3.迷宫问题（栈，深度检索）</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;assert.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ROW  6<span class="comment">//行</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> COL  6<span class="comment">//列</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//地图</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">_Maze</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> map[ROW][COL];</span><br><span class="line">&#125;Maze;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX_SIZE 128</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">_Postion</span><span class="comment">//地图中点的坐标,这个栈中存的元素就是点的坐标</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> _x;</span><br><span class="line">    <span class="type">int</span> _y;</span><br><span class="line">&#125;Postion;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> Postion DataType;</span><br><span class="line"></span><br><span class="line"><span class="comment">//栈的结构体</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">_Stack</span></span><br><span class="line">&#123;</span><br><span class="line">    DataType* top;</span><br><span class="line">    DataType* base;</span><br><span class="line">&#125;Stack;</span><br><span class="line"></span><br><span class="line"><span class="comment">//栈的初始化</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">initStack</span><span class="params">(Stack&amp; S)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    S.base = <span class="keyword">new</span> DataType[MAX_SIZE];</span><br><span class="line">    <span class="keyword">if</span> (!S.base)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    S.top = S.base;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//入栈</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">pushStack</span><span class="params">(Stack&amp; S, DataType data)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!S.base)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (S.top - S.base == MAX_SIZE)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    *(S.top) = data;</span><br><span class="line">    S.top++;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//出栈</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">popStack</span><span class="params">(Stack&amp; S,DataType&amp; e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (S.top == S.base)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    e = *(--S.top);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//返回栈顶元素</span></span><br><span class="line"><span class="function">DataType* <span class="title">getTop</span><span class="params">(Stack&amp; S)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (S.top - S.base == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    <span class="comment">//注意何时自增何时不自增</span></span><br><span class="line">    <span class="keyword">return</span> S.top<span class="number">-1</span>;<span class="comment">//返回栈顶元素的指针</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//返回栈中元素个数</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">getSize</span><span class="params">(Stack&amp; S)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> S.top - S.base;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断栈是否为空</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isEmpty</span><span class="params">(Stack&amp; S)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (S.top == S.base)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//销毁栈</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">destoryStack</span><span class="params">(Stack&amp; S)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (S.base)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">delete</span>[] S.base;</span><br><span class="line">        S.top = S.base = <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//根据给出给出的地图数据初始化结构体地图</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initMaze</span><span class="params">(Maze&amp; m, <span class="type">int</span> map[ROW][COL])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; ROW; i++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; COL; j++)</span><br><span class="line">            m.map[i][j] = map[i][j];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//打印迷宫(地图)</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printMaze</span><span class="params">(Maze&amp; m)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; ROW; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; COL; j++) &#123;</span><br><span class="line">            cout &lt;&lt; m.map[i][j] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断是否是有效的入口</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isValidEnter</span><span class="params">(Maze* m,Postion enter)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(m);<span class="comment">//断言-里面的表达式为0直接终止程序,注意里面的内容是什么</span></span><br><span class="line">    <span class="comment">//只要入口在四个边界上就是合法的,并且是1(道路)</span></span><br><span class="line">    <span class="keyword">if</span> (((enter._x == <span class="number">0</span> || enter._x == ROW - <span class="number">1</span>) || (enter._y == <span class="number">0</span> || enter._y == COL - <span class="number">1</span>)))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断当前位置是否是出口</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isVaildExit</span><span class="params">(Maze* m, Postion cur, Postion enter)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(m);</span><br><span class="line">    <span class="comment">//该结点不能是入口点，除了入口点，在边界上就是合法出口</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ((cur._x != enter._x || cur._y != enter._y) &amp;&amp; ((cur._x == <span class="number">0</span> || cur._x == ROW - <span class="number">1</span>) || (cur._y == <span class="number">0</span> || cur._y == COL - <span class="number">1</span>)))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断当前结点的下一个结点是否能走通-是不是可以走的点</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isNextPass</span><span class="params">(Maze* m, Postion cur, Postion next)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(m);</span><br><span class="line">    <span class="comment">//判断next是不是cur的下一个结点</span></span><br><span class="line">    <span class="comment">//同一行相邻或者同一列相邻</span></span><br><span class="line">    <span class="keyword">if</span> (((next._x == cur._x) &amp;&amp; ((next._y == cur._y + <span class="number">1</span>) || (next._y == cur._y - <span class="number">1</span>)))</span><br><span class="line">        || ((next._y == cur._y) &amp;&amp; ((next._x = cur._x + <span class="number">1</span>) || (next._x = cur._x - <span class="number">1</span>))))</span><br><span class="line">        <span class="comment">//确实是cur的下一个结点(相邻的 )</span></span><br><span class="line">        <span class="comment">//判断这个点是不是在迷宫里</span></span><br><span class="line">        <span class="comment">//合法坐标并且那个位置的值是1</span></span><br><span class="line">        <span class="keyword">if</span> (((next._x &gt;= <span class="number">0</span> &amp;&amp; next._x &lt; ROW) &amp;&amp; (next._y &gt;= <span class="number">0</span> &amp;&amp; next._y &lt; COL))</span><br><span class="line">            &amp;&amp; (m-&gt;map[next._x][next._y] == <span class="number">1</span>))</span><br><span class="line">            <span class="comment">//最后的参数==1，不仅仅是看是否是可以走的位置(道路是1)，</span></span><br><span class="line">            <span class="comment">//同时有了这个我们就不用倒着往往前走了(不走重复的路)，不是有效的结点不只是墙(0)</span></span><br><span class="line">            <span class="comment">//走过的也不是有效结点，直接pop出栈，通过出栈来往前回退</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//寻找迷宫通路</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">PassMaze</span><span class="params">(Maze* m, Postion enter, Stack&amp; s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(m &amp;&amp; <span class="built_in">isValidEnter</span>(m, enter));</span><br><span class="line"></span><br><span class="line">    Postion cur = enter;<span class="comment">//cur存储当前结点</span></span><br><span class="line">    Postion next;<span class="comment">//下一个结点，从入口开始出发向四周移动</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//先将入口压入栈中</span></span><br><span class="line">    <span class="built_in">pushStack</span>(s, cur);</span><br><span class="line">    m-&gt;map[cur._x][cur._y] = <span class="number">2</span>;<span class="comment">//将入口值改为2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//循环求解-当栈中还有路径时</span></span><br><span class="line">    <span class="keyword">while</span> (!<span class="built_in">isEmpty</span>(s))</span><br><span class="line">    &#123;</span><br><span class="line">        cur = *<span class="built_in">getTop</span>(s);<span class="comment">//取到栈顶元素</span></span><br><span class="line">        <span class="comment">//判断当前位置是否是出口</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isVaildExit</span>(m, cur, enter))<span class="comment">//注意参数传递顺序</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;<span class="comment">//是出口直接返回</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//不是出口继续在周围判断</span></span><br><span class="line">        <span class="comment">//把cur当前刚才那个位置拿过来向四周判断</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//先向左判断</span></span><br><span class="line">        next = cur;</span><br><span class="line">        next._y = cur._y - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isNextPass</span>(m,cur,next))<span class="comment">//如果下一个结点走得通</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//走得通就走到那个位置-压进栈</span></span><br><span class="line">            <span class="built_in">pushStack</span>(s, next);</span><br><span class="line">            <span class="comment">//走过的位置-标记</span></span><br><span class="line">            m-&gt;map[next._x][next._y] = m-&gt;map[cur._x][cur._y] + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//之后</span></span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//走不通向另一个方向判断</span></span><br><span class="line">        <span class="comment">//向右走一步</span></span><br><span class="line">        next = cur;</span><br><span class="line">        next._y = cur._y + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isNextPass</span>(m, cur, next))</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">pushStack</span>(s, next);</span><br><span class="line">            m-&gt;map[next._x][next._y] = m-&gt;map[cur._x][cur._y] + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//向下走一步</span></span><br><span class="line">        next = cur;</span><br><span class="line">        next._x = cur._x + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isNextPass</span>(m, cur, next))</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">pushStack</span>(s, next);</span><br><span class="line">            m-&gt;map[next._x][next._y] = m-&gt;map[cur._x][cur._y] + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//向上走一步</span></span><br><span class="line">        next = cur;</span><br><span class="line">        next._x = cur._x - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isNextPass</span>(m, cur, next))</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">pushStack</span>(s, next);</span><br><span class="line">            m-&gt;map[next._x][next._y] = m-&gt;map[cur._x][cur._y] + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//走到这里说明此结点的四个方向都走不通</span></span><br><span class="line">        <span class="comment">//进行回溯</span></span><br><span class="line">        Postion tmp;<span class="comment">//没用 临时接收</span></span><br><span class="line">        <span class="built_in">popStack</span>(s, tmp);<span class="comment">//出栈</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//0-墙 1-路</span></span><br><span class="line">    <span class="type">int</span> map[ROW][COL] = &#123;</span><br><span class="line">            <span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,</span><br><span class="line">            <span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,</span><br><span class="line">            <span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,</span><br><span class="line">            <span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,</span><br><span class="line">            <span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,</span><br><span class="line">            <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Maze m;<span class="comment">//创建一个迷宫(地图)</span></span><br><span class="line">    <span class="built_in">initMaze</span>(m, map);<span class="comment">//初始化迷宫</span></span><br><span class="line">    <span class="built_in">printMaze</span>(m);<span class="comment">//打印迷宫</span></span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;_______&quot;</span> &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//迷宫入口</span></span><br><span class="line">    Postion enter;</span><br><span class="line">    enter._x = <span class="number">0</span>;</span><br><span class="line">    enter._y = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义栈</span></span><br><span class="line">    Stack s;<span class="comment">//用于保存走过的轨迹，便于回溯</span></span><br><span class="line">    <span class="built_in">initStack</span>(s);<span class="comment">//初始化栈</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> ret = <span class="built_in">PassMaze</span>(&amp;m, enter, s);</span><br><span class="line">    <span class="keyword">if</span> (ret)</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;有解&quot;</span> &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;无解&quot;</span> &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">printMaze</span>(m);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-调度问题">4.调度问题</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> INF=<span class="number">1000</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> max_task=<span class="number">10</span>;            	<span class="comment">//最大任务数</span></span><br><span class="line"><span class="type">int</span> n;                           	<span class="comment">//任务数</span></span><br><span class="line"><span class="type">int</span> a[max_task][<span class="number">2</span>];             	<span class="comment">//存储每个作业分别在机器1与机器2上的时间消耗</span></span><br><span class="line"><span class="type">int</span> result[max_task];          		<span class="comment">//存储排列树中的一条路径</span></span><br><span class="line"><span class="type">int</span> best_result[max_task];    		<span class="comment">//存储最优路径</span></span><br><span class="line"><span class="type">int</span> min=INF;                 		<span class="comment">//安排任务最小完成时间</span></span><br><span class="line"><span class="type">int</span> rop[max_task+<span class="number">1</span>];        		<span class="comment">//每个深度对应遍历进度</span></span><br><span class="line"><span class="type">int</span> finish[max_task+<span class="number">1</span>];    			<span class="comment">//每一层消耗时间和</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">swap</span><span class="params">(<span class="type">int</span> result[max_task],<span class="type">int</span> best_result[max_task])</span>   <span class="comment">//复制数组</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">        best_result[i]=result[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">allot_task</span><span class="params">(<span class="type">int</span> depth)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">bool</span> visited[max_task];    	<span class="comment">//标记已安排任务</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=rop[depth];i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(!visited[i])                 <span class="comment">//寻找该层未访问节点</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> f1=<span class="number">0</span>;                 	<span class="comment">//在机器一上的完成时间</span></span><br><span class="line">            <span class="type">int</span> f2=<span class="number">0</span>;                  	<span class="comment">//在机器二上的完成时间</span></span><br><span class="line">            rop[depth]=i+<span class="number">1</span>;           	<span class="comment">//更新该层访问进度</span></span><br><span class="line">            visited[i]=<span class="literal">true</span>;         	<span class="comment">//标记作业</span></span><br><span class="line">            result[depth<span class="number">-1</span>]=i;        	<span class="comment">//加入结果序列</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(visited[j])</span><br><span class="line">                &#123;</span><br><span class="line">                    f1+=a[j][<span class="number">0</span>];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            f2=f1+a[i][<span class="number">1</span>];            	<span class="comment">//该作业完成时间</span></span><br><span class="line">            <span class="keyword">if</span>(f2&lt;finish[depth<span class="number">-1</span>])    	<span class="comment">//该序列执行到此作业消耗时间</span></span><br><span class="line">                f2=finish[depth<span class="number">-1</span>];</span><br><span class="line">            finish[depth]=f2;</span><br><span class="line">            <span class="keyword">if</span>(depth==n)             	<span class="comment">//最后一个作业</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(f2&lt;min)</span><br><span class="line">                &#123;</span><br><span class="line">                    min=f2;</span><br><span class="line">                    swap(result,best_result);      <span class="comment">//保存最优序列</span></span><br><span class="line">                &#125;</span><br><span class="line">                visited[i]=<span class="literal">false</span>;</span><br><span class="line">                rop[depth]=<span class="number">0</span>;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(depth&lt;n)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(f2&gt;min)</span><br><span class="line">                &#123;</span><br><span class="line">                    visited[i]=<span class="literal">false</span>;</span><br><span class="line">                    allot_task(depth<span class="number">-1</span>);     <span class="comment">//回溯</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                &#123;</span><br><span class="line">                    allot_task(depth+<span class="number">1</span>);      <span class="comment">//继续添加作业</span></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        visited[rop[depth]<span class="number">-1</span>]=<span class="literal">false</span>;         <span class="comment">//跟换当前层次作业需要把之前作业解标记</span></span><br><span class="line">    &#125;</span><br><span class="line">    visited[rop[depth]<span class="number">-1</span>]=<span class="literal">false</span>;</span><br><span class="line">    rop[depth]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;请输入任务数：&quot;</span>);</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;作业%d分别在机器1与机器2上运行时间：&quot;</span>,i+<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d %d&quot;</span>,&amp;a[i][<span class="number">0</span>],&amp;a[i][<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    allot_task(<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;最优调度序列为：&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,best_result[i]+<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n消耗时间为：%d\n&quot;</span>,min);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之排序</title>
    <url>/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E4%B9%9D%E7%AB%A0%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h1>第九章排序</h1>
<h2 id="1-排序的概念">1.排序的概念</h2>
<span id="more"></span>
<p>\begin{flalign}<br>
&amp;排序：按照一定的关键字，将一个序列排列成想要得到的一个新的序列。\<br>
&amp;稳定性：若待排序表中有两个元素 R_i 和 R_j，其对应的关键字相同即 key_i = key_j，且在排序前 R_i 在 R_j 的前面，\<br>
&amp;~若使用某一排序算法排序后，R_i 仍然在 R_j 的前⾯，则称这个排序算法是稳定的，否则称排序算法是不稳定的。\<br>
&amp;内部排序和外部排序：整个排序过程完全在内存中进行，叫做内部排序。数据量较大需要借助外部存储设备才能完成，叫做外部排序。<br>
\end{flalign}</p>
<h2 id="2-插入排序">2.插入排序</h2>
<h3 id="（1）直接插入排序">（1）直接插入排序</h3>
<p><em>①</em>  思想：最基本的插入排序，将第<em>i</em>个插入到前<em>i-1</em>个中的适当位置。</p>
<p><em>②</em>  时间复杂度：<em>T(n) = O(n</em>²*)*。</p>
<p><em>③</em>  空间复杂度：<em>S(n) = O(1)</em>。</p>
<p><em>④</em>  稳定性：稳定排序。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//直接插入排序</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">InsertSort</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> n)</span> </span>&#123;	<span class="comment">//将各元素插入已排好序的序列中,位置0的是有序的，所以从1开始</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>, j; i &lt; n; ++i) &#123;    </span><br><span class="line">        <span class="keyword">if</span> (A[i] &lt; A[i<span class="number">-1</span>]) &#123;          <span class="comment">//若A[i]小于前驱元素</span></span><br><span class="line">            <span class="type">int</span> temp = A[i];</span><br><span class="line">            <span class="keyword">for</span> (j = i - <span class="number">1</span>; j &gt;= <span class="number">0</span> &amp;&amp; A[j] &gt; temp; --j) &#123;   <span class="comment">//检查所有前面已排好序的元素</span></span><br><span class="line">                A[j+<span class="number">1</span>] = A[j];    <span class="comment">//所有大于A[i]的元素都向后挪位</span></span><br><span class="line">            &#125;</span><br><span class="line">            A[j+<span class="number">1</span>] = temp;        <span class="comment">//复制到插入位置</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="（2）折半插入排序">（2）折半插入排序</h3>
<p><em>①</em>  思想：因为是已经确定了前部分是有序序列，所以在查找插入位置的时候可以用折半查找的方法进行查找，提高效率。</p>
<p><em>②</em>  时间复杂度：比较时的时间减为O(nlogn)，但是移动元素的时间耗费未变，所以总是得时间复杂度还是O(n²)。</p>
<p><em>③</em>  空间复杂度：<em>S(n) = O(1)</em>。</p>
<p><em>④</em>  稳定性：稳定排序。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//折半插入排序</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">InsertSort2</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> n)</span> </span>&#123;		<span class="comment">//依次将A[1]~A[i-1]插入到前面已排序序列</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; n; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> temp = A[i];</span><br><span class="line">        <span class="type">int</span> low = <span class="number">0</span>, high = i - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (low &lt;= high) &#123;   <span class="comment">//折半查找</span></span><br><span class="line">            <span class="type">int</span> mid = (low + high) / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span> (A[mid] &gt; temp) </span><br><span class="line">                high = mid - <span class="number">1</span>;</span><br><span class="line">            low = mid + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = i<span class="number">-1</span>; j &gt;= low; --j) &#123;		<span class="comment">//将[low, i-1]内的元素全部右移，空出插入位置</span></span><br><span class="line">            A[j+<span class="number">1</span>] = A[j];</span><br><span class="line">        &#125;</span><br><span class="line">        A[low] = temp;  <span class="comment">//插入操作</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="（3）希尔排序">（3）希尔排序</h3>
<p><em>①</em>  思想：又称缩小增量排序法。把待排序序列分成若干较小的子序列，然后逐个使用直接插入排序法排序，最后再对一个较为有序的序列进行一次排序，主要是为了减少移动的次数，提高效率。原理应该就是从无序到渐渐有序，要比直接从无序到有序移动的次数会少一些。</p>
<p><em>②</em>  时间复杂度：时间复杂度与增量序列的选择有关，最坏时间复杂度为O(n²)，当n在某个范围内时，可达O(n^1.3)。</p>
<p><em>③</em>  空间复杂度：<em>S(n) = O(1)</em>。</p>
<p><em>④</em>  稳定性：不稳定排序。仅适用于顺序表，不适用于链表。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//希尔排序</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ShellSort</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> d = n/<span class="number">2</span>; d &gt;= <span class="number">1</span>; d /= <span class="number">2</span>) &#123;   <span class="comment">//步长变化</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = d, j; i &lt; n; i += d) &#123;</span><br><span class="line">            <span class="keyword">if</span> (A[i] &lt; A[i-d]) &#123;  <span class="comment">//需将A[i]插入有序增量子表</span></span><br><span class="line">                <span class="type">int</span> temp = A[i];    <span class="comment">//暂存元素</span></span><br><span class="line">                <span class="keyword">for</span> (j = i-d; j &gt;= <span class="number">0</span> &amp;&amp; A[j] &gt; temp; j -= d) &#123;</span><br><span class="line">                    A[j+d] = A[j];    <span class="comment">//元素后移，查找插入位置</span></span><br><span class="line">                &#125;</span><br><span class="line">                A[j+d] = temp;        <span class="comment">//插入</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="3-选择排序">3.选择排序</h2>
<h3 id="（1）直接选择排序">（1）直接选择排序</h3>
<p><em>①</em>  思想：首先在所有<strong>记录中选出关键字值最小的记录</strong>，把它与第一个记录进行位置交换，然后在其余的记录中再选出关键字值次小的记录与第二个记录进行位置交换，依此类推，直到所有记录排好序。</p>
<p><em>②</em>  时间复杂度：最好最坏平均时间复杂度为O(n²)。</p>
<p><em>③</em>  空间复杂度：<em>S(n) = O(1)</em>。</p>
<p><em>④</em>  稳定性：不稳定排序。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">SelectionSort</span><span class="params">(<span class="type">int</span> A[],<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> temp,flag;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; n<span class="number">-1</span>;i++)&#123;</span><br><span class="line">        flag = i;						<span class="comment">//flag记录此刻需要确定最小值的位置</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = i+<span class="number">1</span>;j &lt; n;j++)&#123;			<span class="comment">//在i+1的位置开始在后寻找最小关键字</span></span><br><span class="line">            <span class="keyword">if</span>(A[flag] &gt; A[j])</span><br><span class="line">                flag = j;</span><br><span class="line">        &#125;</span><br><span class="line">        temp = A[flag];	A[flag] = A[i];	A[i] = temp;		<span class="comment">//将flag的数和后面的最小关键字交换</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="（2）堆排序">（2）堆排序</h3>
<p><em>①</em>  思想<br>
作为选择排序的改进版，堆排序可以把每一趟元素的比较结果保存下来，以便我们在选择最小/大元素时对已经比较过的元素做出相应的调整。<br>
堆排序是一种树形选择排序，在排序过程中可以把元素看成是一颗完全二叉树，每个节点都大（小）于它的两个子节点，每个节点都大于等于它的两个子节点时，就称为大顶堆，也叫堆有序； 当每个节点都小于等于它的两个子节点时，就称为小顶堆。</p>
<p><em>②</em>  时间复杂度：最好最坏平均时间复杂度为O(nlogn)。</p>
<p>​	调整时间和树的高度有关，为O(h)，在建立含n个元素的堆时，关键字的比较总次数不超过4*n，时间复杂度为O(n)</p>
<p><em>③</em>  空间复杂度：<em>S(n) = O(1)</em>。</p>
<p><em>④</em>  稳定性：不稳定排序。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//建立大根堆</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BuildMaxHeap</span><span class="params">(ElemType A[],<span class="type">int</span> len)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = len/<span class="number">2</span>;i&gt;<span class="number">0</span>;i++)				<span class="comment">//从i = [n/2]~1，反复调整堆</span></span><br><span class="line">		<span class="built_in">HeapAdjust</span>(A,i,len);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HeapAdjust</span><span class="params">(ElemType A[],<span class="type">int</span> k,<span class="type">int</span> len)</span></span>&#123;	<span class="comment">//函数HeapAdjust将元素k为根的子树进行调整</span></span><br><span class="line">    A[<span class="number">0</span>] = A[k];						<span class="comment">//A[0]暂存子树的根结点</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">2</span>*k;i &lt;= len;i++)&#123;			<span class="comment">//沿key较大的子结点向下筛选</span></span><br><span class="line">        <span class="keyword">if</span>(i&lt;len&amp;&amp;A[i]&lt;A[i+<span class="number">1</span>])		</span><br><span class="line">            i++;						<span class="comment">//取key较大的子结点的下标</span></span><br><span class="line">        <span class="keyword">if</span>(A[<span class="number">0</span>] &gt;= A[i])	<span class="keyword">break</span>;			<span class="comment">//筛选结束</span></span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            A[k] = A[i];				<span class="comment">//将A[i]调整到双亲结点上</span></span><br><span class="line">            k = i;						<span class="comment">//修改k值，以便继续向下筛选</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    A[k] = A[<span class="number">0</span>];						<span class="comment">//被筛选结点的值放入最终位置</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//堆排序算法</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HeapSort</span><span class="params">(ElemType A[],<span class="type">int</span> len)</span></span>&#123;</span><br><span class="line">    <span class="built_in">BuildMaxHeap</span>(A,len);				<span class="comment">//初始建堆</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = len;i&gt;<span class="number">1</span>;i++)&#123;			<span class="comment">//n-1趟的交换和建堆过程</span></span><br><span class="line">        <span class="built_in">Swap</span>(A[i],A[<span class="number">1</span>]);				<span class="comment">//输出堆顶元素（和堆底元素交换）</span></span><br><span class="line">        <span class="built_in">HeapAdjust</span>(A,<span class="number">1</span>,i<span class="number">-1</span>);			<span class="comment">//调整，把剩余的i-1个元素整理成堆</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="4-交换排序">4.交换排序</h2>
<h3 id="（1）冒泡排序">（1）冒泡排序</h3>
<p><em>①</em>  思想：两两比较相邻记录的关键字，如果反序则交换，直到没有反序的记录为止。以升序冒泡为例：每趟排序过程中通过两两比较相邻元素，将小的数字放到前面，大的数字放到后面。</p>
<p><em>②</em>  时间复杂度：最好O(n)，最坏平均时间复杂度为O(n²)。</p>
<p><em>③</em>  空间复杂度：<em>S(n) = O(1)</em>。</p>
<p><em>④</em>  稳定性：稳定排序。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">BubbleSort</span><span class="params">(ElemType A[],<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; n<span class="number">-1</span>;i++)&#123;</span><br><span class="line">        flag = <span class="literal">false</span>;				<span class="comment">//表示本趟冒泡是否发生交换的标志</span></span><br><span class="line">        <span class="keyword">for</span>(j = n<span class="number">-1</span>;j &gt; i;j--)		<span class="comment">//一趟冒泡过程</span></span><br><span class="line">            <span class="keyword">if</span>(A[j<span class="number">-1</span>]&gt;A[j])&#123;		<span class="comment">//若为逆序</span></span><br><span class="line">                <span class="built_in">swap</span>(A[j<span class="number">-1</span>],A[j]);	<span class="comment">//交换</span></span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">if</span>(flag == <span class="literal">false</span>)</span><br><span class="line">            <span class="keyword">return</span>;					<span class="comment">//本趟遍历后没有发生变换，说明表已经有序</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="（2）快速排序">（2）快速排序</h3>
<p><strong>当每次枢纽都把表等分为长度相近的两个子表时，速度是最快的</strong></p>
<p><em>①</em>  思想：快速排序时所有内部排序算法中平均性能最优的排序算法<br>
在待排序的元素任取一个元素作为基准(通常选第一个元素，但最好的选择方法是从待排序元素中随机选取一个作为基准)，称为基准元素；<br>
将待排序的元素进行分区，比基准元素大的元素放在它的右边，比其小的放在它的左边；<br>
对左右两个分区重复以上步骤直到所有元素都是有序的。</p>
<p><em>②</em>  时间复杂度：最好O(nlogn)，最坏时间复杂度为O(n²)。</p>
<p><em>③</em>  空间复杂度：<em>最好平均情况O(logn)，最坏情况O(n)</em>。</p>
<p><em>④</em>  稳定性：不稳定排序。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">QuickSort</span><span class="params">(ElemType A[],<span class="type">int</span> low,<span class="type">int</span> high)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(low&lt;high)&#123;								<span class="comment">//递归跳出条件</span></span><br><span class="line">        <span class="type">int</span> pos = <span class="built_in">Partitio</span>(A,low,high);			<span class="comment">//划分，将A[low...high]划分为满足上述条件要求的两个字表</span></span><br><span class="line">        <span class="built_in">QuickSort</span>(A,low,pos<span class="number">-1</span>);					<span class="comment">//依次对两个子表进行递归排序</span></span><br><span class="line">        <span class="built_in">QuickSort</span>(A,pos+<span class="number">1</span>,high);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Partition</span><span class="params">(ElemType A[],<span class="type">int</span> low,<span class="type">int</span> high)</span></span>&#123;		<span class="comment">//一趟划分</span></span><br><span class="line">    ElemType pivot = A[low];						<span class="comment">//设当前表中第一个元素为枢纽，对表进行划分</span></span><br><span class="line">    <span class="keyword">while</span>(low&lt;high)&#123;								<span class="comment">//循环跳出条件</span></span><br><span class="line">        <span class="keyword">while</span>(low&lt;high&amp;&amp;A[high]&gt;=pivot)	--high;</span><br><span class="line">        A[low] = A[high];							<span class="comment">//将比枢纽小的元素移动到左端</span></span><br><span class="line">        <span class="keyword">while</span>(low&lt;high&amp;&amp;A[low]&lt;=pivot)	++low;</span><br><span class="line">        A[high] = A[low];							<span class="comment">//将比枢纽大的元素移动到右端</span></span><br><span class="line">    &#125;</span><br><span class="line">    A[low] = pivot;								<span class="comment">//枢纽存放到最终位置</span></span><br><span class="line">    <span class="keyword">return</span> low;									<span class="comment">//返回存放枢纽的最终位置</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="5-归并排序">5.归并排序</h2>
<p><em>①</em>  思想：将待排序序列R[0…n-1]看成是n个长度为1的有序序列，将相邻的有序表成对归并，得到n/2个长度为2的有序表；将这些有序序列再次归并，得到n/4个长度为4的有序序列；如此反复进行下去，最后得到一个长度为n的有序序列。</p>
<p><em>②</em>  时间复杂度：归并排序的形式就是一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的可以得出它的时间复杂度是<strong>O(nlogn)</strong>。</p>
<p><em>③</em>  空间复杂度：<em>S(n) = O(n)</em>。</p>
<p><em>④</em>  稳定性：稳定排序。</p>
<img src="/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E4%B9%9D%E7%AB%A0%E6%8E%92%E5%BA%8F/归并排序.png" style="zoom:80%;">
<h2 id="6-基数排序">6.基数排序</h2>
<p><strong>基数排序的效率和初始序列是否有序没有关联。</strong></p>
<p><em>①</em>  思想：<strong>不需要比较关键字的大小</strong>。根据关键字中各位的值，通过对排序的N个元素进行若干趟“分配”与“收集”来实现排序的。</p>
<p><em>②</em>  时间复杂度：假设在基数排序中，r为基数，d为位数。则基数排序的时间复杂度为<strong>O(d(n+r))</strong>。</p>
<p><em>③</em>  空间复杂度：对于任何位数上的基数进行“装桶”操作时，都需要<strong>n+r</strong>个临时空间。</p>
<p><em>④</em>  稳定性：稳定排序。</p>
<h2 id="7-排序算法总结">7.排序算法总结</h2>
<table>
<thead>
<tr>
<th style="text-align:center">排序类别</th>
<th style="text-align:center">排序算法</th>
<th style="text-align:center">平均情况</th>
<th style="text-align:center">最好情况</th>
<th style="text-align:center">最坏情况</th>
<th style="text-align:center">空间复杂度</th>
<th style="text-align:center">稳定性</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">插入排序</td>
<td style="text-align:center">直接插入排序</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(n)</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">稳定</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">折半插入排序</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(n)</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">稳定</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">希尔排序</td>
<td style="text-align:center"></td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center"></td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">不稳定</td>
</tr>
<tr>
<td style="text-align:center">选择排序</td>
<td style="text-align:center">直接选择排序</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">不稳定</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">堆排序</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">不稳定</td>
</tr>
<tr>
<td style="text-align:center">交换排序</td>
<td style="text-align:center">冒泡排序</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(n)</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">稳定</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">快速排序</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(n²)</td>
<td style="text-align:center">O(logn)</td>
<td style="text-align:center">不稳定</td>
</tr>
<tr>
<td style="text-align:center">归并排序</td>
<td style="text-align:center">归并排序</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(n)</td>
<td style="text-align:center">稳定</td>
</tr>
<tr>
<td style="text-align:center">基数排序</td>
<td style="text-align:center">基数排序</td>
<td style="text-align:center">O(d(n+r))</td>
<td style="text-align:center">O(d(n+r))</td>
<td style="text-align:center">O(d(n+r))</td>
<td style="text-align:center">O(n+r)</td>
<td style="text-align:center">稳定</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之数组</title>
    <url>/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E4%BA%94%E7%AB%A0%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<h1>第五章数组</h1>
<h2 id="第一节数组的概念">第一节数组的概念</h2>
<h3 id="1-数据概念">1.数据概念</h3>
<p>​	数组是由n（n≥1）个相同类型的数据元素构成的有限序列</p>
<span id="more"></span>
<h3 id="2-数组的实现">2.数组的实现</h3>
<p>​	以一维数组A[0…n-1]为例，其存储结构关系式为<br>
$$<br>
LOC(a_i) = LOC(a_0)+i*L\quad\quad (0≤i&lt;n)<br>
$$<br>
​	其中，L时每个数组元素所占的存储单元</p>
<h2 id="第二节特殊矩阵和稀疏矩阵的压缩存储">第二节特殊矩阵和稀疏矩阵的压缩存储</h2>
<h3 id="1-特殊矩阵的压缩存储">1.特殊矩阵的压缩存储</h3>
<h4 id="（1）对称矩阵（1，0）">（1）对称矩阵（1，0）</h4>
<p>$$<br>
k=<br>
\begin{cases}<br>
i(i-1)/2+j-1,\quad\quad i≥j（下三角区和主对角线元素）\\<br>
j(j-1)/2+i-1,\quad\quad i&lt;j（上三角区元素a_{ij} = a_{ji}）<br>
\end{cases}<br>
$$</p>
<h4 id="（2）三角矩阵（1，0）">（2）三角矩阵（1，0）</h4>
<p>下三角矩阵<br>
$$<br>
k=<br>
\begin{cases}<br>
i(i-1)/2+j-1,\quad\quad i≥j（下三角区和主对角线元素）\\<br>
n(n+1)/2,\quad\quad~~~~~~~~~~~ i&lt;j（上三角区元素）<br>
\end{cases}<br>
$$<br>
上三角矩阵<br>
$$<br>
k=<br>
\begin{cases}<br>
(i-1)(2n-i+2)/2+(j-i),\quad\quad i≤j（上三角区和主对角线元素）\\<br>
n(n+1)/2,\quad\quad~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ i&gt;j（下三角区元素）<br>
\end{cases}<br>
$$</p>
<h4 id="（3）三对角矩阵（1，0）">（3）三对角矩阵（1，0）</h4>
<p>$$<br>
k = 2i+j-3<br>
$$</p>
<h3 id="2-稀疏矩阵的压缩存储">2.稀疏矩阵的压缩存储</h3>
<p>稀疏矩阵压缩存储后便失去了随机存取特性<br>
$$<br>
M=\left[<br>
\matrix{<br>
4 &amp; 0 &amp; 0 &amp; 0\<br>
0 &amp; 0 &amp; 6 &amp; 0\<br>
0 &amp; 9 &amp; 0 &amp; 0\<br>
0 &amp; 23 &amp; 0 &amp; 0\<br>
}<br>
\right]<br>
$$<br>
对应三元组</p>
<table>
<thead>
<tr>
<th style="text-align:center">i</th>
<th style="text-align:center">j</th>
<th style="text-align:center">v</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">9</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">1</td>
<td style="text-align:center">23</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之递归算法和广义表</title>
    <url>/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%85%AD%E7%AB%A0%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95%E5%92%8C%E5%B9%BF%E4%B9%89%E8%A1%A8/</url>
    <content><![CDATA[<h1>第六章递归算法和广义表</h1>
<h2 id="第一节递归算法">第一节递归算法</h2>
<h3 id="1-递归算法概念">1.递归算法概念</h3>
<p>​	是一种直接或者间接调用自身函数或者方法的算法。说简单点就是程序自身的调用。</p>
<span id="more"></span>
<h3 id="2-递归算法设计">2.递归算法设计</h3>
<h4 id="（1）阶乘">（1）阶乘</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">fac</span><span class="params">(<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> n*<span class="built_in">f</span>(n<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    cout&lt;&lt;<span class="built_in">f</span>(<span class="number">5</span>)&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//120</span></span><br></pre></td></tr></table></figure>
<h4 id="（2）斐波那契数列">（2）斐波那契数列</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">fib</span><span class="params">(<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">1</span> || n == <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">fib</span>(n<span class="number">-1</span>)+<span class="built_in">fib</span>(n<span class="number">-2</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    cout&lt;&lt;<span class="built_in">fib</span>(<span class="number">10</span>)&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//55</span></span><br></pre></td></tr></table></figure>
<h4 id="（3）杨辉三角的取值">（3）杨辉三角的取值</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">//递归函数</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">(<span class="type">int</span> m,<span class="type">int</span> n)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">0</span>||n == m )<span class="comment">//递归终止条件</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> func(m<span class="number">-1</span>,n)+func(m<span class="number">-1</span>,n<span class="number">-1</span>);<span class="comment">//核心代码</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">    <span class="type">int</span> m,i,j;</span><br><span class="line">    m=<span class="number">6</span>;<span class="comment">//打印前6行杨辉三角</span></span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;=m;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;m-i;j++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;   &quot;</span>);</span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;=i;j++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%6d&quot;</span>,func(i,j));</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（4）汉诺塔">（4）汉诺塔</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Move</span><span class="params">(<span class="type">int</span> n, <span class="type">char</span> A, <span class="type">char</span> B, <span class="type">char</span> C)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">1</span>)&#123;</span><br><span class="line">        <span class="comment">//圆盘只有一个时，只需将其从A塔移到C塔</span></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;move &quot;</span> &lt;&lt; n &lt;&lt; <span class="string">&quot; from &quot;</span> &lt;&lt; A &lt;&lt; <span class="string">&quot; to &quot;</span> &lt;&lt; C &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">Move</span>(n - <span class="number">1</span>, A, C, B);<span class="comment">//递归，把A塔上编号1~n-1的圆盘移到B上，以C为辅助塔</span></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;move &quot;</span> &lt;&lt; n &lt;&lt; <span class="string">&quot; from &quot;</span> &lt;&lt; A &lt;&lt; <span class="string">&quot; to &quot;</span> &lt;&lt; C &lt;&lt; endl;<span class="comment">//把A塔上编号为n的圆盘移到C上</span></span><br><span class="line">        <span class="built_in">Move</span>(n - <span class="number">1</span>, B, A, C);<span class="comment">//递归，把B塔上编号1~n-1的圆盘移到C上，以A为辅助塔</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">Move</span>(<span class="number">3</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="第二节广义表">第二节广义表</h2>
<h3 id="1-广义表概念">1.广义表概念</h3>
<p>​	是一种非线性的数据结构，它的表元素可以是原子或者广义表的一种线性表的扩展结构。</p>
<ul>
<li>​	广义表的长度：表中最上层元素的个数</li>
<li>​	广义表的深度：表中括号的最大层数</li>
<li>​	表头和表尾：当广义表非空时，第一个元素为广义表的表头，其余元素组成的表是广义表的表尾</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">E=()	<span class="comment">//E是一个空表，其长度为0，其深度为1</span></span><br><span class="line">L=(a，b)	<span class="comment">//L是长度为2的广义表，它的两个元素都是原子，因此它是一个线性表，其深度为1</span></span><br><span class="line">A=(x，L)=(x，(a，b))	<span class="comment">//A是长度为2的广义表，第一个元素是原子x，第二个元素是子表L，其深度为2</span></span><br><span class="line">B=(A，y)=((x，(a，b))，y)	<span class="comment">//B是长度为2的广义表，第一个元素是子表A，第二个元素是原子y，其深度为3</span></span><br><span class="line">C=(A，B)=((x，(a，b))，((x，(a，b))，y))	<span class="comment">//C的长度为2，两个元素都是子表，其深度为4</span></span><br><span class="line">D=(a，D)=(a，(a，(a，(…))))	<span class="comment">//D的长度为2，第一个元素是原子，第二个元素是D自身，展开后它是一个无限的广义表，其深度为∞</span></span><br></pre></td></tr></table></figure>
<h3 id="2-广义表存储结构和操作实现">2.广义表存储结构和操作实现</h3>
<h4 id="（1）广义表结点的代码结构">（1）广义表结点的代码结构</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//定义广义表的数据结构</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">GList</span>&#123;</span><br><span class="line">	NodeTag tag; <span class="comment">//用以区分是原子结点还是子表结点</span></span><br><span class="line">	<span class="keyword">union</span>&#123;</span><br><span class="line">		DataType data; <span class="comment">//用以存放原子结点值，其类型由用户自定义</span></span><br><span class="line">		GList *slink; <span class="comment">//指向子表的指针</span></span><br><span class="line">	&#125;;</span><br><span class="line">	GList *next; <span class="comment">//指向下一个表结点</span></span><br><span class="line">&#125; *GListPtr;</span><br></pre></td></tr></table></figure>
<h4 id="（2）求表头、表尾">（2）求表头、表尾</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*求广义表L的表头，并返回表头指针*/</span></span><br><span class="line"><span class="function">GList <span class="title">Head</span><span class="params">(GList L)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (L == <span class="literal">NULL</span>)					<span class="comment">//空表无表头</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">if</span> (L-&gt;tag == ATOM)				<span class="comment">//原子不是表</span></span><br><span class="line">		<span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		<span class="keyword">return</span> L-&gt;atom_htp.htp.hp;	<span class="comment">//返回表头指针</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*求广义表L的表尾，并返回表尾指针*/</span></span><br><span class="line"><span class="function">GList <span class="title">Tail</span><span class="params">(GList L)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (L == <span class="literal">NULL</span>)					<span class="comment">//空表无表尾</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">if</span> (L-&gt;tag == ATOM)				<span class="comment">//原子不是表</span></span><br><span class="line">		<span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		<span class="keyword">return</span> L-&gt;atom_htp.htp.tp;	<span class="comment">//返回表尾指针</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（3）求长度、深度">（3）求长度、深度</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*求广义表长度*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Length</span><span class="params">(GList L)</span> </span>&#123;</span><br><span class="line">	<span class="type">int</span> k = <span class="number">0</span>;</span><br><span class="line">	GLNode* s;</span><br><span class="line">	<span class="keyword">if</span> (L == <span class="literal">NULL</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;					<span class="comment">//空表长度为0</span></span><br><span class="line">	<span class="keyword">if</span> (L-&gt;tag == ATOM)				<span class="comment">//原子不是表</span></span><br><span class="line">		<span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">	s = L;</span><br><span class="line">	<span class="keyword">while</span> (s != <span class="literal">NULL</span>) &#123;				<span class="comment">//统计最上层表的长度</span></span><br><span class="line">		k++;</span><br><span class="line">		s = s-&gt;atom_htp.htp.tp;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> k;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*求广义表的深度*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Depth</span><span class="params">(GList L)</span> </span>&#123;</span><br><span class="line">	<span class="type">int</span> d, max;</span><br><span class="line">	GLNode* s;</span><br><span class="line">	<span class="keyword">if</span> (L == <span class="literal">NULL</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;					<span class="comment">//空表深度为1</span></span><br><span class="line">	<span class="keyword">if</span> (L-&gt;tag == ATOM)</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;					<span class="comment">//原子深度为0</span></span><br><span class="line">	s = L;</span><br><span class="line">	<span class="keyword">while</span> (s != <span class="literal">NULL</span>) &#123;				<span class="comment">//求每个子表的深度的最大值</span></span><br><span class="line">		d = <span class="built_in">Depth</span>(s-&gt;atom_htp.htp.hp);</span><br><span class="line">		<span class="keyword">if</span> (d &gt; max)</span><br><span class="line">			max = d;</span><br><span class="line">		s = s-&gt;atom_htp.htp.tp;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> (max + <span class="number">1</span>);				<span class="comment">//表的深度等于最深子表的深度+1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintGList</span><span class="params">(GListPtr gl)</span></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(gl != <span class="literal">NULL</span>)&#123;</span><br><span class="line">		<span class="keyword">if</span>(gl-&gt;tag == list)&#123;</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;(&quot;</span>);</span><br><span class="line">			<span class="keyword">if</span>(gl-&gt;slink == <span class="literal">NULL</span>)&#123;</span><br><span class="line">				<span class="built_in">printf</span>(<span class="string">&quot;&quot;</span>);</span><br><span class="line">			&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">				<span class="built_in">PrintGList</span>(gl-&gt;slink); <span class="comment">//递归调用输出子表</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, gl-&gt;data); <span class="comment">//输出结点数据域值</span></span><br><span class="line">		&#125;</span><br><span class="line"> </span><br><span class="line">		<span class="keyword">if</span>(gl-&gt;tag == list)&#123;</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;)&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line"> </span><br><span class="line">		<span class="keyword">if</span>(gl-&gt;next != <span class="literal">NULL</span>)&#123;</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">			<span class="built_in">PrintGList</span>(gl-&gt;next); <span class="comment">//递归调用输出下一个节点</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（4）统计原子个数">（4）统计原子个数</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*统计广义表中原子结点数目*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">CountAtom</span><span class="params">(GList L)</span> </span>&#123;</span><br><span class="line">	<span class="type">int</span> n1, n2;</span><br><span class="line">	<span class="keyword">if</span> (L == <span class="literal">NULL</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;							<span class="comment">//空表中没有原子</span></span><br><span class="line">	<span class="keyword">if</span> (L-&gt;tag == ATOM)</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;							<span class="comment">//L指向单个原子</span></span><br><span class="line">	n1 = <span class="built_in">CountAtom</span>(L-&gt;atom_htp.htp.hp);		<span class="comment">//统计表头中的原子数目</span></span><br><span class="line">	n2 = <span class="built_in">CountAtom</span>(L-&gt;atom_htp.htp.tp);		<span class="comment">//统计表尾中的原子数目</span></span><br><span class="line">	<span class="keyword">return</span> (n1 + n2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（5）广义表的复制">（5）广义表的复制</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*复制广义表*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">CopyGList</span><span class="params">(GList S, GList* T)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (S == <span class="literal">NULL</span>) &#123;				<span class="comment">//复制空表</span></span><br><span class="line">		*T = <span class="literal">NULL</span>;</span><br><span class="line">		<span class="keyword">return</span> OK;</span><br><span class="line">	&#125;</span><br><span class="line">	*T = (GLNode*)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(GLNode));</span><br><span class="line">	<span class="keyword">if</span> (*T == <span class="literal">NULL</span>)</span><br><span class="line">		<span class="keyword">return</span> ERROR;</span><br><span class="line">	(*T)-&gt;tag = S-&gt;tag;</span><br><span class="line">	<span class="keyword">if</span> (S-&gt;tag == ATOM)</span><br><span class="line">		(*T)-&gt;atom_htp.atom = S-&gt;atom_htp.atom;		<span class="comment">//复制单个原子</span></span><br><span class="line">	<span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">/*复制表头*/</span></span><br><span class="line">		<span class="built_in">CopyGList</span>(S-&gt;atom_htp.htp.hp, &amp;((*T)-&gt;atom_htp.htp.hp));</span><br><span class="line">		<span class="comment">/*复制表尾*/</span></span><br><span class="line">		<span class="built_in">CopyGList</span>(S-&gt;atom_htp.htp.tp, &amp;((*T)-&gt;atom_htp.htp.tp));</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之查找</title>
    <url>/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%8D%81%E7%AB%A0%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<h1>第十章查找</h1>
<h2 id="第一节查找的概念">第一节查找的概念</h2>
<p>在数据集合中寻找满足某种条件的数据元素的过程</p>
<span id="more"></span>
<h2 id="第二节静态查找">第二节静态查找</h2>
<h3 id="1-顺序（线性）查找">1.顺序（线性）查找</h3>
<h4 id="（1）一般线性表的查找">（1）一般线性表的查找</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;					<span class="comment">//查找表的数据结构</span></span><br><span class="line">    ElemType *elem;				<span class="comment">//元素存储空间基址，建表时按实际长度分配，0号单元留空</span></span><br><span class="line">    <span class="type">int</span> TableLen;				<span class="comment">//表的长度</span></span><br><span class="line">&#125;SSTable;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Search_Seq</span><span class="params">(SSTable ST,ElemType key)</span></span>&#123;</span><br><span class="line">    ST.elem[<span class="number">0</span>] = key;			<span class="comment">//哨兵</span></span><br><span class="line">    <span class="keyword">for</span>(i = ST.TableLen;ST.elem[i]!=key,--i);	<span class="comment">//从后往前找</span></span><br><span class="line">    <span class="keyword">return</span> i;					<span class="comment">//若表中不存在关键字为key的元素，将查找到i=0时退出for循环</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于有n个元素的表，给定值key与表中第i个元素相等，即定位第i个元素时，需进行n-i+1次关键词的比较。</p>
<p>\begin{flalign}<br>
&amp;1.查找成功时:\<br>
&amp;顺序查找的平均长度为：ASL_{成功} = \sum_{i=1}^nP_i(n-i+1)\<br>
&amp;当每个元素的查找概率相等，即P_i=1/n时，有：ASL_{成功} = \sum_{i=1}^nP_i(n-i+1)=(n+1)/2\<br>
&amp;2.查找失败时：\<br>
&amp;与表中各关键词的比较次数时n+1次，从而顺序查找不成功的平均查找长度为：ASL_{不成功} = n+1<br>
\end{flalign}</p>
<h4 id="（2）有序表的查找">（2）有序表的查找</h4>
<p>\begin{flalign}<br>
&amp;1.查找成功时:\<br>
&amp;顺序查找的平均长度为：ASL_{成功} = \sum_{i=1}^nP_i(n-i+1)\<br>
&amp;当每个元素的查找概率相等，即P_i=1/n时，有：ASL_{成功} = \sum_{i=1}^nP_i(n-i+1)=(n+1)/2\<br>
&amp;2.查找失败时：\<br>
&amp;查找不成功的平均查找长度为：ASL_{不成功} = \sum_{j=1}^nq_i(l_j-1)=(1+2…+n+n)/(n+1)=n/2+n/(n+1)<br>
\end{flalign}</p>
<h3 id="2-二分（折半）查找">2.二分（折半）查找</h3>
<p>时间复杂度：O(logn)</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">Binary_Search</span><span class="params">(SeqList L,ElemType key)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> low = <span class="number">0</span>,high = L.TableLen<span class="number">-1</span>,mid;</span><br><span class="line">    <span class="keyword">while</span>(low&lt;=high)&#123;</span><br><span class="line">        min = (low+high)/<span class="number">2</span>;							<span class="comment">//取中间位置</span></span><br><span class="line">        <span class="keyword">if</span>(L.elem[mid] = key)	<span class="keyword">return</span> min;			<span class="comment">//查找成功则返回所在位置</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(L.elem[mid]&gt;key)	high = mid<span class="number">-1</span>;	<span class="comment">//从前半部分继续查找</span></span><br><span class="line">        <span class="keyword">else</span>	low = mid+<span class="number">1</span>;						<span class="comment">//从后半部分继续查找</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;										<span class="comment">//查找失败，返回-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>\begin{flalign}<br>
&amp;ASL_{成功} = 1/n\sum_{i=1}^nl_i=1/n(1<em>1+2</em>2+…+h<em>2^{h-1})=(n+1)/n</em>log_2(n+1)≈log_2(n+1)-1\<br>
\end{flalign}</p>
<h3 id="3-索引（分块）查找">3.索引（分块）查找</h3>
<p>基本思想：将查找表氛围若干子块。块内元素可以无序，但块之间时有序的，即第一个块中的最大关键字小于第二块中的所有记录的关键字，以此类推。再建立一个索引表，索引表中每个元素含有各块的最大关键字和各块中的第一个元素的地址，索引表按关键字有序排列。<br>
$$<br>
\begin{flalign}<br>
&amp;1.分块查找的平均查找长度为索引查找和块内查找的平均长度之和，设索引查找和块内查找的平均查找长度分别为L_l和L_s\<br>
&amp;~~~则分块查找的平均查找长度为：ASL = L_l+L_s\<br>
&amp;2.将长度为n的查找表均匀的分成b块，每块有s各记录，在等概率情况下，若块内和索引表中均采用顺序查找\<br>
&amp;~~~则平均查找长度为：ASL = L_l+L_s = (b+1)/2+(s+1)/2 = (s^2+2s+n)/(2s)\<br>
&amp;3.若s = \sqrt n，则平均查找长度取最小值\sqrt n+1；\<br>
&amp;4.若对索引表采用折半查找时，\<br>
&amp;~~~则平均查找长度为ASL= L_l+L_s = \lceil log_2(b+1)\rceil+(s+1)/2<br>
\end{flalign}<br>
$$</p>
<h2 id="第三节动态查找">第三节动态查找</h2>
<h3 id="二叉排序树（BST）">二叉排序树（BST）</h3>
<p>二叉排序树（二叉查找树）或者是一棵空树，或者时具有下列特性的二叉树：</p>
<p>1）若左子树非空，则左子树上所有结点的值均小于根结点的值；</p>
<p>2）若右子树非空，则右子树上所有结点的值均大于根结点的值；</p>
<p>3）左、右子数也分别是一棵二叉排序树。</p>
<h4 id="（1）查找">（1）查找</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">BSTNode *<span class="title">BST_Search</span><span class="params">(BiTree T,ElemType key)</span></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(T&amp;&amp;key!=T-&gt;data)&#123;				<span class="comment">//若树空或等于根结点值，则结束循环</span></span><br><span class="line">        <span class="keyword">if</span>(key&lt;T-&gt;data)	T = T-&gt;lchild;	<span class="comment">//小于，则在左子树上查找</span></span><br><span class="line">        <span class="keyword">else</span>	T = T-&gt;rchild;			<span class="comment">//大于，则在右子树上查找</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> T;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（2）插入">（2）插入</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">BST_Insert</span><span class="params">(BiTree &amp;T,KetType k)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(T)&#123;									<span class="comment">//原树为空，新插入的记录为新结点</span></span><br><span class="line">        T = (BiTree)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(BSTNode));</span><br><span class="line">        T-&gt;data = k;</span><br><span class="line">        T-&gt;lchild = T-&gt;rchild = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;							<span class="comment">//返回1，表示插入成功</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(k == T-&gt;data)	<span class="keyword">return</span> <span class="number">0</span>;		<span class="comment">//树中存在相同关键字的结点，插入失败</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(k &lt; T-data)		<span class="keyword">return</span> <span class="built_in">BST_Insert</span>(T-&gt;lchild,k);		<span class="comment">//插入到T的左子树</span></span><br><span class="line">    <span class="keyword">else</span>	<span class="keyword">return</span> <span class="built_in">BST_Insert</span>(T-&gt;rchild,k);		<span class="comment">//插入到T的右子树</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（3）构造">（3）构造</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Creat_BST</span><span class="params">(BiTree &amp;T,KetType str[],<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    T = <span class="literal">NULL</span>;					<span class="comment">//初始时T为空树</span></span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(i &lt; n)&#123;				<span class="comment">//依次将每个关键字插入到二叉排序树中</span></span><br><span class="line">        <span class="built_in">BST_Insert</span>(T,str[i]);	</span><br><span class="line">        i++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（4）删除">（4）删除</h4>
<p>①若被删除结点z时叶结点，则直接删除，不会破坏二叉排序树的性质；</p>
<p>②若结点z只有一棵左子树或右子树，则让z的子数称为z父节点的子数，代替z的位置；</p>
<p>③若结点z有左、右两棵子数，则令z的直接后继（或直接前驱）替代z，然后二叉排序树中删去这个直接后继（或直接前驱），这样就转换成了第一种或第二种情况。</p>
<pre class="mermaid">graph TB;
A((53))
B((17))
C((78))
D((09))
E((45))
F((65))
G((94))
H((81))
I((88))
J((23))
A-->B
A-->C
B-->D
B-->E
C-->F
C-->G
E-->J
G-->H
H-->I</pre>
<p>删除78结点后</p>
<pre class="mermaid">graph TB;
A((53))
B((17))
D((09))
E((45))
F((65))
G((94))
H((81))
I((88))
J((23))
A-->B
A-->H
B-->D
B-->E
E-->J
H-->F
H-->G
G-->I</pre>
<p>\begin{flalign}<br>
平衡二叉树的递推公式：n_0=0,n_1=1,n_2=2,n_h=1+n_{h-1}+n_{h-2}<br>
\end{flalign}</p>
<h2 id="第四节哈希查找（散列表）">第四节哈希查找（散列表）</h2>
<h3 id="1-哈希查找的概念">1.哈希查找的概念</h3>
<p>散列函数：一个把查找表中的关键字映射成该关键字对应的地址的函数，记为Hash(key)=Addr（这里的地址可以实数组下标、索引或内存地址等）</p>
<p>散列表：根据关键字而直接进行访问的数据结构。即<em>散列表建立了关键字和存储地址之间的一种直接映射关系</em>。</p>
<h3 id="2-哈希函数">2.哈希函数</h3>
<h4 id="（1）直接定址法">（1）直接定址法</h4>
<p>\begin{flalign}<br>
H(key)=key或H(key)=a×key+b<br>
\end{flalign}</p>
<h4 id="（2）除留余数法">（2）除留余数法</h4>
<p>假定散列表表长为m，取一个不大于m但最接近或等于m的质数p，则散列函数如下：</p>
<p>\begin{flalign}<br>
H(key)=key%p<br>
\end{flalign}</p>
<h4 id="（3）数字分析法">（3）数字分析法</h4>
<h4 id="（4）平方取中法">（4）平方取中法</h4>
<p>取关键字的平方值的中间几位作为散列地址。适用于关键字的每位取值都不够均匀或均小于散列地址所需的位数。</p>
<h3 id="3-哈希冲突的解决方法">3.哈希冲突的解决方法</h3>
<h4 id="（1）开放地址法">（1）开放地址法</h4>
<p>\begin{flalign}<br>
H_i = (H(key)+d_i)%m\<br>
H(key)为散列函数：i = 0,1,2,…,k(k ≤ m-1)；m表示散列表表长；d_i为增量序列<br>
\end{flalign}</p>
<h5 id="–a-线性探测法">–a.线性探测法</h5>
<p>特点：冲突发生时，顺序查看表中下一个单元（探测到表尾地址m-1时，下一个探测地址时表首地址0），知道招初一个空闲单元（当表为填满时一定要找到一个空闲单元）或查遍全表。</p>
<p>缺点：容易造成大量元素在相邻的散列地址上“聚集”（或堆积）起来，大大降低查找效率。</p>
<h5 id="–b-平方探测法">–b.平方探测法</h5>
<p>特点：当d~i~ = 0²，1²，-1²，2²，-2²，…，k²，-k²时，称为平方探测法，其中k ≤ m/2，散列表长度m必须是一个可以表示成4k+3的素数，又称二次探测法。</p>
<p>优点：可以避免出现“堆积”问题。</p>
<p>缺点：不能探测散列表上的所有单元，但至少可以探测到一半单元。</p>
<h5 id="–c-双散列法">–c.双散列法</h5>
<p>​		当d~i~=Hash~2~(key)时，称为双散列法。当通过第一个散列函数H(key)得到的地址发生冲突时，利用第二个散列函数Hash~2~(key)计算该关键字的地址增量。具体散列函数形式如下：</p>
<p>\begin{flalign}<br>
H_i=(H(key)+i×Hash_2(key))%m<br>
\end{flalign}</p>
<p>初始探测位置H~0~=H(key)%m。i是冲突的次数，初始为0。最多经过m-1次探测就会遍历表中所有位置，回到H~0~位置。</p>
<h5 id="–d-伪随机序列法">–d.伪随机序列法</h5>
<p>d~i~ = 伪随机序列时，称为伪随机序列法。</p>
<h4 id="（2）拉链法（链接法）">（2）拉链法（链接法）</h4>
<p>同线性探测法，但改为链表形式。</p>
<h3 id="4-散列查找及性能分析">4.散列查找及性能分析</h3>
<p>散列表的查找效率取决三个因素：散列函数、处理冲突的方法和装填因子。</p>
<p>\begin{flalign}<br>
\alpha = 表中记录数n/散列表长度m<br>
\end{flalign}</p>
<p>散列表的平均查找长度依赖于散列表的装填因子α，而不直接依赖于n或m。直观地看，α越大，表示装填的记录越“满”，发生冲突的可能性越大，反之发生冲突的可能性越小。</p>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之图</title>
    <url>/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%9B%BE/</url>
    <content><![CDATA[<h1>第八章图</h1>
<h2 id="第一节图的概念和存储结构">第一节图的概念和存储结构</h2>
<h3 id="1-概念">1.概念</h3>
<p>线性表可以为空，树可以为空，但是图不能为空。图中不能一个顶点也没有，图的顶点集V一定非空，但边集E可以为空，此时图中只有顶点而没有边。</p>
<span id="more"></span>
<p>（1）有向图<br>
$$<br>
G_1 = (V_1,E_1)\<br>
V_1 = {1,2,3}\<br>
$$</p>
<p>$$<br>
E_1 = {&lt;1,2&gt;,&lt;2,1&gt;,&lt;2,3&gt;}<br>
$$</p>
<pre class="mermaid">graph LR;
A((1))
B((2))
C((3))
A-->B
B-->A
B-->C</pre>
<p>（2）无向图<br>
$$<br>
G_1 = (V_1,E_1)\<br>
V_1 = {1,2,3,4}\<br>
$$</p>
<p>$$<br>
E_1 = {(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)}<br>
$$</p>
<p>（3）简单图、多重图</p>
<ul>
<li>简单图：①不存在重复边；②不存在顶点到自身的边。</li>
<li>多重图：图G中某两个顶点之间的边数大于1条，有允许顶点通过一条边和自身关联。</li>
</ul>
<p>（4）完全图（简单完全图）<br>
$$<br>
\begin{flalign}<br>
&amp;无向完全图|E|取值范围 = [<s>0,n(n-1)/2</s>]\<br>
&amp;有向完全图|E|取值范围 = [<s>0,n(n-1)</s>~~~~]<br>
\end{flalign}<br>
$$<br>
（5）子图：G = (V，E)和G<code> = (V</code>，E<code>)，若V</code>是V的子集，且E`是E的子集</p>
<p>（6）连通、连通图和连通分量（无向图）</p>
<ul>
<li>连通：无向图，顶点v和顶点w有路径存在，则称v和w是连通的</li>
<li>连通图：无向图图G任意两个顶点都是连通的，称连通图，否则为非连通图</li>
<li>连通分量：无向图的极大连通子图</li>
</ul>
<p>（7）强连通图、强连通分量（有向图）</p>
<ul>
<li>强连通：有向图，有一对顶点v和w，从v到w和w到v之间都有路径，则称两个顶点是强连通的</li>
<li>强连通图：任意一对顶点都是强连通的</li>
<li>强连通分量：有向图中的极大强连通分量</li>
</ul>
<p>（8）生成树、生成森林</p>
<p>连通图的生成树是包含图中全部顶点的一个极小连通子图。若顶点数为n，则生成树含有n-1条边</p>
<p>（9）顶点的度、入度和出度<br>
$$<br>
\begin{flalign}<br>
&amp;n个顶点e条边的无向图:\sum_{i=1}^nTD(v_i) = 2e\<br>
&amp;n个顶点e条边的有向图：\sum_{i=1}^nID(v_i) = \sum_{i=1}^nOD(v_i) = e<br>
\end{flalign}<br>
$$<br>
（10）路径、路径长度、回路</p>
<p>若有一个图有n个顶点，并且有大于n-1条边，则该图一定有环</p>
<p>（11）简单路径、简单贿赂</p>
<ul>
<li>简单路径：顶点不重复出现的路径</li>
<li>简单回路：除第一个顶点和最后一个顶点外，其余顶点不重复出现的回路</li>
</ul>
<h3 id="2-存储结构">2.存储结构</h3>
<h4 id="（1）邻接矩阵法">（1）邻接矩阵法</h4>
<p>空间复杂度O(n^2)</p>
<p>无权图<br>
$$<br>
A[i][j] =<br>
\begin{cases}<br>
1,~~~~~~~若(v_i,v_j)或&lt;v_i.v_j&gt;是E(G)中的边\\<br>
0,~~~~~~~若(v_i,v_j)或&lt;v_i.v_j&gt;不是E(G)中的边\<br>
\end{cases}<br>
$$<br>
​	举例如下：</p>
<pre class="mermaid">graph LR;
A((1))
B((2))
C((3))
D((4))
A-->B
A-->C
C-->D
D-->A</pre>
<p>$$<br>
A_1=\left[<br>
\matrix{<br>
0 &amp; 1 &amp; 1 &amp; 0\<br>
0 &amp; 0 &amp; 0 &amp; 0\<br>
0 &amp; 0 &amp; 0 &amp; 1\<br>
1 &amp; 0 &amp; 0 &amp; 0\<br>
}<br>
\right]<br>
$$</p>
<p>有权图<br>
$$<br>
A[i][j] =<br>
\begin{cases}<br>
w_{ij},~~~~~~~~~~~若(v_i,v_j)或&lt;v_i.v_j&gt;是E(G)中的边\\<br>
0或∞,~~~~~~~若(v_i,v_j)或&lt;v_i.v_j&gt;不是E(G)中的边\<br>
\end{cases}<br>
$$<br>
举例如下：</p>
<pre class="mermaid">graph LR;
A((1))
B((2))
C((3))
D((4))
A--5-->B
A--8-->C
C--10-->D
D--21-->A</pre>
<p>$$<br>
A_2=\left[<br>
\matrix{<br>
∞ &amp; 5 &amp; 8 &amp; ∞\<br>
∞ &amp; ∞ &amp; ∞ &amp; ∞\<br>
∞ &amp; ∞ &amp; ∞ &amp; 10\<br>
21 &amp; ∞ &amp; ∞ &amp; ∞\<br>
}<br>
\right]<br>
$$</p>
<p>存储结构定义：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MaxVertextNum 100							<span class="comment">//顶点数目的最大值</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">char</span> VertexType;							<span class="comment">//顶点的数据类型</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">int</span> EdgeType;								<span class="comment">//带权图中边上权值的数据类型</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">    VertexType Vex[MaxVertextNum];						<span class="comment">//顶点表</span></span><br><span class="line">    Edgetype Edge[MaxVertextNum][MaxVertextNum];		<span class="comment">//邻接矩阵，边表</span></span><br><span class="line">    <span class="type">int</span> vexnum,arcnum;									<span class="comment">//图的当前顶点数和弧数</span></span><br><span class="line">&#125;MGraph;</span><br></pre></td></tr></table></figure>
<h4 id="（2）邻接表法">（2）邻接表法</h4>
<ul>
<li>无向图：存储空间O(|V|+2|E|)</li>
<li>有向图：存储空间O(|V|+|E|)</li>
</ul>
<p>顶点表结点结构</p>
<table>
<thead>
<tr>
<th style="text-align:center">顶点域</th>
<th style="text-align:center">边表头指针</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">data</td>
<td style="text-align:center">firstarc</td>
</tr>
</tbody>
</table>
<p>边表结点结构</p>
<table>
<thead>
<tr>
<th style="text-align:center">邻接点域</th>
<th style="text-align:center">指针域</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">adjvex</td>
<td style="text-align:center">nextarc</td>
</tr>
</tbody>
</table>
<p>存储结构定义</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MaxVertexNum 100							<span class="comment">//顶点数目的最大值</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">ArcNode</span>&#123;								<span class="comment">//边表结点</span></span><br><span class="line">    <span class="type">int</span> adjvex;									<span class="comment">//该弧所指向的顶点的位置</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">ArcNode</span> *next;						<span class="comment">//指向下一条弧的指针</span></span><br><span class="line">    <span class="comment">//InfoType info;							//网的边权值</span></span><br><span class="line">&#125;ArcNode;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">VNode</span>&#123;							<span class="comment">//顶点表结点</span></span><br><span class="line">    VertexType data;							<span class="comment">//顶点信息</span></span><br><span class="line">    ArcNode *first;								<span class="comment">//指向第一条依附该顶点的弧的指针</span></span><br><span class="line">&#125;VNode,AdiList[MaxVertexNum];</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">    AdiList vertices;							<span class="comment">//邻接表</span></span><br><span class="line">    <span class="type">int</span> vexnum,arcnum;							<span class="comment">//图的顶点数和弧数</span></span><br><span class="line">&#125;ALGraph;										<span class="comment">//ALGraph是以邻接表存储的图的类型</span></span><br></pre></td></tr></table></figure>
<h4 id="（3）十字链表法（有向图）">（3）十字链表法（有向图）</h4>
<p>图的十字链表表示不唯一，但一个十字链表表示确定一个图</p>
<p>弧结点</p>
<table>
<thead>
<tr>
<th style="text-align:center">tailvex</th>
<th style="text-align:center">headvex</th>
<th style="text-align:center">hlink</th>
<th style="text-align:center">tlink</th>
<th style="text-align:center">info</th>
</tr>
</thead>
</table>
<p>顶点结点</p>
<table>
<thead>
<tr>
<th style="text-align:center">data</th>
<th style="text-align:center">firstin</th>
<th style="text-align:center">firstout</th>
</tr>
</thead>
</table>
<img src="/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%9B%BE/十字链表法.png" style="zoom:80%;">
<h4 id="（4）邻接多重表（无向图）">（4）邻接多重表（无向图）</h4>
<p>顶点结点</p>
<table>
<thead>
<tr>
<th style="text-align:center">mark</th>
<th style="text-align:center">ivex</th>
<th style="text-align:center">ilink</th>
<th style="text-align:center">jvex</th>
<th style="text-align:center">jlink</th>
<th style="text-align:center">info</th>
</tr>
</thead>
</table>
<p>弧顶点</p>
<table>
<thead>
<tr>
<th style="text-align:center">data</th>
<th style="text-align:center">firstedge</th>
</tr>
</thead>
</table>
<img src="/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%9B%BE/邻接多重表.png" style="zoom:80%;">
<h3 id="3-基本算法实现">3.基本算法实现</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Adjacent</span>(G,x,y)：判断图G是否存在边&lt;x,y&gt;或(x,y)。</span><br><span class="line"><span class="built_in">Neighbors</span>(G,x)：列出图G中与结点x邻接的边。</span><br><span class="line"><span class="built_in">InsertVertex</span>(G,x)：在图G中插入顶点x。</span><br><span class="line"><span class="built_in">DeleteVertex</span>(G,x)：在图G中删除顶点x。</span><br><span class="line"><span class="built_in">AddEdge</span>(G,x,y)：若无边边(x,y)或有向边&lt;x,y&gt;不存在，则向图G中添加该边。</span><br><span class="line"><span class="built_in">RemoveEdge</span>(G,x,y)：若无边边(x,y)或有向边&lt;x,y&gt;存在，则向图G中删除该边。 </span><br><span class="line"><span class="built_in">FirstNeighbor</span>(G,x)：求图G中顶点x的第一个邻接点，若有则返回顶点号。若x没有邻接点或图中不存在x，则返回<span class="number">-1</span>。</span><br><span class="line"><span class="built_in">NextNeighbor</span>(G,x,y)：假设图G中顶点y是顶点x的一个邻接点，返回除y外顶点x的下一个邻接点的顶点号，若y是x的最后一个邻接点，则返回<span class="number">-1</span>。</span><br><span class="line"><span class="built_in">Get_edge_value</span>(G,x,y)：获取图中G中边(x,y)或&lt;x,y&gt;对应的权值。</span><br><span class="line"><span class="built_in">Set_edge_value</span>(G,x,y,v)：设置图中G中边(x,y)或&lt;x,y&gt;对应的权值为v。</span><br></pre></td></tr></table></figure>
<h2 id="第二节图的遍历算法">第二节图的遍历算法</h2>
<h3 id="1-广度优先搜索（BFS）">1.广度优先搜索（BFS）</h3>
<ul>
<li>邻接表：空间复杂度O(|V|)	时间复杂度O(|V|+|E|)</li>
<li>邻接矩阵：空间复杂度O(|V|)	时间复杂度O(|V|^2)</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> visited[MAX_VERTEX_NUM];				<span class="comment">//访问标记数组</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFSTraverse</span><span class="params">(Graph G)</span></span>&#123;					<span class="comment">//对图G进行广度优先遍历</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i&lt;G.vexnum;++i)</span><br><span class="line">        visited[i] = FALSE;					<span class="comment">//访问标记数组初始化</span></span><br><span class="line">    <span class="built_in">InitQueue</span>(Q);							<span class="comment">//初始化辅助队列Q</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i&lt;G.vexnum;++i)				<span class="comment">//从0号顶点开始遍历</span></span><br><span class="line">        <span class="keyword">if</span>(!visited[i])						<span class="comment">//对每个连通分量调用一次BFS</span></span><br><span class="line">            <span class="built_in">BFS</span>(G,i);						<span class="comment">//vi未访问过，从vi开始BFS</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFS</span><span class="params">(Graph G,<span class="type">int</span> v)</span></span>&#123;					<span class="comment">//从顶点v出发，广度优先遍历图G</span></span><br><span class="line">    <span class="built_in">visit</span>(v);								<span class="comment">//访问初始顶点v</span></span><br><span class="line">    visited[v] = TRUE;						<span class="comment">//对v做已访问标记</span></span><br><span class="line">    <span class="built_in">EnQueue</span>(Q,v);							<span class="comment">//顶点v入队列Q</span></span><br><span class="line">    <span class="keyword">while</span>(!<span class="built_in">osEmpty</span>(Q))&#123;</span><br><span class="line">        <span class="built_in">DeQueue</span>(Q,v);						<span class="comment">//顶点v出队列</span></span><br><span class="line">        <span class="keyword">for</span>(w = <span class="built_in">FirstNeighbor</span>(G,v);w&gt;=<span class="number">0</span>;w = <span class="built_in">NextNeighbor</span>(G,v,w))	<span class="comment">//检测v所有邻接点</span></span><br><span class="line">            <span class="keyword">if</span>(!visited[w])&#123;				<span class="comment">//w为v的尚未访问的邻接顶点</span></span><br><span class="line">                <span class="built_in">visit</span>(w);					<span class="comment">//访问顶点w</span></span><br><span class="line">                wisited[w] = TRUE;			<span class="comment">//对w做已访问标记</span></span><br><span class="line">                <span class="built_in">EnQueue</span>(Q,w);				<span class="comment">//顶点w入队列</span></span><br><span class="line">            &#125;<span class="comment">//if</span></span><br><span class="line">    &#125;<span class="comment">//while</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-深度优先搜索">2.深度优先搜索</h3>
<ul>
<li>邻接表：空间复杂度O(|V|)	时间复杂度O(|V|+|E|)</li>
<li>邻接矩阵：空间复杂度O(|V|)	时间复杂度O(|V|^2)</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> visited[MAX_VERTEX_NUM];				<span class="comment">//访问标记数组</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFSTraverse</span><span class="params">(Graph G)</span></span>&#123;					<span class="comment">//对图G进行深度优先遍历</span></span><br><span class="line">    <span class="keyword">for</span>(v = <span class="number">0</span>;v&lt;G.vexnum;++v)</span><br><span class="line">        visited[v] = FALSE;					<span class="comment">//访问标记数组初始化</span></span><br><span class="line">    <span class="keyword">for</span>(v = <span class="number">0</span>;v&lt;G.vexnum;++v)				<span class="comment">//从0号顶点开始遍历</span></span><br><span class="line">        <span class="keyword">if</span>(!visited[v])</span><br><span class="line">            <span class="built_in">DFS</span>(G,v);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFS</span><span class="params">(Graph G,<span class="type">int</span> v)</span></span>&#123;					<span class="comment">//从顶点v出发，深度优先遍历图G</span></span><br><span class="line">    <span class="built_in">visit</span>(v);								<span class="comment">//访问初始顶点v</span></span><br><span class="line">    visited[v] = TRUE;						<span class="comment">//对v做已访问标记</span></span><br><span class="line">    <span class="keyword">for</span>(w = <span class="built_in">FirstNeighbor</span>(G,v);w&gt;=<span class="number">0</span>;w = <span class="built_in">NextNeighbor</span>(G,v,w))</span><br><span class="line">        <span class="keyword">if</span>(!visited[w])&#123;					<span class="comment">//w为v的尚未访问的邻接顶点</span></span><br><span class="line">            <span class="built_in">DFS</span>(G,w);</span><br><span class="line">        &#125;<span class="comment">//if</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="第三节最小生成树">第三节最小生成树</h2>
<h3 id="1-性质">1.性质</h3>
<ul>
<li>最小生成树不是唯一的，即最小生成树的树形不唯一。当图G中的个边权值互不相等时，G的最小生成树时唯一的；若无向连通图G的边数比顶点数少1，即G本身就是一棵树，最小生成树就是它本身。</li>
<li>最小生成树的边的权值之和总是唯一的</li>
<li>最小生成树的边数为顶点数-1</li>
</ul>
<h3 id="2-普利姆算法（稠密图）">2.普利姆算法（稠密图）</h3>
<p>$$<br>
时间复杂度：O(|V|^2)<br>
$$</p>
<img src="/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%9B%BE/普利姆.png" style="zoom:80%;">
<h3 id="3-克鲁斯卡尔算法（稀疏图）">3.克鲁斯卡尔算法（稀疏图）</h3>
<p>$$<br>
时间复杂度：O(|E|log|E|)<br>
$$</p>
<img src="/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%9B%BE/克鲁斯卡尔.png" style="zoom:80%;">
<h2 id="第四节最短路径、拓扑排序和关键路径">第四节最短路径、拓扑排序和关键路径</h2>
<h3 id="1-最短路径">1.最短路径</h3>
<h4 id="（1）Dijkstra算法-只适合正数">（1）Dijkstra算法(只适合正数)</h4>
<p>$$<br>
时间复杂度：O(|V|^2)<br>
$$</p>
<p>dist[]：记录从源点v0到其他个顶点当前的最短路径长度。</p>
<p>path[]：path[i]表示从源点到顶点i之间的最短路径的前驱结点。</p>
<img src="/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%9B%BE/Dijkstra.png" style="zoom:80%;">
<h4 id="（2）Floyd算法">（2）Floyd算法</h4>
<p>$$<br>
时间复杂度：O(|V|^3)~~~~~~~~<br>
空间复杂度：O(|V|^2)<br>
$$</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Floyd</span><span class="params">(n)</span></span>&#123;</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> k=<span class="number">1</span>;k&lt;=n;k++)&#123;</span><br><span class="line">		<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">			<span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)&#123;</span><br><span class="line">				dist[i][j]=<span class="built_in">min</span>(dist[i][j],dist[i][k]+dist[k][j]);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（3）有向无环图DAG图">（3）有向无环图DAG图</h4>
<p>用来描述公共子式的表达式的有效工具</p>
<h3 id="2-拓扑排序-AOV网">2.拓扑排序(AOV网)</h3>
<pre class="mermaid">graph LR;
A((1))
B((2))
C((3))
D((4))
E((5))
A-->B
A-->D
B-->C
B-->D
D-->C
C-->E
D-->E</pre>
<table>
<thead>
<tr>
<th style="text-align:center">结点号</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">初始入度</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">第一轮</td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">第二轮</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">第三轮</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">第四轮</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">第五轮</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p>$$<br>
\begin{flalign}<br>
&amp;邻接表时间复杂度：O(|V|+|E|)\<br>
&amp;邻接矩阵时间复杂度：O(|V|^2)<br>
\end{flalign}<br>
$$</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">TopologicalSort</span><span class="params">(Graph G)</span></span>&#123;</span><br><span class="line">    <span class="built_in">InitStack</span>(S);							<span class="comment">//初始化栈，存储入度为0的顶点</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i&lt;G.vexnum;i++)</span><br><span class="line">        <span class="keyword">if</span>(indegree[i] == <span class="number">0</span>)</span><br><span class="line">            <span class="built_in">Push</span>(S,i);						<span class="comment">//将所有入度为0的顶点进栈</span></span><br><span class="line">    <span class="type">int</span> count = <span class="number">0</span>;							<span class="comment">//计数，记录当前已经输出的顶点数</span></span><br><span class="line">    <span class="keyword">while</span>(!<span class="built_in">IsEmpty</span>(S))&#123;						<span class="comment">//栈不空，则存在入度为0的顶点</span></span><br><span class="line">        <span class="built_in">Pop</span>(S,i);							<span class="comment">//栈顶元素出栈</span></span><br><span class="line">        print[count++] = i;					<span class="comment">//输出顶点i</span></span><br><span class="line">        <span class="keyword">for</span>(p = G.vertices[i].firstarc;p;p = p-&gt;nextarc)&#123;		</span><br><span class="line">            <span class="comment">//将所有i指向的顶点的入度-1，并且将入度减为0的顶点压入栈S</span></span><br><span class="line">            v = p-&gt;adjvex;</span><br><span class="line">            <span class="keyword">if</span>(!(--indegree[v]))</span><br><span class="line">                <span class="built_in">Push</span>(S,v);					<span class="comment">//入度为0，则入栈</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;<span class="comment">//while</span></span><br><span class="line">    <span class="keyword">if</span>(count&lt;G.vexnum)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;						<span class="comment">//排序失败，有向图中有回路</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;						<span class="comment">//拓扑排序成功</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-关键路径-AOE网">3.关键路径(AOE网)</h3>
<p>\begin{flalign}<br>
&amp;（1）事件v_k的最早发生时间ve(k)\<br>
&amp;指从源点v_1到顶点v_k的最长路径的长度。事件v_k的最早发生时间决定了所有从v_k开始的活动能够开工的最早时间。\<br>
&amp;（2）事件v_k的最迟发生时间vl(k)\<br>
&amp;指在不推迟整个工程完成的前提下，即保证它的后继时间v_j在其最迟发生时间vl(j)能够发生时，该事件最迟必须发生的时间。\<br>
&amp;（3）活动a_i的最早发生时间e(i)\<br>
&amp;指该活动弧的起点所表示的时间的最早发生时间\<br>
&amp;（4）活动a_i的最迟发生时间l(i)\<br>
&amp;指该活动弧的终点所表示时间的最迟发生时间与该活动所需时间之差。\<br>
\end{flalign}</p>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构之串</title>
    <url>/2023/04/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AC%AC%E5%9B%9B%E7%AB%A0%E4%B8%B2/</url>
    <content><![CDATA[<h1>第四章串</h1>
<h2 id="第一节串的概念和存储结构">第一节串的概念和存储结构</h2>
<h3 id="1-串的概念">1.串的概念</h3>
<p>​	由0个或多个字符组成的有效序列，一般记作<br>
$$<br>
S=‘a_1a_2a_3…a_n’~~~（n≥0）<br>
$$</p>
<span id="more"></span>
<h3 id="2-串的存储结构和基本算法的实现">2.串的存储结构和基本算法的实现</h3>
<h4 id="（1）定长顺序存储表示">（1）定长顺序存储表示</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MAXLEN 255		<span class="comment">//预定义最大串长255</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">	<span class="type">char</span> ch[MAXLEN];		<span class="comment">//每个分量存储一个字符</span></span><br><span class="line">	<span class="type">int</span> length;				<span class="comment">//串的实际长度</span></span><br><span class="line">&#125;SString;</span><br></pre></td></tr></table></figure>
<h4 id="（2）堆分配存储表示">（2）堆分配存储表示</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">    <span class="type">char</span> *ch;		<span class="comment">//按串长分配存储区，ch指向串的基地址</span></span><br><span class="line">    <span class="type">int</span> length;		<span class="comment">//串的长度</span></span><br><span class="line">&#125;HString;</span><br></pre></td></tr></table></figure>
<h4 id="（3）基本操作">（3）基本操作</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">StrAssign</span>(&amp;T,chars)：赋值操作。把串T赋值为chars。</span><br><span class="line"><span class="built_in">StrCopy</span>(&amp;T,S)：复制操作。由串S复制得到串T。</span><br><span class="line"><span class="built_in">StrEmpty</span>(S)：判空操作。若S为空串，则返回TRUE，否则返回FALSE。</span><br><span class="line"><span class="built_in">StrLength</span>(S)：求串长。返回串S的元素个数。</span><br><span class="line"><span class="built_in">ClearString</span>(&amp;S)：清空操作。将S清为空串。</span><br><span class="line"><span class="built_in">Concat</span>(&amp;T,S1,S2)：串联接。用T返回由S1和S2联接而成的新串</span><br><span class="line"><span class="built_in">SubString</span>(&amp;Sub,S,pos,len)：求子串。用Sub返回串S的第pos个字符起长度为len的子串。</span><br><span class="line"><span class="built_in">Index</span>(S,T)：定位操作。若主串S中存在与串T值相同的子串，则返回它在主串S中第一次出现的位置；否则函数值为<span class="number">0</span>。</span><br><span class="line"><span class="built_in">StrCompare</span>(S,T)：比较操作。若S&gt;T，则返回值&gt;<span class="number">0</span>；若S=T，则返回值=<span class="number">0</span>；若S&lt;T，则返回值&lt;<span class="number">0</span>。</span><br><span class="line"><span class="built_in">DestroyString</span>(&amp;S)：销毁中。将串S销毁。</span><br></pre></td></tr></table></figure>
<h2 id="第二节串的匹配算法">第二节串的匹配算法</h2>
<h3 id="1-BF算法（简单模式匹配算法）">1.BF算法（简单模式匹配算法）</h3>
<p>时间复杂度：最好O（n），最坏O（nm）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">BF</span><span class="params">(string S,string T,<span class="type">int</span> pos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = pos;</span><br><span class="line">    <span class="type">int</span> j = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>( i &lt;= S.<span class="built_in">size</span>() &amp;&amp; j &lt;= T.<span class="built_in">size</span>() )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>( S[i<span class="number">-1</span>] == T[j<span class="number">-1</span>] )</span><br><span class="line">        &#123;</span><br><span class="line">            i++;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            i = i-j+<span class="number">2</span>;<span class="comment">//i为母串S的匹配失败的位置，j为模式串S的匹配失败的位置，i-j为S第一次匹配位置之前的长度，</span></span><br><span class="line">            <span class="comment">//+2的原因是一个1是本次匹配的开始位置 ，另一个1是下一次匹配的开始位置。</span></span><br><span class="line">            j = <span class="number">1</span>;<span class="comment">//模式串的下一次匹配开始位置依旧是第一个字符</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>( j &gt; T.<span class="built_in">size</span>() )</span><br><span class="line">        <span class="keyword">return</span> i - T.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> pos;</span><br><span class="line">    string S,T;</span><br><span class="line">    <span class="keyword">while</span>( <span class="literal">true</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;请输入母串：&quot;</span>;</span><br><span class="line">        cin&gt;&gt;S;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;请输入模式串：&quot;</span>;</span><br><span class="line">        cin&gt;&gt;T;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;请输入在母串中开始寻找的位置（小于等于&quot;</span>&lt;&lt;S.<span class="built_in">size</span>()&lt;&lt;<span class="string">&quot;）：&quot;</span>;</span><br><span class="line">        cin&gt;&gt;pos;</span><br><span class="line">        <span class="keyword">while</span> ( pos &gt; S.<span class="built_in">size</span>() )</span><br><span class="line">        &#123;</span><br><span class="line">            cout&lt;&lt;<span class="string">&quot;请重新输入在母串中开始寻找的位置（小于等于&quot;</span>&lt;&lt;S.<span class="built_in">size</span>()&lt;&lt;<span class="string">&quot;）：&quot;</span>;</span><br><span class="line">            cin&gt;&gt;pos;</span><br><span class="line">        &#125;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;模式串在自母串第 &quot;</span>&lt;&lt;pos&lt;&lt;<span class="string">&quot; 位开始出现的位置为 &quot;</span>&lt;&lt;<span class="built_in">BF</span>(S,T,pos)&lt;&lt;endl&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="2-KMP算法">2.KMP算法</h3>
<h4 id="（1）next数组">（1）next数组</h4>
<p>以‘ababa’举例说明：</p>
<ul>
<li>'a’的前缀和后缀都是空集，最长相等前后缀长度为0；</li>
<li>'ab’的前缀为{a}，后缀为{b}，{a}且{b}=空集，最长相等前后缀长度为0；</li>
<li>'aba’的前缀是{a,ab}，后缀是{a,ba}，{a,ab}且{a,ba}={a}，最长相等前后缀长度为1；</li>
<li>'abab’的前缀是{a,ab,aba}，后缀是{a,ba,bab}，{a,ab,aba}且{a,ba,bab}={a}，最长相等前后缀长度为1；</li>
<li>'ababa’的前缀是{a,ab,aba,abab}，后缀是{a,ba,aba,baba}，{a,ab,aba,abab}且{a,ba,aba,baba}={a,aba}，最长相等前后缀长度为3；</li>
</ul>
<p>时间复杂度：O（n+m）；优点：主串不回溯</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Next</span><span class="params">(<span class="type">char</span>*T,<span class="type">int</span> *next)</span>&#123;</span><br><span class="line">    <span class="type">int</span> i=<span class="number">1</span>;</span><br><span class="line">    next[<span class="number">1</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> j=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i&lt;<span class="built_in">strlen</span>(T)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (j==<span class="number">0</span>||T[i<span class="number">-1</span>]==T[j<span class="number">-1</span>]) &#123;</span><br><span class="line">            i++;</span><br><span class="line">            j++;</span><br><span class="line">            next[i]=j;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            j=next[j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">KMP</span><span class="params">(<span class="type">char</span> * S,<span class="type">char</span> * T)</span>&#123;</span><br><span class="line">    <span class="type">int</span> next[<span class="number">10</span>];</span><br><span class="line">    Next(T,next);<span class="comment">//根据模式串T,初始化next数组</span></span><br><span class="line">    <span class="type">int</span> i=<span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> j=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (i&lt;=<span class="built_in">strlen</span>(S)&amp;&amp;j&lt;=<span class="built_in">strlen</span>(T)) &#123;</span><br><span class="line">        <span class="comment">//j==0:代表模式串的第一个字符就和当前测试的字符不相等；S[i-1]==T[j-1],如果对应位置字符相等，两种情况下，指向当前测试的两个指针下标i和j都向后移</span></span><br><span class="line">        <span class="keyword">if</span> (j==<span class="number">0</span> || S[i<span class="number">-1</span>]==T[j<span class="number">-1</span>]) &#123;</span><br><span class="line">            i++;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            j=next[j];<span class="comment">//如果测试的两个字符不相等，i不动，j变为当前测试字符串的next值</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (j&gt;<span class="built_in">strlen</span>(T)) &#123;<span class="comment">//如果条件为真，说明匹配成功</span></span><br><span class="line">        <span class="keyword">return</span> i-(<span class="type">int</span>)<span class="built_in">strlen</span>(T);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> i=KMP(<span class="string">&quot;ababcabcacbab&quot;</span>,<span class="string">&quot;abcac&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d&quot;</span>,i);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="（2）nextval数组">（2）nextval数组</h4>
<table>
<thead>
<tr>
<th style="text-align:center">j</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">模式串T</td>
<td style="text-align:center">a</td>
<td style="text-align:center">b</td>
<td style="text-align:center">a</td>
<td style="text-align:center">b</td>
<td style="text-align:center">a</td>
<td style="text-align:center">a</td>
<td style="text-align:center">a</td>
<td style="text-align:center">b</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">next</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">3</td>
<td style="text-align:center">4</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">nextval</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">4</td>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>考研</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之三大算法</title>
    <url>/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B8%89%E5%A4%A7%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>以算法区分深度学习应用，算法类别可分成三大类：</p>
<ul>
<li>常用于影像数据进行分析处理的<strong>卷积神经网络(简称CNN)</strong></li>
<li>文本分析或自然语言处理的<strong>递归神经网络(简称RNN)</strong></li>
<li>常用于数据生成或非监督式学习应用的<strong>生成对抗网络(简称GAN)</strong></li>
</ul>
<span id="more"></span>
<h1><strong>卷积神经网络CNN</strong></h1>
<p>因为应用种类多样，本篇会以算法类别细分，CNN主要应用可分为图像分类(image classification)、目标检测(object detection)及语义分割(semantic segmentation)。</p>
<h2 id="1、图像分类-Classification"><strong>1、图像分类(Classification)</strong></h2>
<p>将图像进行类别筛选，通过深度学习方法识别图片属于哪种分类类别，其主要重点在于一张图像只包含一种分类类别，即使该影像内容可能有多个目标，所以单纯图像分类的应用并不普遍。不过由于单一目标识别对深度学习算法来说是正确率最高的，所以实际上很多应用会先通过目标检测方法找到该目标，再缩小撷取影像范围进行图像分类。所以只要是目标检测可应用的范围，通常也会使用图像分类方法。</p>
<p>图像分类也是众多用来测试算法基准的方法之一，常使用由ImageNet举办的大规模视觉识别挑战赛(ILSVRC)中提供的公开图像数据进行算法测试。图像分类属于CNN的基础，其相关算法也是最易于理解，故初学者应该都先以图像分类做为跨入深度学习分析的起步。使用图像分类进行识别，通常输入为一张图像，而输出为一个文字类别。</p>
<h2 id="2、目标检测-Object-Detection"><strong>2、目标检测 (Object Detection)</strong></h2>
<p>一张图像内可有一或多个目标物，目标物也可以是属于不同类别。算法主要能达到两种目的：找到目标坐标及识别目标类别。简单来说，就是除了需要知道目标是什么，还需要知道它在哪个位置。</p>
<p>目标检测应用非常普遍，包含文章开头提到的人脸识别相关技术结合应用，或是制造业方面的瑕疵检测，甚至医院用于X光、超音波进行特定身体部位的病况检测等。目标识别的基础可想象为在图像分类上增加标示位置的功能，故学习上也不离图像分类的基础。不过目标检测所标示的坐标通常为矩形或方形，仅知道目标所在位置，并无法针对目标的边缘进行描绘，所以常用见的应用通常会以「知道目标位置即可」作为目标。</p>
<p>最常见的算法为YOLO及R-CNN。其中YOLO因算法特性具有较快的识别速度，目前已来到v3版本。R-CNN针对目标位置搜寻及辨识算法和YOLO稍有不同，虽然速度稍较YOLO慢，但正确率稍高于YOLO。使用目标检测进行识别，通常输入为一张图像，而输出为一个或数个文字类别和一组或多组坐标。</p>
<h2 id="3、语义分割-Semantic-Segmentation"><strong>3、语义分割 (Semantic Segmentation)</strong></h2>
<p>算法会针对一张图像中的每个像素进行识别，也就是说不同于目标检测，语义分割可以正确区别各目标的边界像素，简单来说，语义分割就是像素级别的图像分类，针对每个像素进行分类。当然这类应用的模型就会需要较强大的GPU和花较多时间进行训练。</p>
<p>常见应用类似目标检测，但会使用在对于图像识别有较高精细度，如需要描绘出目标边界的应用。例如制造业上的瑕疵检测，针对不规则形状的大小瑕疵，都可以正确描绘。医学上常用于分辨病理切片上的病变细胞，或是透过MRI、X光或超音波描绘出病变的区块及类别。算法如U-Net或是Mask R-CNN都是常见的实作方法。使用语义分割进行识别，通常输入为一张图像，而输出也为一张等大小的图像，但图像中会以不同色调描绘不同类别的像素。</p>
<h1><strong>递归神经网络RNN</strong></h1>
<p>有别于CNN，RNN的特色在于可处理图像或数值数据，并且由于网络本身具有记忆能力，可学习具有前后相关的数据类型。例如进行语言翻译或文本翻译，一个句子中的前后词汇通常会有一定的关系，但CNN网络无法学习到这层关系，而RNN因具有内存，所以性能会比较好。因为可以通过RNN进行文字理解，其他应用如输入一张图像，但是输出为一段关于图像叙述的句子。</p>
<p>RNN虽然解决了CNN无法处理的问题，但其本身仍然有些缺点，所以现在很多RNN的变形网络，其中最常被使用的网络之一为长短记忆网络(Long Short-Term Network，简称LSTM)。这类网络的输入数据不限于是图像或文字，解决的问题也不限于翻译或文字理解。数值相关数据也同样可以使用LSTM进行分析，例如工厂机器预测性维修应用，可透过LSTM分析机台震动讯号，预测机器是否故障。在医学方面，LSTM可协助解读数以千计的文献，并找出特定癌症的相关信息，例如肿瘤部位、肿瘤大小、期数，甚至治疗方针或存活率等等，透过文字理解进行解析。也可结合图像识别提供病灶关键词，以协助医生撰写病理报告。</p>
<h1><strong>生成对抗网络GAN</strong></h1>
<p>除了深度学习外，有一种新兴的网络称为强化学习(Reinforcement Learning)，其中一种很具有特色的网络为生成式对抗网络(GAN)。</p>
<p>GAN的应用相关论文成长幅度相当大</p>
<p>深度学习领域最需要的是数据，但往往不是所有应用都可以收集到大量数据，并且数据也需要人工进行标注，这是非常消耗时间及人力成本。图像数据可以通过旋转、裁切或改变明暗等方式增加数据量，但如果数据还是不够呢？目前有相当多领域透过GAN方法生成非常近似原始数据的数据，例如3D-GAN就是可以生成高质量3D对象。当然，比较有趣的应用例如人脸置换或表情置换。</p>
<p>另外，SRGAN (Super Resolution GAN)可用于提高原始图像的分辨率，将作为低分辨率影像输入进GAN模型，并生成较高画质的影像(如下图)。这样的技术可整合至专业绘图软件中，协助设计师更有效率完成设计工作。</p>
<p>NVIDIA也有提供一些基于GAN的平台的应用，包含透过GauGAN网络，仅需绘制简单的线条，即可完成漂亮的画作，并且还能随意修改场景的风格。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（一）CNN原理概述</title>
    <url>/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h1><strong>卷积神经网络的架构</strong></h1>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/卷积神经网络的架构.png" alt="卷积神经网络的架构" style="zoom:80%;">
<span id="more"></span>
<h1><strong>CNN解决了什么问题？</strong></h1>
<p>CNN，是近年发展起来的并引起广泛重视的一种高效识别方法，可以说是深度学习算法应用最成功的领域之一，其价值在于能够将大数据量的图片有效地降维成小数据量且不影响结果，同时与人类视觉原理类似，CNN能够较完整地保留图片的特征。</p>
<p>卷积神经网络包括一维卷积神经网络，二维卷积神经网络以及三维卷积神经网络。一维卷积神经网络主要用于序列类的数据处理，二维卷积神经网络常应用于图像类文本的识别，三维卷积神经网络主要应用于医学图像以及视频类数据识别。</p>
<p>在 CNN 出现之前，图像对于人工智能来说一直是一个难题，问题的主要原因有2个：</p>
<ul>
<li><strong>需要处理的数据量太大</strong></li>
<li><strong>保留图像特征</strong></li>
</ul>
<p><strong>需要处理的数据量太大</strong></p>
<p>图像是由每个带有颜色的像素构成的，且每个像素都有RGB（可简单理解为光学三原色：红、绿、蓝）3个参数来表示颜色信息。</p>
<p>假如现在需要处理一张1000×1000像素的图片，就需要处理1000×1000×3=3,000,000个参数！如此大量的数据处理起来是非常消耗资源的，而且这还只是一张不算太大的图片。</p>
<p><strong>保留图像特征</strong></p>
<p>假如将一张图片划分为四个区域，其中一个区域中有圆形表示为数字1，没有圆形则表示为0，那么圆形的位置不同就会产生完全不同的数据表达，上述的这个过程就相当于是传统的图片数字化过程简化版。</p>
<p>对于上述两个问题，CNN通过将复杂问题简化和保留图像特征就较为完美地解决了，那么，CNN是如何进行实现的呢？</p>
<h1><strong>CNN的基本原理</strong></h1>
<h2 id="层级结构"><strong>层级结构</strong></h2>
<p>一个卷积神经网络主要由以下 5 层组成：</p>
<ul>
<li>数据输入层/ Input layer</li>
<li>卷积计算层/ CONV layer</li>
<li>ReLU 激励层 / ReLU layer</li>
<li>池化层 / Pooling layer</li>
<li>全连接层 / FC layer</li>
</ul>
<h3 id="数据输入层">数据输入层</h3>
<p>该层要做的处理主要是对原始图像数据进行预处理，其中包括：</p>
<ul>
<li><strong>去均值</strong>：把输入数据各个维度都中心化为 0，如下图所示，其目的就是把样本的中心拉回到坐标系原点上。</li>
<li><strong>归一化</strong>：幅度归一化到同样的范围，如下所示，即减少各维度数据取值范围的差异而带来的干扰，比如，我们有两个维度的特征 A 和 B，A 范围是 0 到 10，而 B 范围是 0 到 10000，如果直接使用这两个特征是有问题的，好的做法就是归一化，即 A 和 B 的数据都变为 0 到 1 的范围。</li>
<li><strong>PCA/白化</strong>：用 PCA 降维；白化是对数据各个特征轴上的幅度归一化</li>
</ul>
<p>去均值与归一化效果图：</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/去均值与归一化效果图.png" style="zoom:80%;">
<p>去相关与白化效果图：</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/去相关与白化效果图.png" style="zoom:80%;">
<h3 id="卷积计算层">卷积计算层</h3>
<p>这一层就是卷积神经网络最重要的一个层次，也是“卷积神经网络”的名字来源。</p>
<p>在这个卷积层，有两个关键操作：</p>
<ul>
<li><strong>局部关联</strong>。每个神经元看做一个滤波器(filter)</li>
<li><strong>窗口(receptive field)滑动</strong>， filter 对局部数据计算</li>
</ul>
<p>先介绍卷积层遇到的几个名词：</p>
<ul>
<li><strong>深度/depth</strong>（解释见下图）</li>
<li><strong>步幅/stride</strong> （窗口一次滑动的长度）</li>
<li><strong>填充值/zero-padding</strong></li>
</ul>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/卷积计算层.png" style="zoom:80%;">
<p>现在，要改变每一层的行为，有两个主要参数是我们可以调整的。选择了过滤器的尺寸以后，我们还需要选择步幅（stride）和填充（padding）。</p>
<p>步幅控制着过滤器围绕输入内容进行卷积计算的方式。在第一部分我们举的例子中，过滤器通过每次移动一个单元的方式对输入内容进行卷积。过滤器移动的距离就是步幅。在那个例子中，步幅被默认设置为 1。步幅的设置通常要确保输出内容是一个整数而非分数。让我们看一个例子。想象一个 7 x 7 的输入图像，一个 3 x 3 过滤器（简单起见不考虑第三个维度），步幅为 1。这是一种惯常的情况。</p>
<p><img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/%E5%8D%B7%E7%A7%AF-%E6%AD%A5%E9%95%BF1.png" alt="img"></p>
<p>如果步幅增加到 2，输出内容会怎么样。</p>
<p><img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/%E5%8D%B7%E7%A7%AF-%E6%AD%A5%E9%95%BF2.png" alt="img"></p>
<p>所以，正如你能想到的，感受野移动了两个单元，输出内容同样也会减小。注意，如果试图把我们的步幅设置成 3，那我们就会难以调节间距并确保感受野与输入图像匹配。正常情况下，程序员如果想让接受域重叠得更少并且想要更小的空间维度（spatial dimensions）时，他们会增加步幅。</p>
<p><strong>填充值是什么呢？</strong></p>
<p>在此之前，想象一个场景：当你把 5 x 5 x 3 的过滤器用在 32 x 32 x 3 的输入上时，会发生什么？输出的大小会是 28 x 28 x 3。注意，这里空间维度减小了。如果我们继续用卷积层，尺寸减小的速度就会超过我们的期望。在网络的早期层中，我们想要尽可能多地保留原始输入内容的信息，这样我们就能提取出那些低层的特征。比如说我们想要应用同样的卷积层，但又想让输出量维持为 32 x 32 x 3 。为做到这点，我们可以对这个层应用大小为 2 的零填充（zero padding）。零填充在输入内容的边界周围补充零。如果我们用两个零填充，就会得到一个 36 x 36 x 3 的输入卷。</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/填充值.png" style="zoom:80%;">
<p>如果我们在输入内容的周围应用两次零填充，那么输入量就为 32×32×3。然后，当我们应用带有 3 个 5×5×3 的过滤器，以 1 的步幅进行处理时，我们也可以得到一个 32×32×3 的输出</p>
<p>如果你的步幅为 1，而且把零填充设置为</p>
<p>\begin{flalign}<br>
Zero~Padding = (K-1)/2<br>
\end{flalign}</p>
<p>K 是过滤器尺寸，那么输入和输出内容就总能保持一致的空间维度。</p>
<p>计算任意给定卷积层的输出的大小的公式是</p>
<p>\begin{flalign}<br>
O = (W-K+2P)/S + 1<br>
\end{flalign}</p>
<p>其中 O 是输出尺寸，K 是过滤器尺寸，P 是填充，S 是步幅。</p>
<h4 id="卷积的计算">卷积的计算</h4>
<p>下面蓝色矩阵周围有一圈灰色的框，那些就是上面所说到的填充值</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/卷积的计算.png" style="zoom:80%;">
<p>这里的蓝色矩阵就是输入的图像，粉色矩阵就是卷积层的神经元，这里表示了有两个神经元（w0,w1）。绿色矩阵就是经过卷积运算后的输出矩阵，这里的步长设置为 2。</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/卷积的计算-2.png" style="zoom:80%;">
<p>蓝色的矩阵(输入图像)对粉色的矩阵（filter）进行矩阵内积计算并将三个内积运算的结果与偏置值 b 相加（比如上面图的计算：2+（-2+1-2）+（1-2-2） + 1= 2 - 3 - 3 + 1 = -3），计算后的值就是绿框矩阵的一个元素。</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/卷积层-降维.png" style="zoom:80%;">
<p>下面的动态图形象地展示了卷积层的计算过程：</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/卷积层计算过程.gif" style="zoom: 80%">
<h4 id="参数共享机制">参数共享机制</h4>
<p>在卷积层中每个神经元连接数据窗的权重是固定的，每个神经元只关注一个特性。神经元就是图像处理中的滤波器，比如边缘检测专用的 Sobel 滤波器，即卷积层的每个滤波器都会有自己所关注一个图像特征，比如垂直边缘，水平边缘，颜色，纹理等等，这些所有神经元加起来就好比就是整张图像的特征提取器集合。</p>
<p>需要估算的权重个数减少: AlexNet 1 亿 =&gt; 3.5w</p>
<p>一组固定的权重和不同窗口内数据做内积: 卷积</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/卷积效果图.png" style="zoom:80%;">
<h3 id="非线性层（或激活层）">非线性层（或激活层）</h3>
<p>把卷积层输出结果做非线性映射。</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/激活层.png" style="zoom:80%;">
<p>CNN 采用的激活函数一般为 ReLU(The Rectified Linear Unit/修正线性单元)，它的特点是收敛快，求梯度简单，但较脆弱，图像如下。</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/激活函数图像.png" style="zoom:80%;">
<p><strong>激励层的实践经验：</strong></p>
<p>①不要用 sigmoid！不要用 sigmoid！不要用 sigmoid！</p>
<p>② 首先试 RELU，因为快，但要小心点</p>
<p>③ 如果 2 失效，请用 Leaky ReLU 或者 Maxout</p>
<p>④ 某些情况下 tanh 倒是有不错的结果，但是很少</p>
<p>参见 Geoffrey Hinton（即深度学习之父）的论文：Rectified Linear Units Improve Restricted Boltzmann Machines <strong>墙裂推荐此论文！</strong></p>
<h3 id="池化层">池化层</h3>
<p>池化层夹在连续的卷积层中间， 用于压缩数据和参数的量，减小过拟合。</p>
<p>简而言之，如<strong>果输入是图像的话，那么池化层的最主要作用就是压缩图像。</strong></p>
<p>池化层的具体作用：</p>
<ul>
<li><strong>特征不变性</strong>，也就是我们在图像处理中经常提到的特征的尺度不变性，池化操作就是图像的 resize，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。</li>
<li><strong>特征降维</strong>，我们知道一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类冗余信息去除，把最重要的特征抽取出来，这也是池化操作的一大作用。</li>
<li>在一定程度上<strong>防止过拟合</strong>，更方便优化。</li>
</ul>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/池化层.png" style="zoom:80%;">
<p>池化层用的方法有 Max pooling 和 average pooling，而实际用的较多的是 Max pooling。这里就说一下 Max pooling，其实思想非常简单。</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/池化层方法.png" style="zoom:80%;">
<p>对于每个 2 * 2 的窗口选出最大的数作为输出矩阵的相应元素的值，比如输入矩阵第一个 2 * 2 窗口中最大的数是 6，那么输出矩阵的第一个元素就是 6，如此类推。</p>
<h3 id="全连接层">全连接层</h3>
<p>两层之间所有神经元都有权重连接，通常全连接层在卷积神经网络尾部。也就是跟传统的神经网络神经元的连接方式是一样的：</p>
<img src="/2023/04/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B9%8BCNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89CNN%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0/全连接层.PNG" style="zoom:80%;">
<p>一般 CNN 结构依次为</p>
<ul>
<li>INPUT</li>
<li>[ [ CONV -&gt; RELU ] N -&gt; POOL ? ] M</li>
<li>[ FC -&gt; RELU ] * K</li>
<li>FC</li>
</ul>
<h1><strong>说明</strong></h1>
<h2 id="训练算法">训练算法</h2>
<ul>
<li>同一般机器学习算法，先定义 Loss function，衡量和实际结果之间差距。</li>
<li>找到最小化损失函数的 W 和 b， CNN 中用的算法是 SGD（随机梯度下降）。</li>
</ul>
<h2 id="优缺点">优缺点</h2>
<p><strong>优点</strong></p>
<ul>
<li>共享卷积核，对高维数据处理无压力</li>
<li>无需手动选取特征，训练好权重，即得特征分类效果好</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>需要调参，需要大样本量，训练最好要 GPU</li>
<li>物理含义不明确（也就说，我们并不知道没个卷积层到底提取到的是什么特征，而且神经网络本身就是一种难以解释的“黑箱模型”）</li>
</ul>
<h2 id="典型-CNN">典型 CNN</h2>
<ul>
<li>LeNet，这是最早用于数字识别的 CNN</li>
<li>AlexNet， 2012 ILSVRC 比赛远超第 2 名的 CNN，比LeNet 更深，用多层小卷积层叠加替换单大卷积层。</li>
<li>ZF Net， 2013 ILSVRC 比赛冠军</li>
<li>GoogLeNet， 2014 ILSVRC 比赛冠军</li>
<li>VGGNet， 2014 ILSVRC 比赛中的模型，图像识别略差于 GoogLeNet，但是在很多图像转化学习问题(比如 object detection)上效果奇好</li>
</ul>
<h2 id="fine-tuning">fine-tuning</h2>
<p><strong>何谓 fine-tuning？</strong></p>
<p>fine-tuning 就是使用已用于其他目标、预训练好模型的权重或者部分权重，作为初始值开始训练。</p>
<p>那为什么我们不用随机选取选几个数作为权重初始值？原因很简单，第一，自己从头训练卷积神经网络容易出现问题；第二，fine-tuning 能很快收敛到一个较理想的状态，省时又省心。</p>
<p><strong>那 fine-tuning 的具体做法是？</strong></p>
<ul>
<li>复用相同层的权重，新定义层取随机权重初始值</li>
<li>调大新定义层的的学习率，调小复用层学习率</li>
</ul>
<h2 id="常用框架">常用框架</h2>
<p><strong>Caffe</strong></p>
<ul>
<li>源于 Berkeley 的主流 CV 工具包，支持 C++,python,matlab</li>
<li>Model Zoo 中有大量预训练好的模型供使用</li>
</ul>
<p><strong>PyTorch</strong></p>
<ul>
<li>Facebook 用的卷积神经网络工具包</li>
<li>通过时域卷积的本地接口，使用非常直观</li>
<li>定义新网络层简单</li>
</ul>
<p><strong>TensorFlow</strong></p>
<ul>
<li>Google 的深度学习框架</li>
<li>TensorBoard 可视化很方便</li>
<li>数据和模型并行化好，速度快</li>
</ul>
<h1><strong>总结</strong></h1>
<p>卷积网络在本质上是一种输入到输出的映射，它能够学习大量的输入与输出之间的映射关系，而不需要任何输入和输出之间的精确的数学表达式，只要用已知的模式对卷积网络加以训练，网络就具有输入输出对之间的映射能力。</p>
<p>CNN 一个非常重要的特点就是头重脚轻（越往输入权值越小，越往输出权值越多），呈现出一个倒三角的形态，这就很好地避免了 BP 神经网络中反向传播的时候梯度损失得太快。</p>
<p>卷积神经网络 CNN 主要用来识别位移、缩放及其他形式扭曲不变性的二维图形。由于 CNN 的特征检测层通过训练数据进行学习，所以在使用 CNN 时，避免了显式的特征抽取，而隐式地从训练数据中进行学习；再者由于同一特征映射面上的神经元权值相同，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的一大优势。卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性，其布局更接近于实际的生物神经网络，权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点避免了特征提取和分类过程中数据重建的复杂度。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十三）MobileNetv1v2v3网络详解</title>
    <url>/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1>MobileNet详解</h1>
<p>在传统的卷积神经网络中，内存需求大、运算量大，导致无法在移动设备以及嵌入式设备上运行。在之前学习的网络结构中，例如VGG16的权重大小有400+M、ResNet的152层模型权重大小能到达600+M。如此大的模型参数是不可能在移动设备以及嵌入式设备上运行的。</p>
<p>MobileNet网络是由由google团队在2017年提出的，专注于移动端或者嵌入式设备中的轻量级CNN网络。相比传统卷积神经网络，在准确率小幅降低的前提下大大减少模型参数与运算量。(相比VGG16准确率减少了0.9%，但模型参数只有VGG的1/32)。</p>
<h2 id="MobileNet-v1">MobileNet v1</h2>
<p><strong>MobileNetv1版本</strong>原论文：<a href="https://arxiv.org/abs/1704.04861">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></p>
<p>论文网络中的亮点：</p>
<ul>
<li><strong>Depthwise Convolution</strong>（简称DW卷积，大大减少运算量和参数数量）</li>
<li>增加超参数$\alpha$、$\beta$（人为设定，$\alpha$控制卷积层卷积核的个数、$\beta$控制输入图像大小）</li>
</ul>
<h3 id="DW卷积">DW卷积</h3>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/DW卷积.png" alt="DW卷积" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>传统卷积过程</strong></p>
<blockquote>
<p>输入一个深度为3的特征矩阵，经过4个卷积核进行卷积，每个卷积核的深度与输入特征矩阵的深度是相同的，所以每个卷积核深度也为3。又因输出特征矩阵的深度是由卷积核的个数决定的，因此最终输出特征矩阵的深度为4。</p>
<p><strong>总结：</strong></p>
<ul>
<li>卷积核channel = 输入特征矩阵channel</li>
<li>输出特征矩阵channel = 卷积核个数</li>
</ul>
</blockquote>
<p><strong>DW卷积过程</strong></p>
<blockquote>
<p>输入一个深度为3的特征矩阵，经过3个卷积核进行卷积，且卷积核深度为1，也就是说一个卷积核对应输入特征矩阵的一个channel，再得到相应的输出特征矩阵的一个channel。既然一个卷积核负责输入特征矩阵的一个深度，那么卷积核的个数应该和输入特征矩阵的深度相同。又因为每一个卷积核与输入特征矩阵的一个channel进行卷积之后得到一个输出特征矩阵的channel，那么输出特征矩阵的深度与卷积核的个数相同，也和输入特征矩阵的深度相同。</p>
<p><strong>总结：</strong></p>
<ul>
<li>卷积核channel = 1</li>
<li>输入特征矩阵channel = 卷积核个数 = 输出特征矩阵channel</li>
</ul>
</blockquote>
<h3 id="Depthwise-Separable-Conv"><strong>Depthwise Separable Conv</strong></h3>
<blockquote>
<p>也叫做深度可分的卷积操作，由两部分组成，第一部分由DW卷积，第二部分为PW卷积。PW卷积实际上相当于普通卷积，只不过卷积核的大小为1。由下图所示，卷积层中卷积核的深度 = 1。</p>
<p>通常情况下DW卷积和PW卷积是一起使用的。</p>
</blockquote>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/PW卷积.png" alt="PW卷积" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h3 id="DW-PW卷积和普通卷积的区别">DW&amp;PW卷积和普通卷积的区别</h3>
<p>下图（上左）为普通卷积操作，下图（下左）为DW卷积操作，下图（下右）为PW卷积操作，二者结合为深度可分卷积操作。</p>
<p>在普通卷积中，通过卷积操作之后，得到的是channel = 4的特征矩阵；在DW&amp;PW卷积操作之后，得到的同样是channel = 4的特征矩阵。</p>
<blockquote>
<p>参数代表含义：$D_F$：输入特征矩阵的宽高；$D_K$：卷积核的大小；M：输入特征矩阵的深度；N：输出特征矩阵的深度</p>
<p><strong>普通卷积计算量</strong>：卷积核的高x卷积核的宽x输入特征矩阵的深度x输出特征矩阵的深度x输入特征矩阵的高x输入特征矩阵的宽（默认stride = 1）</p>
<p><strong>DW&amp;PW卷积计算量</strong>：</p>
<ul>
<li>DW：卷积核的大小x输入特征矩阵的深度x输入特征矩阵的高宽</li>
<li>PW（相当于普通的卷积）：卷积核的高和宽（都是1）x输入特征矩阵的深度x输出特征矩阵的深度x输入特征矩阵的高宽（默认stride = 1）</li>
</ul>
</blockquote>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/深度可分卷积和普通卷积的参数区别.png" alt="深度可分卷积和普通卷积的参数区别" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>理论上，普通卷积计算量是DW&amp;PW卷积的8~9倍</strong></p>
<h3 id="MobileNet-v1网络结构参数">MobileNet v1网络结构参数</h3>
<p>Filter Shape：3 x 3 x 3 x 32分别指的是卷积核的高宽、深度、个数</p>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/MobileNetv1网络参数.png" alt="MobileNetv1网络参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>超参数$\alpha$、$\beta$</strong></p>
<ul>
<li>$\alpha$：卷积核个数的倍率，用来控制卷积过程中所采用卷积核的个数</li>
<li>$\beta$：分辨率的参数，用来控制输入图像的大小</li>
</ul>
<p>大多数人发现，DW卷积在训练完之后的部分卷积核容易废掉，即卷积核参数大部分为0，也就是说DW卷积核没有起到作用。针对这个问题，在MobileNet v2版本中有一定的改善。</p>
<h2 id="MobileNet-v2">MobileNet v2</h2>
<p>MobileNet v2网络是由google团队在2018年提出的，相比MobileNet v1网络，准确率更高，模型更小。原论文：<a href="https://arxiv.org/abs/1801.04381">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></p>
<p>网络中的亮点：</p>
<ul>
<li>Inverted Residuals（倒残差结构）</li>
<li>Linear Bottlenecks</li>
</ul>
<h3 id="Inverted-Residuals">Inverted Residuals</h3>
<p><strong>Residual block</strong></p>
<blockquote>
<p>对输入特征矩阵采用1x1卷积核进行降维处理，之后经过3x3的卷积核及逆行卷积处理，再通过1x1的卷积核进行升维，之后再输出特征矩阵。<strong>这就形成两边大中间小的瓶颈结构。</strong></p>
<p>注意：采用ReLU激活函数</p>
</blockquote>
<p><strong>Inverted residual block</strong></p>
<blockquote>
<p>对输入特征矩阵采用1x1卷积核进行升维处理，之后经过3x3的卷积核进行DW卷积，再通过1x1的卷积核进行降维处理，之后在输出特征矩阵。<strong>这就形成两边小中间大的橄榄球结构。</strong></p>
<p>注意：采用ReLU6激活函数</p>
</blockquote>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Inverted Residual结构.png" alt="Inverted Residual结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>ReLU6激活函数</strong></p>
<blockquote>
<p>在普通的ReLU激活函数中，当输入值&lt;0时，默认将输出置0；当输入值&gt;0时，即不进行处理。在ReLU6激活函数中，在输入值&lt;0，以及 [ 0, 6 ] 的区间时处理都一致，但在输入值&gt;6时，将会将输出值一直为6。</p>
</blockquote>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/ReLU6激活函数.png" alt="ReLU6激活函数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); zoom: 50%;">
<h3 id="Linear-Bottlenecks">Linear Bottlenecks</h3>
<p>在论文中是针对Inverted residual结构的最后一个1x1的卷积层，使用线性激活函数而不是之前的ReLU激活函数。在下图中是作者在原文中描述为什么在最后一个1x1卷积层不使用ReLU激活函数原因的实验证明。</p>
<blockquote>
<p>首先输入的是一个2维矩阵，channel = 1；之后采用不同维度的matrix T 将输入进行变化，变化到更高的维度，再通过ReLU激活函数得到输出值。之后再使用T矩阵的逆矩阵$T^{-1}$，将输出的矩阵还原回2维的矩阵。当matrix T的维度是2，3的时候（即还原回去之后），所对应的即是图中的Output/dim = 2，Output/dim = 3</p>
<p>由图中可以看到，当被还原之后，图像中已经丢失了很多信息，随着matrix T维度不断的加深，丢失的信息就越来越少。因此<strong>ReLU激活函数对低维特征信息造成大量损失，而对于高维特征信息造成的损失很小</strong></p>
</blockquote>
<p>而在Inverted residual结构当中，是两边细、中间粗的结构，因此在输出时是一个低维的特征向量，需要一个线性的激活函数来替代ReLU激活函数，来避免特征信息的损失。</p>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Linear Bottleneck.png" alt="Linear Bottleneck" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>Inverted residual网络结构图</strong></p>
<blockquote>
<p>Inverted residual网络结构如下图（左），首先通过1x1的卷积层进行卷积，通过ReLU6激活函数进行激活，之后通过DW卷积，卷积核大小为3x3，同样通过ReLU6激活函数激活，最后经过卷积核大小为1x1的卷积处理，使用线性激活函数。</p>
<p>过程信息为下图（右）表格，首先通过1x1卷积层进行升维处理（输出深度为tk，也就是说这里采用的卷积核的个数是tk个）；在第二层中，输入特征矩阵的深度为上一层的输出，即tk，这里采用卷积核大小为3x3的DW卷积，stride = s，由前文可知此处深度不变，依旧是tk，但高宽缩减s倍；最后一层通过1x1卷积核进行降维处理，卷积核个数为k‘。</p>
</blockquote>
<p>注意：**在MobileNet v2版本中，并不是每一个Inverted residual结构中都有shortcut。**在论文中，表述当stride = 1时，是有shortcut，当stride = 2时，是没有shortcut。但通过搭建网络结构之后，会发现论文此处表述有误，<strong>正确表述应该为：当stride = 1且输入特征矩阵与输出特征矩阵shape相同时才有shortcut连接。</strong></p>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Inverted residual网络结构图.png" alt="Inverted residual网络结构图" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h3 id="MobileNet-v2网络结构参数"><strong>MobileNet v2网络结构参数</strong></h3>
<p><strong>相关参数介绍：</strong></p>
<ul>
<li>t：扩展因子，对应着第一层1x1的卷积层所采用的卷积核个数的拓展倍率</li>
<li>c：时输出特征矩阵的深度channel，即是上图中提到的k’，控制着输出特征矩阵的深度</li>
<li>n：bottleneck的重复次数，此处的bottleneck指的是论文中的<strong>Inverted residual结构</strong></li>
<li>s：步距，<strong>仅仅针对每一个block所对应的第一层bottleneck的步距（一个block由一系列bottleneck组成），其他都为1</strong>。假设当n = 2时，即bottleneck需要重复2遍，对于这个结构而言，第一层的步距是2，第二层s为1。</li>
</ul>
<p>注意：在第一个bottleneck中，t = 1，即该处的扩展因子为1，也就是说在第一层卷积层是没有对特征矩阵的深度做调整的。<strong>因此在搭建网络时，因为这一层卷积层没有起到升维或者降维作用，所以会被跳过，直接进入3x3的卷积层中处理。</strong></p>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Mobilenet v2网络结构参数.png" alt="Mobilenet v2网络结构参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>如何理解有无shortcut？</strong></p>
<blockquote>
<p>以输入为$14^2$x64这一行的block来举例，这一行的block采用了3个bottleneck结构，stride = 1，即此处block的第一层卷积层的stride = 1，如果按照官方标注而言，应该需要由shortcut。</p>
<p>但实际上这里不可能有shortcut，因此此处的输入特征矩阵的深度为64，但是输出特征矩阵的深度是96。也就是说，如果有shortcut的话，那么输出特征矩阵的深度应该是64，但从表中可知经过一系列操作后输出的特征矩阵深度是96，所以两个特征矩阵的深度是不相同的，无法相加。</p>
<p>在第二层的时候，s = 1，这里的输入特征矩阵深度是上一层的输出特征矩阵深度，即96，对于第二层bottleneck而言，输入的特征矩阵深度十96，其输出特征矩阵的深度也是96，有因为stride = 1，特征矩阵的高宽不会发生变化，因此满足输入特征矩阵和输出特征矩阵的shape保持一致的条件，此时才能使用shortcut。</p>
<p>因此，<strong>只有当stride = 1且输入特征矩阵与输出特征矩阵shape相同时才有shortcut连接。</strong></p>
</blockquote>
<p><strong>conv2d 1x1</strong></p>
<p>网络结构最后一层是卷积层，输入特征矩阵为1x1x1280，实际上这一层就是一个全连接层，功能上二者一模一样。k表示的是分类的类别个数，若针对ImageNet而言，这里的k = 1000。</p>
<h3 id="性能对比">性能对比</h3>
<p>表头对应为：准确率、模型参数、运算量、运算时间。</p>
<ul>
<li>下图（上）是针对在分类任务中的性能对比，MobileNetV2（1.4）指的是$\alpha$ = 1.4（倍率因子）；</li>
<li>下图（下）是针对在目标检测中的效果对比，将MNet V2与SSDLite联合使用，将MNet v2作为前置网络，SSDLite将其中的一些卷积层换为深度可分卷积，也就是DW卷积+PW卷积。</li>
</ul>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/性能对比.png" alt="性能对比" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h2 id="MobileNet-v3">MobileNet v3</h2>
<p>原论文：<a href="https://arxiv.org/abs/1905.02244">Searching for MobileNetV3</a></p>
<p>论文中的亮点：</p>
<ul>
<li>更新Block（bneck）（即对Inverted residual结构基础上，进行简单改动）</li>
<li>使用NAS搜索参数（Neural Architecture Search）</li>
<li>重新设计耗时层结构（NAS搜索之后得到的网络，之后对网络的每一层的推理时间进行分析，针对某些耗时的层结构做进一步的优化）</li>
</ul>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/MobileNetv3L对比v3S对比v2.png" alt="MobileNetv3L对比v3S对比v2" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>性能对比</strong></p>
<p>在原论文的摘要中，作者提到，v3版本的Large对比v2而言在图像分类任务当中准确率上升有3.2%，延迟有降低20%。</p>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/MobileNetv3性能对比.png" alt="MobileNetv3性能对比" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h3 id="更新Block">更新Block</h3>
<p>在v3当中，做出了Block的更新：</p>
<ul>
<li>加入SE模块，即通道的注意力机制模块</li>
<li>更新了激活函数</li>
</ul>
<p><strong>Mobilenet V2：bottleneck with residual</strong></p>
<blockquote>
<p>在v2当中，会首先通过1x1的卷积核对输入特征矩阵进行升维处理，之后通过BN，ReLU6激活函数，之后是通过3x3的DW卷积，之后进行BN，ReLU激活函数激活，最后通过1x1卷积层进行降维处理，之后只跟了一个BN结构，并没有像前面几层一样还有一个ReLU6激活函数。最后有一个shortcut相加处理。</p>
<p>注意：<strong>当stride = 1且input_c = output_c才有shortcut连接</strong></p>
</blockquote>
<p><strong>Mobilenet V3 block</strong></p>
<p><strong>加入SE模块</strong></p>
<blockquote>
<p>大部分框架与v2保持一致，但是在第二层卷积层中加入了SE注意力机制。也就是说针对得到的特征矩阵，对每个channel进行池化处理，那么特征矩阵的channel是多少，得到的1维向量就有多少元素，之后再通过两个全连接层得到输出向量。</p>
<p>注意：</p>
<ul>
<li><strong>对于第一个全连接层，此处的节点个数 = 该处卷积层特征矩阵channel的1/4</strong>（在v3原论文中作者有给出）</li>
<li>第二层全连接层的节点个数 = 该处卷积层特征矩阵channel</li>
<li>对于输出的向量，可以理解为是对该层卷积层特征矩阵的每一个channel分析出了一个权重关系，觉得比较重要的channel会赋予更大的权重，觉得不是那么重要的channel的维度上就对应较小的权重。</li>
</ul>
</blockquote>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/v3更新Block结构.png" alt="更新Block结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>理解两处的全连接层</strong></p>
<blockquote>
<p>假设此处特征矩阵的channel = 2，首先通过平均池化下采样层操作对每一个channel取一个均值，由于有两个channel，所以得到一个元素个数为2的向量。之后再依次通过两个全连接层，得到输出。</p>
<p>针对FC1，节点个数= 输入特征矩阵channel的1/4，实际情况中channel会很多，不会出现小于4的情况。之后跟着一个ReLU激活函数。对于FC2而言，节点个数 =  输入特征矩阵channel = 2，之后跟着H-sig激活函数（之后讲解）。</p>
<p>之后会得到有2个元素的向量，每一个元素对应的就是每一个channel所对应的权重。比如预测第一个channel的权重 = 0.5，那么就将0.5与第一个channel的当中的所有元素相乘得到一个新的channel数据。</p>
</blockquote>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/v3两处全连接层.png" alt="两处全连接层理解" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>更新激活函数</strong></p>
<p>在v3的Block中所使用的激活函数标注的都是NL激活函数，即非线性激活函数的意思。因为在不同的层之间所使用的激活函数都不一样，因此在下图中并未给出明确的激活函数名称。</p>
<p>注意：在最后一个标注的1x1降维的卷积层中，是没有使用激活函数的，也可以说使用了一个线性激活函数y = x。</p>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/v3更新Block结构.png" alt="更新Block结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h3 id="重新设计耗时层结构">重新设计耗时层结构</h3>
<ul>
<li>
<p>减少第一个卷积层的卷积核个数（32-&gt;16）</p>
<blockquote>
<p>​		在原论文当中，作者提到当卷积核个数变化了之后，准确率是没有变化的，那么就达成了在维持准确率不降的前提下减少计算量的目的，这里大概减少2ms的时间</p>
</blockquote>
</li>
<li>
<p>精简Last Stage</p>
<blockquote>
<p>​		在通过NAS搜索出来的网络结构的最后一个部分叫做Original Last Stage，作者在原论文中发现，这一个流程是比较耗时的，因此作者针对这个结构做出精简化，于是提出了Efficient Last Stage。</p>
<p>​		在精简之后发现，第一个卷积层是没有发生变化的，紧接着直接进行平均池化操作，然后跟着两个卷积核输出。和下图（上）的结构对比而言，减少了许多层结构。调整之后，作者发现准确率无多少变化，但执行时间上减少了7ms，这7ms占据整个推理时间的11%。</p>
</blockquote>
</li>
</ul>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/重新设计耗时层结构.png" alt="重新设计耗时层结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h3 id="重新设计激活函数">重新设计激活函数</h3>
<p>在v2网络结构中，基本使用的激活函数都是ReLU6，目前来说比较常用的激活函数叫做swish激活函数，也就是输入值*sigmoid函数。使用swish激活函数确实会提高网络的准确率，但是在计算、求导上非常复杂，对量化过程也不友好（将模型部署到硬件设备上）。</p>
<p>于是作者提出h-swish激活函数，也就是输入值*h-sigmoid函数，其中h-sigmoid = ReLU6（x+3）/6，也就是在ReLU函数的输入值基础上+3的值除以6。</p>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/重新设计激活函数.png" alt="重新设计激活函数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h3 id="V3-Large网络结构参数">V3-Large网络结构参数</h3>
<ul>
<li><code>input</code>：输入特征矩阵的长宽深；</li>
<li><code>Operator</code>：对应操作，例如第一层进行conv2d操作；bneck指进行的block操作，其中3x3指的是下图（左）中的DW卷积中卷积核的大小</li>
<li><code>exp size</code>：代表第一个升维的1x1卷积需要将维度升到多少</li>
<li><code>#out</code>：输出特征矩阵的channel；</li>
<li><code>SE</code>：是否使用注意力机制</li>
<li><code>NL</code>：使用的激活函数，HS指H-swish激活函数，RE指ReLU6激活函数</li>
<li><code>s</code>：表示DW卷积中的步距stride</li>
</ul>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Mobilenet v3网络结构参数.png" alt="Mobilenet v3-Large网络结构参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p>最后两层有写到NBN结构，指的是不去使用，和全连接层的作用是差不多的，这里直接使用卷积结构。</p>
<p>注意：在第一个bneck结构的第一层卷积层之中，因为i输入的特征矩阵channel = 16且输出的特征矩阵channel = 16，因此没有进行升维和降维，且没有SE结构，直接进行1x1的卷积层输出就没有了，因此在搭建网络中，会省略这一步。</p>
<h3 id="V3-Small网络结构参数">V3-Small网络结构参数</h3>
<img src="/2023/05/22/MobileNetv1v2v3%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Mobilenet v3-Small网络结构参数.png" alt="Mobilenet v3-Small网络结构参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>MobileNetv1v2v3</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（二）Pytorch官方demo（LeNet）</title>
    <url>/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/</url>
    <content><![CDATA[<p>因为之前一直没有搭建conda的环境，笔记也是后来补充，过程忘得七七八八了，就直接从demo代码开始记录。</p>
<p>By the way, <strong>Anaconda Navigator用管理员打开下载包更能省事</strong>。</p>
<h1><strong>LeCun的LeNet（1998）网络架构</strong></h1>
<p>Pytorch Tensor的通道排序： <strong>[ batch, channel, height, width ]</strong></p>
<ul>
<li>batch：一批图像的个数，如图中示例，表示有32张图片</li>
</ul>
<p>又因为本次使用的官方数据集为CIFAR10（官方提供），是彩色图片，所以深度为3（RGB）</p>
<ul>
<li>channel：3（深度）</li>
<li>height：32（高度）</li>
<li>width：32（宽度）</li>
</ul>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/LeCun%E7%9A%84LeNet%EF%BC%881988%EF%BC%89%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.PNG" alt="LeCun的LeNet（1988）网络架构"></p>
<h1>代码示例</h1>
<p>工程目录如下（data数据集的下载方式后文补充）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test1_official_demo</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── train.py（调用模型训练）  </span><br><span class="line">	├── predict.py（调用模型进行预测） </span><br><span class="line">	└── data  </span><br><span class="line">		└── data数据集</span><br></pre></td></tr></table></figure>
<h2 id="模型文件model-py"><a href="http://xn--model-ln2hs62ckm0a4wi.py">模型文件model.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module): </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>)  </span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = self.pool1(x)</span><br><span class="line">        x = F.relu(self.conv2(x)) </span><br><span class="line">        x = self.pool2(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>用的两个包都是pytorch的包，虽然下载的是pytorch的包，但实际使用的时候，导入的还是pytorch.XX</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure>
<h3 id="代码解释">代码解释</h3>
<h4 id="初始化函数">初始化函数</h4>
<p>新建一个类，继承于nn.Module这个父类，类中实现两个方法：<strong>init</strong>()和forward()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module): </span><br></pre></td></tr></table></figure>
<p>在初始化函数中，会实现在搭建网络过程中所需要使用到的一些网络层结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br></pre></td></tr></table></figure>
<p>super函数：因为在定义类的过程中继承了nn.Module这个父类，而super函数是用来解决多重继承中调用父类方法中可能出现的一系列问题，简而言之就是——只要涉及到多继承，一般都会使用super函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># python2.0版本</span></span><br><span class="line"><span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line"><span class="comment"># python3.0版本；在3.0版本下，2.0版本的方式的也能用</span></span><br><span class="line"><span class="comment"># super().__init__()</span></span><br></pre></td></tr></table></figure>
<p>conv1相当于图片中的第一个Convolutions，通过nn.Conv2d()函数来定义卷积层。</p>
<p>3:图片深度，16：使用了16个卷积核 = 输出16维度的特征矩阵，5：卷积核大小5×5</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>) </span><br></pre></td></tr></table></figure>
<p>pool1定义下采样层，相当于图片中第一个Subsampling</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.pool1 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>)</span><br><span class="line">self.pool2 = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>全连接层输入是一个一维向量，需要将特征矩阵展平，图片显示第一层的节点个数是120</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)</span><br></pre></td></tr></table></figure>
<p>第二层的输入是第一层的输出 120，输出为84</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br></pre></td></tr></table></figure>
<p>第三层的输入是第二层的输出 84，输出为10（<strong>需要根据实际的训练集进行修改，本次例子中采用CIFAR10数据集，具有10个类别的分类任务，因此这里设置为10</strong>）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h4 id="forward函数">forward函数</h4>
<p>forward函数中定义正向传播的过程。x代表输入的数据，数据指的是Tensor的通道排序：[batch, channel, height, width]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br></pre></td></tr></table></figure>
<p>relu激活函数。input(3, 32, 32) output(16, 28, 28)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = F.relu(self.conv1(x)) </span><br></pre></td></tr></table></figure>
<p>经过Maxpool2d处理，大小缩减为原来的一半，深度不变</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = self.pool1(x)	<span class="comment"># output(16, 14, 14)</span></span><br><span class="line">x = F.relu(self.conv2(x))    <span class="comment"># output(32, 10, 10)</span></span><br><span class="line">x = self.pool2(x)            <span class="comment"># output(32, 5, 5)</span></span><br></pre></td></tr></table></figure>
<p>数据经过view函数将它展成一维向量，-1代表第一个维度进行自动推理（batch），第二个维度值展平之后的节点个数。view中第一个参数为-1，代表动态调整这个维度上的元素个数，以保证元素的总数不变</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = x.view(-<span class="number">1</span>, <span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>)       <span class="comment"># output(32*5*5)</span></span><br><span class="line">x = F.relu(self.fc1(x))      <span class="comment"># output(120)</span></span><br><span class="line">x = F.relu(self.fc2(x))      <span class="comment"># output(84)</span></span><br><span class="line">x = self.fc3(x)              <span class="comment"># output(10)</span></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="Con2d函数">Con2d函数</h3>
<p>ctrl+鼠标左键点击Conv2d，pycharm自动跳转到Conv2d的函数定义</p>
<p>简介：使用2d卷积的方法对输入的数据进行处理</p>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/Conv2d%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%891.png" alt="Conv2d函数定义1"></p>
<p>其中__init__()函数参数定义如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    <span class="comment"># 输入特征矩阵的深度</span></span></span><br><span class="line"><span class="params">    <span class="comment"># 例子中为彩色图像，所以in_channels应该为3</span></span></span><br><span class="line"><span class="params">    in_channels: <span class="built_in">int</span>,  </span></span><br><span class="line"><span class="params">    <span class="comment"># 使用卷积核的个数</span></span></span><br><span class="line"><span class="params">    <span class="comment"># 使用几个卷积核，那么就会生成一个深度为多少维的特征矩阵</span></span></span><br><span class="line"><span class="params">    out_channels: <span class="built_in">int</span>,  </span></span><br><span class="line"><span class="params">    <span class="comment"># 卷积核的大小</span></span></span><br><span class="line"><span class="params">    kernel_size: _size_2_t,</span></span><br><span class="line"><span class="params">    <span class="comment"># 步距，默认为1</span></span></span><br><span class="line"><span class="params">    stride: _size_2_t = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">    <span class="comment"># 四周进行补0处理，默认为0</span></span></span><br><span class="line"><span class="params">    padding: <span class="type">Union</span>[<span class="built_in">str</span>, _size_2_t] = <span class="number">0</span>,</span></span><br><span class="line"><span class="params">    dilation: _size_2_t = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">    groups: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">    <span class="comment"># 偏置，默认使用</span></span></span><br><span class="line"><span class="params">    bias: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    padding_mode: <span class="built_in">str</span> = <span class="string">&#x27;zeros&#x27;</span>,</span></span><br><span class="line"><span class="params">    device=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    dtype=<span class="literal">None</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>
<p>2.1.1在<a href="https://pytorch.org/docs/stable/index.html">pytorch官方文档</a>中ctrl+F查找Conv2d函数，得到在官方的解释</p>
<img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/Conv2d函数定义2.PNG" alt="Conv2d函数定义2">
<p>每个参数的解释</p>
<img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/Conv2d函数定义3参数解释.PNG" alt="Conv2d函数定义3参数解释">
<p>以及卷积输出维度的变化</p>
<img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/Conv2d函数定义4卷积输出维度的变化.png" alt="Conv2d函数定义4卷积输出维度的变化">
<p>实际相当于</p>
<p>\begin{flalign}<br>
N = (W-F+2P)/S + 1<br>
\end{flalign}</p>
<ul>
<li>输入图片大小：W×W</li>
<li>Filter大小：F×F</li>
<li>步长：S</li>
<li>padding的像素数：P</li>
</ul>
<h3 id="MaxPool2d函数">MaxPool2d函数</h3>
<p>简介：没有初始化函数，因为继承来自_MaxPoolNd父类</p>
<img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/Maxpool2d函数定义.png" alt="Maxpool2d函数定义">
<p>跳转到父类_MaxPoolNd</p>
<img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/Maxpool2d父类_MaxPoolNd函数定义.png" alt="Maxpool2d父类_MaxPoolNd函数定义">
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, </span></span><br><span class="line"><span class="params">     <span class="comment"># 池化核的大小</span></span></span><br><span class="line"><span class="params">     kernel_size: _size_any_t, </span></span><br><span class="line"><span class="params">     <span class="comment"># 步距，默认和kernel_size = _size_any_t一致</span></span></span><br><span class="line"><span class="params">     stride: <span class="type">Optional</span>[_size_any_t] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">     padding: _size_any_t = <span class="number">0</span>, </span></span><br><span class="line"><span class="params">     dilation: _size_any_t = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">     return_indices: <span class="built_in">bool</span> = <span class="literal">False</span>, </span></span><br><span class="line"><span class="params">     ceil_mode: <span class="built_in">bool</span> = <span class="literal">False</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>
<h3 id="测试结果（debug）">测试结果（debug）</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">input1 = torch.rand([<span class="number">32</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>])</span><br><span class="line">model1 = LeNet()</span><br><span class="line"><span class="built_in">print</span>(model1)</span><br><span class="line">output = model1(input1)</span><br></pre></td></tr></table></figure>
<p>终端打印信息</p>
<img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/model终端打印信息.png" alt="model终端打印信息">
<h2 id="调用模型训练train-py"><a href="http://xn--train-7e3i932iipsnyttq3a60a.py">调用模型训练train.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.utils.data</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">    ])</span><br><span class="line"><span class="comment">#50000张训练照片</span></span><br><span class="line">transet = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(transet, batch_size=<span class="number">36</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#10000张测试图片</span></span><br><span class="line">testset = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./data&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">test_data_iter = <span class="built_in">iter</span>(testloader)</span><br><span class="line">test_image, test_label = test_data_iter.__next__()</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;flog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>   <span class="comment">#unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment">#print labels</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(<span class="string">&#x27;%5s&#x27;</span> % classes[test_label[j]] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)))</span><br><span class="line"><span class="comment">#show images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(test_image))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = LeNet()</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, start=<span class="number">0</span>):</span><br><span class="line">        inputs, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = loss_function(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印的过程</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">499</span>:</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                outputs = net(test_image)  <span class="comment"># [batch, 10]</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                accuracy = torch.eq(predict_y, test_label).<span class="built_in">sum</span>().item() / test_label.size(<span class="number">0</span>) </span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                        (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"><span class="comment"># 对模型进行保存</span></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br></pre></td></tr></table></figure>
<h3 id="下载及测试数据集">下载及测试数据集</h3>
<p>使用Compose函数将使用的一些预处理方法给打包成一个整体，首先通过CIFAR10导入数据集，将训练集的每一个图像transform预处理函数进行预处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>
<p>50000张训练照片，下载数据集download=True,下载成功后改download=False；root代表将数据集下载到什么地方，train=True时会导入CIFAR10训练集的样本；download=True自动下载；transform=transform对图像进行预处理</p>
<p>或者在当前文件夹下新建data文件夹，<a href="https://pan.baidu.com/s/1300Lz9xthY11o2jfTPpx3g?pwd=1234">直接下载</a>CIFAR10数据集并在data文件夹下解压</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">transet = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br></pre></td></tr></table></figure>
<p>将数据集导入进来，分成一个个批次，这里指每一批随机拿出batch_size=36张图片进行训练；shuffle=True表示是否要将数据集打乱，一般为True；num_workers理解为载入数据的线程数，目前windows环境下也可以设置，但不能超过支持的线程个数，可以加快图片载入的速度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainloader = torch.utils.data.DataLoader(transet, batch_size=<span class="number">36</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>10000张测试图片，测试时将batch_size改为4</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">testset = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./data&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">10000</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>iter函数是将更改生成的testloader转化为一个可迭代的迭代器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_data_iter = <span class="built_in">iter</span>(testloader)</span><br></pre></td></tr></table></figure>
<p>通过__next__()方法获取到一批数据，可拿到图像及图像对应的标签值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_image, test_label = test_data_iter.__next__()</span><br></pre></td></tr></table></figure>
<p>导入标签，元组类型，不可更改，0，1，…，9</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;flog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>测试代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>   <span class="comment">#unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print labels</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(<span class="string">&#x27;%5s&#x27;</span> % classes[test_label[j]] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)))</span><br><span class="line"><span class="comment"># show images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(test_image))</span><br></pre></td></tr></table></figure>
<p><strong>数据集下载</strong></p>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/%E4%B8%8B%E8%BD%BDdata%E6%95%B0%E6%8D%AE%E9%9B%86.png" alt="下载data数据集"></p>
<p><strong>ToTensor函数</strong></p>
<p>将PIL图像或者numpy数据转化为tensor。导入的原始图片，无论是PIL或者通过numpy导入（一般图像为高度，宽度，深度，每一个像素值都是[0, 255]），通过ToTensor函数之后，将shape（长宽高的值）转化为[0.0, 1.0]</p>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/ToTensor.png" alt="ToTensor"></p>
<p><strong>Normalize函数</strong></p>
<p>使用均值和标准差转化tensor，计算方式 ： 输出 = （原始数据 - 均值）/ 标准差</p>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/Normalize.png" alt="Normalize"></p>
<p><strong>测试结果</strong></p>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C.png" alt="测试结果"></p>
<h3 id="构造模型">构造模型</h3>
<p>注释掉测试的输出代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net = LeNet()</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<p>将训练集训练多少次，这里为5次</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br></pre></td></tr></table></figure>
<p>用来累计在训练过程中的损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">running_loss = <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>遍历训练集样本；enumerate函数不仅能返回每一批的数据data，还能返回这一批data所对应的步数index，相当于C++中的枚举</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, start=<span class="number">0</span>):</span><br></pre></td></tr></table></figure>
<p>输入的图像及标签</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs, labels = data</span><br></pre></td></tr></table></figure>
<p>将历史损失梯度清零；</p>
<p>为什么每计算一个batch，就需要调用一次optimizer.zero._grad()？</p>
<p>如果不清除历史梯度，就会对计算的历史梯度进行累加（通过这个特性你能够变相实现一个很大batch数值的训练），主要还是硬件设备受限，防止爆内存</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer.zero_grad()</span><br></pre></td></tr></table></figure>
<p>将我们得到的数的图片输入到网络进行正向传播，得到输出</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">outputs = net(inputs)</span><br></pre></td></tr></table></figure>
<p>通过定义的loss_function来计算损失，outputs：网络预测的值，labels：真实标签</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss = loss_function(outputs, labels)</span><br></pre></td></tr></table></figure>
<p>对loss进行反向传播</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss.backward()</span><br></pre></td></tr></table></figure>
<p>通过优化器optimizer中step函数进行参数更新</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
<p>打印的过程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">running_loss += loss.item()</span><br></pre></td></tr></table></figure>
<p>每隔500步，打印一次数据信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">499</span>:</span><br></pre></td></tr></table></figure>
<p>with是一个上下文管理器，意思是在接下来的计算过程中，不要去计算每个节点的误差损失梯度；否则会自动生成前向的传播图，会占用大量内存，测试时应该禁用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = net(test_image)  <span class="comment"># [batch, 10]</span></span><br></pre></td></tr></table></figure>
<p>predict_y寻找outputs中数值最大的，也就是最有可能的标签类型；dim：第几个维度，第0个维度是batch，第1个维度指10个标签结果；[1]指只需要知道index即可，不需要知晓具体的值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>将预测的标签类别和真实的标签类别进行比较，相同的地方返回1，不相同返回0；使用求和函数，得出在本次预测对了多少个样本；tensor得到的并不是数值，item()才可以拿到</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据准确率</span></span><br><span class="line">accuracy = torch.eq(predict_y, test_label).<span class="built_in">sum</span>().item() / test_label.size(<span class="number">0</span>)    </span><br></pre></td></tr></table></figure>
<p>迭代到第几轮，在某一轮的多少步，训练过程中的累加误差，测试样本的准确率</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))</span><br><span class="line">running_loss = <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>debug一下，会暂时没反应，点开任务管理器，CPU已经100%，等待一段时间会有打印结果</p>
<img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/CPU满.png" style="zoom:50%;">
<p><strong>打印结果</strong></p>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="模型预测结果"></p>
<p>训练完之后在当前目录下生成一个模型权重文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对模型进行保存</span></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br></pre></td></tr></table></figure>
<h2 id="调用模型进行预测predict-py"><a href="http://xn--predict-js9lk59kqvgulxcq6cedky7mgu5a.py">调用模型进行预测predict.py</a></h2>
<p>在网上随便下载一张分类在模型中的图片，存放在当前文件夹下取名1.jpg</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">     <span class="comment">#将图像缩放在32×32的大小</span></span><br><span class="line">    [transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),   </span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化LeNet</span></span><br><span class="line">net = LeNet()</span><br><span class="line"><span class="comment"># 使用load_state_dict载入更改保存的Lenet.pth</span></span><br><span class="line">net.load_state_dict(torch.load(<span class="string">&#x27;Lenet.pth&#x27;</span>))</span><br><span class="line"><span class="comment"># 载入之后，根据python的PIL import Image的模块，去载入图像</span></span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&#x27;1.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 预处理</span></span><br><span class="line">im = transform(im)  <span class="comment"># [C, H, W]</span></span><br><span class="line"><span class="comment"># Tensor规定时需要4个维度，但transform输出仅有3个</span></span><br><span class="line"><span class="comment"># 因此需要在index = 0处增加一个新的维度</span></span><br><span class="line">im = torch.unsqueeze(im, dim=<span class="number">0</span>)  <span class="comment"># [N, C, H, W]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># 将图像传入网络</span></span><br><span class="line">    outputs = net(im)</span><br><span class="line">    <span class="comment"># 寻找输出中的最大值</span></span><br><span class="line">    predict = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>].numpy()</span><br><span class="line"><span class="comment"># 将index索引传入到classes，得出类别</span></span><br><span class="line"><span class="built_in">print</span>(classes[<span class="built_in">int</span>(predict)])</span><br></pre></td></tr></table></figure>
<h3 id="预测结果"><strong>预测结果</strong></h3>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
<h3 id="假设：将max函数改为softmax函数"><strong>假设：将max函数改为softmax函数</strong></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># 将图像传入网络</span></span><br><span class="line">    outputs = net(im)</span><br><span class="line">    <span class="comment"># 寻找输出中的最大值</span></span><br><span class="line">    predict = torch.softmax(outputs, dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(predict)</span><br><span class="line"><span class="comment">#classes = (&#x27;plane&#x27;, &#x27;car&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;,&#x27;deer&#x27;, &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;)</span></span><br></pre></td></tr></table></figure>
<p>输出结果为：经过softmax处理之后的概率分布</p>
<p>预测index  = 0的值概率为93.0%，后面都很小，忽略不看</p>
<p><img src="/2023/04/29/pytorch%E5%AE%98%E6%96%B9demo/softmax%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C.png" alt="softmax输出结果"></p>
<h1>总结</h1>
<p>首先，回顾之前学习LeNet，通过pytorch搭建LeNet模型；</p>
<p>接着，介绍并下载了CIFAR10数据集，对数据集进行预处理，查看图片并导入到LeNet模型，定义了损失函数、优化器；</p>
<p>最后，进行了网络的训练，对训练好的权重进行保存，通过预测脚本，调用保存的模型权重进行预测。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>LeNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（四）使用pytorch搭建AlexNet并训练花分类数据集</title>
    <url>/2023/05/03/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAAlexNet%E5%B9%B6%E8%AE%AD%E7%BB%83%E8%8A%B1%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    <content><![CDATA[<h1>AlexNet网络架构</h1>
<p><img src="/2023/05/03/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAAlexNet%E5%B9%B6%E8%AE%AD%E7%BB%83%E8%8A%B1%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86/AlexNet%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%BF%87%E7%A8%8B%E6%80%BB%E7%BB%93.png" alt="AlexNet网络架构过程总结"></p>
<h1>搭建AlexNet</h1>
<p>工程目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test2_alexnet</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── train.py（调用模型训练）  </span><br><span class="line">	├── predict.py（调用模型进行预测） </span><br><span class="line">	└── class_indices.json（将索引和分类一一对应，代码运行之后会自动生成）</span><br><span class="line">└── data_set </span><br><span class="line">	├── split_data.py(自动将数据集划分成训练集train和验证集val（训练集：测试集 = 9 ：1）</span><br><span class="line">	└── flower_data</span><br><span class="line">		├── train(split_data.py分出来的)</span><br><span class="line">		├── flower_photos(split_data.py分出来的)</span><br><span class="line">		└── flower_photos</span><br><span class="line">			├── daisy 雏菊</span><br><span class="line">			├── dandelion 蒲公英</span><br><span class="line">			├── roses 玫瑰</span><br><span class="line">			├── sunflowers 向日葵</span><br><span class="line">			└── tulips 郁金香</span><br></pre></td></tr></table></figure>
<h2 id="模型文件model-py"><a href="http://xn--model-ln2hs62ckm0a4wi.py">模型文件model.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">48</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">48</span>, <span class="number">128</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)   <span class="comment">#展平处理</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&quot;fan_out&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>创建类AlexNet，继承于父类nn.Module</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(nn.Module):</span><br></pre></td></tr></table></figure>
<p>通过初始化函数来定义AlexNet网络在正向传播过程中所需要使用到的一些层结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># python2.0版本</span></span><br><span class="line">    <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">    <span class="comment"># python3.0版本</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br></pre></td></tr></table></figure>
<h3 id="nn-Sequential模块">nn.Sequential模块</h3>
<p>这里与Pytorch官方demo不一样的是：使用到<strong>nn.Sequential模块</strong>。nn.Sequential能够将一系列的层结构进行打包，组合成一个新的结构，在这取名为features。features代表专门用于提取图像特征的结构。</p>
<p>为什么使用nn.Sequential模块？——精简代码，减少工作量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.features = nn.Sequential(</span><br></pre></td></tr></table></figure>
<h3 id="padding用法解释">padding用法解释</h3>
<p>卷积核大小：11；卷积核个数原模型是96：由于数据集较小和加快运算速度，<strong>因此这里取一半48</strong>，经检测正确率相差不大；输入的图片是RGB的彩色图片：3；</p>
<p>padding有两种写的类型：一种是整型，一种是tuple类型。<strong>当padding=1时，代表在图片上下左右分别补一个单位的0</strong>。如果传入的是<strong>tuple(1, 2)：1代表上下方各补一行0；2表示左右两侧各补两列0</strong>。</p>
<p>如果想要实现第一层的padding在上一堂课中讲到，是在最左边补一列0，最上面补一行0，最右边补两列0，最下面补两行0。<strong>nn.ZeroPad2d((1,2,1,2))：左侧补一列，右侧补两列，上方补一行，下方补两行</strong>。</p>
<p>这里使用padding = 2，按照公式计算出来结果为55.25，在Pytorch中如果计算结果为小数，会自动将小数点去掉。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># input[3, 224, 224]    output[48, 55, 55]</span></span><br><span class="line">nn.Conv2d(<span class="number">3</span>, <span class="number">48</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>),</span><br></pre></td></tr></table></figure>
<p>inplace参数理解为Pytorch通过一种方法增加计算量，但降低内存使用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"><span class="comment"># output[48, 27, 27]</span></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line"><span class="comment"># output[128, 27, 27]</span></span><br><span class="line">nn.Conv2d(<span class="number">48</span>, <span class="number">128</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"><span class="comment"># output[128, 13, 13]</span></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line"><span class="comment"># output[192, 13, 13]</span></span><br><span class="line">nn.Conv2d(<span class="number">128</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"><span class="comment"># output[192, 13, 13]</span></span><br><span class="line">nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"><span class="comment"># output[128, 13, 13]</span></span><br><span class="line">nn.Conv2d(<span class="number">192</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"><span class="comment"># output[128, 6, 6]</span></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br></pre></td></tr></table></figure>
<h3 id="classifier全连接层">classifier全连接层</h3>
<p>classifier包含之后的三层全连接层</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.classifier = nn.Sequential(</span><br><span class="line">    <span class="comment"># p代表失活比例，默认为0.5</span></span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">2048</span>),</span><br><span class="line">    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),</span><br><span class="line">    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># num_classes数据集类别的个数，5</span></span><br><span class="line">    nn.Linear(<span class="number">2048</span>, num_classes),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>当搭建网络过程中传入初始化权重init_weights=trus，会进入到初始化权重函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> init_weights:</span><br><span class="line">    self._initialize_weights()</span><br></pre></td></tr></table></figure>
<h3 id="forward函数">forward函数</h3>
<p>forward函数中定义正向传播的过程。x代表输入的数据，数据指的是Tensor的通道排序：[batch, channel, height, width]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    x = self.features(x)</span><br><span class="line">    x = torch.flatten(x, start_dim=<span class="number">1</span>)   <span class="comment">#展平处理</span></span><br><span class="line">    x = self.classifier(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="initialize-weights函数">_initialize_weights函数</h3>
<p>初始化权重函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br></pre></td></tr></table></figure>
<p>遍历modules模块，modules定义中：返回一个迭代器，迭代器中会遍历网络中所有的模块。而言之，通过self.modules()，会迭代定义的每一个层结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br></pre></td></tr></table></figure>
<p>遍历层结构之后，判断属于哪一个类别，此处为判断是否为卷积层</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">    nn.init.kaiming_normal_(m.weight, mode=<span class="string">&quot;fan_out&quot;</span>)</span><br><span class="line">    <span class="comment"># 如果偏置不为0的话，就以0来作为初始化</span></span><br><span class="line">    <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    	nn.init.constant_(m.bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>遍历层结构之后，判断属于哪一个类别，此处为判断是否为全连接层。如果传进来的实例是全连接层，那么会通过normal_（正态分布）给权重weight赋值，均值=0，方差=0.01，偏置初始化0</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">    nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="训练模型train-py"><a href="http://xn--train-7e3i932ikr8adkya.py">训练模型train.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> AlexNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line">data_transform = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>), </span><br><span class="line">        transforms.RandomHorizontalFlip(), </span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">    <span class="string">&quot;val&quot;</span>: transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line">data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;..&quot;</span>))</span><br><span class="line">image_path = data_root + <span class="string">&quot;/data_set/flower_data/&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">train_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/train&quot;</span>,</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line">flower_list = train_dataset.class_to_idx</span><br><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    train_dataset,batch_size=batch_size, shuffle=<span class="literal">True</span>,num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">validate_dataset = datasets.ImageFolder(</span><br><span class="line">    root=image_path + <span class="string">&quot;/val&quot;</span>,transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(</span><br><span class="line">    validate_dataset,batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>,num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">test_data_iter = <span class="built_in">iter</span>(validate_loader)</span><br><span class="line">test_image, test_label = test_data_iter.__next__()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>  <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>.join(<span class="string">&#x27;%5s&#x27;</span> % cla_dict[test_label[j].item()] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)))</span><br><span class="line">imshow(utils.make_grid(test_image))</span><br><span class="line"></span><br><span class="line">net = AlexNet(num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">net.to(device)</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;./AlexNet.pth&#x27;</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    net.train()</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    t1 = time.perf_counter()</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(images.to(device))</span><br><span class="line">        loss = loss_function(outputs, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        rate = (step + <span class="number">1</span>) / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        a = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>(rate * <span class="number">50</span>)</span><br><span class="line">        b = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>((<span class="number">1</span> - rate) * <span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\rtrain loss: &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">int</span>(rate * <span class="number">100</span>), a, b, loss), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(time.perf_counter() - t1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    acc = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data_test <span class="keyword">in</span> validate_loader:</span><br><span class="line">            test_image, test_label = data_test</span><br><span class="line">            outputs = net(test_image.to(device))</span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += torch.eq(predict_y, test_label.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line">        accurate_test = acc / val_num</span><br><span class="line">        <span class="keyword">if</span> accurate_test &gt; best_acc:</span><br><span class="line">            best_acc = accurate_test</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / step, accurate_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="测试训练集">测试训练集</h3>
<p>判断使用GPU还是CPU来训练，GPU会比CPU快几十倍，如果终端打印信息为cuda：0，则使用了GPU跑代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br></pre></td></tr></table></figure>
<p>RandomResizedCrop：初始化图像尺寸，将图片尺寸全部改为224*224；RandomHorizontalFlip：水平方向随机翻转图像的函数，强化测试</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_transform = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>), <span class="comment">#随机裁剪到224*224</span></span><br><span class="line">                                 transforms.RandomHorizontalFlip(), <span class="comment">#水平方向随机翻转的函数</span></span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">    <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br></pre></td></tr></table></figure>
<p>确认数据集所在文件位置，getcwd获取当前文件所在目录，…表示返回上层目录，拓展：…/…表示返回上上层目录</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;..&quot;</span>))</span><br><span class="line">image_path = data_root + <span class="string">&quot;/data_set/flower_data/&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">train_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/train&quot;</span>,</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>train_num表示一共多少训练图片，用来后续计算准确率，正确个数 / train_num</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_num = <span class="built_in">len</span>(train_dataset)</span><br></pre></td></tr></table></figure>
<p>{‘daisy’：0, ‘dandelion’：1, ‘roses’：2, ‘sunflower’：3, ‘tulips’：4}分别对应雏菊、蒲公英、玫瑰、向日葵、郁金香</p>
<p>flower_list：获取分类的名称所对应的索引</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">flower_list = train_dataset.class_to_idx</span><br></pre></td></tr></table></figure>
<p>遍历flower_list字典，将key和val反过来，是为了预测之后返回的索引能直接使用字典对应到所属的类别</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br></pre></td></tr></table></figure>
<p>通过json将cla_dict字典编码成json的格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>打开class_indices.json文件，将json_str保存进去，为了方便预测时读取信息。这句代码将会在当前文件夹生成class_indices.json，如工程目录所示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br></pre></td></tr></table></figure>
<p>进行训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                           batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/val&quot;</span>,</span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                              batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                              num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">test_data_iter = <span class="built_in">iter</span>(validate_loader)</span><br><span class="line">test_image, test_label = test_data_iter.__next__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>  <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>.join(<span class="string">&#x27;%5s&#x27;</span> % cla_dict[test_label[j].item()] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)))</span><br><span class="line">imshow(utils.make_grid(test_image))</span><br></pre></td></tr></table></figure>
<h3 id="训练结果">训练结果</h3>
<p><img src="/2023/05/03/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAAlexNet%E5%B9%B6%E8%AE%AD%E7%BB%83%E8%8A%B1%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C%E5%9B%BE.png" alt="训练结果图"></p>
<h3 id="构造模型">构造模型</h3>
<p>注释掉测试训练集的输出代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net = AlexNet(num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">net.to(device)</span><br><span class="line"><span class="comment"># CrossEntropyLoss针对多类别的损失交叉熵函数</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 调试用来查看模型的参数</span></span><br><span class="line"><span class="comment"># pata = list(net.parameters())</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;./AlexNet.pth&#x27;</span></span><br><span class="line"><span class="comment"># 历史最优准确率初始化</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>进行10轮训练，并将结果动态打印在终端</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br></pre></td></tr></table></figure>
<h4 id="train训练">train训练</h4>
<p>使用到Dropout，想要实现的是在训练过程中失活一部分神经元，而不想在预测过程中失活。因此通过net.train()和net.eval()来管理Dropout方法，在net.train()中开启Dropout方法，而在net.eval()中会关闭掉</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net.train()</span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line">t1 = time.perf_counter()</span><br><span class="line"><span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">    images, labels = data</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    outputs = net(images.to(device))</span><br><span class="line">    loss = loss_function(outputs, labels.to(device))</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    running_loss += loss.item()</span><br></pre></td></tr></table></figure>
<p>打印在训练过程中的训练进度，len(train_loader)获取训练一轮所需要的步数step + 1获取当前的轮数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">	rate = (step + <span class="number">1</span>) / <span class="built_in">len</span>(train_loader)</span><br><span class="line">    a = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>(rate * <span class="number">50</span>)</span><br><span class="line">    b = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>((<span class="number">1</span> - rate) * <span class="number">50</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\rtrain loss: &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">int</span>(rate * <span class="number">100</span>), a, b, loss), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(time.perf_counter() - t1)</span><br></pre></td></tr></table></figure>
<h4 id="validate预测">validate预测</h4>
<p>在net.eval()中会关闭Dropout方法，不让神经元失活</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net.<span class="built_in">eval</span>()</span><br><span class="line">acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">	<span class="keyword">for</span> data_test <span class="keyword">in</span> validate_loader:</span><br><span class="line">		test_image, test_label = data_test</span><br><span class="line">         outputs = net(test_image.to(device))</span><br><span class="line">         predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">         acc += torch.eq(predict_y, test_label.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line">     accurate_test = acc / val_num</span><br><span class="line">     <span class="keyword">if</span> accurate_test &gt; best_acc:</span><br><span class="line">         best_acc = accurate_test</span><br><span class="line">         torch.save(net.state_dict(), save_path)</span><br><span class="line">     <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / step, accurate_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="打印结果">打印结果</h3>
<p><img src="/2023/05/03/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAAlexNet%E5%B9%B6%E8%AE%AD%E7%BB%83%E8%8A%B1%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86/train%E5%87%86%E7%A1%AE%E7%8E%87.png" alt="train准确率"></p>
<h2 id="预测模型predict-py"><a href="http://xn--predict-js9lk59kovgtv2k.py">预测模型predict.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> AlexNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在网上随便下载一张郁金香的图片放在当前文件夹，取名为tulip.jpg</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;tulip.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(img)</span><br><span class="line"><span class="comment"># [N, C, H, W]</span></span><br><span class="line"><span class="comment"># 预处理img中，已经默认将channel参数提到最前面</span></span><br><span class="line">img = data_transform(img)</span><br><span class="line"><span class="comment"># unsqueeze表示升维，因为图片只有长高深三个维度，需要新增一个batch的维度</span></span><br><span class="line"><span class="comment"># dim = 0，表示在第一个位置插入batch维度</span></span><br><span class="line">img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    json_file = <span class="built_in">open</span>(<span class="string">&#x27;./class_indices.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    class_indict = json.load(json_file)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line">    exit(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化网络</span></span><br><span class="line">model = AlexNet(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入网络模型</span></span><br><span class="line">model_weights_path = <span class="string">&quot;./AlexNet.pth&quot;</span></span><br><span class="line">model.load_state_dict(torch.load(model_weights_path))</span><br><span class="line"><span class="comment"># 关掉Dropout</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># img经过model得到正向传输，将batch参数压缩掉</span></span><br><span class="line">    output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">    predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 得到概率最大的类别名称</span></span><br><span class="line">    predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"><span class="comment"># 打印类别名称及对应概率</span></span><br><span class="line"><span class="built_in">print</span>(class_indict[<span class="built_in">str</span>(predict_cla)], predict[predict_cla].item())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="预测结果">预测结果</h3>
<p><img src="/2023/05/03/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAAlexNet%E5%B9%B6%E8%AE%AD%E7%BB%83%E8%8A%B1%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
<h1>总结</h1>
<p>如果有需要用到AlexNet训练自己的图片，可以在data_set中更改为自己的图片和对应类别，需要注意的是需要在代码中将num_classes的数值定为自己数据集的分类数量。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>AlexNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（八）使用pytorch搭建GoogLeNet网络</title>
    <url>/2023/05/10/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAGoogLeNet%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1>pytorch搭建GoogLeNet</h1>
<p>model模型搭建对照以下参数表及网络架构图</p>
<p><img src="/2023/05/10/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAGoogLeNet%E7%BD%91%E7%BB%9C/GoogLeNet%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0.png" alt="GoogLeNet网络参数"></p>
<p><img src="/2023/05/10/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAGoogLeNet%E7%BD%91%E7%BB%9C/GoogLeNet%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.png" alt="GoogLeNet网络架构"></p>
<h2 id="model-py"><a href="http://model.py">model.py</a></h2>
<p>相比于AlexNet 和 VggNet 只有卷积层和全连接层这两种结构，GoogLeNet多了Inception和辅助分类器（Auxiliary Classifier），而 Inception和辅助分类器也是由多个卷积层和全连接层组合的，因此在定义模型时可以将<strong>卷积、Inception 、辅助分类器</strong>定义成不同的类，调用时更加方便。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GoogLeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(GoogLeNet, self).__init__()</span><br><span class="line">        self.aux_logits = aux_logits</span><br><span class="line"></span><br><span class="line">        self.conv1 = BasicConv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>)</span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = BasicConv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.conv3 = BasicConv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.maxpool2 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.inception3a = Inception(<span class="number">192</span>, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">        self.inception3b = Inception(<span class="number">256</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>, <span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">        self.maxpool3 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.inception4a = Inception(<span class="number">480</span>, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4b = Inception(<span class="number">512</span>, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4c = Inception(<span class="number">512</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4d = Inception(<span class="number">512</span>, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4e = Inception(<span class="number">528</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        self.maxpool4 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.inception5a = Inception(<span class="number">832</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        self.inception5b = Inception(<span class="number">832</span>, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.aux_logits:</span><br><span class="line">            self.aux1 = InceptionAux(<span class="number">512</span>, num_classes)</span><br><span class="line">            self.aux2 = InceptionAux(<span class="number">528</span>, num_classes)</span><br><span class="line"></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># N x 3 x 224 x 224</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="comment"># N x 64 x 112 x 112</span></span><br><span class="line">        x = self.maxpool1(x)</span><br><span class="line">        <span class="comment"># N x 64 x 56 x 56</span></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        <span class="comment"># N x 64 x 56 x 56</span></span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        <span class="comment"># N x 192 x 56 x 56</span></span><br><span class="line">        x = self.maxpool2(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># N x 192 x 28 x 28</span></span><br><span class="line">        x = self.inception3a(x)</span><br><span class="line">        <span class="comment"># N x 256 x 28 x 28</span></span><br><span class="line">        x = self.inception3b(x)</span><br><span class="line">        <span class="comment"># N x 480 x 28 x 28</span></span><br><span class="line">        x = self.maxpool3(x)</span><br><span class="line">        <span class="comment"># N x 480 x 14 x 14</span></span><br><span class="line">        x = self.inception4a(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:</span><br><span class="line">            aux1 = self.aux1(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4b(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line">        x = self.inception4c(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line">        x = self.inception4d(x)</span><br><span class="line">        <span class="comment"># N x 528 x 14 x 14</span></span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:</span><br><span class="line">            aux2 = self.aux2(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4e(x)</span><br><span class="line">        <span class="comment"># N x 832 x 14 x 14</span></span><br><span class="line">        x = self.maxpool4(x)</span><br><span class="line">        <span class="comment"># N x 832 x 7 x 7</span></span><br><span class="line">        x = self.inception5a(x)</span><br><span class="line">        <span class="comment"># N x 832 x 7 x 7</span></span><br><span class="line">        x = self.inception5b(x)</span><br><span class="line">        <span class="comment"># N x 1024 x 7 x 7</span></span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        <span class="comment"># N x 1024 x 1 x 1</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># N x 1024</span></span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="comment"># N x 1000 (num_classes)</span></span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:</span><br><span class="line">            <span class="keyword">return</span> x, aux2, aux1</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.branch2 = nn.Sequential(</span><br><span class="line">            BasicConv2d(in_channels, ch3x3red, kernel_size=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(ch3x3red, ch3x3, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch3 = nn.Sequential(</span><br><span class="line">            BasicConv2d(in_channels, ch5x5red, kernel_size=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(ch5x5red, ch5x5, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch4 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(in_channels, pool_proj, kernel_size=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        branch1 = self.branch1(x)</span><br><span class="line">        branch2 = self.branch2(x)</span><br><span class="line">        branch3 = self.branch3(x)</span><br><span class="line">        branch4 = self.branch4(x)</span><br><span class="line"></span><br><span class="line">        outputs = [branch1, branch2, branch3, branch4]</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InceptionAux</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(InceptionAux, self).__init__()</span><br><span class="line">        self.averagePool = nn.AvgPool2d(kernel_size=<span class="number">5</span>, stride=<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># output[batch, 128, 4, 4]</span></span><br><span class="line">        self.conv = BasicConv2d(in_channels, <span class="number">128</span>, kernel_size=<span class="number">1</span>)  </span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14</span></span><br><span class="line">        x = self.averagePool(x)</span><br><span class="line">        <span class="comment"># aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="comment"># N x 128 x 4 x 4</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.5</span>, training=self.training)</span><br><span class="line">        <span class="comment"># N x 2048</span></span><br><span class="line">        x = F.relu(self.fc1(x), inplace=<span class="literal">True</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.5</span>, training=self.training)</span><br><span class="line">        <span class="comment"># N x 1024</span></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="comment"># N x num_classes</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicConv2d</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicConv2d, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="BasicConv2d类模板">BasicConv2d类模板</h3>
<p>定义BasicConv2d类，包含了卷积层和ReLU激活函数的卷积模板，继承nn.Module，将卷积层和ReLU激活函数打包在一起</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicConv2d</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicConv2d, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="Inception类模板">Inception类模板</h3>
<p>定义Inception类模板，同样继承于nn.Module父类。初始函数中输入Inception函数所需要使用的参数：</p>
<ul>
<li><code>in_channels</code>：输入特征矩阵的深度；</li>
<li><code>ch1X1</code>：第一个分支中1X1卷积核的个数；</li>
<li><code>ch3X3red</code>：第二个分支中1X1卷积核的个数；</li>
<li><code>ch3x3</code>：第二个分支中3X3卷积核的个数；</li>
<li><code>ch5x5red</code>：第三个分支中1X1卷积核的个数；</li>
<li><code>ch5x5</code>：第三个分支中5X5卷积核的个数；</li>
<li><code>pool_proj</code>：第四个分支中1X1卷积核的个数</li>
</ul>
<p>分支1：self.branch1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>分支2：self.branch2</p>
<p>padding=1：保证输出大小等于输入大小。output_size = (input_size - 3 + 2*1)/1 + 1 = input_size</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.branch2 = nn.Sequential(</span><br><span class="line">    BasicConv2d(in_channels, ch3x3red, kernel_size=<span class="number">1</span>),</span><br><span class="line">    BasicConv2d(ch3x3red, ch3x3, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>分支3：self.branch3</p>
<p>padding=2：保证输出大小等于输入大小。output_size=(input_size - 5 + 2 * 2) / 1 + 1 = input_size</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.branch3 = nn.Sequential(</span><br><span class="line">    BasicConv2d(in_channels, ch5x5red, kernel_size=<span class="number">1</span>),</span><br><span class="line">    BasicConv2d(ch5x5red, ch5x5, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>分支4：self.branch4</p>
<p>padding=1：保证输出大小等于输入大小。output_size = (input_size - 3 + 2*1)/1 + 1 = input_size。池化操作不会改变特征矩阵的深度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.branch4 = nn.Sequential(</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    BasicConv2d(in_channels, pool_proj, kernel_size=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>在forward正向传播函数中，将输出放入列表中，再通过torch.cat（concatention）函数对输出进行在深度方向的合并</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">outputs = [branch1, branch2, branch3, branch4]</span><br></pre></td></tr></table></figure>
<p>在pytorch中，通道[batch, channel, hight, width]，因为延深度方向拼接，因此位置在第1个（0，1，2，3）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="InceptionAux辅助分类器">InceptionAux辅助分类器</h3>
<p>当实例化一个模型model之后，可以通过model.train()和model.eval()来控制模型的状态，在model.train()模式下self.training=True，在model.eval()模式下self.training=False</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = F.dropout(x, <span class="number">0.5</span>, training=self.training)</span><br></pre></td></tr></table></figure>
<h3 id="GoogLeNet类">GoogLeNet类</h3>
<p>aux_logits：是否使用辅助分类器；init_weights：是否对权重进行初始化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">False</span></span>):</span><br></pre></td></tr></table></figure>
<p>为了将特征矩阵的高宽缩减为原来的一半，（224 - 7 + 2 * 3)/2 + 1 = 112.5在pytorch中默认向下取整，也就是112。当ceil_mode-True，表示结果数据如果为小数的话，那么向上取整，反之向下取整</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conv1 = BasicConv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>)</span><br><span class="line">self.maxpool1 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>Inception的深度可以用过查看参数表格得到，或通过上一个Inception层的四个分支的特征矩阵深度加起来得到</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.inception4a = Inception(<span class="number">480</span>, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line">self.inception4b = Inception(<span class="number">512</span>, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">self.inception4c = Inception(<span class="number">512</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">self.inception4d = Inception(<span class="number">512</span>, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">self.inception4e = Inception(<span class="number">528</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">self.maxpool4 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>平均池化下采样层，AdaptiveAvgPool2d自适应平均池化下采样：无论输入特征矩阵高宽是多少，都能得到指定的特征矩阵的高和宽</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>输入的展平后的向量节点个数为1024，输出的节点个数是num_classes</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.fc = nn.Linear(<span class="number">1024</span>, num_classes)</span><br></pre></td></tr></table></figure>
<p>在forward正向传播函数中，self.training判断当前模型是处于训练模式还是验证模式，如果是训练模式的话九尾True，反之为False</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:</span><br><span class="line">    aux1 = self.aux1(x)</span><br></pre></td></tr></table></figure>
<h2 id="train-py"><a href="http://train.py">train.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> GoogLeNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line">data_transform = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                 transforms.RandomHorizontalFlip(),</span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">    <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line">data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;..&quot;</span>))</span><br><span class="line">image_path = os.path.join(data_root, <span class="string">&quot;data_set&quot;</span>, <span class="string">&quot;flower_data&quot;</span>)</span><br><span class="line"><span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;train&quot;</span>),</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">flower_list = train_dataset.class_to_idx</span><br><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line"><span class="comment"># write dict into json file</span></span><br><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                           batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=nw)</span><br><span class="line"></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>),</span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                              batch_size=batch_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                              num_workers=nw)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(train_num,</span><br><span class="line">                                                                       val_num))</span><br><span class="line"></span><br><span class="line"><span class="comment"># test_data_iter = iter(validate_loader)</span></span><br><span class="line"><span class="comment"># test_image, test_label = test_data_iter.next()</span></span><br><span class="line"></span><br><span class="line">net = GoogLeNet(num_classes=<span class="number">5</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 如果要使用官方的预训练权重，注意是将权重载入官方的模型，不是我们自己实现的模型</span></span><br><span class="line"><span class="comment"># 官方的模型中使用了bn层以及改了一些参数，不能混用</span></span><br><span class="line"><span class="comment"># import torchvision</span></span><br><span class="line"><span class="comment"># net = torchvision.models.googlenet(num_classes=5)</span></span><br><span class="line"><span class="comment"># model_dict = net.state_dict()</span></span><br><span class="line"><span class="comment"># # 预训练权重下载地址: https://download.pytorch.org/models/googlenet-1378be20.pth</span></span><br><span class="line"><span class="comment"># pretrain_model = torch.load(&quot;googlenet.pth&quot;)</span></span><br><span class="line"><span class="comment"># del_list = [&quot;aux1.fc2.weight&quot;, &quot;aux1.fc2.bias&quot;,</span></span><br><span class="line"><span class="comment">#             &quot;aux2.fc2.weight&quot;, &quot;aux2.fc2.bias&quot;,</span></span><br><span class="line"><span class="comment">#             &quot;fc.weight&quot;, &quot;fc.bias&quot;]</span></span><br><span class="line"><span class="comment"># pretrain_dict = &#123;k: v for k, v in pretrain_model.items() if k not in del_list&#125;</span></span><br><span class="line"><span class="comment"># model_dict.update(pretrain_dict)</span></span><br><span class="line"><span class="comment"># net.load_state_dict(model_dict)</span></span><br><span class="line">net.to(device)</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0003</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">30</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line">save_path = <span class="string">&#x27;./googleNet.pth&#x27;</span></span><br><span class="line">train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    net.train()</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    train_bar = tqdm(train_loader, file=sys.stdout)</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        logits, aux_logits2, aux_logits1 = net(images.to(device))</span><br><span class="line">        loss0 = loss_function(logits, labels.to(device))</span><br><span class="line">        loss1 = loss_function(aux_logits1, labels.to(device))</span><br><span class="line">        loss2 = loss_function(aux_logits2, labels.to(device))</span><br><span class="line">        loss = loss0 + loss1 * <span class="number">0.3</span> + loss2 * <span class="number">0.3</span></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, epochs, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># validate</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    acc = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        val_bar = tqdm(validate_loader, file=sys.stdout)</span><br><span class="line">        <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">            val_images, val_labels = val_data</span><br><span class="line">            outputs = net(val_images.to(device))</span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    val_accurate = acc / val_num</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">          (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">        best_acc = val_accurate</span><br><span class="line">        torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>train.py代码和前期VGG和AlexNet代码内容大同小异，有两点不同需要注意：</p>
<h3 id="实例化代码">实例化代码</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net = GoogLeNet(num_classes=<span class="number">5</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="损失函数">损失函数</h3>
<p>有三个部分，分别是主干输出loss、两个辅助分类器输出loss（权重0.3）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">logits, aux_logits2, aux_logits1 = net(images.to(device))</span><br><span class="line">loss0 = loss_function(logits, labels.to(device))</span><br><span class="line">loss1 = loss_function(aux_logits1, labels.to(device))</span><br><span class="line">loss2 = loss_function(aux_logits2, labels.to(device))</span><br><span class="line">loss = loss0 + loss1 * <span class="number">0.3</span> + loss2 * <span class="number">0.3</span></span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure>
<h2 id="predict-py"><a href="http://predict.py">predict.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> GoogLeNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line">img_path = <span class="string">&quot;../tulip.jpg&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">plt.imshow(img)</span><br><span class="line"><span class="comment"># [N, C, H, W]</span></span><br><span class="line">img = data_transform(img)</span><br><span class="line"><span class="comment"># expand batch dimension</span></span><br><span class="line">img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># read class_indict</span></span><br><span class="line">json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">model = GoogLeNet(num_classes=<span class="number">5</span>, aux_logits=<span class="literal">False</span>).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load model weights</span></span><br><span class="line">weights_path = <span class="string">&quot;./googleNet.pth&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(weights_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(weights_path)</span><br><span class="line"></span><br><span class="line">missing_keys, unexpected_keys = model.load_state_dict(torch.load(weights_path, map_location=device), strict=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># predict class</span></span><br><span class="line">    output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">    predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">    predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                             predict[predict_cla].numpy())</span><br><span class="line">plt.title(print_res)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                              predict[i].numpy()))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>预测部分跟AlexNet和VGG类似，需要注意在<strong>实例化模型时不需要辅助分类器</strong>（因为辅助分类器目的在于在训练模型过程中防止过拟合的同时增强模型的正确率，当训练结束后，相关参数已经保存在权重文件中，因此在预测时，并不需要使用辅助分类器）</p>
<p>aux_logits=False不会构建辅助分类器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = GoogLeNet(num_classes=<span class="number">5</span>, aux_logits=<span class="literal">False</span>).to(device)</span><br></pre></td></tr></table></figure>
<p>strict默认为true，意思是精准匹配当前模型和需要载入的权重模型的结构。当设置为False后，现在搭建的GoogLeNet是没有辅助分类器的，所以于保存的模型结构会缺失一些结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">missing_keys, unexpected_keys = model.load_state_dict(torch.load(weights_path, map_location=device), strict=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h1>总结</h1>
<p>训练过程过于漫长，今后在时间充裕的时候可以试一试</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>GoogLeNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十）使用pytorch搭建ResNet并基于迁移学习训练</title>
    <url>/2023/05/13/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNet%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<p>工程目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test5_resnet</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,resNet.pth）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	├── resnet-pre.pth（用于迁移学习时，提前下载好官方的resNet权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<p>原论文中分别对应18、34、50、101、152层的网络结构参数一览表</p>
<p><img src="/2023/05/13/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNet%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/%E5%8E%9F%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8.png" alt="原论文中的参数列表"></p>
<h1><a href="http://model.py">model.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channel)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channel)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,</span><br><span class="line">                               kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channel)</span><br><span class="line">        <span class="comment"># -----------------------------------------</span></span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, </span><br><span class="line">                               kernel_size=<span class="number">3</span>, stride=stride, bias=<span class="literal">False</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channel)</span><br><span class="line">        <span class="comment"># -----------------------------------------</span></span><br><span class="line">        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion,</span><br><span class="line">                               kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, blocks_num, num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span>, groups=<span class="number">1</span>, width_per_group=<span class="number">64</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.include_top = include_top</span><br><span class="line">        self.in_channel = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.groups = groups</span><br><span class="line">        self.width_per_group = width_per_group</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, self.in_channel, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>,</span><br><span class="line">                               padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(self.in_channel)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">64</span>, blocks_num[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, blocks_num[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, blocks_num[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, blocks_num[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> self.include_top:</span><br><span class="line">            self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))  <span class="comment"># output size = (1, 1)</span></span><br><span class="line">            self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, channel, block_num, stride=<span class="number">1</span></span>):</span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.in_channel != channel * block.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(channel * block.expansion))</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.in_channel,</span><br><span class="line">                            channel,</span><br><span class="line">                            downsample=downsample,</span><br><span class="line">                            stride=stride,</span><br><span class="line">                            groups=self.groups,</span><br><span class="line">                            width_per_group=self.width_per_group))</span><br><span class="line">        self.in_channel = channel * block.expansion</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, block_num):</span><br><span class="line">            layers.append(block(self.in_channel,</span><br><span class="line">                                channel,</span><br><span class="line">                                groups=self.groups,</span><br><span class="line">                                width_per_group=self.width_per_group))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.include_top:</span><br><span class="line">            x = self.avgpool(x)</span><br><span class="line">            x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">            x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet34</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet34-333f7ec4.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet50</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet50-19c8e357.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet101</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet101-5d3b4d8f.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnext50_32x4d</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth</span></span><br><span class="line">    groups = <span class="number">32</span></span><br><span class="line">    width_per_group = <span class="number">4</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">                  num_classes=num_classes,</span><br><span class="line">                  include_top=include_top,</span><br><span class="line">                  groups=groups,</span><br><span class="line">                  width_per_group=width_per_group)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnext101_32x8d</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth</span></span><br><span class="line">    groups = <span class="number">32</span></span><br><span class="line">    width_per_group = <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>],</span><br><span class="line">                  num_classes=num_classes,</span><br><span class="line">                  include_top=include_top,</span><br><span class="line">                  groups=groups,</span><br><span class="line">                  width_per_group=width_per_group)</span><br></pre></td></tr></table></figure>
<h2 id="对应18、34层的残差结构">对应18、34层的残差结构</h2>
<p><img src="/2023/05/13/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNet%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/residual%E7%BB%93%E6%9E%84.png" alt="18和34层的residual结构18和34层"></p>
<p>首先定义一个类BasicBlock，对应着18层和34层所对应的残差结构，继承来自于nn.Module父类。<strong>包含实线与虚线残差结构的功能，依靠初始化函数中downsample参数进行分辨</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">       <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">	   <span class="comment"># ......</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>expansion参数对应着残差结构中，主分支所采用的卷积核的个数是否发生变化。例如图上（左）显示，其输入特征矩阵和输出特征矩阵的shape是一致的，因此由expansion = 1来表示卷积核的个数并没有发生变化，也就是1倍。</p>
<p>在之后搭建第50、101、152层的残差结构时，会发现输出特征矩阵的深度是输入特征矩阵的4倍，也就是说，残差结构中，第三层的卷积核个数是第一、二层的四倍，因此expansion = 4。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">expansion = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="定义初始函数">定义初始函数</h3>
<p>下采样参数downsample默认为none，所对应着虚线残差结构中的shortcut的1 x 1的卷积层。作用是对上一层的输出进行维度上的缩放，保证shortcut和本层的输出能够在同一维度上合并</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>conv1–out_channels</strong></p>
<ul>
<li>output_size = （input_size - 3 + 2 * 1 ）/ 1 + 1 = input_size（ shape保持不变）</li>
<li>当stride = 2时，对应的是虚线残差结构：output_size = （input_size - 3 + 2 * 1）/ 2 + 1 = input_size / 2 + 0.5 = input_size / 2（向下取整）</li>
</ul>
<p><strong>conv1–bias</strong></p>
<ul>
<li>bias=False，代表不使用bias参数，在上堂课中说明，使用Batch Normalization时，使用或者不使用bias的效果是一样的</li>
</ul>
<p><strong>bn1–out_channel</strong></p>
<ul>
<li>Batch Normalization：所输入的参数是对着应输入特征矩阵的深度，也就是对应着卷积层1输出特征矩阵的深度，也就是out_channel</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,</span><br><span class="line">                       kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn1 = nn.BatchNorm2d(out_channel)</span><br><span class="line">self.relu = nn.ReLU()</span><br><span class="line">self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,</span><br><span class="line">                       kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn2 = nn.BatchNorm2d(out_channel)</span><br><span class="line">self.downsample = downsample</span><br></pre></td></tr></table></figure>
<h3 id="正向传播函数">正向传播函数</h3>
<ul>
<li>identity = x：将x赋值给identity，也就是shortcut上的输出值</li>
<li>对下采样函数downsample进行判断，<strong>如果是None（没有输入下采样函数），则表示shortcut是实线，则可以跳过这部分，反之将输入特征矩阵x输入下采样函数downsample，得到shortcut函数的输出</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    identity = x</span><br><span class="line">    <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">    out = self.conv1(x)</span><br><span class="line">    out = self.bn1(out)</span><br><span class="line">    out = self.relu(out)</span><br><span class="line"></span><br><span class="line">    out = self.conv2(out)</span><br><span class="line">    out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">    out += identity</span><br><span class="line">    out = self.relu(out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="对应50、101、152层残差结构">对应50、101、152层残差结构</h2>
<p><img src="/2023/05/13/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNet%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/residual%E7%BB%93%E6%9E%84(50%E3%80%81101%E3%80%81152%E5%B1%82).png" alt="residual结构(50、101、152层)"></p>
<p>注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。<strong>但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2，这么做的好处是能够在top1上提升大概0.5%的准确率</strong>。可参考<a href="https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch">Resnet v1.5</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        <span class="comment"># ......</span></span></span><br><span class="line"><span class="params">                 </span></span><br><span class="line"><span class="params">    <span class="keyword">def</span> forward(<span class="params">self, x</span>):</span></span><br><span class="line"><span class="params">        <span class="comment"># ......</span></span></span><br><span class="line"><span class="params">        <span class="keyword">return</span> out</span></span><br></pre></td></tr></table></figure>
<p>在搭建第50、101、152层的残差结构时，会发现输出特征矩阵的深度是输入特征矩阵的4倍，也就是说，残差结构中，第三层的卷积核个数是第一、二层的四倍，因此expansion = 4。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">expansion = <span class="number">4</span></span><br></pre></td></tr></table></figure>
<h3 id="定义初始函数-2">定义初始函数</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br></pre></td></tr></table></figure>
<p>**conv1：**output_size = （input_size - 1 + 2 * 0 ）/ 1 + 1 = input_size（ shape保持不变）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,</span><br><span class="line">                       kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn1 = nn.BatchNorm2d(out_channel)</span><br></pre></td></tr></table></figure>
<p><strong>conv2：</strong></p>
<ul>
<li><code>实线</code>：stride默认=1，output_size = （input_size - 3 + 2 * 1 ）/ 1 + 1 = input_size + 0.5 = input_size （ shape保持不变）</li>
<li><code>虚线</code>：stride = 2，由参数传入，output_size = （input_size - 3 + 2 * 1 ）/ 2 + 1 = input_size / 2 + 0.5 = input_size / 2</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, </span><br><span class="line">                       kernel_size=<span class="number">3</span>, stride=stride, bias=<span class="literal">False</span>, padding=<span class="number">1</span>)</span><br><span class="line">self.bn2 = nn.BatchNorm2d(out_channel)</span><br></pre></td></tr></table></figure>
<p><strong>conv3：</strong></p>
<ul>
<li>output_size = （input_size - 1 + 2 * 0 ）/ 1 + 1 = input_size （高宽不变）</li>
<li>out_channels=out_channel * self.expansion：表示深度变为上一层输出特征矩阵深度的4倍（self.expansion = 4）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion,</span><br><span class="line">                       kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 这里我认为也可以改成self.bn3 = nn.BatchNorm2d(out_channels)</span></span><br><span class="line">self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)</span><br><span class="line">self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">self.downsample = downsample</span><br></pre></td></tr></table></figure>
<h3 id="正向传播函数-2">正向传播函数</h3>
<p>identity = x：将x赋值给identity，也就是shortcut上的输出值</p>
<p>对下采样函数downsample进行判断，<strong>如果是None（没有输入下采样函数），则表示shortcut是实线，则可以跳过这部分，反之则对应虚线的残差结构，将输入特征矩阵x输入下采样函数downsample，得到shortcut函数的输出</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    identity = x</span><br><span class="line">    <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">    out = self.conv1(x)</span><br><span class="line">    out = self.bn1(out)</span><br><span class="line">    out = self.relu(out)</span><br><span class="line"></span><br><span class="line">    out = self.conv2(out)</span><br><span class="line">    out = self.bn2(out)</span><br><span class="line">    out = self.relu(out)</span><br><span class="line"></span><br><span class="line">    out = self.conv3(out)</span><br><span class="line">    out = self.bn3(out)</span><br><span class="line"></span><br><span class="line">    out += identity</span><br><span class="line">    out = self.relu(out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="ResNet网络框架">ResNet网络框架</h2>
<p>在初始化函数当中，<code>传入的block</code>就是对应的残差结构，会根据定义的层结构传入不同的block，例如传入是18、34层的残差结构，那么就是BasicBlock，如果传入的是50、101、152层的残差结构，那么就是Bottleneck;</p>
<p><code>blocks_num</code>：传入的是一个列表类型，对应的是使用残差结构的数目。例如对应使用34层的残差结构，那么根据参数表来看，blocks_num = [ 3, 4, 6, 3 ]；对于101层就是[ 3, 4, 23, 3 ]</p>
<p><code>include_top</code>：是为了方便以后能在ResNet网络基础上搭建更加复杂的网络，本节课并没有使用到，但代码中实现了该方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, blocks_num, num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span>, groups=<span class="number">1</span>, width_per_group=<span class="number">64</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, channel, block_num, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="定义初始函数-3">定义初始函数</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, blocks_num, num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span> </span>):</span><br><span class="line">	<span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">	self.include_top = include_top</span><br></pre></td></tr></table></figure>
<p>根据参数表，无论在哪一个层结构下，在经过Maxpooling下采样层之后，输出特征矩阵的深度都为64</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.in_channel = <span class="number">64</span></span><br></pre></td></tr></table></figure>
<p><strong>conv1</strong>：首先输入的是RGB彩色图像，因此先输入3。对应参数表中7x7的卷积层，特征矩阵深度还是64，没有发生变化，为了使特征矩阵的高和宽缩减为原来的一半，因此kernel_size = 7，padding = 3, stride = 2。</p>
<p><strong>output_size = （ input_size - 7 + 2 * 3 ）/ 2 + 1 = input_size / 2 + 0.5 = intput_size / 2</strong>（向下取整）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.conv1 = nn.Conv2d(<span class="number">3</span>, self.in_channel, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>,</span><br><span class="line">                       padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn1 = nn.BatchNorm2d(self.in_channel)</span><br><span class="line">self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><strong>maxpool</strong>：kernel_size = 3, 特征矩阵深度还是64，为了使特征矩阵的高和宽缩减为原来的一半，因此pading = 1，stride = 2</p>
<p><strong>output_size = （ input_size - 3 + 2 * 1 ）/ 2 + 1 = input_size / 2 + 0.5 = intput_size / 2</strong>（向下取整）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>接下来定义layer1、layer2、layer3、layer4</p>
<p>其中layer1对应的是参数表中conv2所对应的一系列残差结构；layer2对应的是vonv3所对应的一系列残差结构；layer3对应是conv4；layer4对应conv5。这一系列layer是通过_make_layer函数生成的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.layer1 = self._make_layer(block, <span class="number">64</span>, blocks_num[<span class="number">0</span>])</span><br><span class="line">self.layer2 = self._make_layer(block, <span class="number">128</span>, blocks_num[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">self.layer3 = self._make_layer(block, <span class="number">256</span>, blocks_num[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">self.layer4 = self._make_layer(block, <span class="number">512</span>, blocks_num[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>在输入时已经将include_top默认为True，通过自适应的平均池化下采样操作AdaptiveAvgPool2d，无论输入特征矩阵的高和宽是多少，都会以(1, 1)的形式，输出高和宽为1的特征矩阵。</p>
<p>再通过全连接层，也就是输出节点层，通过nn.Linear类进行定义。输入的节点个数，也就是通过平均池化下采样层之后所得到特征矩阵展平后的节点个数。由于通过平均池化下采样之后得到的特征矩阵的高和宽都是1，那么展平后的节点个数即特征矩阵的深度。</p>
<blockquote>
<p>对于18、34层而言，通过conv5.x经过一系列残差结构输出的特征矩阵的深度为512，所以输入数据为512 * block.expansion，block.expansion = 1；</p>
<p>对于50、101、152层来说，通过conv5.x经过一系列残差结构输出的特征矩阵的深度为2048，也就是512的4倍，正好此时block.expansion = 4。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> self.include_top:</span><br><span class="line">    self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))  <span class="comment"># output size = (1, 1)</span></span><br><span class="line">    self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br></pre></td></tr></table></figure>
<p>最后对卷积层进行初始化操作</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">        nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="make-layer函数">_make_layer函数</h3>
<p><code>block</code>：对应的是BasicBlock（18、34层）或者Bottleneck（50、101、152层）</p>
<p><code>channel</code>：对应的是残差结构中卷积层所使用卷积核的个数，例如layer1对应的是conv2.1中卷积核的个数64，layer2对应的是conv3.1卷积核的个数128，layer3对应conv4.1卷积核个数是256，layer4对应conv5.1卷积核个数是512</p>
<p><code>block_num</code>：表示该层一共包含多少个残差结构，例如在34层残差机构当中，conv2.x中一共包含3个，conv3.x包含4个，conv4.x包含6个，conv5.x包含3个</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, channel, block_num, stride=<span class="number">1</span></span>):</span><br><span class="line">    downsample = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
<p><strong>18、34层的网络结构会跳过该判断语句，50、101、152层的网络结构会执行该判断下的语句，即生成下采样函数downsample。</strong></p>
<p>在layer1中，因没有输入stride，所以默认stride = 1，因此判断语句前半段不成立。in_channel判断是否等于channel * block.expansion。当在18、34层残差结构时，由于block.expansion = 1，而channel对应layer1中输入为64，所以二者相等，判断失效。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.in_channel != channel * block.expansion:</span><br><span class="line">    downsample = nn.Sequential(</span><br><span class="line">        nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">        nn.BatchNorm2d(channel * block.expansion))</span><br></pre></td></tr></table></figure>
<p>首先定义layers的列表，block对应的是BasicBlock（18、34层）或者Bottleneck（50、101、152层）。等于是将网络结构中虚线残差结构的conv2.1、conv3.1、conv4.1、conv5.1的输出特征矩阵以列表的形式存放在layers列表中，在本次循环中存放进的是conv2.1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layers = []</span><br><span class="line">layers.append(block(self.in_channel,</span><br><span class="line">                    channel,</span><br><span class="line">                    downsample=downsample,</span><br><span class="line">                    stride=stride))</span><br><span class="line">self.in_channel = channel * block.expansion</span><br></pre></td></tr></table></figure>
<p>以循环的方式将实线残差结构依次存放仅layers列表中。range（1， block_num）中从1开始，因为上面的步骤已经将0做好了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, block_num):</span><br><span class="line">    layers.append(block(self.in_channel, channel))</span><br><span class="line"><span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
<p>结合以上对layer1的过程描述，<code>_make_layer函数</code>实际上是将conv2.x、conv3.x、conv4.x、conv5.x每一层中虚线和实线对应的特征矩阵存放进对应的layers列表中。例如50层的conv2.x，layer1对应是[ 虚线，实线，实线 ]。</p>
<h3 id="正向传播函数-3">正向传播函数</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># conv1</span></span><br><span class="line">    x = self.conv1(x)</span><br><span class="line">    x = self.bn1(x)</span><br><span class="line">    x = self.relu(x)</span><br><span class="line">    x = self.maxpool(x)</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># conv2</span></span><br><span class="line">    x = self.layer1(x)</span><br><span class="line">    <span class="comment"># conv3</span></span><br><span class="line">    x = self.layer2(x)</span><br><span class="line">    <span class="comment"># conv4</span></span><br><span class="line">    x = self.layer3(x)</span><br><span class="line">    <span class="comment"># conv5</span></span><br><span class="line">    x = self.layer4(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.include_top:</span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        <span class="comment"># 展平处理</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 全连接</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="定义ResNet网络架构的函数">定义ResNet网络架构的函数</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 18层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet18</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"><span class="comment"># 34层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet34</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet34-333f7ec4.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"><span class="comment"># 50层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet50</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet101-5d3b4d8f.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"><span class="comment"># 101层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet101</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet101-5d3b4d8f.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br><span class="line"><span class="comment"># 152层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet152</span>(<span class="params">num_classes=<span class="number">1000</span>, include_top=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/resnet101-5d3b4d8f.pth</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>], num_classes=num_classes, include_top=include_top)</span><br></pre></td></tr></table></figure>
<h1><a href="http://train.py">train.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> resnet34</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                                   transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;..&quot;</span>))  <span class="comment"># get data root path</span></span><br><span class="line">    image_path = os.path.join(data_root, <span class="string">&quot;data_set&quot;</span>, <span class="string">&quot;flower_data&quot;</span>)  <span class="comment"># flower data set path</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;train&quot;</span>),</span><br><span class="line">                                         transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">    train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">    flower_list = train_dataset.class_to_idx</span><br><span class="line">    cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line">    <span class="comment"># write dict into json file</span></span><br><span class="line">    json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">16</span></span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line"></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw)</span><br><span class="line"></span><br><span class="line">    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>),</span><br><span class="line">                                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">    val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">    validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                                  batch_size=batch_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                                  num_workers=nw)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(train_num,</span><br><span class="line">                                                                           val_num))</span><br><span class="line"></span><br><span class="line">    net = resnet34()</span><br><span class="line">    <span class="comment"># load pretrain weights</span></span><br><span class="line">    <span class="comment"># download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./resnet34-pre.pth&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(model_weight_path), <span class="string">&quot;file &#123;&#125; does not exist.&quot;</span>.<span class="built_in">format</span>(model_weight_path)</span><br><span class="line">    net.load_state_dict(torch.load(model_weight_path, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">    <span class="comment"># for param in net.parameters():</span></span><br><span class="line">    <span class="comment">#     param.requires_grad = False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># change fc layer structure</span></span><br><span class="line">    in_channel = net.fc.in_features</span><br><span class="line">    net.fc = nn.Linear(in_channel, <span class="number">5</span>)</span><br><span class="line">    net.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># define loss function</span></span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># construct an optimizer</span></span><br><span class="line">    params = [p <span class="keyword">for</span> p <span class="keyword">in</span> net.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.Adam(params, lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">    epochs = <span class="number">3</span></span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line">    save_path = <span class="string">&#x27;./resNet34.pth&#x27;</span></span><br><span class="line">    train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        net.train()</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        train_bar = tqdm(train_loader, file=sys.stdout)</span><br><span class="line">        <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">            images, labels = data</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            logits = net(images.to(device))</span><br><span class="line">            loss = loss_function(logits, labels.to(device))</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># print statistics</span></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                     epochs,</span><br><span class="line">                                                                     loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            val_bar = tqdm(validate_loader, file=sys.stdout)</span><br><span class="line">            <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">                val_images, val_labels = val_data</span><br><span class="line">                outputs = net(val_images.to(device))</span><br><span class="line">                <span class="comment"># loss = loss_function(outputs, test_labels)</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">                val_bar.desc = <span class="string">&quot;valid epoch[&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                           epochs)</span><br><span class="line"></span><br><span class="line">        val_accurate = acc / val_num</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p><strong>训练结果</strong>（迁移学习），准确率最终能达到93%</p>
<p><img src="/2023/05/13/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNet%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/train%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="train迁移学习训练结果"></p>
<p>如果不想使用迁移学习的方法，可以将以下代码注释</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_weight_path = <span class="string">&quot;./resnet34-pre.pth&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(model_weight_path), <span class="string">&quot;file &#123;&#125; does not exist.&quot;</span>.<span class="built_in">format</span>(model_weight_path)</span><br><span class="line">net.load_state_dict(torch.load(model_weight_path, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line"><span class="comment"># for param in net.parameters():</span></span><br><span class="line"><span class="comment">#     param.requires_grad = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># change fc layer structure</span></span><br><span class="line">in_channel = net.fc.in_features</span><br><span class="line">net.fc = nn.Linear(in_channel, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>并将传入resnet实例化参数的地方net = resnet34()传入num_classes = 5</p>
<h1><a href="http://predict.py">predict.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> resnet34</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="number">256</span>),</span><br><span class="line">         transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;./tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = resnet34(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    weights_path = <span class="string">&quot;./resNet34.pth&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(weights_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(weights_path)</span><br><span class="line">    model.load_state_dict(torch.load(weights_path, map_location=device))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># prediction</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>预测结果（迁移学习）</p>
<p><img src="/2023/05/13/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAResNet%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/predict%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="predict迁移学习预测结果"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>ResNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（六）使用pytorch搭建VGG网络</title>
    <url>/2023/05/07/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVGG%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p><img src="/2023/05/07/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVGG%E7%BD%91%E7%BB%9C/VGG%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%A1%A8.png" alt="VGG网络架构表"></p>
<p>在上堂课讲解了D模型，今次以实操的形式，针对模型A、B、D、E做一个代码的实现。将代码构造分为两部分：提取特征网络结构（图中橙色框）、分类网络结构（图中绿色框）</p>
<h1>VGG网络架构</h1>
<h2 id="model-py"><a href="http://model.py">model.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># official pretrain weights</span></span><br><span class="line">model_urls = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg11-bbd30ac9.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg13-c768596a.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg16-397923af.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGG</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(VGG, self).__init__()</span><br><span class="line">        self.features = features</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, num_classes)</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># N x 3 x 224 x 224</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        <span class="comment"># N x 512 x 7 x 7</span></span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># N x 512*7*7</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.xavier_uniform_(m.weight)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.xavier_uniform_(m.weight)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_features</span>(<span class="params">cfg: <span class="built_in">list</span></span>):</span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&quot;M&quot;</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            layers += [conv2d, nn.ReLU(<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">cfgs = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">model_name=<span class="string">&quot;vgg16&quot;</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cfg = cfgs[model_name]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Warning: model number &#123;&#125; not in cfgs dict!&quot;</span>.<span class="built_in">format</span>(model_name))</span><br><span class="line">        exit(-<span class="number">1</span>)</span><br><span class="line">    model = VGG(make_features(cfg), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>定义一个字典文件，字典中每个key代表着一个模型的配置文件。</p>
<ul>
<li>eg：vgg11：对应A配置（模型A），即11层的网络结构（11层指的是卷积层+全连接层的个数）；</li>
<li>vgg13：对应配置B（模型B），即13层网络结构；</li>
<li>vgg16：对应配置D（模型D），即16层网络结构；</li>
<li>vgg19：对应配置E（模型E），即19层网络结构；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cfgs = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>含义解释：eg：vgg11的配置文件，对应的值是一个列表，其中列表的数字代表着卷积层中卷积核的个数，其中的字符M代表的是池化层的结构。</p>
<p>对应着表中配置A的内容，第一层是一个3*3的卷积，有64个卷积核，因此在配置列表中的第一个元素是64；第二层是一个最大池化下采样层，因此配置列表中对应的是一个M字符；第三层是一个卷积层大小为3*3的卷积核，有128个卷积核，因此在配置列表中对应的元素为128；第四层是一个最大池化下采样层，对应一个M字符；</p>
<p>接下来经过的是2个3*3的卷积核个数为256的卷积核，因此配置列表中对应两个256；再接下来是一个最大池化下采样层，对应一个M字符；接下来经过的是2个3*3的卷积核个数为512的卷积核，因此配置列表中对应两个512；再接下来是一个最大池化下采样层，对应一个M字符；接下来经过的是2个3*3的卷积核个数为512的卷积核，因此配置列表中对应两个512；再接下来是一个最大池化下采样层，对应一个M字符；</p>
<h3 id="提取特征网络结构">提取特征网络结构</h3>
<p>提取特征网络结构，传入参数为列表类型的配置变量，在运行过程中，只需要传入cfgs对应配置的列表即可。</p>
<p>假设传入一个列表，首先定义空列表layers，用来存放创建的每一层结构；紧接着定义in_channels变量，因为输入的是rgb彩色图像，所以输入通道为3；接下来通过一个for循环来遍历配置列表。如果当前的配置元素是一个M字符，则该层是一个最大池化层，那么创建一个最大池化下采样层，就是nn.MaxPool2d。上节课讲到，在VGG网络中，所有的最大池化下采样池化核大小都为2，步距也都为2，因此kernel_size=2, stride=2。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_features</span>(<span class="params">cfg: <span class="built_in">list</span></span>):</span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&quot;M&quot;</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            layers += [conv2d, nn.ReLU(<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
<p>如果当前的配置元素不为M字符，则该层是一个卷积层。</p>
<p>创建一个卷积操作nn.Conv2d，在第一层卷积层中，输入的深度是彩色图像的3，因此第一个值是in_channels；输出的特征矩阵的深度对应着卷积核的个数，因此在第一层卷积层中，v对应64。上堂课中讲到，在VGG中，所有的卷积核为3*3，步距为1，padding为1（stride默认为1，所以没写）。因为每一个卷积层都需要采用ReLU激活函数，所以将刚刚定义好的卷积层和ReLU激活函数拼接在一起，并添加在事先定义好的layers列表中。</p>
<p>当特征矩阵通过该层卷积之后，输出深度变为v，因此执行in_channels = v，因此再下一层卷积层时，它的in_channel会自动变为上一层的卷积层的输出特征矩阵的深度。</p>
<p>通过for循环遍历配置列表，能得到一个有卷积操作和池化操作所组成的一个列表。</p>
<p>接下来通过nn.Sequential函数，将layers列表通过非关键字参数的形式传入进去。在代码中layers前有一个*，代表着是通过非关键字参数传入函数。</p>
<p>原因：在Sequential类中给出了两个使用示例：第一个是最常用的，通过将一个个非关键字参数输入到Sequential类中，就能生成一个新的网络层结构；第二种通过一个有序的字典的形式进行输入。我们这是通过一个非关键字参数的形式输入，因此加了一个*。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># class Sequential(Module):</span></span><br><span class="line">    model = nn.Sequential(</span><br><span class="line">              nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>),</span><br><span class="line">              nn.ReLU(),</span><br><span class="line">              nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>),</span><br><span class="line">              nn.ReLU()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Using Sequential with OrderedDict. This is functionally the</span></span><br><span class="line">    <span class="comment"># same as the above code</span></span><br><span class="line">    model = nn.Sequential(OrderedDict([</span><br><span class="line">              (<span class="string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">              (<span class="string">&#x27;relu1&#x27;</span>, nn.ReLU()),</span><br><span class="line">              (<span class="string">&#x27;conv2&#x27;</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">              (<span class="string">&#x27;relu2&#x27;</span>, nn.ReLU())</span><br><span class="line">            ]))</span><br></pre></td></tr></table></figure>
<p><strong>（函数被调用的时候，使用*解包一个可迭代对象作为函数的参数，字典对象可以使用两个参数，解包后将作为关键字参数传递给函数；解包：将序列里面的元素一个个拆开）</strong></p>
<h3 id="分类网络结构">分类网络结构</h3>
<p>定义VGG类，继承于nn.Module父类，在初始化函数中，传进参数有features（提取特征网络结构），num_classes（分类类别个数），init_weights（是否对网络进行权重初始化）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VGG</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span><br></pre></td></tr></table></figure>
<p>通过nn.Sequential生成分类网络结构，在VGG网络结构中，图像通过提取特征网络结构之后，会生成一个7*7*512的特征矩阵，如果要进行全连接操作，需要先进行展平处理。在全连接操作之前，加入Dropout函数，目的是为了减少过拟合，有50%的几率随机失活神经元。第一层全连接层，原论文当中应该是4096，但为了减少训练参数，这里减半2048</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.classifier = nn.Sequential(</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>, <span class="number">2048</span>),</span><br><span class="line">    nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),</span><br><span class="line">    nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">2048</span>, num_classes)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>是否需要对网络对参数可视化，如果为init_weights为true，就会进入到事先定义的初始化权重函数中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> init_weights:</span><br><span class="line">    self._initialize_weights()</span><br></pre></td></tr></table></figure>
<p>正向传播过程：输入x为输入的图像数据，features：提取特征网络结构，接着对输出进行展平处理，展平之后再将输出的特征矩阵输入到classifier函数中，最后得到输出</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># N x 3 x 224 x 224</span></span><br><span class="line">    x = self.features(x)</span><br><span class="line">    <span class="comment"># N x 512 x 7 x 7</span></span><br><span class="line">    x = torch.flatten(x, start_dim=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># N x 512*7*7</span></span><br><span class="line">    x = self.classifier(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>在初始化权重函数中，会遍历网络的每一个子模块，即每一层。如果遍历的当前层是卷积层，就用xavier_uniform_初始化方法取初始化卷积层权重，如果有使用到偏置的话，会初始化偏置为0。</p>
<p>如果遍历当前层是全连接层，那么同样使用xavier_uniform_初始化方法去初始化全连接层权重，同样讲偏置为0。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line">            <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line">            nn.init.constant_(m.bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>实例化所给定的配置模型，通过传入变量model_name，需要实例化哪一个模型配置，默认为vgg16。</p>
<p>以此代码为例：将vgg16传入到vgg函数中，cfg = cfgs[vgg16]，即vgg16关键字对应的配置列表内容，再通过VGG类实例化VGG网络（首先传入第一个参数是features（来源于make_features），后面两个*对应的变量是一个可变函数的字典变量，通过在调用VGG函数时所传入的字典变量，这个字典变量可能包含了分类个数，是否初始化权重的bool变量）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">model_name=<span class="string">&quot;vgg16&quot;</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cfg = cfgs[model_name]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Warning: model number &#123;&#125; not in cfgs dict!&quot;</span>.<span class="built_in">format</span>(model_name))</span><br><span class="line">        exit(-<span class="number">1</span>)</span><br><span class="line">    model = VGG(make_features(cfg), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h2 id="train-py"><a href="http://train.py">train.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> vgg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line">data_transform = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                 transforms.RandomHorizontalFlip(),</span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">    <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># getcwd获取当前文件所在目录，..返回上层目录</span></span><br><span class="line">data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;..&quot;</span>))  <span class="comment"># get data root path</span></span><br><span class="line">image_path = data_root + <span class="string">&quot;/data_set/flower_data/&quot;</span></span><br><span class="line"><span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">train_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/train&quot;</span>,</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"><span class="comment"># 雏菊         蒲公英          玫瑰      向日葵         郁金香</span></span><br><span class="line"><span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line"><span class="comment"># 获取分类的名称所对应的索引</span></span><br><span class="line">flower_list = train_dataset.class_to_idx</span><br><span class="line"><span class="comment"># 遍历flower_list字典，将key和val反过来，是为了预测之后返回的索引能直接使用字典对应到所属的类别</span></span><br><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line"><span class="comment"># 通过json将cla_dict字典编码成json的格式</span></span><br><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 打开class_indices.json文件，将json_str保存进去，为了方便预测时读取信息</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                           batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/val&quot;</span>,</span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                              batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                              num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test_data_iter = iter(validate_loader)</span></span><br><span class="line"><span class="comment"># test_image, test_label = test_data_iter.__next__()</span></span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&#x27;vgg16&#x27;</span></span><br><span class="line">net = vgg(model_name=model_name, num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">net.to(device)</span><br><span class="line"><span class="comment"># CrossEntropyLoss针对多类别的损失交叉熵函数</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 调试用来查看模型的参数</span></span><br><span class="line"><span class="comment"># pata = list(net.parameters())</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;./&#123;&#125;Net.pth&#x27;</span>.<span class="built_in">format</span>(model_name)</span><br><span class="line"><span class="comment"># 历史最优准确率初始化</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    <span class="comment"># 使用到Dropout，想要实现的是在训练过程中失活一部分神经元，而不想在预测过程中失活</span></span><br><span class="line">    <span class="comment"># 因此通过net.train()和net.eval()来管理Dropout方法，在net.train()中开启Dropout方法，而在net.eval()中会关闭掉</span></span><br><span class="line">    net.train()</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    t1 = time.perf_counter()</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(images.to(device))</span><br><span class="line">        loss = loss_function(outputs, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="comment"># 打印在训练过程中的训练进度，len(train_loader)获取训练一轮所需要的步数step + 1获取当前的轮数</span></span><br><span class="line">        rate = (step + <span class="number">1</span>) / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        a = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>(rate * <span class="number">50</span>)</span><br><span class="line">        b = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>((<span class="number">1</span> - rate) * <span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\rtrain loss: &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">int</span>(rate * <span class="number">100</span>), a, b, loss), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(time.perf_counter() - t1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># validate</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data_test <span class="keyword">in</span> validate_loader:</span><br><span class="line">            test_image, test_label = data_test</span><br><span class="line">            outputs = net(test_image.to(device))</span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += torch.eq(predict_y, test_label.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line">        accurate_test = acc / val_num</span><br><span class="line">        <span class="keyword">if</span> accurate_test &gt; best_acc:</span><br><span class="line">            best_acc = accurate_test</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / step, accurate_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>代码内容和在AlexNet中一致，不做特别讲解，额外说明一下图像初始化中的某处特殊性，及修改了调用VGG函数的部分参数</p>
<h3 id="说明transforms-Normalize">说明transforms.Normalize</h3>
<p>在大多数VGG使用论文中，大部分会在预处理第一步，将RGB三个通道分别减去[123.68,116.78,103.94]，这三个值分别对应imageNet的图像数据集的所有数据三个通道的均值。</p>
<p>但这里并没有减去均值，因为这里搭建的VGG模型是从头开始训练的，如果需要基于迁移学习的方式进行再训练的话，就需要减去均值，因为预训练的模型是基于imageNet数据集进行训练的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_transform = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                 transforms.RandomHorizontalFlip(),</span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br></pre></td></tr></table></figure>
<h3 id="调用vgg函数">调用vgg函数</h3>
<p>通过model_name确认调用哪一个配置文件，num_classes和init_weights参数输入进去之后，会保存在model中**kwargs的可变长度字典当中。当调用VGG类时，即可调用相应的参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_name = <span class="string">&#x27;vgg16&#x27;</span></span><br><span class="line">net = vgg(model_name=model_name, num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h1>总结</h1>
<p>因为VGG网络非常大，而训练集样本太小（只有3k+），是无法充分训练vgg网络，因此不做训练展示，且网络太大， 训练起来可能需要几个小时，在训练中能够达到的准确率大概在80%，时间漫长效果不太好，不建议日常使用。</p>
<p>如果需要使用VGG网络，建议使用迁移学习的方法。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>VGG</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十四）使用pytorch搭建MobileNetV2V3并基于迁移学习训练</title>
    <url>/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<h1>MobileNet v2v3网络搭建</h1>
<p><strong>工程目录</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test6_mobilenet</span><br><span class="line">	├── model_v2.py（MobileNet v2模型文件）  </span><br><span class="line">	├── model_v3.py（MobileNet v3模型文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,MobileNetV2/V3.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	├── mobilenet_v2.pth（用于迁移学习时，提前下载好官方的MobileNet v2权重脚本）</span><br><span class="line">	└── mobilenet_v3_large.pth（用于迁移学习时，提前下载好官方的mobilenet_v3_large权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h2 id="model-v2-py">model_v2.py</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_make_divisible</span>(<span class="params">ch, divisor=<span class="number">8</span>, min_ch=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNReLU</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, groups=<span class="number">1</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride, expand_ratio</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MobileNetV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, alpha=<span class="number">1.0</span>, round_nearest=<span class="number">8</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h3 id="网络结构参数"><strong>网络结构参数</strong></h3>
<blockquote>
<p>先通过普通卷积，之后进行一个Inverted residual结构（n：倒残差结构重复几遍），一直重复倒残差结构，再通过1x1的普通卷积操作，紧接着平均池化下采样，最后是通过1x1卷积得到最终输出（作用同全连接层）</p>
</blockquote>
<p>搭建该网络重点在于<strong>搭建好Inverted residual结构</strong></p>
<img src="/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/Mobilenetv2网络结构参数.png" alt="Mobilenetv2网络结构参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h3 id="ConvBNReLU类">ConvBNReLU类</h3>
<p>ConvBNReLU类是包含conv、BN和ReLU6激活函数的组合层。在MNv2网络中，所有卷积层以及上节课所讲的DW卷积操作，基本上都是由卷积+BN+ReLU6激活函数组成的。</p>
<p><strong>唯一不同的是在Inverted residual结构中的第三层，也就是使用1x1的卷积对特征矩阵进行降维处理，这里使用线性激活函数</strong>，其他地方就都是通过卷积+BN+ReLU6激活函数组成。</p>
<p>因此创建ConvBNReLU类，继承来自<strong>nn.Sequential父类</strong>（nn.Sequential不需要写forward函数，此处参照pytorch的官方实现）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNReLU</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, groups=<span class="number">1</span></span>):</span><br><span class="line">        padding = (kernel_size - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">        <span class="built_in">super</span>(ConvBNReLU, self).__init__(</span><br><span class="line">            nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, groups=groups, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channel),</span><br><span class="line">            nn.ReLU6(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h3 id="Inverted-residual结构">Inverted residual结构</h3>
<p>类似于ResNet中的残差结构，只不过普通的ResNet的残差结构是两头粗中间细的结构，但倒残差结构是两头细中间粗的结构。</p>
<img src="/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/Inverted residual参数结构.png" alt="Inverted residual结构参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<blockquote>
<p>第一层：普通卷积层，卷积核大小为1x1，激活函数是ReLU6，采用卷积核个数为tk（t是倍率因子，用来扩大特征矩阵深度）；</p>
<p>第二层：DW卷积，卷积核大小为3x3，步距stride = s（传入参数），激活函数是ReLU6，卷积核个数 = 输入特征矩阵深度 = 输出特征矩阵深度，缩减高宽；</p>
<p>第三层：普通1x1卷积层，采用线性激活函数，卷积核个数为k‘（人为设定）</p>
</blockquote>
<p><strong>__init__函数</strong></p>
<ul>
<li>初始化函数传入参数<code>expand_ratio</code>：拓展因子，即上图表中的t</li>
<li>定义隐层<code>hidden_channel</code>：第一层卷积核的个数，即上图表中的tk</li>
<li><code>self.use_shortcut</code>：是一个bool变量，判断在正向传播过程中是否采用shortcut（只有当stride = 1且输入特征矩阵的shape与输出特征矩阵的shape保持一致市才能使用sortcut）</li>
<li>定义层列表<code>layers</code>：判断expand_ratio是否等于1（在v2网络结构参数表中的第一个bottleneck的第一层中，n = 1，s = 1，因此特征矩阵的shape都未发生变化，因此在搭建过程中进行跳过），当expand_ratio = 1时，跳过该处1x1卷积层。</li>
</ul>
<blockquote>
<p>假设此处expand_ratio！= 1，那么就需要在layers列表中添加一个卷积层，调用ConvBNReLU层结构（输入特征矩阵深度，hidden_channel，由上图（右表）得知第一层卷积核大小为1x1）。</p>
</blockquote>
<ul>
<li>调用<code>layers.extend</code>函数：添加一系列层结构，实际上通过extend和append函数添加层结构是一样的，只不过extend函数能够实现一次性批量插入多个元素。</li>
</ul>
<blockquote>
<p>对于Inverted residual结构，第二层是DW卷积，因此此处调用定义好的ConvBNReLU层结构，输入特征矩阵深度为上一层的输出特征矩阵深度hidden_channel，输出深度同样为hidden_channel（因为DW卷积层的输入特征矩阵深度和输出特征矩阵深度是一样的）</p>
<p>stride是传入的参数，group默认为1时是普通卷积，当传入与输入特征矩阵深度相同的个数的话，就是DW卷积。而此处输入特征矩阵的深度是hidden_channel，因此此处groups=hidden_channel。</p>
<p>第三层是1x1的普通卷积，所采用的的激活函数是线性激活函数（y = x），不能使用定义好的ConvBNReLU，因此使用原始的Conv2d，输入特征矩阵深度为上一层输出特征矩阵深度，输出特征矩阵深度为传入参数out_channel，卷积核大小为1</p>
<p>最后使用Batch Normalization标准化处理。</p>
<p>注意：<strong>因为第三层使用线性激活函数y = x，等于不对输入做任何处理，因此不需要再额外定义一个激活层函数，因为不添加激活层函数，就等于linear激活函数</strong></p>
</blockquote>
<ul>
<li>最后通过nn.Sequential类将*layers参数传入进去（*用于将层列表解包为位置参数，这使我们能够像船体单个参数一样将层列表传递给Sequential模块</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, out_channel, stride, expand_ratio</span>):</span><br><span class="line">        <span class="built_in">super</span>(InvertedResidual, self).__init__()</span><br><span class="line">        hidden_channel = in_channel * expand_ratio</span><br><span class="line">        self.use_shortcut = stride == <span class="number">1</span> <span class="keyword">and</span> in_channel == out_channel</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">if</span> expand_ratio != <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 1x1 pointwise conv</span></span><br><span class="line">            layers.append(ConvBNReLU(in_channel, hidden_channel, kernel_size=<span class="number">1</span>))</span><br><span class="line">        layers.extend([</span><br><span class="line">            <span class="comment"># 3x3 depthwise conv</span></span><br><span class="line">            ConvBNReLU(hidden_channel, hidden_channel, stride=stride, groups=hidden_channel),</span><br><span class="line">            <span class="comment"># 1x1 pointwise conv(linear)</span></span><br><span class="line">            nn.Conv2d(hidden_channel, out_channel, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channel),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
<p><strong>forward函数</strong></p>
<p>x为输入特征矩阵</p>
<p>首先进行判断，是否使用shortcut，如果使用即返回特征矩阵与shortcut相加之后的输出特征矩阵；如果不使用shortcut，则直接返回主分支上的输出特征矩阵。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">	<span class="keyword">if</span> self.use_shortcut:</span><br><span class="line">		<span class="keyword">return</span> x + self.conv(x)</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure>
<h3 id="make-divisible函数">_make_divisible函数</h3>
<p><strong>是为了将卷积核个数（输出的通道个数）调整为输入round_nearest参数的整数倍</strong>。搭建中采用round_nearest=8，也就是要将卷积核的个数设置为8的整数倍。</p>
<p>目的：为了更好的调用硬件设备，比如多GPU变形运算，或者多机器分布式运算</p>
<ul>
<li><code>ch</code>：传入的卷积核个数（输出特征矩阵的channel）</li>
<li><code>divisor</code>：传入round_nearest基数，即将卷积核个数ch调整为divisor的整数倍</li>
<li><code>min_ch</code>：最小通道数，如果为None，就将min_ch设置为divisor</li>
<li><code>new_ch</code>：即将卷积核个数调整为离它最近的8的倍数的值</li>
<li>之后进行判断new_ch是否小于传入ch的0.9倍，如果小于，则加上一个divisor（为了确保new_ch向下取整的时候，不会减少超过10%）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_divisible</span>(<span class="params">ch, divisor=<span class="number">8</span>, min_ch=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This function is taken from the original tf repo.</span></span><br><span class="line"><span class="string">    It ensures that all layers have a channel number that is divisible by 8</span></span><br><span class="line"><span class="string">    It can be seen here:</span></span><br><span class="line"><span class="string">    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> min_ch <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        min_ch = divisor</span><br><span class="line">    new_ch = <span class="built_in">max</span>(min_ch, <span class="built_in">int</span>(ch + divisor / <span class="number">2</span>) // divisor * divisor)</span><br><span class="line">    <span class="comment"># Make sure that round down does not go down by more than 10%.</span></span><br><span class="line">    <span class="keyword">if</span> new_ch &lt; <span class="number">0.9</span> * ch:</span><br><span class="line">        new_ch += divisor</span><br><span class="line">    <span class="keyword">return</span> new_ch</span><br></pre></td></tr></table></figure>
<h3 id="定义MNv2网络">定义MNv2网络</h3>
<ul>
<li><code>block</code>：将前面定义的InvertedResidual类传给block</li>
<li><code>input_channel</code>：是第一层卷积层所采用的卷积核的个数，也就是下一层输出特征矩阵的深度，为8的倍数</li>
<li><code>last_channel</code>：指的是参数表中1x1的卷积核，输出特征矩阵深度为1280</li>
<li><code>inverted_residual_setting</code>：根据参数表创建list列表，列表中的元素对应着参数表中每一行的参数t（拓展因子）、c（输出channel）、n（倒残差结构重复次数）、s（每一个block第一层卷积层的步距）</li>
<li><code>features</code>：在其中先添加第一个卷积层，输入channel即彩色图片</li>
</ul>
<blockquote>
<p>通过循环定义一系列的Inverted residual结构。将每一层output_channel通过_make_divisible函数进行调整，再进行n次的Inverted residual（在循环中除了列表中的stride = s，其他都是 = 1）</p>
<p>在经过一系列Inverted residual处理后，接下来的是一个1x1的卷积层，直接使用ConvBNReLU</p>
</blockquote>
<ul>
<li>
<p><code>self.features</code>：通常将以上一系列层结构统称为特征提取层，所以Sequential将刚刚定义好的一系列层结构通过位置参数的形式传入进去，打包成一个整体。</p>
</li>
<li>
<p>定义由<code>self.avgpool</code>和<code>self.classifier</code>组成的分类器</p>
<blockquote>
<p>首先定义平均池化下采样层（采用自适应的平均池化下采样操作，给定输出特征矩阵的高宽为1）</p>
<p>再通过nn.Sequential将Dropout层和全连接层组合在一起</p>
</blockquote>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MobileNetV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, alpha=<span class="number">1.0</span>, round_nearest=<span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MobileNetV2, self).__init__()</span><br><span class="line">        block = InvertedResidual</span><br><span class="line">        input_channel = _make_divisible(<span class="number">32</span> * alpha, round_nearest)</span><br><span class="line">        last_channel = _make_divisible(<span class="number">1280</span> * alpha, round_nearest)</span><br><span class="line"></span><br><span class="line">        inverted_residual_setting = [</span><br><span class="line">            <span class="comment"># t, c, n, s</span></span><br><span class="line">            [<span class="number">1</span>, <span class="number">16</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">            [<span class="number">6</span>, <span class="number">24</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">            [<span class="number">6</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">            [<span class="number">6</span>, <span class="number">64</span>, <span class="number">4</span>, <span class="number">2</span>],</span><br><span class="line">            [<span class="number">6</span>, <span class="number">96</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">            [<span class="number">6</span>, <span class="number">160</span>, <span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">            [<span class="number">6</span>, <span class="number">320</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        features = []</span><br><span class="line">        <span class="comment"># conv1 layer</span></span><br><span class="line">        features.append(ConvBNReLU(<span class="number">3</span>, input_channel, stride=<span class="number">2</span>))</span><br><span class="line">        <span class="comment"># building inverted residual residual blockes</span></span><br><span class="line">        <span class="keyword">for</span> t, c, n, s <span class="keyword">in</span> inverted_residual_setting:</span><br><span class="line">            output_channel = _make_divisible(c * alpha, round_nearest)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                stride = s <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">                features.append(block(input_channel, output_channel, stride, expand_ratio=t))</span><br><span class="line">                input_channel = output_channel</span><br><span class="line">        <span class="comment"># building last several layers</span></span><br><span class="line">        features.append(ConvBNReLU(input_channel, last_channel, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># combine feature layers</span></span><br><span class="line">        self.features = nn.Sequential(*features)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># building classifier</span></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(last_channel, num_classes)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p><strong>权重初始化</strong></p>
<ul>
<li>遍历每一个子模块，如果是卷积层，就对权重进行初始化，如果存在偏置，则将偏置设置为0；</li>
<li>如果子模块是一个BN层，则将方差设置为1，均值设置为0；</li>
<li>如果子模块是一个全连接层的话，对权重进行初始化，normal_函数为一个正态分布函数，将权重调整为均值为0.0，方差为0.01的正态分布；将偏置设置为0</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># weight initialization</span></span><br><span class="line">	<span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">			nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>)</span><br><span class="line">			<span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">				nn.init.zeros_(m.bias)</span><br><span class="line">		<span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">			nn.init.ones_(m.weight)</span><br><span class="line">			nn.init.zeros_(m.bias)</span><br><span class="line">		<span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">			nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">			nn.init.zeros_(m.bias)</span><br></pre></td></tr></table></figure>
<p><strong>正向传播过程</strong></p>
<p>首先将输入特征矩阵输入进特征提取部分，通过平均池化下采样得到输出，再对输出进行展平处理，最后通过分类器得到最终输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">	x = self.features(x)</span><br><span class="line">	x = self.avgpool(x)</span><br><span class="line">	x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">	x = self.classifier(x)</span><br><span class="line">	<span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="model-v3-py">model_v3.py</h2>
<img src="/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/Mobilenet v3网络结构参数.png" alt="Mobilenet v3网络结构参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Callable</span>, <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, Tensor</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line"><span class="comment">#同MobileNet v2中的_make_divisible作用一致</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_make_divisible</span>(<span class="params">ch, divisor=<span class="number">8</span>, min_ch=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNActivation</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_planes: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 out_planes: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span> = <span class="number">3</span>, </span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span> = <span class="number">1</span>, </span></span><br><span class="line"><span class="params">                 groups: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 activation_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SqueezeExcitation</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_c: <span class="built_in">int</span>, squeeze_factor: <span class="built_in">int</span> = <span class="number">4</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidualConfig</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_c: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 kernel: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 expanded_c: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 out_c: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 use_se: <span class="built_in">bool</span>, </span></span><br><span class="line"><span class="params">                 activation: <span class="built_in">str</span>, </span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 width_multi: <span class="built_in">float</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">adjust_channels</span>(<span class="params">channels: <span class="built_in">int</span>, width_multi: <span class="built_in">float</span></span>):</span><br><span class="line">        <span class="keyword">return</span> _make_divisible(channels * width_multi, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cnf: InvertedResidualConfig, norm_layer: <span class="type">Callable</span>[..., nn.Module]</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MobileNetV3</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, </span></span><br><span class="line"><span class="params">                 inverted_residual_setting: <span class="type">List</span>[InvertedResidualConfig], </span></span><br><span class="line"><span class="params">                 last_channel: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 block: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_forward_impl</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mobilenet_v3_large</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                       reduced_tail: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; MobileNetV3:</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mobilenet_v3_small</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                       reduced_tail: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; MobileNetV3:</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h3 id="make-divisible函数-2">_make_divisible函数</h3>
<p>同MobileNet v2中的_make_divisible作用一致，<strong>是为了将卷积核个数（输出的通道个数）调整为输入round_nearest参数的整数倍</strong>。搭建中采用round_nearest=8，也就是要将卷积核的个数设置为8的整数倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_divisible</span>(<span class="params">ch, divisor=<span class="number">8</span>, min_ch=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This function is taken from the original tf repo.</span></span><br><span class="line"><span class="string">    It ensures that all layers have a channel number that is divisible by 8</span></span><br><span class="line"><span class="string">    It can be seen here:</span></span><br><span class="line"><span class="string">    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> min_ch <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        min_ch = divisor</span><br><span class="line">    new_ch = <span class="built_in">max</span>(min_ch, <span class="built_in">int</span>(ch + divisor / <span class="number">2</span>) // divisor * divisor)</span><br><span class="line">    <span class="comment"># Make sure that round down does not go down by more than 10%.</span></span><br><span class="line">    <span class="keyword">if</span> new_ch &lt; <span class="number">0.9</span> * ch:</span><br><span class="line">        new_ch += divisor</span><br><span class="line">    <span class="keyword">return</span> new_ch</span><br></pre></td></tr></table></figure>
<h3 id="ConvBNActivation类">ConvBNActivation类</h3>
<p>ConvBNActivation类是包含conv、BN和激活函数的组合层。</p>
<ul>
<li><code>in_planes</code>：输入特征矩阵的深度</li>
<li><code>out_planes</code>：输出特征矩阵的深度，对应卷积核的个数</li>
<li><code>norm_layer</code>：对应的在卷积后接的BN层</li>
<li><code>activation_layer</code>：对应激活函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNActivation</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 in_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 groups: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 activation_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span>):</span><br><span class="line">        padding = (kernel_size - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        <span class="keyword">if</span> activation_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            activation_layer = nn.ReLU6</span><br><span class="line">        <span class="built_in">super</span>(ConvBNActivation, self).__init__(nn.Conv2d(in_channels=in_planes,</span><br><span class="line">                                                         out_channels=out_planes,</span><br><span class="line">                                                         kernel_size=kernel_size,</span><br><span class="line">                                                         stride=stride,</span><br><span class="line">                                                         padding=padding,</span><br><span class="line">                                                         groups=groups,</span><br><span class="line">                                                         bias=<span class="literal">False</span>),</span><br><span class="line">                                               norm_layer(out_planes),</span><br><span class="line">                                               activation_layer(inplace=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
<h3 id="SqueezeExcitation模块">SqueezeExcitation模块</h3>
<p><strong>初始化函数</strong></p>
<p>相当于两个全连接层。</p>
<ul>
<li><strong>对于第一个全连接层，此处的节点个数 = 该处输入的特征矩阵channel的1/4</strong>（在v3原论文中作者有给出）</li>
<li>第二层全连接层的节点个数 = 该处输入的特征矩阵channel</li>
<li>第一个全连接层的激活函数是ReLU，第二个全连接层的激活函数是hard-sigmoid</li>
</ul>
<img src="/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/SE注意力机制模块.png" alt="SE注意力机制模块" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<ul>
<li><code>squeeze_factor</code>：因为第一个全连接层的节点个数是输入的特征矩阵channel的1/4，所以这里存放的是分母4；</li>
<li><code>squeeze_c</code>：调用_make_divisible方法调整到离该数最近的8的整数倍的数字；</li>
<li><code>self.fc1</code>：使用卷积来作为全连接层，作用与全连接层一样</li>
<li><code>self.fc2</code>：输入channel是上一层的输出channel，所以是squeeze_c，又因为SE机制最终输出需要和输入特征矩阵的channel保持一致，所以输出channel为input_c</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SqueezeExcitation</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_c: <span class="built_in">int</span>, squeeze_factor: <span class="built_in">int</span> = <span class="number">4</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SqueezeExcitation, self).__init__()</span><br><span class="line">        squeeze_c = _make_divisible(input_c // squeeze_factor, <span class="number">8</span>)</span><br><span class="line">        self.fc1 = nn.Conv2d(input_c, squeeze_c, <span class="number">1</span>)</span><br><span class="line">        self.fc2 = nn.Conv2d(squeeze_c, input_c, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><strong>正向传播函数</strong></p>
<p>如上图（下）第三个特征矩阵需要进行池化操作，因此进行自适应池化下采样操作，并且返回特征矩阵的高宽是1x1。再将拿到的输出通过全连接层，relu激活函数，第二层全连接层，和一个h-sigmoid激活函数，得到输出。<strong>这里的输出就是第二层全连接层的输出，也就是得到了不同channel对应的权重</strong>。</p>
<p>接下来需要将输出与原特征矩阵相乘，得到通过SE模块之后的输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor: <span class="comment"># 返回Tensor结构</span></span><br><span class="line">       scale = F.adaptive_avg_pool2d(x, output_size=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">       scale = self.fc1(scale)</span><br><span class="line">       scale = F.relu(scale, inplace=<span class="literal">True</span>)</span><br><span class="line">       scale = self.fc2(scale)</span><br><span class="line">       scale = F.hardsigmoid(scale, inplace=<span class="literal">True</span>)</span><br><span class="line">       <span class="keyword">return</span> scale * x</span><br></pre></td></tr></table></figure>
<h3 id="InvertedResidualConfig类">InvertedResidualConfig类</h3>
<p>InvertedResidualConfig对应的是MobileNetV3中的每一个bneck结构的参数配置，其中有</p>
<ul>
<li><code>input_c</code>：输入特征矩阵的大小（主要指channel）；</li>
<li><code>kernel</code>：每一层使用的kernel_size（即DW卷积中的卷积核大小）；</li>
<li><code>expanded_c</code>：第一层卷积层所采用的的卷积核的个数；</li>
<li><code>out_c</code>：最后一层1x1的卷积层输出得到特征矩阵的channel；</li>
<li><code>use_se</code>：是否使用SE注意力机制；</li>
<li><code>activation</code>：采用的激活函数，RE表示采用ReLU激活函数，HS表示采用H-Swish激活函数；</li>
<li><code>stride</code>：指的是DW卷积所对应的步距；</li>
<li><code>width_multi</code>：就是MNv2中提到的$\alpha$参数，用来调节每一个卷积层所使用channel的倍率因子。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidualConfig</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 expanded_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 use_se: <span class="built_in">bool</span>,</span></span><br><span class="line"><span class="params">                 activation: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 width_multi: <span class="built_in">float</span></span>):</span><br><span class="line">        self.input_c = self.adjust_channels(input_c, width_multi)</span><br><span class="line">        self.kernel = kernel</span><br><span class="line">        self.expanded_c = self.adjust_channels(expanded_c, width_multi)</span><br><span class="line">        self.out_c = self.adjust_channels(out_c, width_multi)</span><br><span class="line">        self.use_se = use_se</span><br><span class="line">        self.use_hs = activation == <span class="string">&quot;HS&quot;</span>  <span class="comment"># whether using h-swish activation</span></span><br><span class="line">        self.stride = stride</span><br></pre></td></tr></table></figure>
<p><strong>adjust_channels函数</strong></p>
<p>是一个静态方法，其实也是直接调用了_make_divisible方法，传入参数为channel和$\alpha$倍率因子，最终得到channel和$\alpha$的乘积离8最近的整数倍的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_channels</span>(<span class="params">channels: <span class="built_in">int</span>, width_multi: <span class="built_in">float</span></span>):</span><br><span class="line">	<span class="keyword">return</span> _make_divisible(channels * width_multi, <span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<h3 id="InvertedResidual类">InvertedResidual类</h3>
<p><strong>初始化函数</strong></p>
<ul>
<li><code>cnf</code>：前文提到的InvertedResidualConfig配置文件；</li>
<li><code>norm_layer</code>：对应的在卷积后接的BN层</li>
<li><code>cnf.stride</code>：判断步距是否为1或2，因为在网络参数表中，步距只有1和2两种情况，当出现第三种情况时，就是不合法的步距情况；再判断</li>
<li><code>self.use_res_connect</code>：是否使用shortcut连接，shortcut只有在stride == 1且input_c == output_c时才有；</li>
<li><code>activation_layer</code>：判断使用ReLU或者H-Swish激活函数（官方是在1.7及以上版本中才有官方实现的H-Swish和H-Sigmoid激活函数，如果需要使用MNv3网络的话，得把pytorch版本更新至1.7及以上）</li>
<li>expand区域指在InvertedResidual结构中的第一个1x1卷积层进行升维处理，因为第一个kneck存在输入特征矩阵的channel和输出特征矩阵的channel相等，因此可以跳过，所以会进行判断cnf.expanded_c != cnf.input_c；</li>
<li>depthwise区域为dw卷积区域</li>
</ul>
<blockquote>
<p><code>groups</code>：由于DW卷积是针对每一个channel都单独使用一个channel为1的卷积核来进行卷及处理，所以groups和channel的个数是保持一致的，所以groups=cnf.expanded_c</p>
</blockquote>
<ul>
<li>project区域是InvertedResidual结构中1x1卷积中的降维部分，activation_layer=nn.Identity中的Identity其实就是线性y = x，没有做任何处理；</li>
<li></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 cnf: InvertedResidualConfig,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Callable</span>[..., nn.Module]</span>):</span><br><span class="line">        <span class="built_in">super</span>(InvertedResidual, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cnf.stride <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;illegal stride value.&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.use_res_connect = (cnf.stride == <span class="number">1</span> <span class="keyword">and</span> cnf.input_c == cnf.out_c)</span><br><span class="line"></span><br><span class="line">        layers: <span class="type">List</span>[nn.Module] = []</span><br><span class="line">        activation_layer = nn.Hardswish <span class="keyword">if</span> cnf.use_hs <span class="keyword">else</span> nn.ReLU</span><br><span class="line"></span><br><span class="line">        <span class="comment"># expand</span></span><br><span class="line">        <span class="keyword">if</span> cnf.expanded_c != cnf.input_c:</span><br><span class="line">            layers.append(ConvBNActivation(cnf.input_c,</span><br><span class="line">                                           cnf.expanded_c,</span><br><span class="line">                                           kernel_size=<span class="number">1</span>,</span><br><span class="line">                                           norm_layer=norm_layer,</span><br><span class="line">                                           activation_layer=activation_layer))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># depthwise</span></span><br><span class="line">        layers.append(ConvBNActivation(cnf.expanded_c,</span><br><span class="line">                                       cnf.expanded_c,</span><br><span class="line">                                       kernel_size=cnf.kernel,</span><br><span class="line">                                       stride=cnf.stride,</span><br><span class="line">                                       groups=cnf.expanded_c,</span><br><span class="line">                                       norm_layer=norm_layer,</span><br><span class="line">                                       activation_layer=activation_layer))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cnf.use_se:</span><br><span class="line">            layers.append(SqueezeExcitation(cnf.expanded_c))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project</span></span><br><span class="line">        layers.append(ConvBNActivation(cnf.expanded_c,</span><br><span class="line">                                       cnf.out_c,</span><br><span class="line">                                       kernel_size=<span class="number">1</span>,</span><br><span class="line">                                       norm_layer=norm_layer,</span><br><span class="line">                                       activation_layer=nn.Identity))</span><br><span class="line"></span><br><span class="line">        self.block = nn.Sequential(*layers)</span><br><span class="line">        self.out_channels = cnf.out_c</span><br></pre></td></tr></table></figure>
<p><strong>正向传播函数</strong></p>
<p>将特征矩阵传入block方法得到主分支输出特征矩阵，再经过判断是否有shortcut，如果有则相加，无则直接输出主分支特征矩阵。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">	result = self.block(x)</span><br><span class="line">	<span class="keyword">if</span> self.use_res_connect:</span><br><span class="line">		result += x</span><br><span class="line">	<span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h3 id="定义MNv3类">定义MNv3类</h3>
<p><strong>初始化函数</strong></p>
<ul>
<li><code>inverted_residual_setting</code>：对应一系列bneck结构参数的列表；</li>
<li><code>last_channel</code>：对应是MNv3网络参数表中倒数第二个全连接层的输出节点的个数；</li>
<li><code>block</code>：就是之前定义的InvertedResidual模块；</li>
<li><code>norm_layer</code>：对应的在卷积后接的BN层；</li>
</ul>
<p>当inverted_residual_setting为空或者不是一个list的话都会报错。</p>
<p><strong>building first layer</strong>创建第一层conv2d</p>
<blockquote>
<p>firstconv_output_c获取第一个bneck结构的输入特征矩阵的channel，所对应的是第一个卷积层输出的channel；</p>
<p>ConvBNActivation对应的是第一个conv2d，无论是v3-Large还是v3-Small，第一个都是3x3的卷积层。所以先创建了一个3x3的卷积层。</p>
</blockquote>
<p><strong>building inverted residual blocks</strong>创建block模块</p>
<blockquote>
<p>遍历每一个bneck结构，将每一层的配置文件和norm_layer都传给block，将创建好的每一个block结构，也就是InvertedResidual模块给填进layers当中。</p>
</blockquote>
<p><strong>building last several layers</strong>创建平均池化下采样层和几个卷积层</p>
<blockquote>
<p><code>lastconv_input_c</code>：最后一个bneck模块的输出特征矩阵channel；</p>
<p><code>lastconv_output_c</code>：无论是v3-Large还是v3-Small，lastconv_output_c都是lastconv_input_c的6倍</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MobileNetV3</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 inverted_residual_setting: <span class="type">List</span>[InvertedResidualConfig],</span></span><br><span class="line"><span class="params">                 last_channel: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 block: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MobileNetV3, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> inverted_residual_setting:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;The inverted_residual_setting should not be empty.&quot;</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> (<span class="built_in">isinstance</span>(inverted_residual_setting, <span class="type">List</span>) <span class="keyword">and</span></span><br><span class="line">                  <span class="built_in">all</span>([<span class="built_in">isinstance</span>(s, InvertedResidualConfig) <span class="keyword">for</span> s <span class="keyword">in</span> inverted_residual_setting])):</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&quot;The inverted_residual_setting should be List[InvertedResidualConfig]&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> block <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            block = InvertedResidual</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = partial(nn.BatchNorm2d, eps=<span class="number">0.001</span>, momentum=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">        layers: <span class="type">List</span>[nn.Module] = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># building first layer</span></span><br><span class="line">        firstconv_output_c = inverted_residual_setting[<span class="number">0</span>].input_c</span><br><span class="line">        layers.append(ConvBNActivation(<span class="number">3</span>,</span><br><span class="line">                                       firstconv_output_c,</span><br><span class="line">                                       kernel_size=<span class="number">3</span>,</span><br><span class="line">                                       stride=<span class="number">2</span>,</span><br><span class="line">                                       norm_layer=norm_layer,</span><br><span class="line">                                       activation_layer=nn.Hardswish))</span><br><span class="line">        <span class="comment"># building inverted residual blocks</span></span><br><span class="line">        <span class="keyword">for</span> cnf <span class="keyword">in</span> inverted_residual_setting:</span><br><span class="line">            layers.append(block(cnf, norm_layer))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># building last several layers</span></span><br><span class="line">        lastconv_input_c = inverted_residual_setting[-<span class="number">1</span>].out_c</span><br><span class="line">        lastconv_output_c = <span class="number">6</span> * lastconv_input_c</span><br><span class="line">        layers.append(ConvBNActivation(lastconv_input_c,</span><br><span class="line">                                       lastconv_output_c,</span><br><span class="line">                                       kernel_size=<span class="number">1</span>,</span><br><span class="line">                                       norm_layer=norm_layer,</span><br><span class="line">                                       activation_layer=nn.Hardswish))</span><br><span class="line">        self.features = nn.Sequential(*layers)</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.classifier = nn.Sequential(nn.Linear(lastconv_output_c, last_channel),</span><br><span class="line">                                        nn.Hardswish(inplace=<span class="literal">True</span>),</span><br><span class="line">                                        nn.Dropout(p=<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">                                        nn.Linear(last_channel, num_classes))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># initial weights</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&quot;fan_out&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.zeros_(m.bias)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, (nn.BatchNorm2d, nn.GroupNorm)):</span><br><span class="line">                nn.init.ones_(m.weight)</span><br><span class="line">                nn.init.zeros_(m.bias)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.zeros_(m.bias)</span><br></pre></td></tr></table></figure>
<p><strong>正向传播函数</strong></p>
<p>将输入特征矩阵依次通过特征提取、平均池化、展平和classifier处理得到输出结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_impl</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">return</span> self._forward_impl(x)</span><br></pre></td></tr></table></figure>
<h3 id="定义mobilenet-v3-large">定义mobilenet_v3_large</h3>
<ul>
<li><code>width_multi</code>：$\alpha$超参数，用来调整channel；</li>
<li><code>bneck_conf</code>：同样使用partial方法，给InvertedResidualConfig方法传入默认参数width_multi，即$\alpha$超参数；</li>
<li><code>adjust_channels</code>：即InvertedResidualConfig类中的adjust_channels方法，使用partial方法，给InvertedResidualConfig.adjust_channels方法传入默认参数width_multi，即$\alpha$超参数；</li>
<li><code>reduce_divider</code>：对应最后三层bneck结构，对卷积的channel进行了调整，这里默认为False，指不做调整，如果设置为True，可以减少一些参数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mobilenet_v3_large</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                       reduced_tail: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; MobileNetV3:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Constructs a large MobileNetV3 architecture from</span></span><br><span class="line"><span class="string">    &quot;Searching for MobileNetV3&quot; &lt;https://arxiv.org/abs/1905.02244&gt;.</span></span><br><span class="line"><span class="string">    weights_link:</span></span><br><span class="line"><span class="string">    https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        num_classes (int): number of classes</span></span><br><span class="line"><span class="string">        reduced_tail (bool): If True, reduces the channel counts of all feature layers</span></span><br><span class="line"><span class="string">            between C4 and C5 by 2. It is used to reduce the channel redundancy in the</span></span><br><span class="line"><span class="string">            backbone for Detection and Segmentation.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    width_multi = <span class="number">1.0</span></span><br><span class="line">    bneck_conf = partial(InvertedResidualConfig, width_multi=width_multi)</span><br><span class="line">    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_multi=width_multi)</span><br><span class="line"></span><br><span class="line">    reduce_divider = <span class="number">2</span> <span class="keyword">if</span> reduced_tail <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    inverted_residual_setting = [</span><br><span class="line">        <span class="comment"># input_c, kernel, expanded_c, out_c, use_se, activation, stride</span></span><br><span class="line">        bneck_conf(<span class="number">16</span>, <span class="number">3</span>, <span class="number">16</span>, <span class="number">16</span>, <span class="literal">False</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">16</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">24</span>, <span class="literal">False</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">2</span>),  <span class="comment"># C1</span></span><br><span class="line">        bneck_conf(<span class="number">24</span>, <span class="number">3</span>, <span class="number">72</span>, <span class="number">24</span>, <span class="literal">False</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">24</span>, <span class="number">5</span>, <span class="number">72</span>, <span class="number">40</span>, <span class="literal">True</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">2</span>),  <span class="comment"># C2</span></span><br><span class="line">        bneck_conf(<span class="number">40</span>, <span class="number">5</span>, <span class="number">120</span>, <span class="number">40</span>, <span class="literal">True</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">40</span>, <span class="number">5</span>, <span class="number">120</span>, <span class="number">40</span>, <span class="literal">True</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">40</span>, <span class="number">3</span>, <span class="number">240</span>, <span class="number">80</span>, <span class="literal">False</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">2</span>),  <span class="comment"># C3</span></span><br><span class="line">        bneck_conf(<span class="number">80</span>, <span class="number">3</span>, <span class="number">200</span>, <span class="number">80</span>, <span class="literal">False</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">80</span>, <span class="number">3</span>, <span class="number">184</span>, <span class="number">80</span>, <span class="literal">False</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">80</span>, <span class="number">3</span>, <span class="number">184</span>, <span class="number">80</span>, <span class="literal">False</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">80</span>, <span class="number">3</span>, <span class="number">480</span>, <span class="number">112</span>, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">112</span>, <span class="number">3</span>, <span class="number">672</span>, <span class="number">112</span>, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">112</span>, <span class="number">5</span>, <span class="number">672</span>, <span class="number">160</span> // reduce_divider, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">2</span>),  <span class="comment"># C4</span></span><br><span class="line">        bneck_conf(<span class="number">160</span> // reduce_divider, <span class="number">5</span>, <span class="number">960</span> // reduce_divider, <span class="number">160</span> // reduce_divider, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">160</span> // reduce_divider, <span class="number">5</span>, <span class="number">960</span> // reduce_divider, <span class="number">160</span> // reduce_divider, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">    ]</span><br><span class="line">    last_channel = adjust_channels(<span class="number">1280</span> // reduce_divider)  <span class="comment"># C5</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MobileNetV3(inverted_residual_setting=inverted_residual_setting,</span><br><span class="line">                       last_channel=last_channel,</span><br><span class="line">                       num_classes=num_classes)</span><br></pre></td></tr></table></figure>
<h3 id="定义mobilenet-v3-small">定义mobilenet_v3_small</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mobilenet_v3_small</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                       reduced_tail: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; MobileNetV3:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Constructs a large MobileNetV3 architecture from</span></span><br><span class="line"><span class="string">    &quot;Searching for MobileNetV3&quot; &lt;https://arxiv.org/abs/1905.02244&gt;.</span></span><br><span class="line"><span class="string">    weights_link:</span></span><br><span class="line"><span class="string">    https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        num_classes (int): number of classes</span></span><br><span class="line"><span class="string">        reduced_tail (bool): If True, reduces the channel counts of all feature layers</span></span><br><span class="line"><span class="string">            between C4 and C5 by 2. It is used to reduce the channel redundancy in the</span></span><br><span class="line"><span class="string">            backbone for Detection and Segmentation.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    width_multi = <span class="number">1.0</span></span><br><span class="line">    bneck_conf = partial(InvertedResidualConfig, width_multi=width_multi)</span><br><span class="line">    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_multi=width_multi)</span><br><span class="line"></span><br><span class="line">    reduce_divider = <span class="number">2</span> <span class="keyword">if</span> reduced_tail <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    inverted_residual_setting = [</span><br><span class="line">        <span class="comment"># input_c, kernel, expanded_c, out_c, use_se, activation, stride</span></span><br><span class="line">        bneck_conf(<span class="number">16</span>, <span class="number">3</span>, <span class="number">16</span>, <span class="number">16</span>, <span class="literal">True</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">2</span>),  <span class="comment"># C1</span></span><br><span class="line">        bneck_conf(<span class="number">16</span>, <span class="number">3</span>, <span class="number">72</span>, <span class="number">24</span>, <span class="literal">False</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">2</span>),  <span class="comment"># C2</span></span><br><span class="line">        bneck_conf(<span class="number">24</span>, <span class="number">3</span>, <span class="number">88</span>, <span class="number">24</span>, <span class="literal">False</span>, <span class="string">&quot;RE&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">24</span>, <span class="number">5</span>, <span class="number">96</span>, <span class="number">40</span>, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">2</span>),  <span class="comment"># C3</span></span><br><span class="line">        bneck_conf(<span class="number">40</span>, <span class="number">5</span>, <span class="number">240</span>, <span class="number">40</span>, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">40</span>, <span class="number">5</span>, <span class="number">240</span>, <span class="number">40</span>, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">40</span>, <span class="number">5</span>, <span class="number">120</span>, <span class="number">48</span>, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">48</span>, <span class="number">5</span>, <span class="number">144</span>, <span class="number">48</span>, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">48</span>, <span class="number">5</span>, <span class="number">288</span>, <span class="number">96</span> // reduce_divider, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">2</span>),  <span class="comment"># C4</span></span><br><span class="line">        bneck_conf(<span class="number">96</span> // reduce_divider, <span class="number">5</span>, <span class="number">576</span> // reduce_divider, <span class="number">96</span> // reduce_divider, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        bneck_conf(<span class="number">96</span> // reduce_divider, <span class="number">5</span>, <span class="number">576</span> // reduce_divider, <span class="number">96</span> // reduce_divider, <span class="literal">True</span>, <span class="string">&quot;HS&quot;</span>, <span class="number">1</span>)</span><br><span class="line">    ]</span><br><span class="line">    last_channel = adjust_channels(<span class="number">1024</span> // reduce_divider)  <span class="comment"># C5</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MobileNetV3(inverted_residual_setting=inverted_residual_setting,</span><br><span class="line">                       last_channel=last_channel,</span><br><span class="line">                       num_classes=num_classes)</span><br></pre></td></tr></table></figure>
<h2 id="train-py"><a href="http://train.py">train.py</a></h2>
<p>下载官方权重文件：输入import torchvision.model.mobilenet，ctrl+左键进入函数当中，会有显示下载链接</p>
<p>该训练脚本与前期使用的AlexNet、VGG、GooglNet以及ResNet所使用的训练脚本基本一致。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="comment"># 训练MobileNetv2</span></span><br><span class="line"><span class="keyword">from</span> model_v2 <span class="keyword">import</span> MobileNetV2</span><br><span class="line"><span class="comment"># 训练MobileNetv3-Large</span></span><br><span class="line"><span class="keyword">from</span> model_v3 <span class="keyword">import</span> mobilenet_v3_large</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">16</span></span><br><span class="line">    epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                                   transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="string">&quot;..&quot;</span>))  <span class="comment"># get data root path</span></span><br><span class="line">    image_path = os.path.join(data_root, <span class="string">&quot;data_set&quot;</span>, <span class="string">&quot;flower_data&quot;</span>)  <span class="comment"># flower data set path</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;train&quot;</span>),</span><br><span class="line">                                         transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">    train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">    flower_list = train_dataset.class_to_idx</span><br><span class="line">    cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line">    <span class="comment"># write dict into json file</span></span><br><span class="line">    json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line"></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw)</span><br><span class="line"></span><br><span class="line">    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>),</span><br><span class="line">                                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">    val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">    validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                                  batch_size=batch_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                                  num_workers=nw)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(train_num,</span><br><span class="line">                                                                           val_num))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    <span class="comment"># 训练MobileNetv2</span></span><br><span class="line">    net = MobileNetV2(num_classes=<span class="number">5</span>)</span><br><span class="line">	<span class="comment"># 训练MobileNetv3-Large</span></span><br><span class="line">    net = mobilenet_v3_large(num_classes=<span class="number">5</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># load pretrain weights</span></span><br><span class="line">    <span class="comment"># download url: https://download.pytorch.org/models/mobilenet_v2-b0353104.pth</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./mobilenet_v2.pth&quot;</span> <span class="comment">#&quot;./mobilenet_v3_large.pth&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(model_weight_path), <span class="string">&quot;file &#123;&#125; dose not exist.&quot;</span>.<span class="built_in">format</span>(model_weight_path)</span><br><span class="line">    pre_weights = torch.load(model_weight_path, map_location=<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># delete classifier weights</span></span><br><span class="line">    pre_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pre_weights.items() <span class="keyword">if</span> net.state_dict()[k].numel() == v.numel()&#125;</span><br><span class="line">    missing_keys, unexpected_keys = net.load_state_dict(pre_dict, strict=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># freeze features weights</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> net.features.parameters():</span><br><span class="line">        param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    net.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># define loss function</span></span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># construct an optimizer</span></span><br><span class="line">    params = [p <span class="keyword">for</span> p <span class="keyword">in</span> net.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.Adam(params, lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line">    save_path = <span class="string">&#x27;./MobileNetV2.pth&#x27;</span> <span class="comment"># save_path = &#x27;./MobileNetV3.pth&#x27;</span></span><br><span class="line">    train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        net.train()</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        train_bar = tqdm(train_loader, file=sys.stdout)</span><br><span class="line">        <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">            images, labels = data</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            logits = net(images.to(device))</span><br><span class="line">            loss = loss_function(logits, labels.to(device))</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># print statistics</span></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                     epochs,</span><br><span class="line">                                                                     loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            val_bar = tqdm(validate_loader, file=sys.stdout)</span><br><span class="line">            <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">                val_images, val_labels = val_data</span><br><span class="line">                outputs = net(val_images.to(device))</span><br><span class="line">                <span class="comment"># loss = loss_function(outputs, test_labels)</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">                val_bar.desc = <span class="string">&quot;valid epoch[&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                           epochs)</span><br><span class="line">        val_accurate = acc / val_num</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>**需要注意的不同点：**模型权重加载部分</p>
<p>首先实例化模型，将类别个数设置为5；</p>
<p>通过torch.load函数载入预训练参数，载入进之后是一个字典类型。因为官方是在ImageNet数据集上进行预训练，所以最后一层全连接层的节点个数 = 1000，而我们这最后一层节点个数 = 5，所以最后一层不能用。</p>
<p>因此首先遍历权重字典，查找权重名称中是否含有classifier参数，如果有这个参数，说明是最后一层全连接层的参数。如果没有classifier，则直接保存进pre_dict字典变量当中。</p>
<p>再通过net.load_state_dict函数将不包含classifier全连接层的权重字典全部载入进去。</p>
<p>之后冻结特征提取部分的所有权重，通过遍历net.features下的所有参数，将参数的requires_grad全部设置为False，这样就不会对其进行求导及参数更新</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create model</span></span><br><span class="line"> net = MobileNetV2(num_classes=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># load pretrain weights</span></span><br><span class="line"> <span class="comment"># download url: https://download.pytorch.org/models/mobilenet_v2-b0353104.pth</span></span><br><span class="line"> model_weight_path = <span class="string">&quot;./mobilenet_v2.pth&quot;</span></span><br><span class="line"> <span class="keyword">assert</span> os.path.exists(model_weight_path), <span class="string">&quot;file &#123;&#125; dose not exist.&quot;</span>.<span class="built_in">format</span>(model_weight_path)</span><br><span class="line"> pre_weights = torch.load(model_weight_path, map_location=<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># delete classifier weights</span></span><br><span class="line"> pre_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pre_weights.items() <span class="keyword">if</span> <span class="string">&quot;classifier&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> k&#125;</span><br><span class="line"> missing_keys, unexpected_keys = net.load_state_dict(pre_dict, strict=<span class="literal">False</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment"># freeze features weights</span></span><br><span class="line"> <span class="keyword">for</span> param <span class="keyword">in</span> net.features.parameters():</span><br><span class="line">     param.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h3 id="MNv2训练结果"><strong>MNv2训练结果</strong></h3>
<p><img src="/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/MNv2%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="MNv2训练结果"></p>
<h3 id="MNv3-Large训练结果"><strong>MNv3-Large训练结果</strong></h3>
<p><img src="/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/MNv3%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="MNv3训练结果"></p>
<h2 id="predict-py"><a href="http://predict.py">predict.py</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># MNv2</span></span><br><span class="line"><span class="keyword">from</span> model_v2 <span class="keyword">import</span> MobileNetV2</span><br><span class="line"><span class="comment"># MNv3-Large</span></span><br><span class="line"><span class="keyword">from</span> model_v3 <span class="keyword">import</span> mobilenet_v3_large</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="number">256</span>),</span><br><span class="line">         transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    <span class="comment"># MNv2</span></span><br><span class="line">    model = MobileNetV2(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># MNv3-Large</span></span><br><span class="line">    model = mobilenet_v3_large(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./MobileNetV2.pth&quot;</span> <span class="comment"># model_weight_path = &quot;./MobileNetV3.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h3 id="MNv2预测结果"><strong>MNv2预测结果</strong></h3>
<p><img src="/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/MNv2%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="MNv2预测结果"></p>
<h3 id="MNv3-Large预测结果"><strong>MNv3-Large预测结果</strong></h3>
<p><img src="/2023/05/23/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAMobileNetV2V3%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83/MNv3%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="MNv3预测结果"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>MobileNetV2V3</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十五）ShuffleNetv1v2理论讲解</title>
    <url>/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/</url>
    <content><![CDATA[<h1>ShuffleNetv1</h1>
<p>在ShuffleNetv1中，作者<strong>提出channel shuffle思想</strong>，也就是<strong>ShuffleNet Unit中全是GConv和DWConv</strong>。原论文：<a href="https://arxiv.org/abs/1707.01083"> ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</a></p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/ShuffleNetv1v2性能对比.png" alt="ShuffleNetv1v2性能对比" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h2 id="Channel-Shuffle">Channel Shuffle</h2>
<p>在普通组卷积过程中，尽管减少了参数与计算量，但是组与组之间是没有信息交流的（如下图左所示）。为了解决这个问题，ShuffleNetv1中提出channel shuffle的概念，<strong>假设在GConv1中划分为g组，则在每一组中划分g份，将每一组中的第1份放在GConv2的第一组中，每一组中的第2份放在GConv2的第二组中…将每一组中的第i份放在GConv2的第i组中。</strong></p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/channel shuffle概念.png" alt="channel shuffle概念" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p>作者发现：在ResNeXt网络中的PW卷积（1x1普通卷积）在理论上占据了整个网络计算量的93.4%，由此得知，<strong>在网络中的Group Conv在理论上占用网络计算量是很少的</strong>，大部分被1x1的普通卷积所占用了计算量。</p>
<p><strong>因此作者将bneck中第一层和最后一层的1x1普通卷积改为1x1组卷积，且加入Channel Shuffle处理</strong>。下图（左）是原始的普通1x1卷积；下图（中）是将block中第一层和最后一层普通卷积改为组卷积，stride = 1；</p>
<p>下图（右）是shortcut中通过一个3x3平均池化下采样操作且stride = 2池化层进行下采样（在ResNet以及ResNeXt网络中，如果stride = 2，那么shortcut中直接采用卷积下采样），在主分支中通过的DW卷积stride = 2，最后将主分支和shortcut的输出通过Concat<strong>拼接</strong>在一起。</p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/1x1普通卷积改为1x1Group Conv.png" alt="1x1普通卷积改为1x1Group Conv" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h2 id="网络参数">网络参数</h2>
<p>论文中大部分搭建网络采用是g = 3的参数，对应指的是group的个数</p>
<ul>
<li><code>repeat</code>：指该层重复次数；</li>
<li><code>Stage2</code>：将shufflenet当中每个block进行堆叠，第一个block的stride = 2，重复堆叠1次，第二个block的stride = 1，重复堆叠3次。</li>
<li><code>GlobalPool</code>：全球池化</li>
</ul>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/ShuffleNetv1网络参数.png" alt="ShuffleNetv1网络参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>参数对比</strong></p>
<p>假设输入特征矩阵为c x h x w，bottleneck中1x1卷积或3x3卷积的输出channel为m。（FLOPs：计算量）</p>
<p>备注：经过下图的bottleneck之后，其输入特征矩阵和输出特征矩阵的channel保持一致（因为主分支和shortcut直接相加）</p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/ResNet ResNeXt和ShuffleNet参数对比.png" alt="ResNet ResNeXt和ShuffleNet参数对比" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h1>ShuffleNetv2</h1>
<blockquote>
<p>FLOPS：全大写，指每秒浮点运算次数，可以理解为计算的速度。是衡量硬件性能的一个指标。( 硬件 )</p>
<p>FLOPs：s小写，指浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度。(模型在论文中常用GFLOPs(1 GFLOPs = 10^9 FLOPs )</p>
</blockquote>
<p>ShuffleNetv2中，作者提到计算复杂度不能只看FLOPs，还需参考其他的指标，之后<strong>提出4条如何设计出高效的网络准则</strong>，并且基于准则上<strong>提出新的block设计</strong>。原论文：<a href="https://arxiv.org/abs/1807.11164">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design </a></p>
<p>在之前的网络设计当中（例如MobileNet和ShuffleNetv1）经常使用ELOPs（衡量模型运算/复杂度的间接指标），但在实际使用过程中是直接由推理速度（直接的评价指标）去判断计算的快慢。</p>
<p>计算复杂度不能只看FLOPs，还需参考其他的指标，例如MAC内存访问的时间成本（memory access cost）和并行等级（degree of parallelism）。在相同FLOPs下，会因为并行等级、运行平台造成执行消耗时间的不同。</p>
<h2 id="设计高效网络的4条建议">设计高效网络的4条建议</h2>
<ul>
<li>当**卷积层的输入特征矩阵与输出特征矩阵channel相等($c_1=c_2$)**时MAC最小(保持FLOPs不变时)（针对1x1卷积层）</li>
</ul>
<blockquote>
<p>B为使用1x1卷积层时消耗的FLOPs</p>
<p>MAC = $hw(c_1+c_2)+c_1c_2 = hwc_1+hwc_2+c_1c_2$ = 输入特征矩阵的内存消耗+输出特征矩阵的内存消耗+卷积核的内存消耗</p>
</blockquote>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/g1-MAC最小时.png" alt="g1-MAC最小时" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<ul>
<li>当<strong>GConv的groups增大时</strong>(保持FLOPs不变时)，<strong>MAC也会增大</strong></li>
</ul>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/g2-Group.png" alt="g2-Group" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<ul>
<li><strong>网络设计的碎片化程度（分支程度，串联/并联）越高，速度越慢</strong></li>
</ul>
<p>网络设计碎片化程度在越高的情况下，虽然会提升模型的准确率，但同样会降低运行效率</p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/g3-网络碎片化.png" alt="g3-网络碎片化" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<ul>
<li><strong>Element-wise操作带来的影响</strong>是不可忽视的</li>
</ul>
<p>ReLU激活操作、相加操作（shortcut）、偏置等<strong>对每一个元素进行操作的都叫Element-wise操作</strong></p>
<p>特点：ELOPs很小，MAC很大</p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/g4-Element-wise操作.png" alt="g4-Element-wise操作" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<p><strong>总结</strong></p>
<ol>
<li>尽可能让输入特征矩阵与输出特征矩阵的比值为1；</li>
<li>需要注意group conv的计算成本，不能一味地增大group数，虽然增大group数会降低参数和减少ELOPs，但是会增加计算成本；</li>
<li>降低网络的碎片程度，如果需要一个高效的网络，便不要设计过多分支的网路结构；</li>
<li>尽可能减少使用Element-wise。</li>
</ol>
<h2 id="基于4点建议设计的ShuffleNetv2">基于4点建议设计的ShuffleNetv2</h2>
<p>下图（a）（b）为ShuffleNetv1中stride为1和2的网络结构，下图（c）（d）为ShuffleNetv2中stride为1和2的网路结构情况。</p>
<blockquote>
<p>在（c）中，首先将输入特征矩阵的channel划分为两个分支（channel split操作），分别为c-c‘和c’。根据g3（减少碎片化程度），所以在左边分支中未进行任何操作，另一个分支中由三个卷积层组成，输入特征矩阵和输出特征矩阵拥有相同的channel，且两个1x1的卷积不再使用group conv。最后通过concat拼接。</p>
<p>在（d）中，没有channel split操作，因此通过concat拼接之后输出特征矩阵的channel翻倍。</p>
</blockquote>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/4条高效网络设计.png" alt="4条高效网络设计" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h2 id="网络参数-2">网络参数</h2>
<p>网络框架与ShuffleNetv1基本保持一致，<strong>唯一不同在于ShuffleNetv2比v1多了一个Conv5的1x1卷积操作</strong>。</p>
<p>而且对于stage2的第一个block，它的两个分支中输出的channel并不等于输入的channel，而是直接设置为指定输出channe的一半，比如对于1x版本，每分支的channel应该是58，不是24。</p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/ShuffleNetv2网络参数.png" alt="ShuffleNetv2网络参数" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h2 id="性能指标">性能指标</h2>
<p><strong>ShuffleNet v2 0.5/1x版本</strong></p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/ShuffleNetv2性能指标.png" alt="ShuffleNetv2 0.5/1x版本性能指标" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>ShuffleNet v2 1.5/2x版本</strong></p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/ShuffleNetv2 1.5版本性能指标.png" alt="ShuffleNetv2 1.5/2x版本性能指标" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p><strong>ShuffleNetv2 2x版本+SE性能指标</strong></p>
<img src="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/ShuffleNetv2 2.0版本+SE性能指标.png" alt="ShuffleNetv2 2.0版本+SE性能指标" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>ShuffleNetv1v2</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十六）使用Pytorch搭建ShuffleNetv2</title>
    <url>/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/</url>
    <content><![CDATA[<h1>工程目录</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test7_shufflenet</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── my_dataset.py（数据处理文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,ShuffleNetV2.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── shufflenetv2_x1.pth（用于迁移学习时，提前下载好官方的shufflenetv2_x1权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<p><strong>tips:</strong></p>
<ol>
<li>下载好数据集，代码中默认使用的是花分类数据集，下载地址: <a href="https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz">花分类数据集</a>, 如果下载不了的话可以通过百度云链接下载: <a href="https://pan.baidu.com/s/1QLCTA4sXnQAw_yvxPj9szg">花分类数据集</a> 提取码:58p0</li>
<li>在<code>train.py</code>脚本中将<code>--data-path</code>设置成解压后的<code>flower_photos</code>文件夹绝对路径</li>
<li>下载预训练权重，在<code>model.py</code>文件中每个模型都有提供预训练权重的下载地址，根据自己使用的模型下载对应预训练权重</li>
<li>在<code>train.py</code>脚本中将<code>--weights</code>参数设成下载好的预训练权重路径</li>
<li>设置好数据集的路径<code>--data-path</code>以及预训练权重的路径<code>--weights</code>就能使用<code>train.py</code>脚本开始训练了(训练过程中会自动生成<code>class_indices.json</code>文件)</li>
<li>在<code>predict.py</code>脚本中导入和训练脚本中同样的模型，并将<code>model_weight_path</code>设置成训练好的模型权重路径(默认保存在weights文件夹下)</li>
<li>在<code>predict.py</code>脚本中将<code>img_path</code>设置成你自己需要预测的图片绝对路径</li>
<li>设置好权重路径<code>model_weight_path</code>和预测的图片路径<code>img_path</code>就能使用<code>predict.py</code>脚本进行预测了</li>
<li>如果要使用自己的数据集，请按照花分类数据集的文件结构进行摆放(即一个类别对应一个文件夹)，并且将训练以及预测脚本中的<code>num_classes</code>设置成你自己数据的类别数</li>
</ol>
<h1><a href="http://model.py">model.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Callable</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">channel_shuffle</span>(<span class="params">x: Tensor, groups: <span class="built_in">int</span></span>) -&gt; Tensor:</span><br><span class="line">	<span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_c: <span class="built_in">int</span>, output_c: <span class="built_in">int</span>, stride: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">depthwise_conv</span>(<span class="params">input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                       output_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                       kernel_s: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                       stride: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                       padding: <span class="built_in">int</span> = <span class="number">0</span>,</span></span><br><span class="line"><span class="params">                       bias: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; nn.Conv2d:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ShuffleNetV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 stages_repeats: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                 stages_out_channels: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 inverted_residual: <span class="type">Callable</span>[..., nn.Module] = InvertedResidual</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_forward_impl</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shufflenet_v2_x0_5</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shufflenet_v2_x1_0</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shufflenet_v2_x1_5</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shufflenet_v2_x2_0</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h2 id="channel-shuffle函数">channel_shuffle函数</h2>
<p>将输入进来的特征矩阵channel平均分为group组（大组），平分之后再将每组内的channel平均分为group组（小组），之后在每组（大组）中索引相同的数据挪到一起，便实现了经过channel_shuffle操作之后，每一组中的数据都包含之前划分group组之后每一组的数据。</p>
<p>备注：2022年的pytorch中自带channel_shuffle函数，但自带的函数不能用GPU训练，推荐自己写一个。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">channel_shuffle</span>(<span class="params">x: Tensor, groups: <span class="built_in">int</span></span>) -&gt; Tensor:</span><br><span class="line"></span><br><span class="line">    batch_size, num_channels, height, width = x.size()</span><br><span class="line">    channels_per_group = num_channels // groups</span><br><span class="line"></span><br><span class="line">    <span class="comment"># reshape</span></span><br><span class="line">    <span class="comment"># [batch_size, num_channels, height, width] -&gt; [batch_size, groups, channels_per_group, height, width]</span></span><br><span class="line">    x = x.view(batch_size, groups, channels_per_group, height, width)</span><br><span class="line"></span><br><span class="line">    x = torch.transpose(x, <span class="number">1</span>, <span class="number">2</span>).contiguous()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># flatten</span></span><br><span class="line">    x = x.view(batch_size, -<span class="number">1</span>, height, width)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>假设：num_channels = 6，groups = 3，<strong>view函数</strong>作用可如下图理解，将channel为6的数据划分为3个组。</p>
<img src="/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/shuffle channel.png" alt="shuffle channel" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<p><strong>transpose方法</strong>：将维度1和维度2的数据进行调换（可以理解为转置）。contiguous：将Tensor数据转化为内存中连续的数据。</p>
<img src="/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/transpose方法.png" alt="transpose方法" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<p>再通过view将transpose之后的数据进行展开**（view重塑张量，此处张量的元素个数为6，batch_size = 6，-1指元素排列形状的列数即为1）**</p>
<img src="/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/view函数展开.png" alt="view函数展开" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<h2 id="InvertedResidual类">InvertedResidual类</h2>
<img src="/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/InvertedResidual.png" alt="InvertedResidual" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<p><strong>初始化函数</strong></p>
<ul>
<li><code>input_c</code>：输入特征矩阵的channel</li>
<li><code>output_c</code>：输出特征矩阵的channel</li>
<li><code>stride</code>：DW卷积的步距</li>
<li><code>branch1</code>：（c）和（d）左边的分支，（c）分支stride = 1，特征矩阵（前面以及经过channel split）保持不变，（d）分支stride = 2，先经过3x3的DW卷积将深度变为原来的一半，再通过1x1的普通卷积；</li>
<li><code>branch2</code>：（c）和（d）右边的分支，且处理一致。先通过1x1的普通卷积（（c）中深度保持不变，（d）中深度为原先的一半），再通过3x3的dw卷积，以及1x1的普通卷积；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_c: <span class="built_in">int</span>, output_c: <span class="built_in">int</span>, stride: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(InvertedResidual, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stride <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;illegal stride value.&quot;</span>)</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> output_c % <span class="number">2</span> == <span class="number">0</span></span><br><span class="line">        branch_features = output_c // <span class="number">2</span></span><br><span class="line">        <span class="comment"># 当stride为1时，input_channel应该是branch_features的两倍</span></span><br><span class="line">        <span class="comment"># python中 &#x27;&lt;&lt;&#x27; 是位运算，可理解为计算×2的快速方法</span></span><br><span class="line">        <span class="keyword">assert</span> (self.stride != <span class="number">1</span>) <span class="keyword">or</span> (input_c == branch_features &lt;&lt; <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.stride == <span class="number">2</span>:</span><br><span class="line">            self.branch1 = nn.Sequential(</span><br><span class="line">                self.depthwise_conv(input_c, input_c, kernel_s=<span class="number">3</span>, stride=self.stride, padding=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(input_c),</span><br><span class="line">                nn.Conv2d(input_c, branch_features, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(branch_features),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.branch1 = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        self.branch2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_c <span class="keyword">if</span> self.stride &gt; <span class="number">1</span> <span class="keyword">else</span> branch_features, branch_features, kernel_size=<span class="number">1</span>,</span><br><span class="line">                      stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(branch_features),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            self.depthwise_conv(branch_features, branch_features, kernel_s=<span class="number">3</span>, stride=self.stride, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(branch_features),</span><br><span class="line">            nn.Conv2d(branch_features, branch_features, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(branch_features),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>depthwise_conv函数</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">depthwise_conv</span>(<span class="params">input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                       output_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                       kernel_s: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                       stride: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                       padding: <span class="built_in">int</span> = <span class="number">0</span>,</span></span><br><span class="line"><span class="params">                       bias: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; nn.Conv2d:</span><br><span class="line">        <span class="keyword">return</span> nn.Conv2d(in_channels=input_c, out_channels=output_c, kernel_size=kernel_s,</span><br><span class="line">                         stride=stride, padding=padding, bias=bias, groups=input_c)</span><br></pre></td></tr></table></figure>
<p><strong>forward函数</strong></p>
<p>当self.stride == 1时，通过chunk函数将x在dim = 1的维度上进行2分处理（通道位**[ batch, channel, height, width ]**），再通过torch.cat函数将x1（stride = 1时左分支不做处理）与经过self.branch2函数处理的x2进行concat拼接得到输出特征矩阵；</p>
<p>在另一种stride == 2的情况下，直接将x带入self.branch1和self.branch2函数，并将输出特征矩阵进行拼接，得到最终特征矩阵；</p>
<p>之后将输出特征矩阵在深度上分成2组进行channel_shuffle处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">if</span> self.stride == <span class="number">1</span>:</span><br><span class="line">            x1, x2 = x.chunk(<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">            out = torch.cat((x1, self.branch2(x2)), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            out = torch.cat((self.branch1(x), self.branch2(x)), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = channel_shuffle(out, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="ShuffleNetV2类">ShuffleNetV2类</h2>
<p><strong>shufflenetv2网络结构</strong></p>
<img src="/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/shufflenetv2网洛结构.png" alt="shufflenetv2网络结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<p><strong>初始化函数</strong></p>
<ul>
<li><code>stages_repeats</code>：shufflenet_v2_x1_0版本中，内容为[4, 8, 4]；</li>
<li><code>stages_out_channels</code>：对应[ Conv1，Stage2，Stage3，Stage4，Conv5 ]，shufflenet_v2_x1_0版本中，内容为[24, 116, 232, 464, 1024]；</li>
<li><code>self.stage2: nn.Sequential</code>：表示声明self.stage2是通过nn.Sequential来实现的</li>
<li>通过zip函数将<code>stage_names</code>、<code>stages_repeats</code>和<code>self._stage_out_channels</code>列表打包成字典的形式(shufflenet_v2_x1_0版本中，self._stage_out_channels只到1024前一个，即464。因为前两个列表长度都为3），打包之后形式为</li>
</ul>
<blockquote>
<p>{stage_names：Stage2，stages_repeats：4，self._stage_out_channels：116}</p>
</blockquote>
<ul>
<li><code>setattr函数</code>：给self设置一个变量，变量名称为{name}，变量的值为nn.Sequential(*seq)，即每一个Stage的每个block输出特征矩阵的列表值，所以构建好Stage的一系列层结构；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ShuffleNetV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 stages_repeats: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                 stages_out_channels: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 inverted_residual: <span class="type">Callable</span>[..., nn.Module] = InvertedResidual</span>):</span><br><span class="line">        <span class="built_in">super</span>(ShuffleNetV2, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(stages_repeats) != <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;expected stages_repeats as list of 3 positive ints&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(stages_out_channels) != <span class="number">5</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;expected stages_out_channels as list of 5 positive ints&quot;</span>)</span><br><span class="line">        self._stage_out_channels = stages_out_channels</span><br><span class="line"></span><br><span class="line">        <span class="comment"># input RGB image</span></span><br><span class="line">        input_channels = <span class="number">3</span></span><br><span class="line">        output_channels = self._stage_out_channels[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channels, output_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(output_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        input_channels = output_channels</span><br><span class="line"></span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Static annotations for mypy</span></span><br><span class="line">        self.stage2: nn.Sequential</span><br><span class="line">        self.stage3: nn.Sequential</span><br><span class="line">        self.stage4: nn.Sequential</span><br><span class="line"></span><br><span class="line">        stage_names = [<span class="string">&quot;stage&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">        <span class="keyword">for</span> name, repeats, output_channels <span class="keyword">in</span> <span class="built_in">zip</span>(stage_names, stages_repeats,</span><br><span class="line">                                                  self._stage_out_channels[<span class="number">1</span>:]):</span><br><span class="line">            seq = [inverted_residual(input_channels, output_channels, <span class="number">2</span>)]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(repeats - <span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 每一个Stage中，除了第一个block的stride = 2，其他都是为1</span></span><br><span class="line">                seq.append(inverted_residual(output_channels, output_channels, <span class="number">1</span>))</span><br><span class="line">            <span class="built_in">setattr</span>(self, name, nn.Sequential(*seq))</span><br><span class="line">            input_channels = output_channels</span><br><span class="line"></span><br><span class="line">        output_channels = self._stage_out_channels[-<span class="number">1</span>]</span><br><span class="line">        self.conv5 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channels, output_channels, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(output_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Linear(output_channels, num_classes)</span><br></pre></td></tr></table></figure>
<p><strong>forward函数</strong></p>
<ul>
<li><code>x = self.stage2(x)</code>：关联初始化函数的<code>self.stage2: nn.Sequential</code>，继续关联到<code>setattr(self, name, nn.Sequential(*seq))</code></li>
<li><code>mean方法</code>：进行全局池化操作，[ 2, 3 ] 分别指高度和宽度两个维度进行求均值的操作</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_impl</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">	<span class="comment"># See note [TorchScript super()]</span></span><br><span class="line">    x = self.conv1(x)</span><br><span class="line">    x = self.maxpool(x)</span><br><span class="line">    x = self.stage2(x)</span><br><span class="line">    x = self.stage3(x)</span><br><span class="line">    x = self.stage4(x)</span><br><span class="line">    x = self.conv5(x)</span><br><span class="line">    x = x.mean([<span class="number">2</span>, <span class="number">3</span>])  <span class="comment"># global pool</span></span><br><span class="line">    x = self.fc(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">    <span class="keyword">return</span> self._forward_impl(x)</span><br></pre></td></tr></table></figure>
<h2 id="实例化ShuffleNet">实例化ShuffleNet</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">shufflenet_v2_x0_5</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Constructs a ShuffleNetV2 with 0.5x output channels, as described in</span></span><br><span class="line"><span class="string">    `&quot;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&quot;</span></span><br><span class="line"><span class="string">    &lt;https://arxiv.org/abs/1807.11164&gt;`.</span></span><br><span class="line"><span class="string">    weight: https://download.pytorch.org/models/shufflenetv2_x0.5-f707e7126e.pth</span></span><br><span class="line"><span class="string">    :param num_classes:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ShuffleNetV2(stages_repeats=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">4</span>],</span><br><span class="line">                         stages_out_channels=[<span class="number">24</span>, <span class="number">48</span>, <span class="number">96</span>, <span class="number">192</span>, <span class="number">1024</span>],</span><br><span class="line">                         num_classes=num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shufflenet_v2_x1_0</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Constructs a ShuffleNetV2 with 1.0x output channels, as described in</span></span><br><span class="line"><span class="string">    `&quot;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&quot;</span></span><br><span class="line"><span class="string">    &lt;https://arxiv.org/abs/1807.11164&gt;`.</span></span><br><span class="line"><span class="string">    weight: https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth</span></span><br><span class="line"><span class="string">    :param num_classes:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ShuffleNetV2(stages_repeats=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">4</span>],</span><br><span class="line">                         stages_out_channels=[<span class="number">24</span>, <span class="number">116</span>, <span class="number">232</span>, <span class="number">464</span>, <span class="number">1024</span>],</span><br><span class="line">                         num_classes=num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shufflenet_v2_x1_5</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Constructs a ShuffleNetV2 with 1.0x output channels, as described in</span></span><br><span class="line"><span class="string">    `&quot;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&quot;</span></span><br><span class="line"><span class="string">    &lt;https://arxiv.org/abs/1807.11164&gt;`.</span></span><br><span class="line"><span class="string">    weight: https://download.pytorch.org/models/shufflenetv2_x1_5-3c479a10.pth</span></span><br><span class="line"><span class="string">    :param num_classes:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ShuffleNetV2(stages_repeats=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">4</span>],</span><br><span class="line">                         stages_out_channels=[<span class="number">24</span>, <span class="number">176</span>, <span class="number">352</span>, <span class="number">704</span>, <span class="number">1024</span>],</span><br><span class="line">                         num_classes=num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shufflenet_v2_x2_0</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Constructs a ShuffleNetV2 with 1.0x output channels, as described in</span></span><br><span class="line"><span class="string">    `&quot;ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design&quot;</span></span><br><span class="line"><span class="string">    &lt;https://arxiv.org/abs/1807.11164&gt;`.</span></span><br><span class="line"><span class="string">    weight: https://download.pytorch.org/models/shufflenetv2_x2_0-8be3c8ee.pth</span></span><br><span class="line"><span class="string">    :param num_classes:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ShuffleNetV2(stages_repeats=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">4</span>],</span><br><span class="line">                         stages_out_channels=[<span class="number">24</span>, <span class="number">244</span>, <span class="number">488</span>, <span class="number">976</span>, <span class="number">2048</span>],</span><br><span class="line">                         num_classes=num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<h1><a href="http://train.py">train.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.optim.lr_scheduler <span class="keyword">as</span> lr_scheduler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> shufflenet_v2_x1_0</span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(args)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Start Tensorboard with &quot;tensorboard --logdir=runs&quot;, view at http://localhost:6006/&#x27;</span>)</span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                                   transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果存在预训练权重则载入</span></span><br><span class="line">    model = shufflenet_v2_x1_0(num_classes=args.num_classes).to(device)</span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(args.weights):</span><br><span class="line">            weights_dict = torch.load(args.weights, map_location=device)</span><br><span class="line">            load_weights_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> weights_dict.items()</span><br><span class="line">                                 <span class="keyword">if</span> model.state_dict()[k].numel() == v.numel()&#125;</span><br><span class="line">            <span class="built_in">print</span>(model.load_state_dict(load_weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">&quot;not found weights file: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(args.weights))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否冻结权重</span></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除最后的全连接层外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;fc&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    pg = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.SGD(pg, lr=args.lr, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">4E-5</span>)</span><br><span class="line">    <span class="comment"># Scheduler https://arxiv.org/pdf/1812.01187.pdf</span></span><br><span class="line">    lf = <span class="keyword">lambda</span> x: ((<span class="number">1</span> + math.cos(x * math.pi / args.epochs)) / <span class="number">2</span>) * (<span class="number">1</span> - args.lrf) + args.lrf  <span class="comment"># cosine</span></span><br><span class="line">    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        mean_loss = train_one_epoch(model=model,</span><br><span class="line">                                    optimizer=optimizer,</span><br><span class="line">                                    data_loader=train_loader,</span><br><span class="line">                                    device=device,</span><br><span class="line">                                    epoch=epoch)</span><br><span class="line"></span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        acc = evaluate(model=model,</span><br><span class="line">                       data_loader=val_loader,</span><br><span class="line">                       device=device)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;[epoch &#123;&#125;] accuracy: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch, <span class="built_in">round</span>(acc, <span class="number">3</span>)))</span><br><span class="line">        tags = [<span class="string">&quot;loss&quot;</span>, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], mean_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;./weights/model-&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br></pre></td></tr></table></figure>
<p>此处使用迁移学习方法，除了最后的全连接层，前面参数都来自官方shufflenetv2_x1权重，如果想要自己训练模型，则需要进行两步：</p>
<blockquote>
<p>parser.add_argument，<strong>default=‘shufflenetv2_x1.pth’ ==&gt; default=‘’</strong>；<strong>default=True==&gt; default = False</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">30</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.01</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lrf&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># shufflenetv2_x1.0 官方权重下载地址</span></span><br><span class="line">    <span class="comment"># https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;shufflenetv2_x1.pth&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<p><strong>训练结果</strong></p>
<p><img src="/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h1><a href="http://predict.py">predict.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> shufflenet_v2_x1_0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="number">256</span>),</span><br><span class="line">         transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = shufflenet_v2_x1_0(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/model-29.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p><strong>预测结果</strong></p>
<p><img src="/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
<h1><a href="http://utils.py">utils.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_split_data</span>(<span class="params">root: <span class="built_in">str</span>, val_rate: <span class="built_in">float</span> = <span class="number">0.2</span></span>):</span><br><span class="line">    random.seed(<span class="number">0</span>)  <span class="comment"># 保证随机结果可复现</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(root), <span class="string">&quot;dataset root: &#123;&#125; does not exist.&quot;</span>.<span class="built_in">format</span>(root)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历文件夹，一个文件夹对应一个类别</span></span><br><span class="line">    flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(root) <span class="keyword">if</span> os.path.isdir(os.path.join(root, cla))]</span><br><span class="line">    <span class="comment"># 排序，保证各平台顺序一致</span></span><br><span class="line">    flower_class.sort()</span><br><span class="line">    <span class="comment"># 生成类别名称以及对应的数字索引</span></span><br><span class="line">    class_indices = <span class="built_in">dict</span>((k, v) <span class="keyword">for</span> v, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(flower_class))</span><br><span class="line">    json_str = json.dumps(<span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> class_indices.items()), indent=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">    train_images_path = []  <span class="comment"># 存储训练集的所有图片路径</span></span><br><span class="line">    train_images_label = []  <span class="comment"># 存储训练集图片对应索引信息</span></span><br><span class="line">    val_images_path = []  <span class="comment"># 存储验证集的所有图片路径</span></span><br><span class="line">    val_images_label = []  <span class="comment"># 存储验证集图片对应索引信息</span></span><br><span class="line">    every_class_num = []  <span class="comment"># 存储每个类别的样本总数</span></span><br><span class="line">    supported = [<span class="string">&quot;.jpg&quot;</span>, <span class="string">&quot;.JPG&quot;</span>, <span class="string">&quot;.png&quot;</span>, <span class="string">&quot;.PNG&quot;</span>]  <span class="comment"># 支持的文件后缀类型</span></span><br><span class="line">    <span class="comment"># 遍历每个文件夹下的文件</span></span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        cla_path = os.path.join(root, cla)</span><br><span class="line">        <span class="comment"># 遍历获取supported支持的所有文件路径</span></span><br><span class="line">        images = [os.path.join(root, cla, i) <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(cla_path)</span><br><span class="line">                  <span class="keyword">if</span> os.path.splitext(i)[-<span class="number">1</span>] <span class="keyword">in</span> supported]</span><br><span class="line">        <span class="comment"># 排序，保证各平台顺序一致</span></span><br><span class="line">        images.sort()</span><br><span class="line">        <span class="comment"># 获取该类别对应的索引</span></span><br><span class="line">        image_class = class_indices[cla]</span><br><span class="line">        <span class="comment"># 记录该类别的样本数量</span></span><br><span class="line">        every_class_num.append(<span class="built_in">len</span>(images))</span><br><span class="line">        <span class="comment"># 按比例随机采样验证样本</span></span><br><span class="line">        val_path = random.sample(images, k=<span class="built_in">int</span>(<span class="built_in">len</span>(images) * val_rate))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> img_path <span class="keyword">in</span> images:</span><br><span class="line">            <span class="keyword">if</span> img_path <span class="keyword">in</span> val_path:  <span class="comment"># 如果该路径在采样的验证集样本中则存入验证集</span></span><br><span class="line">                val_images_path.append(img_path)</span><br><span class="line">                val_images_label.append(image_class)</span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># 否则存入训练集</span></span><br><span class="line">                train_images_path.append(img_path)</span><br><span class="line">                train_images_label.append(image_class)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images were found in the dataset.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">sum</span>(every_class_num)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images for training.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(train_images_path)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(val_images_path)))</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(train_images_path) &gt; <span class="number">0</span>, <span class="string">&quot;number of training images must greater than 0.&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(val_images_path) &gt; <span class="number">0</span>, <span class="string">&quot;number of validation images must greater than 0.&quot;</span></span><br><span class="line"></span><br><span class="line">    plot_image = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> plot_image:</span><br><span class="line">        <span class="comment"># 绘制每种类别个数柱状图</span></span><br><span class="line">        plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(flower_class)), every_class_num, align=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">        <span class="comment"># 将横坐标0,1,2,3,4替换为相应的类别名称</span></span><br><span class="line">        plt.xticks(<span class="built_in">range</span>(<span class="built_in">len</span>(flower_class)), flower_class)</span><br><span class="line">        <span class="comment"># 在柱状图上添加数值标签</span></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(every_class_num):</span><br><span class="line">            plt.text(x=i, y=v + <span class="number">5</span>, s=<span class="built_in">str</span>(v), ha=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置x坐标</span></span><br><span class="line">        plt.xlabel(<span class="string">&#x27;image class&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置y坐标</span></span><br><span class="line">        plt.ylabel(<span class="string">&#x27;number of images&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置柱状图的标题</span></span><br><span class="line">        plt.title(<span class="string">&#x27;flower class distribution&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_images_path, train_images_label, val_images_path, val_images_label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_data_loader_image</span>(<span class="params">data_loader</span>):</span><br><span class="line">    batch_size = data_loader.batch_size</span><br><span class="line">    plot_num = <span class="built_in">min</span>(batch_size, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), json_path + <span class="string">&quot; does not exist.&quot;</span></span><br><span class="line">    json_file = <span class="built_in">open</span>(json_path, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    class_indices = json.load(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(plot_num):</span><br><span class="line">            <span class="comment"># [C, H, W] -&gt; [H, W, C]</span></span><br><span class="line">            img = images[i].numpy().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 反Normalize操作</span></span><br><span class="line">            img = (img * [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>] + [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]) * <span class="number">255</span></span><br><span class="line">            label = labels[i].item()</span><br><span class="line">            plt.subplot(<span class="number">1</span>, plot_num, i+<span class="number">1</span>)</span><br><span class="line">            plt.xlabel(class_indices[<span class="built_in">str</span>(label)])</span><br><span class="line">            plt.xticks([])  <span class="comment"># 去掉x轴的刻度</span></span><br><span class="line">            plt.yticks([])  <span class="comment"># 去掉y轴的刻度</span></span><br><span class="line">            plt.imshow(img.astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_pickle</span>(<span class="params">list_info: <span class="built_in">list</span>, file_name: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(list_info, f)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_pickle</span>(<span class="params">file_name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">list</span>:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        info_list = pickle.load(f)</span><br><span class="line">        <span class="keyword">return</span> info_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">model, optimizer, data_loader, device, epoch</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    loss_function = torch.nn.CrossEntropyLoss()</span><br><span class="line">    mean_loss = torch.zeros(<span class="number">1</span>).to(device)</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    data_loader = tqdm(data_loader, file=sys.stdout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        images, labels = data</span><br><span class="line"></span><br><span class="line">        pred = model(images.to(device))</span><br><span class="line"></span><br><span class="line">        loss = loss_function(pred, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        mean_loss = (mean_loss * step + loss.detach()) / (step + <span class="number">1</span>)  <span class="comment"># update mean losses</span></span><br><span class="line"></span><br><span class="line">        data_loader.desc = <span class="string">&quot;[epoch &#123;&#125;] mean loss &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch, <span class="built_in">round</span>(mean_loss.item(), <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> torch.isfinite(loss):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;WARNING: non-finite loss, ending training &#x27;</span>, loss)</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mean_loss.item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, data_loader, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证样本总个数</span></span><br><span class="line">    total_num = <span class="built_in">len</span>(data_loader.dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于存储预测正确的样本个数</span></span><br><span class="line">    sum_num = torch.zeros(<span class="number">1</span>).to(device)</span><br><span class="line"></span><br><span class="line">    data_loader = tqdm(data_loader, file=sys.stdout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        images, labels = data</span><br><span class="line">        pred = model(images.to(device))</span><br><span class="line">        pred = torch.<span class="built_in">max</span>(pred, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        sum_num += torch.eq(pred, labels.to(device)).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sum_num.item() / total_num</span><br></pre></td></tr></table></figure>
<h1>my_dataset.py</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义数据集&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, images_path: <span class="built_in">list</span>, images_class: <span class="built_in">list</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.images_path = images_path</span><br><span class="line">        self.images_class = images_class</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        img = Image.<span class="built_in">open</span>(self.images_path[item])</span><br><span class="line">        <span class="comment"># RGB为彩色图片，L为灰度图片</span></span><br><span class="line">        <span class="keyword">if</span> img.mode != <span class="string">&#x27;RGB&#x27;</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;image: &#123;&#125; isn&#x27;t RGB mode.&quot;</span>.<span class="built_in">format</span>(self.images_path[item]))</span><br><span class="line">        label = self.images_class[item]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):</span><br><span class="line">        <span class="comment"># 官方实现的default_collate可以参考</span></span><br><span class="line">        <span class="comment"># https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py</span></span><br><span class="line">        images, labels = <span class="built_in">tuple</span>(<span class="built_in">zip</span>(*batch))</span><br><span class="line"></span><br><span class="line">        images = torch.stack(images, dim=<span class="number">0</span>)</span><br><span class="line">        labels = torch.as_tensor(labels)</span><br><span class="line">        <span class="keyword">return</span> images, labels</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>ShuffleNetv2</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十七）EfficientNet网络详解</title>
    <url>/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>原论文：<a href="https://arxiv.org/pdf/1905.11946v1.pdf">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></p>
<h1>前言</h1>
<p>在之前的学习的网络结构（例如AlexNet，VGG，ResNet等）中，都将输入图像分辨率固定为224，为什么卷积的个数要设置为这个值，为什么网络的深度设为这么深？这些问题你要问设计作者的话，估计回复就四个字——工程经验。</p>
<p>而这篇论文<strong>同时探索输入分辨率、网络的深度、宽度对准确率的影响</strong>。在论文中提到，本文提出的EfficientNet-B7在Imagenet top-1上达到了当年最高准确率84.3%，与之前准确率最高的GPipe相比，参数数量（Params）仅为其1/8.4，推理速度提升了6.1倍（看上去又快又轻量，但个人实际使用起来发现很吃显存）。下图是EfficientNet与其他网络的对比（注意：<strong>参数数量少并不意味推理速度就快</strong>）。</p>
<img src="/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNet-B7参数准确率对比.png" alt="EfficientNet-B7参数准确率对比" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h1>论文思想</h1>
<ul>
<li>下图（a）是传统的卷积神经网络；</li>
<li>下图（b）是在（a）的基础上增大了网络的宽度width，实际上指的是特征矩阵的channel。即增加卷积核的个数（增加特征矩阵的<code>channels</code>）来提升网络的性能；</li>
<li>下图（c）是在（a）的基础上增大了网络的深度channel，实际上指的是通过增加网络的深度<code>layers</code>。即使用更多的层结构来提升网络的性能；</li>
<li>下图（d）是在（a）的基础上通过增加输入<code>网络的分辨率</code>来提升网络的性能；</li>
<li>本篇论文中<strong>同时增加网络的<code>width</code>、<code>channel</code>以及输入网络的分辨率来提升网络的性能</strong>，如图（e）</li>
</ul>
<img src="/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/网络结构为提高准确率所采取的方法.png" alt="网络结构为提高准确率所采取的方法" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<ul>
<li>增加网络的<code>width</code>，即增加卷积核的个数，能够获得更高细粒度的特征并且也更容易训练，但对于width很大而深度较浅的网络往往很难学习到更深层次的特征。</li>
<li>根据以往的经验，增加网络的深度<code>depth</code>，即增加网络的层结构，能够得到更加丰富、复杂的特征并且能够很好的应用到其它任务中。但网络的深度过深会面临梯度消失，训练困难的问题。</li>
<li>增加输入网络的图像分辨率能够潜在得获得更高细粒度的特征模板，但对于非常高的输入分辨率，准确率的增益也会减小。并且大分辨率图像会增加计算量。</li>
</ul>
<img src="/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/分别增加width depth和分辨率的准确率.png" alt="分别增加width depth和分辨率的准确率" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h1>EfficientNet的网络结构</h1>
<p>通过网络搜索（<strong>Neural Architecture Search</strong>)技术得到的结构（B1-B7就是在B0的基础上修改<code>Resolution</code>，<code>Channels</code>以及<code>Layers</code>），整个网络框架由一系列Stage组成。<strong>表中的卷积层后都默认跟有BN以及Swish激活函数</strong>，MBConv为MobileNet Conv。</p>
<ul>
<li><code>Resolution</code>：每一层Stage输入特征矩阵的高和宽；</li>
<li><code>Channels</code>：通过该Stage后输出特征矩阵的Channels；</li>
<li><code>Layers</code>：指将Operator操作重复多少次</li>
<li><code>stride</code>：指的是每一层Stage的第一个MBConv中卷积核的stride，其余默认stride = 1</li>
</ul>
<p>网络总共分成了9个Stage，第一个Stage是一个卷积核大小为3x3步距为2的普通卷积层（包含BN和激活函数Swish），Stage2～Stage8都是在重复堆叠MBConv结构，而Stage9由一个普通的1x1的卷积层（包含BN和激活函数Swish）、一个平均池化层和一个全连接层组成。</p>
<p>表格中每个MBConv后会跟一个数字1或6，这里的1或6就是倍率因子n即MBConv中第一个1x1的卷积层会将输入特征矩阵的channels扩充为n倍，其中k3x3或k5x5表示MBConv中Depthwise Conv所采用的卷积核大小。</p>
<img src="/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNet-B0网络结构.png" alt="EfficientNet-B0网络结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h2 id="MBConv结构">MBConv结构</h2>
<p>MBConv其实就是MobileNetV3网络中的InvertedResidualBlock，但也有些许区别。一个是采用的激活函数不一样（EfficientNet的MBConv中使用的都是<strong>Swish激活函数</strong>），另一个是在<strong>每个MBConv中都加入了SE（Squeeze-and-Excitation）模块</strong>。</p>
<p>如下图所示，MBConv结构主要由一个1x1的普通卷积（升维作用，包含BN和Swish），一个kxk的Depthwise Conv卷积（包含BN和Swish）<strong>k的具体值可看EfficientNet-B0的网络框架主要有3x3和5x5两种情况</strong>，一个SE模块，一个1x1的普通卷积（降维作用，包含BN），一个Droupout层构成。搭建过程中还需要注意几点：</p>
<blockquote>
<ul>
<li>第一个升维的1x1卷积层，它的卷积核个数是输入特征矩阵channel的n倍，n ∈ { 1 , 6 }。</li>
<li>当n = 1时，不要第一个升维的1x1卷积层，即Stage2中的MBConv结构都没有第一个升维的1x1卷积层（这和MobileNetV3网络类似）。</li>
<li>关于shortcut连接，仅当输入MBConv结构的特征矩阵与输出的特征矩阵shape相同时才存在（代码中可通过stride==1 and inputc_channels==output_channels条件来判断）。</li>
</ul>
<p>注意：<strong>在源码实现中只有使用shortcut的时候才有Dropout层</strong></p>
</blockquote>
<img src="/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/MBConv结构.png" alt="MBConv结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<p>SE模块如下图所示，由一个全局平均池化，两个全连接层组成。第一个全连接层的节点个数是输入该MBConv特征矩阵channels的1/4，且使用Swish激活函数。第二个全连接层的节点个数等于<code>Depthwise Conv</code>层输出的特征矩阵<code>channels</code>，且使用Sigmoid激活函数。</p>
<img src="/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/SE模块.png" alt="SE模块" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
<h2 id="EfficientNet-B0-B7参数">EfficientNet-B0-B7参数</h2>
<ul>
<li><code>input_size</code>代表训练网络时输入网络的图像大小</li>
<li><code>width coeficient</code>：代表channel维度上的倍率因子，比如在 EfcientNetB0中Stagel的3x3卷积层所使用的卷积核个数是32，那么在B6中就是 32 X 18=57.6接着取整到离它最近的8的整数倍即56，其它Stage同理。</li>
<li><code>depth coeficient</code>：代表depth维度上的倍率因子（仅针对Stage2到Stage8），比如在EcientNetB0中Stage7的L=4，那么在B6中就是 4 X 2.6=10.4，接着向上取整即11。</li>
<li><code>drop_connect_rate</code>是在<code>MBConv</code>结构中dropout层使用的<code>drop_rate</code>，在官方keras模块的实现中<code>MBConv</code>结构的<code>drop_rate</code>是从0递增到<code>drop_connect_rate</code>的（<strong>在源码实现中只有使用shortcut的时候才有Dropout层</strong>）。还需要注意的是，这里的Dropout层是<code>Stochastic Depth</code>，即会随机丢掉整个block的主分支（只剩捷径分支，相当于直接跳过了这个block）也可以理解为减少了网络的深度。</li>
<li><code>dropout_rate</code>是最后一个全连接层前的<code>dropout</code>层（在<code>stage9</code>的Pooling与FC之间）的<code>dropout_rate</code>。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Model</th>
<th style="text-align:center">input_size</th>
<th style="text-align:center">width_coefficient</th>
<th style="text-align:center">depth_coefficient</th>
<th style="text-align:center">dropout_connect_rate</th>
<th style="text-align:center">dropout_rate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">EfficientNetB0</td>
<td style="text-align:center">224x224</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.2</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB1</td>
<td style="text-align:center">240x240</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">1.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.2</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB2</td>
<td style="text-align:center">260x260</td>
<td style="text-align:center">1.1</td>
<td style="text-align:center">1.2</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.3</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB3</td>
<td style="text-align:center">300x300</td>
<td style="text-align:center">1.2</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.3</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB4</td>
<td style="text-align:center">380x380</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">1.8</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.4</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB5</td>
<td style="text-align:center">456x456</td>
<td style="text-align:center">1.6</td>
<td style="text-align:center">2.2</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.4</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB6</td>
<td style="text-align:center">528x528</td>
<td style="text-align:center">1.8</td>
<td style="text-align:center">2.6</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.5</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB7</td>
<td style="text-align:center">600x600</td>
<td style="text-align:center">2.0</td>
<td style="text-align:center">3.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.5</td>
</tr>
</tbody>
</table>
<h1>EfficientNet与当时主流网络的性能参数对比</h1>
<p>虽然参数少，准确率高，但是超级占显存。</p>
<img src="/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNet与当时主流网络的性能参数对比.png" alt="EfficientNet与当时主流网络的性能参数对比" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224); ">
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>EfficientNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十八）使用Pytorch搭建EfficientNet网络</title>
    <url>/2023/05/27/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNet%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1>回顾</h1>
<h2 id="EfficientNet-B0网络结构">EfficientNet-B0网络结构</h2>
<p>EfficientNet网络结构基本上分为9个Stage，第一个Stage是一个卷积核大小为3x3步距为2的普通卷积层（包含BN和激活函数Swish）；第二至第八的Stage 都是使用MBConv，也就是在MobileNetv3所使用到的InvertedResidualBlock结构。</p>
<p>每个MBConv后会跟一个数字1或6，这里的1或6就是倍率因子n即MBConv中第一个1x1的卷积层会将输入特征矩阵的channels扩充为n倍，其中k3x3或k5x5表示MBConv中Depthwise Conv所采用的卷积核大小。</p>
<img src="/2023/05/27/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNet%E7%BD%91%E7%BB%9C/EfficientNet-B0网络结构.png" alt="EfficientNet-B0网络结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<h2 id="MBConv结构">MBConv结构</h2>
<p>MBConv结构主要由一个1x1的普通卷积（升维作用，包含BN和Swish），一个kxk的Depthwise Conv卷积（包含BN和Swish）<strong>k的具体值可看EfficientNet-B0的网络框架主要有3x3和5x5两种情况</strong>，一个SE模块，一个1x1的普通卷积（降维作用，包含BN），一个Droupout层构成。</p>
<img src="/2023/05/27/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNet%E7%BD%91%E7%BB%9C/MBConv结构.png" alt="MBConv结构" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<h2 id="SE模块">SE模块</h2>
<img src="/2023/05/27/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNet%E7%BD%91%E7%BB%9C/SE模块.png" alt="SE模块" style="border-width: 1px; border-style: solid; border-color: rgb(224, 224, 224);  ">
<h1>工程目录</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test9_efficientnet</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── my_dataset.py（数据处理文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,EfficientNet.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── efficientnet-b0.pth（用于迁移学习时，提前下载好官方的efficientnet-b0权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h1>搭建网络结构</h1>
<h2 id="代码框架">代码框架</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span>, <span class="type">Callable</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_make_divisible</span>(<span class="params">ch, divisor=<span class="number">8</span>, min_ch=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNActivation</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 in_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 groups: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 activation_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SqueezeExcitation</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,   <span class="comment"># block input channel</span></span></span><br><span class="line"><span class="params">                 expand_c: <span class="built_in">int</span>,  <span class="comment"># block expand channel</span></span></span><br><span class="line"><span class="params">                 squeeze_factor: <span class="built_in">int</span> = <span class="number">4</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidualConfig</span>:</span><br><span class="line">    <span class="comment"># kernel_size, in_channel, out_channel, exp_ratio, strides, use_SE, drop_connect_rate</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 kernel: <span class="built_in">int</span>,          <span class="comment"># 3 or 5</span></span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 expanded_ratio: <span class="built_in">int</span>,  <span class="comment"># 1 or 6</span></span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span>,          <span class="comment"># 1 or 2</span></span></span><br><span class="line"><span class="params">                 use_se: <span class="built_in">bool</span>,         <span class="comment"># True</span></span></span><br><span class="line"><span class="params">                 drop_rate: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 index: <span class="built_in">str</span>,           <span class="comment"># 1a, 2a, 2b, ...</span></span></span><br><span class="line"><span class="params">                 width_coefficient: <span class="built_in">float</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">adjust_channels</span>(<span class="params">channels: <span class="built_in">int</span>, width_coefficient: <span class="built_in">float</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 cnf: InvertedResidualConfig,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Callable</span>[..., nn.Module]</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EfficientNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 width_coefficient: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 depth_coefficient: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 dropout_rate: <span class="built_in">float</span> = <span class="number">0.2</span>,</span></span><br><span class="line"><span class="params">                 drop_connect_rate: <span class="built_in">float</span> = <span class="number">0.2</span>,</span></span><br><span class="line"><span class="params">                 block: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span></span><br><span class="line"><span class="params">                 </span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">round_repeats</span>(<span class="params">repeats</span>):</span><br><span class="line">            <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_forward_impl</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b0</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b1</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b2</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b3</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b4</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b5</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b6</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b7</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h2 id="make-divisible函数">_make_divisible函数</h2>
<p><strong>是为了将卷积核个数（输出的通道个数ch）调整为输入divisor参数的整数倍</strong>。搭建中采用divisor=8，也就是要将卷积核的个数设置为8的整数倍。</p>
<p>目的：为了更好的调用硬件设备，比如多GPU变形运算，或者多机器分布式运算</p>
<ul>
<li><code>ch</code>：传入的卷积核个数（输出特征矩阵的channel）</li>
<li><code>divisor</code>：传入round_nearest基数，即将卷积核个数ch调整为divisor的整数倍</li>
<li><code>min_ch</code>：最小通道数，如果为None，就将min_ch设置为divisor</li>
<li><code>new_ch</code>：即将卷积核个数调整为离它最近的8的倍数的值</li>
<li>之后进行判断new_ch是否小于传入ch的0.9倍，如果小于，则加上一个divisor（为了确保new_ch向下取整的时候，不会减少超过10%）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_divisible</span>(<span class="params">ch, divisor=<span class="number">8</span>, min_ch=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This function is taken from the original tf repo.</span></span><br><span class="line"><span class="string">    It ensures that all layers have a channel number that is divisible by 8</span></span><br><span class="line"><span class="string">    It can be seen here:</span></span><br><span class="line"><span class="string">    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> min_ch <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        min_ch = divisor</span><br><span class="line">    new_ch = <span class="built_in">max</span>(min_ch, <span class="built_in">int</span>(ch + divisor / <span class="number">2</span>) // divisor * divisor)</span><br><span class="line">    <span class="comment"># Make sure that round down does not go down by more than 10%.</span></span><br><span class="line">    <span class="keyword">if</span> new_ch &lt; <span class="number">0.9</span> * ch:</span><br><span class="line">        new_ch += divisor</span><br><span class="line">    <span class="keyword">return</span> new_ch</span><br></pre></td></tr></table></figure>
<h2 id="ConvBNActivation类">ConvBNActivation类</h2>
<p>在MBConv结构中，基本上的组成都是<strong>卷积+BN+Swish激活函数</strong>（尽管第二次1x1卷积之后没有激活函数）</p>
<ul>
<li><code>group</code>：用来分辨是使用普通卷积还是dw卷积</li>
<li><code>norm_layer</code>：在EfficientNet中相当于BN结构</li>
<li><code>activation_layer</code>：BN结构之后的激活函数，当传入为nn.identity，指不做任何处理的方法</li>
<li><code>nn.SiLU</code>：实际上和Swish函数一样（只有官方torch版本≥1.7的时候，才有该激活函数）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNActivation</span>(nn.Sequential):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 in_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 groups: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 activation_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span>):</span><br><span class="line">        padding = (kernel_size - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        <span class="keyword">if</span> activation_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            activation_layer = nn.SiLU  <span class="comment"># alias Swish  (torch&gt;=1.7)</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(ConvBNActivation, self).__init__(nn.Conv2d(in_channels=in_planes,</span><br><span class="line">                                                         out_channels=out_planes,</span><br><span class="line">                                                         kernel_size=kernel_size,</span><br><span class="line">                                                         stride=stride,</span><br><span class="line">                                                         padding=padding,</span><br><span class="line">                                                         groups=groups,</span><br><span class="line">                                                         bias=<span class="literal">False</span>),</span><br><span class="line">                                               norm_layer(out_planes),</span><br><span class="line">                                               activation_layer())</span><br></pre></td></tr></table></figure>
<h2 id="SE模块-2">SE模块</h2>
<ul>
<li><code>input_c</code>：对应的是MBConv模块输入特征矩阵的channel；</li>
<li><code>expand_c</code>：对应的是MBConv模块中第一个1x1的卷积层升维之后所输出的特征矩阵channel</li>
</ul>
<blockquote>
<p>由于MBConv模块中的dw卷积是不会对特征矩阵channel做变化的，因此dw卷积之后的特征矩阵channel与 = 第一层1x1卷积层之后的特征矩阵channel = expand_c</p>
</blockquote>
<ul>
<li><code>squeeze_factor</code>：第一个全连接层的结点个数 = input_c // squeeze_factor（第一个全连接层<strong>原理上特别注意</strong>：是input_c除以4）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SqueezeExcitation</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,   <span class="comment"># block input channel</span></span></span><br><span class="line"><span class="params">                 expand_c: <span class="built_in">int</span>,  <span class="comment"># block expand channel</span></span></span><br><span class="line"><span class="params">                 squeeze_factor: <span class="built_in">int</span> = <span class="number">4</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SqueezeExcitation, self).__init__()</span><br><span class="line">        squeeze_c = input_c // squeeze_factor</span><br><span class="line">        <span class="comment"># 此处的Conv2d理论上和使用全连接层效果上是一样的</span></span><br><span class="line">        self.fc1 = nn.Conv2d(expand_c, squeeze_c, <span class="number">1</span>)</span><br><span class="line">        self.ac1 = nn.SiLU()  <span class="comment"># 效果同Swish，只是名字不一样</span></span><br><span class="line">        self.fc2 = nn.Conv2d(squeeze_c, expand_c, <span class="number">1</span>)</span><br><span class="line">        self.ac2 = nn.Sigmoid()</span><br><span class="line">	<span class="comment"># -&gt; Tensor表示最后返回值的类型</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        scale = F.adaptive_avg_pool2d(x, output_size=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        scale = self.fc1(scale)</span><br><span class="line">        scale = self.ac1(scale)</span><br><span class="line">        scale = self.fc2(scale)</span><br><span class="line">        scale = self.ac2(scale)</span><br><span class="line">        <span class="keyword">return</span> scale * x</span><br></pre></td></tr></table></figure>
<h2 id="InvertedResidualConfig类">InvertedResidualConfig类</h2>
<p>类似于MobileNetv3中的InvertedResidualConfig，在EfficientNet中，对应的是每一个MBConv模块中的配置参数。</p>
<ul>
<li>
<p><code>kernel</code>：每一层MBConv模块使用的kernel_size（即DW卷积中的卷积核大小，3x3 or 5x5）；</p>
</li>
<li>
<p><code>input_c</code>：输入MBConv模块的特征矩阵channel；</p>
</li>
<li>
<p><code>out_c</code>：MBConv模块输出特征矩阵的channel；</p>
</li>
<li>
<p><code>expanded_ratio</code>：对应MBConv模块中1x1卷积层，用来调节每一个卷积层所使用channel的倍率因子；</p>
</li>
<li>
<p><code>stride</code>：指的是DW卷积所对应的步距；</p>
</li>
<li>
<p><code>use_se</code>：是否使用SE注意力机制；</p>
</li>
<li>
<p><code>drop_rate</code>：随机失活比例；</p>
</li>
<li>
<p><code>index</code>：记录当前MBConv模块的名称，用来方便后期分析；</p>
</li>
<li>
<p><code>width_coefficient</code>：关于网络宽度width上的倍率因子（实际上指特征矩阵的channel）。</p>
<p><code>@staticmethod</code>：静态方法（可以不实例化类就直接调用，主要是类显得不重要的时候用）</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidualConfig</span>:</span><br><span class="line">    <span class="comment"># kernel_size, in_channel, out_channel, exp_ratio, strides, use_SE, drop_connect_rate</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 kernel: <span class="built_in">int</span>,          <span class="comment"># 3 or 5</span></span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 expanded_ratio: <span class="built_in">int</span>,  <span class="comment"># 1 or 6</span></span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span>,          <span class="comment"># 1 or 2</span></span></span><br><span class="line"><span class="params">                 use_se: <span class="built_in">bool</span>,         <span class="comment"># True</span></span></span><br><span class="line"><span class="params">                 drop_rate: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 index: <span class="built_in">str</span>,           <span class="comment"># 1a, 2a, 2b, ...</span></span></span><br><span class="line"><span class="params">                 width_coefficient: <span class="built_in">float</span></span>):</span><br><span class="line">        self.input_c = self.adjust_channels(input_c, width_coefficient)</span><br><span class="line">        self.kernel = kernel</span><br><span class="line">        self.expanded_c = self.input_c * expanded_ratio</span><br><span class="line">        self.out_c = self.adjust_channels(out_c, width_coefficient)</span><br><span class="line">        self.use_se = use_se</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.drop_rate = drop_rate</span><br><span class="line">        self.index = index</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">adjust_channels</span>(<span class="params">channels: <span class="built_in">int</span>, width_coefficient: <span class="built_in">float</span></span>):</span><br><span class="line">        <span class="keyword">return</span> _make_divisible(channels * width_coefficient, <span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<h2 id="InvertedResidual类（MBConv模块）">InvertedResidual类（MBConv模块）</h2>
<p>同MobileNetv3一致（从pytorch搭建MobileNetv3复制过来的）</p>
<ul>
<li><code>cnf</code>：前文提到的InvertedResidualConfig配置文件；</li>
<li><code>norm_layer</code>：对应的在卷积后接的BN层</li>
<li><code>cnf.stride</code>：判断步距是否为1或2，因为在网络参数表中，步距只有1和2两种情况，当出现第三种情况时，就是不合法的步距情况；再判断</li>
<li><code>self.use_res_connect</code>：是否使用shortcut连接，shortcut只有在stride == 1且input_c == output_c时才有；</li>
<li><code>activation_layer</code>：判断使用ReLU或者H-Swish激活函数（官方是在1.7及以上版本中才有官方实现的H-Swish和H-Sigmoid激活函数，如果需要使用MNv3网络的话，得把pytorch版本更新至1.7及以上）</li>
<li>expand区域指在InvertedResidual结构中的第一个1x1卷积层进行升维处理，因为第一个block存在输入特征矩阵的channel和输出特征矩阵的channel相等，因此可以跳过，所以会进行判断cnf.expanded_c != cnf.input_c；</li>
<li>depthwise区域为dw卷积区域</li>
</ul>
<blockquote>
<p><code>groups</code>：由于DW卷积是针对每一个channel都单独使用一个channel为1的卷积核来进行卷及处理，所以groups和channel的个数是保持一致的，所以groups=cnf.expanded_c</p>
</blockquote>
<ul>
<li>project区域是InvertedResidual结构中1x1卷积中的降维部分，activation_layer=nn.Identity中的Identity其实就是线性y = x，没有做任何处理；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 cnf: InvertedResidualConfig,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Callable</span>[..., nn.Module]</span>):</span><br><span class="line">        <span class="built_in">super</span>(InvertedResidual, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cnf.stride <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;illegal stride value.&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.use_res_connect = (cnf.stride == <span class="number">1</span> <span class="keyword">and</span> cnf.input_c == cnf.out_c)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义有序字典layers</span></span><br><span class="line">        layers = OrderedDict()</span><br><span class="line">        activation_layer = nn.SiLU  <span class="comment"># alias Swish</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># expand</span></span><br><span class="line">        <span class="keyword">if</span> cnf.expanded_c != cnf.input_c:</span><br><span class="line">            layers.update(&#123;<span class="string">&quot;expand_conv&quot;</span>: ConvBNActivation(cnf.input_c,</span><br><span class="line">                                                           cnf.expanded_c,</span><br><span class="line">                                                           kernel_size=<span class="number">1</span>,</span><br><span class="line">                                                           norm_layer=norm_layer,</span><br><span class="line">                                                           activation_layer=activation_layer)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># depthwise</span></span><br><span class="line">        layers.update(&#123;<span class="string">&quot;dwconv&quot;</span>: ConvBNActivation(cnf.expanded_c,</span><br><span class="line">                                                  cnf.expanded_c,</span><br><span class="line">                                                  kernel_size=cnf.kernel,</span><br><span class="line">                                                  stride=cnf.stride,</span><br><span class="line">                                                  groups=cnf.expanded_c,</span><br><span class="line">                                                  norm_layer=norm_layer,</span><br><span class="line">                                                  activation_layer=activation_layer)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cnf.use_se:</span><br><span class="line">            layers.update(&#123;<span class="string">&quot;se&quot;</span>: SqueezeExcitation(cnf.input_c,</span><br><span class="line">                                                   cnf.expanded_c)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project</span></span><br><span class="line">        layers.update(&#123;<span class="string">&quot;project_conv&quot;</span>: ConvBNActivation(cnf.expanded_c,</span><br><span class="line">                                                        cnf.out_c,</span><br><span class="line">                                                        kernel_size=<span class="number">1</span>,</span><br><span class="line">                                                        norm_layer=norm_layer,</span><br><span class="line">                                                        activation_layer=nn.Identity)&#125;)</span><br><span class="line"></span><br><span class="line">        self.block = nn.Sequential(layers)</span><br><span class="line">        self.out_channels = cnf.out_c</span><br><span class="line">        self.is_strided = cnf.stride &gt; <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 只有在使用shortcut且drop_rate大于0时才使用dropout层</span></span><br><span class="line">        <span class="keyword">if</span> self.use_res_connect <span class="keyword">and</span> cnf.drop_rate &gt; <span class="number">0</span>:</span><br><span class="line">            self.dropout = DropPath(cnf.drop_rate)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.dropout = nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        result = self.block(x)</span><br><span class="line">        result = self.dropout(result)</span><br><span class="line">        <span class="keyword">if</span> self.use_res_connect:</span><br><span class="line">            result += x</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h2 id="EfficientNet类">EfficientNet类</h2>
<ul>
<li><code>width coeficient</code>：代表channel维度上的倍率因子，比如在 EfcientNetB0中Stagel的3x3卷积层所使用的卷积核个数是32，那么在B6中就是 32 X 18=57.6接着取整到离它最近的8的整数倍即56，其它Stage同理。</li>
<li><code>depth coeficient</code>：代表depth维度上的倍率因子（仅针对Stage2到Stage8），比如在EcientNetB0中Stage7的L=4，那么在B6中就是 4 X 2.6=10.4，接着向上取整即11。</li>
<li><code>drop_connect_rate</code>：对应MBConv模块Dropout层的随机失活比例（并不是所有层的Dropout都是0.2，而是渐渐从0增长至0.2）；</li>
<li><code>dropout_rate</code>：MBConv模块中最后一个全连接层前面的Dropout层的随机失活比例，对应EfficientNet网络中Stage9当中<code>FC</code>全连接层前面的一个Dropout层的随机失活比例。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Model</th>
<th style="text-align:center">input_size</th>
<th style="text-align:center">width_coefficient</th>
<th style="text-align:center">depth_coefficient</th>
<th style="text-align:center">drop_connect_rate</th>
<th style="text-align:center">dropout_rate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">EfficientNetB0</td>
<td style="text-align:center">224x224</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.2</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB1</td>
<td style="text-align:center">240x240</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">1.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.2</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB2</td>
<td style="text-align:center">260x260</td>
<td style="text-align:center">1.1</td>
<td style="text-align:center">1.2</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.3</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB3</td>
<td style="text-align:center">300x300</td>
<td style="text-align:center">1.2</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.3</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB4</td>
<td style="text-align:center">380x380</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">1.8</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.4</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB5</td>
<td style="text-align:center">456x456</td>
<td style="text-align:center">1.6</td>
<td style="text-align:center">2.2</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.4</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB6</td>
<td style="text-align:center">528x528</td>
<td style="text-align:center">1.8</td>
<td style="text-align:center">2.6</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.5</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB7</td>
<td style="text-align:center">600x600</td>
<td style="text-align:center">2.0</td>
<td style="text-align:center">3.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.5</td>
</tr>
</tbody>
</table>
<p><code>default_cnf</code>：存储网络中Stage2~Stage8之间的默认配置文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EfficientNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 width_coefficient: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 depth_coefficient: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 dropout_rate: <span class="built_in">float</span> = <span class="number">0.2</span>,</span></span><br><span class="line"><span class="params">                 drop_connect_rate: <span class="built_in">float</span> = <span class="number">0.2</span>,</span></span><br><span class="line"><span class="params">                 block: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span></span><br><span class="line"><span class="params">                 </span>):</span><br><span class="line">        <span class="built_in">super</span>(EfficientNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># kernel_size, in_channel, out_channel, exp_ratio, strides, use_SE, drop_connect_rate, repeats</span></span><br><span class="line">        default_cnf = [[<span class="number">3</span>, <span class="number">32</span>, <span class="number">16</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="literal">True</span>, drop_connect_rate, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">16</span>, <span class="number">24</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="literal">True</span>, drop_connect_rate, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">5</span>, <span class="number">24</span>, <span class="number">40</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="literal">True</span>, drop_connect_rate, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">40</span>, <span class="number">80</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="literal">True</span>, drop_connect_rate, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">5</span>, <span class="number">80</span>, <span class="number">112</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="literal">True</span>, drop_connect_rate, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">5</span>, <span class="number">112</span>, <span class="number">192</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="literal">True</span>, drop_connect_rate, <span class="number">4</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">192</span>, <span class="number">320</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="literal">True</span>, drop_connect_rate, <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">round_repeats</span>(<span class="params">repeats</span>):</span><br><span class="line">            <span class="string">&quot;&quot;&quot;Round number of repeats based on depth multiplier.&quot;&quot;&quot;</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">int</span>(math.ceil(depth_coefficient * repeats))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> block <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            block = InvertedResidual</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = partial(nn.BatchNorm2d, eps=<span class="number">1e-3</span>, momentum=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        adjust_channels = partial(InvertedResidualConfig.adjust_channels,</span><br><span class="line">                                  width_coefficient=width_coefficient)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># build inverted_residual_setting</span></span><br><span class="line">        bneck_conf = partial(InvertedResidualConfig,</span><br><span class="line">                             width_coefficient=width_coefficient)</span><br><span class="line"></span><br><span class="line">        b = <span class="number">0</span></span><br><span class="line">        num_blocks = <span class="built_in">float</span>(<span class="built_in">sum</span>(round_repeats(i[-<span class="number">1</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> default_cnf))</span><br><span class="line">        inverted_residual_setting = []</span><br><span class="line">        <span class="comment"># 遍历每一个Stage</span></span><br><span class="line">        <span class="keyword">for</span> stage, args <span class="keyword">in</span> <span class="built_in">enumerate</span>(default_cnf):</span><br><span class="line">            cnf = copy.copy(args)</span><br><span class="line">            <span class="comment"># 遍历每一个Stage中的MBConv模块</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(round_repeats(cnf.pop(-<span class="number">1</span>))):</span><br><span class="line">                <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># strides equal 1 except first cnf</span></span><br><span class="line">                    cnf[-<span class="number">3</span>] = <span class="number">1</span>  <span class="comment"># strides</span></span><br><span class="line">                    cnf[<span class="number">1</span>] = cnf[<span class="number">2</span>]  <span class="comment"># input_channel equal output_channel</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 最后的以及被pop出去，现在cnf[-1]指的是drop_connect_rate</span></span><br><span class="line">                cnf[-<span class="number">1</span>] = args[-<span class="number">2</span>] * b / num_blocks  <span class="comment"># update dropout ratio</span></span><br><span class="line">                <span class="comment"># 通过该方法能记录当前MBConv结构是属于第几个Stage中的第几个MBConv结构</span></span><br><span class="line">                index = <span class="built_in">str</span>(stage + <span class="number">1</span>) + <span class="built_in">chr</span>(i + <span class="number">97</span>)  <span class="comment"># 1a, 2a, 2b, ...</span></span><br><span class="line">                inverted_residual_setting.append(bneck_conf(*cnf, index))</span><br><span class="line">                b += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># create layers</span></span><br><span class="line">        layers = OrderedDict()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># first conv </span></span><br><span class="line">        <span class="comment"># Stage1</span></span><br><span class="line">        layers.update(&#123;<span class="string">&quot;stem_conv&quot;</span>: ConvBNActivation(in_planes=<span class="number">3</span>,</span><br><span class="line">                                                     out_planes=adjust_channels(<span class="number">32</span>),</span><br><span class="line">                                                     kernel_size=<span class="number">3</span>,</span><br><span class="line">                                                     stride=<span class="number">2</span>,</span><br><span class="line">                                                     norm_layer=norm_layer)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># building inverted residual blocks </span></span><br><span class="line">        <span class="comment"># Stage2~Stage8</span></span><br><span class="line">        <span class="keyword">for</span> cnf <span class="keyword">in</span> inverted_residual_setting:</span><br><span class="line">            layers.update(&#123;cnf.index: block(cnf, norm_layer)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># build top</span></span><br><span class="line">        <span class="comment"># Stage9</span></span><br><span class="line">        last_conv_input_c = inverted_residual_setting[-<span class="number">1</span>].out_c</span><br><span class="line">        last_conv_output_c = adjust_channels(<span class="number">1280</span>)</span><br><span class="line">        layers.update(&#123;<span class="string">&quot;top&quot;</span>: ConvBNActivation(in_planes=last_conv_input_c,</span><br><span class="line">                                               out_planes=last_conv_output_c,</span><br><span class="line">                                               kernel_size=<span class="number">1</span>,</span><br><span class="line">                                               norm_layer=norm_layer)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Stage~Stage8+Stagr9的Conv1，特征提取部分</span></span><br><span class="line">        self.features = nn.Sequential(layers)</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        classifier = []</span><br><span class="line">        <span class="keyword">if</span> dropout_rate &gt; <span class="number">0</span>:</span><br><span class="line">            classifier.append(nn.Dropout(p=dropout_rate, inplace=<span class="literal">True</span>))</span><br><span class="line">        classifier.append(nn.Linear(last_conv_output_c, num_classes))</span><br><span class="line">        self.classifier = nn.Sequential(*classifier)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># initial weights</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&quot;fan_out&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.zeros_(m.bias)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                nn.init.ones_(m.weight)</span><br><span class="line">                nn.init.zeros_(m.bias)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.zeros_(m.bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_forward_impl</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">return</span> self._forward_impl(x)</span><br></pre></td></tr></table></figure>
<h2 id="实例化EfficientNet-B0-B7">实例化EfficientNet-B0~B7</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b0</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># input image size 224x224</span></span><br><span class="line">    <span class="keyword">return</span> EfficientNet(width_coefficient=<span class="number">1.0</span>,</span><br><span class="line">                        depth_coefficient=<span class="number">1.0</span>,</span><br><span class="line">                        dropout_rate=<span class="number">0.2</span>,</span><br><span class="line">                        num_classes=num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b1</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># input image size 240x240</span></span><br><span class="line">    <span class="keyword">return</span> EfficientNet(width_coefficient=<span class="number">1.0</span>,</span><br><span class="line">                        depth_coefficient=<span class="number">1.1</span>,</span><br><span class="line">                        dropout_rate=<span class="number">0.2</span>,</span><br><span class="line">                        num_classes=num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b2</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># input image size 260x260</span></span><br><span class="line">    <span class="keyword">return</span> EfficientNet(width_coefficient=<span class="number">1.1</span>,</span><br><span class="line">                        depth_coefficient=<span class="number">1.2</span>,</span><br><span class="line">                        dropout_rate=<span class="number">0.3</span>,</span><br><span class="line">                        num_classes=num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b3</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># input image size 300x300</span></span><br><span class="line">    <span class="keyword">return</span> EfficientNet(width_coefficient=<span class="number">1.2</span>,</span><br><span class="line">                        depth_coefficient=<span class="number">1.4</span>,</span><br><span class="line">                        dropout_rate=<span class="number">0.3</span>,</span><br><span class="line">                        num_classes=num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b4</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># input image size 380x380</span></span><br><span class="line">    <span class="keyword">return</span> EfficientNet(width_coefficient=<span class="number">1.4</span>,</span><br><span class="line">                        depth_coefficient=<span class="number">1.8</span>,</span><br><span class="line">                        dropout_rate=<span class="number">0.4</span>,</span><br><span class="line">                        num_classes=num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b5</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># input image size 456x456</span></span><br><span class="line">    <span class="keyword">return</span> EfficientNet(width_coefficient=<span class="number">1.6</span>,</span><br><span class="line">                        depth_coefficient=<span class="number">2.2</span>,</span><br><span class="line">                        dropout_rate=<span class="number">0.4</span>,</span><br><span class="line">                        num_classes=num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b6</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># input image size 528x528</span></span><br><span class="line">    <span class="keyword">return</span> EfficientNet(width_coefficient=<span class="number">1.8</span>,</span><br><span class="line">                        depth_coefficient=<span class="number">2.6</span>,</span><br><span class="line">                        dropout_rate=<span class="number">0.5</span>,</span><br><span class="line">                        num_classes=num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnet_b7</span>(<span class="params">num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># input image size 600x600</span></span><br><span class="line">    <span class="keyword">return</span> EfficientNet(width_coefficient=<span class="number">2.0</span>,</span><br><span class="line">                        depth_coefficient=<span class="number">3.1</span>,</span><br><span class="line">                        dropout_rate=<span class="number">0.5</span>,</span><br><span class="line">                        num_classes=num_classes)</span><br></pre></td></tr></table></figure>
<h1>训练结果</h1>
<p>注意：<strong><code>from model import efficientnet_b0 as create_model</code>中的<code>efficientnet_b0</code>需要和`num_model = &quot;B0&quot;保持一致</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.optim.lr_scheduler <span class="keyword">as</span> lr_scheduler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> efficientnet_b0 <span class="keyword">as</span> create_model</span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(args)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Start Tensorboard with &quot;tensorboard --logdir=runs&quot;, view at http://localhost:6006/&#x27;</span>)</span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    img_size = &#123;<span class="string">&quot;B0&quot;</span>: <span class="number">224</span>,</span><br><span class="line">                <span class="string">&quot;B1&quot;</span>: <span class="number">240</span>,</span><br><span class="line">                <span class="string">&quot;B2&quot;</span>: <span class="number">260</span>,</span><br><span class="line">                <span class="string">&quot;B3&quot;</span>: <span class="number">300</span>,</span><br><span class="line">                <span class="string">&quot;B4&quot;</span>: <span class="number">380</span>,</span><br><span class="line">                <span class="string">&quot;B5&quot;</span>: <span class="number">456</span>,</span><br><span class="line">                <span class="string">&quot;B6&quot;</span>: <span class="number">528</span>,</span><br><span class="line">                <span class="string">&quot;B7&quot;</span>: <span class="number">600</span>&#125;</span><br><span class="line">    num_model = <span class="string">&quot;B0&quot;</span></span><br><span class="line"></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(img_size[num_model]),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(img_size[num_model]),</span><br><span class="line">                                   transforms.CenterCrop(img_size[num_model]),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果存在预训练权重则载入</span></span><br><span class="line">    model = create_model(num_classes=args.num_classes).to(device)</span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(args.weights):</span><br><span class="line">            weights_dict = torch.load(args.weights, map_location=device)</span><br><span class="line">            load_weights_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> weights_dict.items()</span><br><span class="line">                                 <span class="keyword">if</span> model.state_dict()[k].numel() == v.numel()&#125;</span><br><span class="line">            <span class="built_in">print</span>(model.load_state_dict(load_weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">&quot;not found weights file: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(args.weights))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否冻结权重</span></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除最后一个卷积层和全连接层外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="string">&quot;features.top&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name) <span class="keyword">and</span> (<span class="string">&quot;classifier&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name):</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;training &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">    pg = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.SGD(pg, lr=args.lr, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1E-4</span>)</span><br><span class="line">    <span class="comment"># Scheduler https://arxiv.org/pdf/1812.01187.pdf</span></span><br><span class="line">    lf = <span class="keyword">lambda</span> x: ((<span class="number">1</span> + math.cos(x * math.pi / args.epochs)) / <span class="number">2</span>) * (<span class="number">1</span> - args.lrf) + args.lrf  <span class="comment"># cosine</span></span><br><span class="line">    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        mean_loss = train_one_epoch(model=model,</span><br><span class="line">                                    optimizer=optimizer,</span><br><span class="line">                                    data_loader=train_loader,</span><br><span class="line">                                    device=device,</span><br><span class="line">                                    epoch=epoch)</span><br><span class="line"></span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        acc = evaluate(model=model,</span><br><span class="line">                       data_loader=val_loader,</span><br><span class="line">                       device=device)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;[epoch &#123;&#125;] accuracy: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch, <span class="built_in">round</span>(acc, <span class="number">3</span>)))</span><br><span class="line">        tags = [<span class="string">&quot;loss&quot;</span>, <span class="string">&quot;accuracy&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], mean_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;./weights/model-&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">30</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.01</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lrf&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># download model weights</span></span><br><span class="line">    <span class="comment"># 链接: https://pan.baidu.com/s/1ouX0UmjCsmSx3ZrqXbowjw  密码: 090i</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./efficientnetb0.pth&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<p><img src="/2023/05/27/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNet%E7%BD%91%E7%BB%9C/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h1>预测结果</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> efficientnet_b0 <span class="keyword">as</span> create_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    img_size = &#123;<span class="string">&quot;B0&quot;</span>: <span class="number">224</span>,</span><br><span class="line">                <span class="string">&quot;B1&quot;</span>: <span class="number">240</span>,</span><br><span class="line">                <span class="string">&quot;B2&quot;</span>: <span class="number">260</span>,</span><br><span class="line">                <span class="string">&quot;B3&quot;</span>: <span class="number">300</span>,</span><br><span class="line">                <span class="string">&quot;B4&quot;</span>: <span class="number">380</span>,</span><br><span class="line">                <span class="string">&quot;B5&quot;</span>: <span class="number">456</span>,</span><br><span class="line">                <span class="string">&quot;B6&quot;</span>: <span class="number">528</span>,</span><br><span class="line">                <span class="string">&quot;B7&quot;</span>: <span class="number">600</span>&#125;</span><br><span class="line">    num_model = <span class="string">&quot;B0&quot;</span></span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(img_size[num_model]),</span><br><span class="line">         transforms.CenterCrop(img_size[num_model]),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = create_model(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/model-2.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p><img src="/2023/05/27/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNet%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>EfficientNet</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（十九）EfficientNetV2网络详解</title>
    <url>/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1>前言</h1>
<p>本节课讲的是EfficientNet网络的升级版EfficientNetV2，这篇论文发表在2021年的CVPR，原论文：<a href="https://arxiv.org/abs/2104.00298">EfficientNetV2: Smaller Models and Faster Training </a>。</p>
<p>下图为EfficientNetV2网络和时下流行网络的性能对比，其中紫色的线对应着EfficientNetV2的S、M和L三个不同大小模型的准确率和训练速度，红色的线对应着EfficientNetV2首先在EfficientNet21K上的预训练，之后再ImageNet上进行迁移学习</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E5%92%8C%E6%97%B6%E4%B8%8B%E6%B5%81%E8%A1%8C%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="EfficientNetV2网络和时下流行网络的性能对比"></p>
<p><strong>网络创新点</strong></p>
<ul>
<li>引入Fused-MBConv模块；</li>
<li>引入渐进式学习策略（学习更快）</li>
</ul>
<p>在EfficientNetV1中作者关注的是准确率，参数数量以及FLOPS(理论计算量小不代表推理速度快)，在EfficientNetV2中作者进一步关注模型的训练速度。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E4%B8%8EEfficientNetV1%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="EfficientNetV2与EfficientNetV1性能对比"></p>
<h1>EfficientNetV1中存在的问题</h1>
<p><strong>1、训练图像的尺寸很大时，训练速度非常慢</strong></p>
<p>针对这个问题一个比较好想到的办法就是降低训练图像的尺寸，之前也有一些文章这么干过。降低训练图像的尺寸不仅能够加快训练速度，还能使用更大的batch_size。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV1%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98-%E5%9B%BE%E7%89%87%E5%B0%BA%E5%AF%B8.png" alt="EfficientNetV1存在问题-图片尺寸"></p>
<p><strong>2、在网络浅层中使用Depthwise convolutions速度会很慢</strong></p>
<p>无法充分利用现有的一些加速器(虽然理论上计算量很小，但实际使用起来并没有想象中那么快)。故引入Fused-MBConv结构。</p>
<p>下图左边分别为MBConv和Fused-MBConv结构，下图右展示了不使用Fused-MBConv结构、仅将Stage2~4中的MBConv替换为Fused-MBConv结构、仅将Stage2~6中的MBConv替换为Fused-MBConv结构和将Stage2~8的MBConv替换为Fused-MBConv结构。</p>
<p>在前二者替换效果来看，训练速度和准确率都有提高，但全部替换的形式导致准确率和训练速度都下降，由此可见，<strong>并不能无脑的将MBConv转化为Fused-MBConv</strong>。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Fused-MBConv%E7%BB%93%E6%9E%84.png" alt="Fused-MBConv结构"></p>
<p><strong>3、同等的放大每个stage是次优的</strong></p>
<p>在EfficientNetV1中每个stage的深度和宽度都是同等放大的。但<strong>每个stage对网络的训练速度以及参数数量的贡献并不相同</strong>，所以直接使用同等缩放的策略并不合理。在这篇文章中，作者<strong>采用了非均匀的缩放策略来缩放模型</strong>。</p>
<table>
<thead>
<tr>
<th style="text-align:center">Model</th>
<th style="text-align:center">input_size</th>
<th style="text-align:center">width_coefficient</th>
<th style="text-align:center">depth_coefficient</th>
<th style="text-align:center">dropout_connect_rate</th>
<th style="text-align:center">dropout_rate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">EfficientNetB0</td>
<td style="text-align:center">224x224</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.2</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB1</td>
<td style="text-align:center">240x240</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">1.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.2</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB2</td>
<td style="text-align:center">260x260</td>
<td style="text-align:center">1.1</td>
<td style="text-align:center">1.2</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.3</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB3</td>
<td style="text-align:center">300x300</td>
<td style="text-align:center">1.2</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.3</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB4</td>
<td style="text-align:center">380x380</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">1.8</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.4</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB5</td>
<td style="text-align:center">456x456</td>
<td style="text-align:center">1.6</td>
<td style="text-align:center">2.2</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.4</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB6</td>
<td style="text-align:center">528x528</td>
<td style="text-align:center">1.8</td>
<td style="text-align:center">2.6</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.5</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB7</td>
<td style="text-align:center">600x600</td>
<td style="text-align:center">2.0</td>
<td style="text-align:center">3.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.5</td>
</tr>
</tbody>
</table>
<h1>EfficientNetV2中做出的贡献</h1>
<p>在之前的一些研究中，主要关注的是准确率以及参数数量（注意，参数数量少并不代表推理速度更快)。但在近些年的研究中，开始关注网络的训练速度以及推理速度(可能是准确率刷不动了）。</p>
<ul>
<li>引入新的网络（EfficientNetV2），该网络在训练速度以及参数数量上都优于先前的一些网络；</li>
<li>提出了改进的渐进学习方法，该方法会<strong>根据训练图像的尺寸动态调节正则方法</strong>（提升训练速度、准确率），其中方法有Dropout、Rand Augment、Mixup；</li>
<li>通过实验与先前的一些网络相比，<strong>训练速度提升11倍</strong>，参数数量减少为1/6.8</li>
</ul>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E5%92%8C%E5%87%86%E7%A1%AE%E7%8E%87%E5%AF%B9%E6%AF%94.png" alt="EfficientNetV2训练参数和准确率对比"></p>
<h1>EfficientNetV2网络框架</h1>
<p><strong>注意，在源码中Stage6的输出Channels是等于256并不是表格中的272，Stage7的输出Channels是1280并不是表格中的1792</strong>，后续论文的版本会修正过来。</p>
<p>相比与EfficientNetV1，主要有以下不同：</p>
<ul>
<li><strong>除了使用<code>MBConv</code>模块，还使用<code>Fused-MBConv</code>模块</strong>（主要是在网络浅层中使用）；</li>
<li><strong>会使用较小的<code>expansion ratio</code></strong>（<code>MBConv</code>中第一个<code>expand conv1x1</code>或者<code>Fused-MBConv</code>中第一个<code>expand conv3x3</code>）比如<code>4</code>，在EfficientNetV1中基本都是<code>6</code>. 这样的好处是能够减少内存访问开销；</li>
<li><strong>偏向使用更小的<code>kernel_size(3x3)</code></strong>，在EfficientNetV1中使用了很多<code>5x5</code>的kernel_size。通过下表可以看到使用的kernel_size全是<code>3x3</code>的，由于<code>3x3</code>的感受野是要比<code>5x5</code>小的，所以需要堆叠更多的层结构以增加感受野；</li>
<li><strong>移除了EfficientNetV1中最后一个步距为1的stage (V1中的stage8)</strong></li>
</ul>
<p><code>Stride</code>就是步距，注意每个Stage中会重复堆叠Operator模块多次，只有第一个Opertator模块的步距是按照表格中Stride来设置的，其他的默认都是1。 <code>#Channels</code>表示该Stage输出的特征矩阵的Channels，<code>#Layers</code>表示该Stage重复堆叠Operator的次数。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2-S%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6.png" alt="EfficientNetV2-S模型框架"></p>
<h2 id="Fused-MBConv模块">Fused-MBConv模块</h2>
<p>通过上表可以看到EfficientNetV2-S分为Stage0到Stage7（EfficientNetV1中是Stage1到Stage9）。Operator表示在当前Stage中使用的模块：</p>
<ul>
<li>
<p>Conv3x3就是普通的3x3卷积 + 激活函数（SiLU）+ BN；</p>
</li>
<li>
<p>Fused-MBConv模块名称后跟的1，4表示expansion ratio，k3x3表示kenel_size为3x3，下面是结构图。</p>
</li>
</ul>
<p><strong>注意</strong>：</p>
<ul>
<li>当expansion ratio = 1时是没有expand conv的；</li>
<li>这里没有使用到SE结构的（原论文图中有SE）；</li>
<li>当stride = 1且输入输出Channels相等时才有shortcut连接；</li>
<li>当有shortcut连接时才有Dropout层，而且这里的Dropout层是Stochastic Depth，即会随机丢掉整个block的主分支（只剩捷径分支，相当于直接跳过了这个block）也可以理解为减少了网络的深度。</li>
</ul>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Fused-MBConv%E6%A8%A1%E5%9D%97.png" alt="Fused-MBConv模块"></p>
<h2 id="EfficientNet网络中的Dropout">EfficientNet网络中的Dropout</h2>
<p>EfficientNet网络中的Dropout与前期所有网络结构的Dropout不全一样，例如原始的Dropout参数丢弃比例为0.2，但EfficientNet中给出Dropout = 0.2的参数表示该网络在0~0.2的丢弃比例下逐渐失活。引用论文为：<a href="https://arxiv.org/abs/1603.09382">Deep Networks with Stochastic Depth</a></p>
<p>下图可以理解为正向传播过程中将输入的特征矩阵经历了一个又一个block，每一个block都可以认为是一个残差结构。例如主分支通过$f$函数进行输出，shortcut直接从输入引到输出，在此过程中，会以一定的概率来对主分支进行丢弃（直接放弃整个主分支，相当于直接将上一层的输出引入到下一层的输入，相当于没有这一层）。即Stochastic Depth（随机深度，指的是网络的depth，因为会随机丢弃任意一层block）。</p>
<p>下图中表示存活概率从1.0至0.5，一个渐变的过程。但在EfficientNetV2中采用drop_prob是0~0.2的丢弃比例（提升训练速度，小幅提升准确率）。</p>
<p>注意：<strong>这里的dropout层仅指Fused-MBConv模块以及MBConv模块中的dropout层，不包括最后全连接前的dropout层</strong></p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B-Dropout.png" alt="正向传播过程-Dropout"></p>
<h2 id="MBConv模块">MBConv模块</h2>
<p>MBConv模块和EfficientNetV1中是一样的，其中模块名称后跟的4、6表示expansion ratio，SE0.25表示使用了SE模块，0.25表示SE模块中第一个全连接层的节点个数是输入该MBConv模块特征矩阵channels的1/4</p>
<p>下面是MBConv模块结构图。<strong>注意当stride=1且输入输出Channels相等时才有shortcut连接</strong>。同样这里的<strong>Dropout层是Stochastic Depth</strong>。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/MBConv%E6%A8%A1%E5%9D%97.png" alt="MBConv模块"></p>
<h2 id="EfficientNetV2-S的详细参数">EfficientNetV2-S的详细参数</h2>
<p>首先在官方的源码中有个baseline config注意这个不是V2-S的配置，在efficientnetv2 -&gt; effnetv2_configs.py文件中 。</p>
<ul>
<li><code>r</code>代表当前Stage中Operator重复堆叠的次数；</li>
<li><code>k</code>代表kernel_size；</li>
<li><code>s</code>代表步距stride；</li>
<li><code>e</code>代表expansion ratio；</li>
<li><code>i</code>代表input channels；</li>
<li><code>o</code>代表output channels；</li>
<li><code>c</code>代表conv_type，1代表Fused-MBConv，0代表MBConv（默认为MBConv）；</li>
<li><code>se</code>代表使用SE模块，以及se_ratio</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#################### EfficientNet V2 configs ####################</span></span><br><span class="line">v2_base_block = [  <span class="comment"># The baseline config for v2 models.</span></span><br><span class="line">    <span class="string">&#x27;r1_k3_s1_e1_i32_o16_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r2_k3_s2_e4_i16_o32_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r2_k3_s2_e4_i32_o48_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r3_k3_s2_e4_i48_o96_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s1_e6_i96_o112_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r8_k3_s2_e6_i112_o192_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>EfficientNetV2-S的配置是在baseline的基础上采用了width倍率因子1.4， depth倍率因子1.8得到的（这两个倍率因子是EfficientNetV1-B4中采用的）。</p>
<p>注意：只针对存在MBConv模块或Fused-MBConv模块的Stage，例如<code>r2_k3_s1_e1_i24_o24_c1</code>对应<code>Stage1</code>，Operator重复堆叠2次，kernel_size等于3，stride等于1，expansion等于1，input_channels等于24，output_channels等于24，conv_type为<code>Fused-MBConv</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">v2_s_block = [  <span class="comment"># about base * (width1.4, depth1.8)</span></span><br><span class="line">    <span class="string">&#x27;r2_k3_s1_e1_i24_o24_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r4_k3_s2_e4_i24_o48_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r4_k3_s2_e4_i48_o64_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r6_k3_s2_e4_i64_o128_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r9_k3_s1_e6_i128_o160_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r15_k3_s2_e6_i160_o256_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2-S%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6.png" alt="EfficientNetV2-S模型框架"></p>
<h2 id="EfficientNetV2-M的详细参数">EfficientNetV2-M的详细参数</h2>
<p>EfficientNetV2-M的配置是在baseline的基础上采用了width倍率因子1.6， depth倍率因子2.2得到的（这两个倍率因子是EfficientNetV1-B5中采用的）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">v2_m_block = [  <span class="comment"># about base * (width1.6, depth2.2)</span></span><br><span class="line">    <span class="string">&#x27;r3_k3_s1_e1_i24_o24_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s2_e4_i24_o48_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s2_e4_i48_o80_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i80_o160_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r14_k3_s1_e6_i160_o176_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r18_k3_s2_e6_i176_o304_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s1_e6_i304_o512_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>通过配置文件可知Stage0的卷积核个数是24（<code>i24</code>）</p>
<h2 id="EfficientNetV2-L的详细参数">EfficientNetV2-L的详细参数</h2>
<p>EfficientNetV2-L的配置是在baseline的基础上采用了width倍率因子2.0， depth倍率因子3.1得到的（这两个倍率因子是EfficientNetV1-B7中采用的）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">v2_l_block = [  <span class="comment"># about base * (width2.0, depth3.1)</span></span><br><span class="line">    <span class="string">&#x27;r4_k3_s1_e1_i32_o32_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i32_o64_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i64_o96_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r10_k3_s2_e4_i96_o192_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r19_k3_s1_e6_i192_o224_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r25_k3_s2_e6_i224_o384_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s1_e6_i384_o640_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>通过配置文件可知Stage0的卷积核个数是32（<code>i32</code>）</p>
<p>注意：<strong>EfficientNetV2-M和EfficientNetV2-L比EfficientNetV2-S多出一个Stage</strong></p>
<h2 id="EfficientNetV2其他训练参数">EfficientNetV2其他训练参数</h2>
<p>下面是源码中给出的关于<code>efficientnetv2-s</code>，<code>efficientnetv2-m</code>和<code>efficientnetv2-l</code>三个参数的配置信息。</p>
<p>其中的<code>v2_s_block</code>，<code>v2_m_block</code>以及<code>v2_l_block</code>就是上面刚刚讲到过的网络配置参数，剩下就关注下<code>train_size</code>, <code>eval_size</code>, <code>dropout</code>, <code>randaug</code>, <code>mixup</code>, <code>aug</code>即可。比如<code>efficientnetv2-s</code>的<code>train_size=300</code>（注意实际训练中train_size是会变化的，但最大不超过300，但在验证过程中默认为384x383，后面讲Progressive Learning中会细讲），<code>eval_size=384</code>，<code>dropout=0.2</code>（指的是最后一个Stage中池化层和全连接层之间的一个dropout_rate），<code>randaug=10，mixup=0，aug='randaug'</code>（针对迁移学习策略所使用到的参数）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">efficientnetv2_params = &#123;</span><br><span class="line">    <span class="comment"># (block, width, depth, train_size, eval_size, dropout, randaug, mixup, aug)</span></span><br><span class="line">    <span class="string">&#x27;efficientnetv2-s&#x27;</span>:  <span class="comment"># 83.9% @ 22M</span></span><br><span class="line">        (v2_s_block, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">300</span>, <span class="number">384</span>, <span class="number">0.2</span>, <span class="number">10</span>, <span class="number">0</span>, <span class="string">&#x27;randaug&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;efficientnetv2-m&#x27;</span>:  <span class="comment"># 85.2% @ 54M</span></span><br><span class="line">        (v2_m_block, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">384</span>, <span class="number">480</span>, <span class="number">0.3</span>, <span class="number">15</span>, <span class="number">0.2</span>, <span class="string">&#x27;randaug&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;efficientnetv2-l&#x27;</span>:  <span class="comment"># 85.7% @ 120M</span></span><br><span class="line">        (v2_l_block, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">384</span>, <span class="number">480</span>, <span class="number">0.4</span>, <span class="number">20</span>, <span class="number">0.5</span>, <span class="string">&#x27;randaug&#x27;</span>),</span><br></pre></td></tr></table></figure>
<h1>Progressive Learning渐进学习策略</h1>
<p>训练图像的尺寸对训练模型的效率有很大的影响。所以在之前的一些工作中很多人尝试使用动态的图像尺寸（比如一开始用很小的图像尺寸，后面再增大）来加速网络的训练，但通常会导致Accuracy降低。为什么会出现这种情况呢？</p>
<p>作者提出了一个猜想：Accuracy的降低是不平衡的正则化<code>unbalanced regularization</code>导致的。在训练不同尺寸的图像时，应该使用动态的正则方法（之前都是使用固定的正则方法）。</p>
<p>为了验证这个猜想，作者接着做了一些实验。训练模型过程中尝试使用不同的图像尺寸以及不同强度的数据增强<code>data augmentations</code>。当训练的图片尺寸较小时，使用较弱的数据增强<code>augmentation</code>能够达到更好的结果；当训练的图像尺寸较大时，使用更强的数据增强能够达到更好的接果。如下表所示，当<code>Size=128</code>，<code>RandAug magnitude=5</code>时效果最好；当<code>Size=300</code>，<code>RandAug magnitude=15</code>时效果最好：</p>
<p>![Progressive Learning渐进学习策略效果](EfficientNetV2网络详解/Progressive Learning渐进学习策略效果.png)</p>
<p>基于以上实验，作者就提出了渐进式训练策略<code>Progressive Learning</code>。如下图所示，<strong>在训练早期使用较小的训练尺寸以及较弱的正则方法<code>weak regularization</code>，这样网络能够快速的学习到一些简单的表达能力。接着逐渐提升图像尺寸，同时增强正则方法<code>adding stronger regularization</code></strong>。这里所说的<code>regularization</code>包括<code>dropout rate</code>，<code>RandAugment magnitude</code>以及<code>mixup ratio</code>。</p>
<p>![Progressive Learning渐进学习策略实验](EfficientNetV2网络详解/Progressive Learning渐进学习策略实验.png)</p>
<p>下表给出了EfficientNetV2（S，M，L）三个模型的渐进学习策略参数：</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E4%B8%89%E4%B8%AA%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B8%90%E8%BF%9B%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E5%8F%82%E6%95%B0.png" alt="EfficientNetV2三个模型的渐进学习策略参数"></p>
<p>通过对比可以看出使用渐进式学习策略确实能够有效提升训练速度。为了进一步验证渐进式学习策略的有效性，作者还在Resnet以及EfficientNetV1上进行了测试，如下表所示，使用了渐进式学习策略后确实能够有效提升训练速度并且能够小幅提升Accuracy。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E6%B8%90%E8%BF%9B%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E5%9C%A8%E5%90%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="渐进学习策略在各网络模型中的性能对比"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>EfficientNetV2</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（二十）使用Pytorch搭建EfficientNetV2网络</title>
    <url>/2023/05/30/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNetV2%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1>工程目录</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test11_efficientnetV2</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── my_dataset.py（数据处理文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,EfficientNet.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── pre_efficientnetv2-s.pth（用于迁移学习时，提前下载好官方的pre_efficientnetv2-s权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h1><a href="http://model.py">model.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Callable</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNAct</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 in_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 groups: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 activation_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SqueezeExcite</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,   <span class="comment"># block input channel</span></span></span><br><span class="line"><span class="params">                 expand_c: <span class="built_in">int</span>,  <span class="comment"># block expand channel</span></span></span><br><span class="line"><span class="params">                 se_ratio: <span class="built_in">float</span> = <span class="number">0.25</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MBConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 expand_ratio: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 se_ratio: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 drop_rate: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Callable</span>[..., nn.Module]</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FusedMBConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 expand_ratio: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 se_ratio: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 drop_rate: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Callable</span>[..., nn.Module]</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EfficientNetV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 model_cnf: <span class="built_in">list</span>,</span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 num_features: <span class="built_in">int</span> = <span class="number">1280</span>,</span></span><br><span class="line"><span class="params">                 dropout_rate: <span class="built_in">float</span> = <span class="number">0.2</span>,</span></span><br><span class="line"><span class="params">                 drop_connect_rate: <span class="built_in">float</span> = <span class="number">0.2</span></span>):</span><br><span class="line">		<span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnetv2_s</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnetv2_m</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnetv2_l</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h2 id="DropPath类">DropPath类</h2>
<p>直接调用drop_path函数，原理和上节课一致，如下文所述。</p>
<p>EfficientNet网络中的Dropout与前期所有网络结构的Dropout不全一样，例如原始的Dropout参数丢弃比例为0.2，但EfficientNet中给出Dropout = 0.2的参数表示该网络在0~0.2的丢弃比例下逐渐失活。引用论文为：<a href="https://arxiv.org/abs/1603.09382">Deep Networks with Stochastic Depth</a></p>
<p>下图可以理解为正向传播过程中将输入的特征矩阵经历了一个又一个block，每一个block都可以认为是一个残差结构。例如主分支通过$f$函数进行输出，shortcut直接从输入引到输出，在此过程中，会以一定的概率来对主分支进行丢弃（直接放弃整个主分支，相当于直接将上一层的输出引入到下一层的输入，相当于没有这一层）。即Stochastic Depth（随即深度，指的是网络的depth，因为会随机丢弃任意一层block）。</p>
<p>下图中表示存活概率从1.0至0.5，一个渐变的过程。但在EfficientNetV2中采用drop_prob是0~0.2的丢弃比例（提升训练速度，小幅提升准确率）。</p>
<p>注意：<strong>这里的dropout层仅指Fused-MBConv模块以及MBConv模块中的dropout层，不包括最后全连接前的dropout层</strong></p>
<p><img src="/2023/05/30/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNetV2%E7%BD%91%E7%BB%9C/%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B-Dropout.png" alt="正向传播过程-Dropout"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).</span></span><br><span class="line"><span class="string">    &quot;Deep Networks with Stochastic Depth&quot;, https://arxiv.org/pdf/1603.09382.pdf</span></span><br><span class="line"><span class="string">    This function is taken from the rwightman.</span></span><br><span class="line"><span class="string">    It can be seen here:</span></span><br><span class="line"><span class="string">    https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/drop.py#L140</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> drop_prob == <span class="number">0.</span> <span class="keyword">or</span> <span class="keyword">not</span> training:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    keep_prob = <span class="number">1</span> - drop_prob</span><br><span class="line">    shape = (x.shape[<span class="number">0</span>],) + (<span class="number">1</span>,) * (x.ndim - <span class="number">1</span>)  <span class="comment"># work with diff dim tensors, not just 2D ConvNets</span></span><br><span class="line">    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)</span><br><span class="line">    random_tensor.floor_()  <span class="comment"># binarize</span></span><br><span class="line">    output = x.div(keep_prob) * random_tensor</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).</span></span><br><span class="line"><span class="string">    &quot;Deep Networks with Stochastic Depth&quot;, https://arxiv.org/pdf/1603.09382.pdf</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DropPath, self).__init__()</span><br><span class="line">        self.drop_prob = drop_prob</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> drop_path(x, self.drop_prob, self.training)</span><br></pre></td></tr></table></figure>
<h2 id="ConvBNAct类">ConvBNAct类</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNAct</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 in_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_planes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 groups: <span class="built_in">int</span> = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 activation_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvBNAct, self).__init__()</span><br><span class="line"></span><br><span class="line">        padding = (kernel_size - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        <span class="keyword">if</span> activation_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            activation_layer = nn.SiLU  <span class="comment"># alias Swish  (torch&gt;=1.7)</span></span><br><span class="line"></span><br><span class="line">        self.conv = nn.Conv2d(in_channels=in_planes,</span><br><span class="line">                              out_channels=out_planes,</span><br><span class="line">                              kernel_size=kernel_size,</span><br><span class="line">                              stride=stride,</span><br><span class="line">                              padding=padding,</span><br><span class="line">                              groups=groups,</span><br><span class="line">                              bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.bn = norm_layer(out_planes)</span><br><span class="line">        self.act = activation_layer()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        result = self.conv(x)</span><br><span class="line">        result = self.bn(result)</span><br><span class="line">        result = self.act(result)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h2 id="SqueezeExcite类">SqueezeExcite类</h2>
<p>SE模块如下图所示，由一个全局平均池化，两个全连接层组成。第一个全连接层的节点个数是输入该MBConv特征矩阵channels的1/4，且使用Swish激活函数。第二个全连接层的节点个数等于<code>Depthwise Conv</code>层输出的特征矩阵<code>channels</code>，且使用Sigmoid激活函数。</p>
<p><img src="/2023/05/30/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNetV2%E7%BD%91%E7%BB%9C/SE%E6%A8%A1%E5%9D%97.png" alt="SE模块"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SqueezeExcite</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,   <span class="comment"># block input channel</span></span></span><br><span class="line"><span class="params">                 expand_c: <span class="built_in">int</span>,  <span class="comment"># block expand channel</span></span></span><br><span class="line"><span class="params">                 se_ratio: <span class="built_in">float</span> = <span class="number">0.25</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SqueezeExcite, self).__init__()</span><br><span class="line">        squeeze_c = <span class="built_in">int</span>(input_c * se_ratio)</span><br><span class="line">        self.conv_reduce = nn.Conv2d(expand_c, squeeze_c, <span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.SiLU()  <span class="comment"># alias Swish</span></span><br><span class="line">        self.conv_expand = nn.Conv2d(squeeze_c, expand_c, <span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        scale = x.mean((<span class="number">2</span>, <span class="number">3</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">        scale = self.conv_reduce(scale)</span><br><span class="line">        scale = self.act1(scale)</span><br><span class="line">        scale = self.conv_expand(scale)</span><br><span class="line">        scale = self.act2(scale)</span><br><span class="line">        <span class="keyword">return</span> scale * x</span><br></pre></td></tr></table></figure>
<h2 id="MBConv类">MBConv类</h2>
<p><img src="/2023/05/30/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNetV2%E7%BD%91%E7%BB%9C/MBConv%E6%A8%A1%E5%9D%97.png" alt="MBConv模块"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MBConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 expand_ratio: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 se_ratio: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 drop_rate: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Callable</span>[..., nn.Module]</span>):</span><br><span class="line">        <span class="built_in">super</span>(MBConv, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stride <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;illegal stride value.&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.has_shortcut = (stride == <span class="number">1</span> <span class="keyword">and</span> input_c == out_c)</span><br><span class="line"></span><br><span class="line">        activation_layer = nn.SiLU  <span class="comment"># alias Swish</span></span><br><span class="line">        expanded_c = input_c * expand_ratio</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在EfficientNetV2中，MBConv中不存在expansion=1的情况所以conv_pw肯定存在</span></span><br><span class="line">        <span class="keyword">assert</span> expand_ratio != <span class="number">1</span></span><br><span class="line">        <span class="comment"># Point-wise expansion</span></span><br><span class="line">        self.expand_conv = ConvBNAct(input_c,</span><br><span class="line">                                     expanded_c,</span><br><span class="line">                                     kernel_size=<span class="number">1</span>,</span><br><span class="line">                                     norm_layer=norm_layer,</span><br><span class="line">                                     activation_layer=activation_layer)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Depth-wise convolution</span></span><br><span class="line">        self.dwconv = ConvBNAct(expanded_c,</span><br><span class="line">                                expanded_c,</span><br><span class="line">                                kernel_size=kernel_size,</span><br><span class="line">                                stride=stride,</span><br><span class="line">                                groups=expanded_c,</span><br><span class="line">                                norm_layer=norm_layer,</span><br><span class="line">                                activation_layer=activation_layer)</span><br><span class="line"></span><br><span class="line">        self.se = SqueezeExcite(input_c, expanded_c, se_ratio) <span class="keyword">if</span> se_ratio &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Point-wise linear projection</span></span><br><span class="line">        self.project_conv = ConvBNAct(expanded_c,</span><br><span class="line">                                      out_planes=out_c,</span><br><span class="line">                                      kernel_size=<span class="number">1</span>,</span><br><span class="line">                                      norm_layer=norm_layer,</span><br><span class="line">                                      activation_layer=nn.Identity)  <span class="comment"># 注意这里没有激活函数，所有传入Identity</span></span><br><span class="line"></span><br><span class="line">        self.out_channels = out_c</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 只有在使用shortcut连接时才使用dropout层</span></span><br><span class="line">        self.drop_rate = drop_rate</span><br><span class="line">        <span class="keyword">if</span> self.has_shortcut <span class="keyword">and</span> drop_rate &gt; <span class="number">0</span>:</span><br><span class="line">            self.dropout = DropPath(drop_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        result = self.expand_conv(x)</span><br><span class="line">        result = self.dwconv(result)</span><br><span class="line">        result = self.se(result)</span><br><span class="line">        result = self.project_conv(result)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.has_shortcut:</span><br><span class="line">            <span class="keyword">if</span> self.drop_rate &gt; <span class="number">0</span>:</span><br><span class="line">                result = self.dropout(result)</span><br><span class="line">            result += x</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h2 id="FusedMBConv类">FusedMBConv类</h2>
<p><img src="/2023/05/30/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNetV2%E7%BD%91%E7%BB%9C/Fused-MBConv%E6%A8%A1%E5%9D%97.png" alt="Fused-MBConv模块"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FusedMBConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 input_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_c: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 expand_ratio: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 se_ratio: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 drop_rate: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">                 norm_layer: <span class="type">Callable</span>[..., nn.Module]</span>):</span><br><span class="line">        <span class="built_in">super</span>(FusedMBConv, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> stride <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">assert</span> se_ratio == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.has_shortcut = stride == <span class="number">1</span> <span class="keyword">and</span> input_c == out_c</span><br><span class="line">        self.drop_rate = drop_rate</span><br><span class="line"></span><br><span class="line">        self.has_expansion = expand_ratio != <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        activation_layer = nn.SiLU  <span class="comment"># alias Swish</span></span><br><span class="line">        expanded_c = input_c * expand_ratio</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 只有当expand ratio不等于1时才有expand conv</span></span><br><span class="line">        <span class="keyword">if</span> self.has_expansion:</span><br><span class="line">            <span class="comment"># Expansion convolution</span></span><br><span class="line">            self.expand_conv = ConvBNAct(input_c,</span><br><span class="line">                                         expanded_c,</span><br><span class="line">                                         kernel_size=kernel_size,</span><br><span class="line">                                         stride=stride,</span><br><span class="line">                                         norm_layer=norm_layer,</span><br><span class="line">                                         activation_layer=activation_layer)</span><br><span class="line"></span><br><span class="line">            self.project_conv = ConvBNAct(expanded_c,</span><br><span class="line">                                          out_c,</span><br><span class="line">                                          kernel_size=<span class="number">1</span>,</span><br><span class="line">                                          norm_layer=norm_layer,</span><br><span class="line">                                          activation_layer=nn.Identity)  <span class="comment"># 注意没有激活函数</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 当只有project_conv时的情况</span></span><br><span class="line">            self.project_conv = ConvBNAct(input_c,</span><br><span class="line">                                          out_c,</span><br><span class="line">                                          kernel_size=kernel_size,</span><br><span class="line">                                          stride=stride,</span><br><span class="line">                                          norm_layer=norm_layer,</span><br><span class="line">                                          activation_layer=activation_layer)  <span class="comment"># 注意有激活函数</span></span><br><span class="line"></span><br><span class="line">        self.out_channels = out_c</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 只有在使用shortcut连接时才使用dropout层</span></span><br><span class="line">        self.drop_rate = drop_rate</span><br><span class="line">        <span class="keyword">if</span> self.has_shortcut <span class="keyword">and</span> drop_rate &gt; <span class="number">0</span>:</span><br><span class="line">            self.dropout = DropPath(drop_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">if</span> self.has_expansion:</span><br><span class="line">            result = self.expand_conv(x)</span><br><span class="line">            result = self.project_conv(result)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result = self.project_conv(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.has_shortcut:</span><br><span class="line">            <span class="keyword">if</span> self.drop_rate &gt; <span class="number">0</span>:</span><br><span class="line">                result = self.dropout(result)</span><br><span class="line"></span><br><span class="line">            result += x</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h2 id="EfficientNetV2类">EfficientNetV2类</h2>
<p><img src="/2023/05/30/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNetV2%E7%BD%91%E7%BB%9C/EfficientNetV2-S%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6.png" alt="EfficientNetV2-S模型框架"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EfficientNetV2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 model_cnf: <span class="built_in">list</span>,</span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span> = <span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 num_features: <span class="built_in">int</span> = <span class="number">1280</span>,</span></span><br><span class="line"><span class="params">                 dropout_rate: <span class="built_in">float</span> = <span class="number">0.2</span>,</span></span><br><span class="line"><span class="params">                 drop_connect_rate: <span class="built_in">float</span> = <span class="number">0.2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(EfficientNetV2, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> cnf <span class="keyword">in</span> model_cnf:</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(cnf) == <span class="number">8</span></span><br><span class="line">        <span class="comment"># eps=1e-3为论文设置，不能更改</span></span><br><span class="line">        norm_layer = partial(nn.BatchNorm2d, eps=<span class="number">1e-3</span>, momentum=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        stem_filter_num = model_cnf[<span class="number">0</span>][<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        self.stem = ConvBNAct(<span class="number">3</span>,</span><br><span class="line">                              stem_filter_num,</span><br><span class="line">                              kernel_size=<span class="number">3</span>,</span><br><span class="line">                              stride=<span class="number">2</span>,</span><br><span class="line">                              norm_layer=norm_layer)  <span class="comment"># 激活函数默认是SiLU</span></span><br><span class="line"></span><br><span class="line">        total_blocks = <span class="built_in">sum</span>([i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> model_cnf])</span><br><span class="line">        block_id = <span class="number">0</span></span><br><span class="line">        blocks = []</span><br><span class="line">        <span class="keyword">for</span> cnf <span class="keyword">in</span> model_cnf:</span><br><span class="line">            repeats = cnf[<span class="number">0</span>]</span><br><span class="line">            op = FusedMBConv <span class="keyword">if</span> cnf[-<span class="number">2</span>] == <span class="number">0</span> <span class="keyword">else</span> MBConv</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(repeats):</span><br><span class="line">                blocks.append(op(kernel_size=cnf[<span class="number">1</span>],</span><br><span class="line">                                 input_c=cnf[<span class="number">4</span>] <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> cnf[<span class="number">5</span>],</span><br><span class="line">                                 out_c=cnf[<span class="number">5</span>],</span><br><span class="line">                                 expand_ratio=cnf[<span class="number">3</span>],</span><br><span class="line">                                 stride=cnf[<span class="number">2</span>] <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span>,</span><br><span class="line">                                 se_ratio=cnf[-<span class="number">1</span>],</span><br><span class="line">                                 drop_rate=drop_connect_rate * block_id / total_blocks,</span><br><span class="line">                                 norm_layer=norm_layer))</span><br><span class="line">                block_id += <span class="number">1</span></span><br><span class="line">        self.blocks = nn.Sequential(*blocks)</span><br><span class="line"></span><br><span class="line">        head_input_c = model_cnf[-<span class="number">1</span>][-<span class="number">3</span>]</span><br><span class="line">        head = OrderedDict()</span><br><span class="line"></span><br><span class="line">        head.update(&#123;<span class="string">&quot;project_conv&quot;</span>: ConvBNAct(head_input_c,</span><br><span class="line">                                               num_features,</span><br><span class="line">                                               kernel_size=<span class="number">1</span>,</span><br><span class="line">                                               norm_layer=norm_layer)&#125;)  <span class="comment"># 激活函数默认是SiLU</span></span><br><span class="line"></span><br><span class="line">        head.update(&#123;<span class="string">&quot;avgpool&quot;</span>: nn.AdaptiveAvgPool2d(<span class="number">1</span>)&#125;)</span><br><span class="line">        head.update(&#123;<span class="string">&quot;flatten&quot;</span>: nn.Flatten()&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> dropout_rate &gt; <span class="number">0</span>:</span><br><span class="line">            head.update(&#123;<span class="string">&quot;dropout&quot;</span>: nn.Dropout(p=dropout_rate, inplace=<span class="literal">True</span>)&#125;)</span><br><span class="line">        head.update(&#123;<span class="string">&quot;classifier&quot;</span>: nn.Linear(num_features, num_classes)&#125;)</span><br><span class="line"></span><br><span class="line">        self.head = nn.Sequential(head)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># initial weights</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&quot;fan_out&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.zeros_(m.bias)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                nn.init.ones_(m.weight)</span><br><span class="line">                nn.init.zeros_(m.bias)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.zeros_(m.bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># Stage0对应的3x3卷积</span></span><br><span class="line">        x = self.stem(x)</span><br><span class="line">        x = self.blocks(x)</span><br><span class="line">        x = self.head(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="实例化efficientnetv2类">实例化efficientnetv2类</h2>
<ul>
<li><code>r</code>代表当前Stage中Operator重复堆叠的次数；</li>
<li><code>k</code>代表kernel_size；</li>
<li><code>s</code>代表步距stride；</li>
<li><code>e</code>代表expansion ratio；</li>
<li><code>i</code>代表input channels；</li>
<li><code>o</code>代表output channels；</li>
<li><code>c</code>代表conv_type，1代表Fused-MBConv，0代表MBConv（默认为MBConv）；</li>
<li><code>se</code>代表使用SE模块，以及se_ratio</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#################### EfficientNet V2 configs ####################</span></span><br><span class="line">v2_s_block = [  <span class="comment"># about base * (width1.4, depth1.8)</span></span><br><span class="line">    <span class="string">&#x27;r2_k3_s1_e1_i24_o24_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r4_k3_s2_e4_i24_o48_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r4_k3_s2_e4_i48_o64_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r6_k3_s2_e4_i64_o128_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r9_k3_s1_e6_i128_o160_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r15_k3_s2_e6_i160_o256_se0.25&#x27;</span>,</span><br><span class="line">]</span><br><span class="line">v2_m_block = [  <span class="comment"># about base * (width1.6, depth2.2)</span></span><br><span class="line">    <span class="string">&#x27;r3_k3_s1_e1_i24_o24_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s2_e4_i24_o48_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s2_e4_i48_o80_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i80_o160_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r14_k3_s1_e6_i160_o176_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r18_k3_s2_e6_i176_o304_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s1_e6_i304_o512_se0.25&#x27;</span>,</span><br><span class="line">]</span><br><span class="line">v2_l_block = [  <span class="comment"># about base * (width2.0, depth3.1)</span></span><br><span class="line">    <span class="string">&#x27;r4_k3_s1_e1_i32_o32_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i32_o64_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i64_o96_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r10_k3_s2_e4_i96_o192_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r19_k3_s1_e6_i192_o224_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r25_k3_s2_e6_i224_o384_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s1_e6_i384_o640_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>按照配置文件实例化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnetv2_s</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    EfficientNetV2</span></span><br><span class="line"><span class="string">    https://arxiv.org/abs/2104.00298</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># train_size: 300, eval_size: 384</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># repeat, kernel, stride, expansion, in_c, out_c, operator, se_ratio</span></span><br><span class="line">    model_config = [[<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">24</span>, <span class="number">24</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">24</span>, <span class="number">48</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">48</span>, <span class="number">64</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">6</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">1</span>, <span class="number">0.25</span>],</span><br><span class="line">                    [<span class="number">9</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">128</span>, <span class="number">160</span>, <span class="number">1</span>, <span class="number">0.25</span>],</span><br><span class="line">                    [<span class="number">15</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">160</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">0.25</span>]]</span><br><span class="line"></span><br><span class="line">    model = EfficientNetV2(model_cnf=model_config,</span><br><span class="line">                           num_classes=num_classes,</span><br><span class="line">                           dropout_rate=<span class="number">0.2</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnetv2_m</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    EfficientNetV2</span></span><br><span class="line"><span class="string">    https://arxiv.org/abs/2104.00298</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># train_size: 384, eval_size: 480</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># repeat, kernel, stride, expansion, in_c, out_c, operator, se_ratio</span></span><br><span class="line">    model_config = [[<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">24</span>, <span class="number">24</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">5</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">24</span>, <span class="number">48</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">5</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">48</span>, <span class="number">80</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">7</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">80</span>, <span class="number">160</span>, <span class="number">1</span>, <span class="number">0.25</span>],</span><br><span class="line">                    [<span class="number">14</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">160</span>, <span class="number">176</span>, <span class="number">1</span>, <span class="number">0.25</span>],</span><br><span class="line">                    [<span class="number">18</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">176</span>, <span class="number">304</span>, <span class="number">1</span>, <span class="number">0.25</span>],</span><br><span class="line">                    [<span class="number">5</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">304</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">0.25</span>]]</span><br><span class="line"></span><br><span class="line">    model = EfficientNetV2(model_cnf=model_config,</span><br><span class="line">                           num_classes=num_classes,</span><br><span class="line">                           dropout_rate=<span class="number">0.3</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficientnetv2_l</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    EfficientNetV2</span></span><br><span class="line"><span class="string">    https://arxiv.org/abs/2104.00298</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># train_size: 384, eval_size: 480</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># repeat, kernel, stride, expansion, in_c, out_c, operator, se_ratio</span></span><br><span class="line">    model_config = [[<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">7</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">7</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">64</span>, <span class="number">96</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [<span class="number">10</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">96</span>, <span class="number">192</span>, <span class="number">1</span>, <span class="number">0.25</span>],</span><br><span class="line">                    [<span class="number">19</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">192</span>, <span class="number">224</span>, <span class="number">1</span>, <span class="number">0.25</span>],</span><br><span class="line">                    [<span class="number">25</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">224</span>, <span class="number">384</span>, <span class="number">1</span>, <span class="number">0.25</span>],</span><br><span class="line">                    [<span class="number">7</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">384</span>, <span class="number">640</span>, <span class="number">1</span>, <span class="number">0.25</span>]]</span><br><span class="line"></span><br><span class="line">    model = EfficientNetV2(model_cnf=model_config,</span><br><span class="line">                           num_classes=num_classes,</span><br><span class="line">                           dropout_rate=<span class="number">0.4</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h1><a href="http://train.py">train.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.optim.lr_scheduler <span class="keyword">as</span> lr_scheduler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> efficientnetv2_s <span class="keyword">as</span> create_model</span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(args)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Start Tensorboard with &quot;tensorboard --logdir=runs&quot;, view at http://localhost:6006/&#x27;</span>)</span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    img_size = &#123;<span class="string">&quot;s&quot;</span>: [<span class="number">300</span>, <span class="number">384</span>],  <span class="comment"># train_size, val_size</span></span><br><span class="line">                <span class="string">&quot;m&quot;</span>: [<span class="number">384</span>, <span class="number">480</span>],</span><br><span class="line">                <span class="string">&quot;l&quot;</span>: [<span class="number">384</span>, <span class="number">480</span>]&#125;</span><br><span class="line">    num_model = <span class="string">&quot;s&quot;</span></span><br><span class="line"></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(img_size[num_model][<span class="number">0</span>]),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(img_size[num_model][<span class="number">1</span>]),</span><br><span class="line">                                   transforms.CenterCrop(img_size[num_model][<span class="number">1</span>]),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果存在预训练权重则载入</span></span><br><span class="line">    model = create_model(num_classes=args.num_classes).to(device)</span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(args.weights):</span><br><span class="line">            weights_dict = torch.load(args.weights, map_location=device)</span><br><span class="line">            load_weights_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> weights_dict.items()</span><br><span class="line">                                 <span class="keyword">if</span> model.state_dict()[k].numel() == v.numel()&#125;</span><br><span class="line">            <span class="built_in">print</span>(model.load_state_dict(load_weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">&quot;not found weights file: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(args.weights))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是否冻结权重</span></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除head外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;head&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;training &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">    pg = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.SGD(pg, lr=args.lr, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1E-4</span>)</span><br><span class="line">    <span class="comment"># Scheduler https://arxiv.org/pdf/1812.01187.pdf</span></span><br><span class="line">    lf = <span class="keyword">lambda</span> x: ((<span class="number">1</span> + math.cos(x * math.pi / args.epochs)) / <span class="number">2</span>) * (<span class="number">1</span> - args.lrf) + args.lrf  <span class="comment"># cosine</span></span><br><span class="line">    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        train_loss, train_acc = train_one_epoch(model=model,</span><br><span class="line">                                                optimizer=optimizer,</span><br><span class="line">                                                data_loader=train_loader,</span><br><span class="line">                                                device=device,</span><br><span class="line">                                                epoch=epoch)</span><br><span class="line"></span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        val_loss, val_acc = evaluate(model=model,</span><br><span class="line">                                     data_loader=val_loader,</span><br><span class="line">                                     device=device,</span><br><span class="line">                                     epoch=epoch)</span><br><span class="line"></span><br><span class="line">        tags = [<span class="string">&quot;train_loss&quot;</span>, <span class="string">&quot;train_acc&quot;</span>, <span class="string">&quot;val_loss&quot;</span>, <span class="string">&quot;val_acc&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], train_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], train_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], val_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">3</span>], val_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">4</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;./weights/model-&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">30</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.01</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lrf&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># download model weights</span></span><br><span class="line">    <span class="comment"># 链接: https://pan.baidu.com/s/1uZX36rvrfEss-JGj4yfzbQ  密码: 5gu1</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./pre_efficientnetv2-s.pth&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<p><strong>训练结果</strong></p>
<p><img src="/2023/05/30/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNetV2%E7%BD%91%E7%BB%9C/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h1><a href="http://predict.py">predict.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> efficientnetv2_s <span class="keyword">as</span> create_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    img_size = &#123;<span class="string">&quot;s&quot;</span>: [<span class="number">300</span>, <span class="number">384</span>],  <span class="comment"># train_size, val_size</span></span><br><span class="line">                <span class="string">&quot;m&quot;</span>: [<span class="number">384</span>, <span class="number">480</span>],</span><br><span class="line">                <span class="string">&quot;l&quot;</span>: [<span class="number">384</span>, <span class="number">480</span>]&#125;</span><br><span class="line">    num_model = <span class="string">&quot;s&quot;</span></span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(img_size[num_model][<span class="number">1</span>]),</span><br><span class="line">         transforms.CenterCrop(img_size[num_model][<span class="number">1</span>]),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;../tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = create_model(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/model-29.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p><strong>预测结果</strong></p>
<p><img src="/2023/05/30/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNetV2%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
<h1><a href="http://utils.py">utils.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_split_data</span>(<span class="params">root: <span class="built_in">str</span>, val_rate: <span class="built_in">float</span> = <span class="number">0.2</span></span>):</span><br><span class="line">    random.seed(<span class="number">0</span>)  <span class="comment"># 保证随机结果可复现</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(root), <span class="string">&quot;dataset root: &#123;&#125; does not exist.&quot;</span>.<span class="built_in">format</span>(root)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历文件夹，一个文件夹对应一个类别</span></span><br><span class="line">    flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(root) <span class="keyword">if</span> os.path.isdir(os.path.join(root, cla))]</span><br><span class="line">    <span class="comment"># 排序，保证各平台顺序一致</span></span><br><span class="line">    flower_class.sort()</span><br><span class="line">    <span class="comment"># 生成类别名称以及对应的数字索引</span></span><br><span class="line">    class_indices = <span class="built_in">dict</span>((k, v) <span class="keyword">for</span> v, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(flower_class))</span><br><span class="line">    json_str = json.dumps(<span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> class_indices.items()), indent=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">    train_images_path = []  <span class="comment"># 存储训练集的所有图片路径</span></span><br><span class="line">    train_images_label = []  <span class="comment"># 存储训练集图片对应索引信息</span></span><br><span class="line">    val_images_path = []  <span class="comment"># 存储验证集的所有图片路径</span></span><br><span class="line">    val_images_label = []  <span class="comment"># 存储验证集图片对应索引信息</span></span><br><span class="line">    every_class_num = []  <span class="comment"># 存储每个类别的样本总数</span></span><br><span class="line">    supported = [<span class="string">&quot;.jpg&quot;</span>, <span class="string">&quot;.JPG&quot;</span>, <span class="string">&quot;.png&quot;</span>, <span class="string">&quot;.PNG&quot;</span>]  <span class="comment"># 支持的文件后缀类型</span></span><br><span class="line">    <span class="comment"># 遍历每个文件夹下的文件</span></span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        cla_path = os.path.join(root, cla)</span><br><span class="line">        <span class="comment"># 遍历获取supported支持的所有文件路径</span></span><br><span class="line">        images = [os.path.join(root, cla, i) <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(cla_path)</span><br><span class="line">                  <span class="keyword">if</span> os.path.splitext(i)[-<span class="number">1</span>] <span class="keyword">in</span> supported]</span><br><span class="line">        <span class="comment"># 排序，保证各平台顺序一致</span></span><br><span class="line">        images.sort()</span><br><span class="line">        <span class="comment"># 获取该类别对应的索引</span></span><br><span class="line">        image_class = class_indices[cla]</span><br><span class="line">        <span class="comment"># 记录该类别的样本数量</span></span><br><span class="line">        every_class_num.append(<span class="built_in">len</span>(images))</span><br><span class="line">        <span class="comment"># 按比例随机采样验证样本</span></span><br><span class="line">        val_path = random.sample(images, k=<span class="built_in">int</span>(<span class="built_in">len</span>(images) * val_rate))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> img_path <span class="keyword">in</span> images:</span><br><span class="line">            <span class="keyword">if</span> img_path <span class="keyword">in</span> val_path:  <span class="comment"># 如果该路径在采样的验证集样本中则存入验证集</span></span><br><span class="line">                val_images_path.append(img_path)</span><br><span class="line">                val_images_label.append(image_class)</span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># 否则存入训练集</span></span><br><span class="line">                train_images_path.append(img_path)</span><br><span class="line">                train_images_label.append(image_class)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images were found in the dataset.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">sum</span>(every_class_num)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images for training.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(train_images_path)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(val_images_path)))</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(train_images_path) &gt; <span class="number">0</span>, <span class="string">&quot;number of training images must greater than 0.&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(val_images_path) &gt; <span class="number">0</span>, <span class="string">&quot;number of validation images must greater than 0.&quot;</span></span><br><span class="line"></span><br><span class="line">    plot_image = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> plot_image:</span><br><span class="line">        <span class="comment"># 绘制每种类别个数柱状图</span></span><br><span class="line">        plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(flower_class)), every_class_num, align=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">        <span class="comment"># 将横坐标0,1,2,3,4替换为相应的类别名称</span></span><br><span class="line">        plt.xticks(<span class="built_in">range</span>(<span class="built_in">len</span>(flower_class)), flower_class)</span><br><span class="line">        <span class="comment"># 在柱状图上添加数值标签</span></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(every_class_num):</span><br><span class="line">            plt.text(x=i, y=v + <span class="number">5</span>, s=<span class="built_in">str</span>(v), ha=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置x坐标</span></span><br><span class="line">        plt.xlabel(<span class="string">&#x27;image class&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置y坐标</span></span><br><span class="line">        plt.ylabel(<span class="string">&#x27;number of images&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置柱状图的标题</span></span><br><span class="line">        plt.title(<span class="string">&#x27;flower class distribution&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_images_path, train_images_label, val_images_path, val_images_label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_data_loader_image</span>(<span class="params">data_loader</span>):</span><br><span class="line">    batch_size = data_loader.batch_size</span><br><span class="line">    plot_num = <span class="built_in">min</span>(batch_size, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), json_path + <span class="string">&quot; does not exist.&quot;</span></span><br><span class="line">    json_file = <span class="built_in">open</span>(json_path, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    class_indices = json.load(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(plot_num):</span><br><span class="line">            <span class="comment"># [C, H, W] -&gt; [H, W, C]</span></span><br><span class="line">            img = images[i].numpy().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 反Normalize操作</span></span><br><span class="line">            img = (img * [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>] + [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]) * <span class="number">255</span></span><br><span class="line">            label = labels[i].item()</span><br><span class="line">            plt.subplot(<span class="number">1</span>, plot_num, i+<span class="number">1</span>)</span><br><span class="line">            plt.xlabel(class_indices[<span class="built_in">str</span>(label)])</span><br><span class="line">            plt.xticks([])  <span class="comment"># 去掉x轴的刻度</span></span><br><span class="line">            plt.yticks([])  <span class="comment"># 去掉y轴的刻度</span></span><br><span class="line">            plt.imshow(img.astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_pickle</span>(<span class="params">list_info: <span class="built_in">list</span>, file_name: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(list_info, f)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_pickle</span>(<span class="params">file_name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">list</span>:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        info_list = pickle.load(f)</span><br><span class="line">        <span class="keyword">return</span> info_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">model, optimizer, data_loader, device, epoch</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    loss_function = torch.nn.CrossEntropyLoss()</span><br><span class="line">    accu_loss = torch.zeros(<span class="number">1</span>).to(device)  <span class="comment"># 累计损失</span></span><br><span class="line">    accu_num = torch.zeros(<span class="number">1</span>).to(device)   <span class="comment"># 累计预测正确的样本数</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    sample_num = <span class="number">0</span></span><br><span class="line">    data_loader = tqdm(data_loader, file=sys.stdout)</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        images, labels = data</span><br><span class="line">        sample_num += images.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        pred = model(images.to(device))</span><br><span class="line">        pred_classes = torch.<span class="built_in">max</span>(pred, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        accu_num += torch.eq(pred_classes, labels.to(device)).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        loss = loss_function(pred, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        accu_loss += loss.detach()</span><br><span class="line"></span><br><span class="line">        data_loader.desc = <span class="string">&quot;[train epoch &#123;&#125;] loss: &#123;:.3f&#125;, acc: &#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,</span><br><span class="line">                                                                               accu_loss.item() / (step + <span class="number">1</span>),</span><br><span class="line">                                                                               accu_num.item() / sample_num)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> torch.isfinite(loss):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;WARNING: non-finite loss, ending training &#x27;</span>, loss)</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> accu_loss.item() / (step + <span class="number">1</span>), accu_num.item() / sample_num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, data_loader, device, epoch</span>):</span><br><span class="line">    loss_function = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    accu_num = torch.zeros(<span class="number">1</span>).to(device)   <span class="comment"># 累计预测正确的样本数</span></span><br><span class="line">    accu_loss = torch.zeros(<span class="number">1</span>).to(device)  <span class="comment"># 累计损失</span></span><br><span class="line"></span><br><span class="line">    sample_num = <span class="number">0</span></span><br><span class="line">    data_loader = tqdm(data_loader, file=sys.stdout)</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        images, labels = data</span><br><span class="line">        sample_num += images.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        pred = model(images.to(device))</span><br><span class="line">        pred_classes = torch.<span class="built_in">max</span>(pred, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        accu_num += torch.eq(pred_classes, labels.to(device)).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        loss = loss_function(pred, labels.to(device))</span><br><span class="line">        accu_loss += loss</span><br><span class="line"></span><br><span class="line">        data_loader.desc = <span class="string">&quot;[valid epoch &#123;&#125;] loss: &#123;:.3f&#125;, acc: &#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,</span><br><span class="line">                                                                               accu_loss.item() / (step + <span class="number">1</span>),</span><br><span class="line">                                                                               accu_num.item() / sample_num)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> accu_loss.item() / (step + <span class="number">1</span>), accu_num.item() / sample_num</span><br></pre></td></tr></table></figure>
<h1>my_dataset.py</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义数据集&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, images_path: <span class="built_in">list</span>, images_class: <span class="built_in">list</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.images_path = images_path</span><br><span class="line">        self.images_class = images_class</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        img = Image.<span class="built_in">open</span>(self.images_path[item])</span><br><span class="line">        <span class="comment"># RGB为彩色图片，L为灰度图片</span></span><br><span class="line">        <span class="keyword">if</span> img.mode != <span class="string">&#x27;RGB&#x27;</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;image: &#123;&#125; isn&#x27;t RGB mode.&quot;</span>.<span class="built_in">format</span>(self.images_path[item]))</span><br><span class="line">        label = self.images_class[item]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):</span><br><span class="line">        <span class="comment"># 官方实现的default_collate可以参考</span></span><br><span class="line">        <span class="comment"># https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py</span></span><br><span class="line">        images, labels = <span class="built_in">tuple</span>(<span class="built_in">zip</span>(*batch))</span><br><span class="line"></span><br><span class="line">        images = torch.stack(images, dim=<span class="number">0</span>)</span><br><span class="line">        labels = torch.as_tensor(labels)</span><br><span class="line">        <span class="keyword">return</span> images, labels</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>EfficientNetV2</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（二十一）Vision Transformer(vit)网络详解</title>
    <url>/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1>前言</h1>
<p>原论文：<a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></p>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3.png" alt="Transformer vit模型架构"></p>
<p>Transformer最初提出是针对NLP领域的，并且在NLP领域大获成功。这篇论文也是受到其启发，尝试将Transformer应用到CV领域。通过这篇文章的实验，给出的最佳模型在ImageNet1K上能够达到88.55%的准确率（先在Google自家的JFT数据集上进行了预训练，之后再到ImageNet1K上进行迁移学习），说明Transformer在CV领域确实是有效的，而且效果还挺惊人。</p>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Transformer-vit%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C.png" alt="Transformer-vit模型效果"></p>
<h1>模型详解</h1>
<p>在论文中作者主要拿ResNet、ViT（纯Transformer模型）以及Hybrid（传统CNN和Transformer混合模型）三个模型进行比较。本节课主要讲解ViT，也会简单了解Hybrid模型</p>
<h2 id="Vision-Transformer模型">Vision Transformer模型</h2>
<p>模型由三个模块组成</p>
<ul>
<li>Linear Projection of Flattened Patches(Embedding层)</li>
<li>Transformer Encoder(图右侧有给出更加详细的结构)</li>
<li>MLP Head（最终用于分类的层结构）</li>
</ul>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Vision-Transformer%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84.png" alt="Vision Transformer模型架构"></p>
<ul>
<li>如上图所示，首先输入一张图片，之后将图片分成一个个Paches，例如性能表中表头的<strong>ViT-L16</strong>，指的是每一个Patches是16x16大小的。</li>
<li>之后将每一个Patches输入到Embedding层，也就是Linear Projection of Flattened Patches。</li>
<li>通过Embedding层之后会得到一个个向量，通常称为token。</li>
<li>紧接着在一系列token的最前面加上新的token，专门用于分类的[class]token（这里增加一个[class]token是参考RERT网络）。那么这里的class所对应的token的维度和之前得到的token是一样的，都是一个向量，且向量长度相同。</li>
<li>之后还需要加上位置的信息，如上图左所示，Patch+Position Embedding（对应表中0，1，2…9），因此此刻的一系列token已经加上[class]token以及叠加上位置信息的token。</li>
<li>将一系列token输入到<strong>Transformer Encoder（对应上图右）</strong>，就是将Encoder Block重复堆叠L次（上图右中信息[灰色框框]重复L次）</li>
<li>之后再将[class]token对应的输出（在Transformer Muti-Head Attention模块中，输入几个变量，那么就会输出几个输出的变量，都是一一对应的，<strong>但此刻仅用于分类，因此只提取针对[class]token所对应的输出</strong>）通过MLP Head得到最终分类结果。</li>
</ul>
<h3 id="Embedding层">Embedding层</h3>
<p>对于标准的Transformer模块，要求输入的是token（向量）序列，即二维矩阵[num_token, token_dim]，如下图，token0-9对应的都是向量，以ViT-B/16为例，每个token向量长度为768（对应token_dim）。</p>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Embedding%E5%B1%82%E7%BB%93%E6%9E%84.png" alt="Embedding层结构"></p>
<p>对于图像数据而言，其数据格式为[H, W, C]是三维矩阵明显不是Transformer想要的。所以需要先通过一个Embedding层来对数据做个变换。如下图所示，首先将一张图片按给定大小分成一堆Patches。以ViT-B/16为例，将输入图片(224x224)按照16x16大小的Patch进行划分，划分后会得到$( 224 / 16 )^2=196$个Patches。接着通过线性映射将每个Patch映射到一维向量中，以ViT-B/16为例，每个Patche数据shape为[16, 16, 3]通过映射得到一个长度为768的向量（后面都直接称为token）。<code>[16, 16, 3] -&gt; [768]</code></p>
<p><strong>在代码实现中，直接通过一个卷积层来实现</strong>。 以ViT-B/16为例，直接使用一个卷积核大小为16x16，步距为16，卷积核个数为768的卷积来实现。通过卷积[224, 224, 3] -&gt; [14, 14, 768]，然后把H以及W两个维度展平即可[14, 14, 768] -&gt; [196, 768]，此时正好变成了一个二维矩阵，正是Transformer想要的。</p>
<blockquote>
<p>[224,224,3]-&gt;[14,14, 768] -&gt;[196,768]</p>
</blockquote>
<p><strong>在输入Transformer Encoder之前注意需要加上[class]token以及Position Embedding</strong>。 在原论文中，作者说参考BERT，在刚刚得到的一堆tokens中插入一个专门用于分类的[class]token，这个[class]token是一个可训练的参数，数据格式和其他token一样都是一个向量，以ViT-B/16为例，就是一个长度为768的向量，与之前从图片中生成的tokens拼接在一起，Cat([1, 768], [196, 768]) -&gt; [197, 768]。然后关于Position Embedding就是之前Transformer中讲到的Positional Encoding，这里的Position Embedding采用的是一个可训练的参数（1D Pos. Emb.），是直接叠加在tokens上的（add），所以shape要一样。以ViT-B/16为例，刚刚拼接[class]token后shape是[197, 768]，那么这里的Position Embedding的shape也是[197, 768]。</p>
<blockquote>
<p>拼接[class]token: Cat([1, 768]，[196, 768]) -&gt;[197, 768]</p>
<p>叠加Position Embedding: [197, 768]-&gt;[197, 768]</p>
</blockquote>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Embedding%E5%B1%82%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3.png" alt="Embedding层结构详解"></p>
<p>对于<strong>是否使用</strong>Position Embedding作者也有做一系列对比试验，<strong>在源码中默认使用的是<code>1D Pos. Emb.</code></strong>，对比不使用Position Embedding准确率提升了大概3个点，和<code>2D Pos. Emb.</code>比起来没太大差别。</p>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Position-Embedding%E5%AF%B9%E6%AF%94%E8%AF%95%E9%AA%8C.png" alt="Position Embedding对比试验"></p>
<p>前文说到，会为每一个Patches增加一个位置编码，其实就是一个向量，我们可以针对每一个位置上的位置编码和其他位置上的位置编码求训练相似度，即能得到下图。如下图所示（关于训练得到的位置编码，<strong>在每个位置上和其他位置的余弦相似度</strong>），这里的Patches大小是32x32的，224/32 = 7，所以大小为7x7。</p>
<p>理解：会在每一个token上叠加一个位置编码，那么针对每一个patches的位置编码其实就是一个向量，那么可以针对每一个位置上的位置编码和其他位置上的位置编码去求一个余弦相似度，即能得到如下图。（<strong>就是每个小小格子和其他小小格子计算相似度，所有的大格子其实都是同一张图</strong>）</p>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Patches%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81.png" alt="Patches位置编码"></p>
<h3 id="Transformer-Encoder层">Transformer Encoder层</h3>
<p>Transformer Encoder其实就是重复堆叠Encoder Block L次，下图是Encoder Block，主要由以下几部分组成：</p>
<ul>
<li>Layer Norm，这种Normalization方法主要是针对NLP领域提出的，这里是对每个token进行Norm处理</li>
<li>Multi-Head Attention</li>
<li>Dropout/DropPath，在原论文的代码中是直接使用的Dropout层，在但rwightman（大神）实现的代码中使用的是DropPath（stochastic depth），可能后者会更好一点。</li>
<li>MLP Block，如图右侧所示，就是全连接+GELU激活函数+Dropout组成，需要注意的是<strong>第一个全连接层会把输入节点个数翻4倍[197, 768] -&gt; [197, 3072]，第二个全连接层会还原回原节点个数[197, 3072] -&gt; [197, 768]</strong></li>
</ul>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Transformer-Encoder%E5%B1%82.png" alt="Transformer Encoder层"></p>
<h3 id="MLP-Head层">MLP Head层</h3>
<p>注意，在Transformer Encoder前有个Dropout层，后有一个LayerNorm（细节都在源码中）</p>
<p>训练ImageNet21K或者是更大数据集时是由Linear+tanh激活函数+Linear，但是迁移到ImageNet1K上或者自己的数据上时，只有一个Linear。因此<strong>可以将MLP Head简单理解为一个全连接层</strong>。如果需要最终输出一个类别的话，需要接上softmax函数。</p>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/MLP-Head%E5%B1%82.png" alt="MLP Head层"></p>
<h3 id="Vision-Transformer网络结构">Vision Transformer网络结构</h3>
<p>以ViT-B/16为例，讲解网络过程。假设输入图片为一张RGB彩色图片（224x224x3）</p>
<ul>
<li>首先经过<strong>Patch Embedding</strong>层（Conv2d+Flatten）</li>
</ul>
<blockquote>
<p>Conv2d：卷积层的卷积核大小为16x16，stride = 16，卷积核个数为768。通过卷积层之后，输入特征矩阵的shape由<code>[224，224，3]-&gt;[14，14，768]</code>；</p>
<p>Flatten：通过展平处理，将<code>[14，14，768]-&gt;[196，768]</code>。</p>
</blockquote>
<ul>
<li>紧接着进行<strong>Concat</strong>处理，[class]token的shape是[1，768]（可训练的参数），与[196，768]进行concat拼接（<strong>拼接操作</strong>），得到[197，768]。再加上（<strong>相加操作</strong>）<strong>Position Embedding</strong>（可训练的参数），因此shape依旧为[197，768]；</li>
<li>通过Dropout层；</li>
<li>通过<strong>Transformer Encoder</strong>，就是将Encoder Block重复L次（12次）；</li>
<li>通过Layer Norm得到的输出shape是[197，768]；</li>
<li>再提取[class]token所对应的输出，直接对[197，768]数据进行切片，只需要提取出[class]token所对应的输出即可，切片之后得到输出[1，768];</li>
<li>之后通过<strong>MLP Head</strong>得到最终的输出（如果ImageNet21K上进行预训练的话，Pre-Logits其实就是一个全连接层+tanh激活函数；但是在ImageNet1K上或者自己的数据上时，Pre-Logits可以不要它，即MLP Head只有一个全连接层）。</li>
</ul>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Vision-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" alt="Vision Transformer网络结构"></p>
<h2 id="Hybrid混合模型">Hybrid混合模型</h2>
<p>将传统CNN特征提取和Transformer进行结合。</p>
<p>下图是以ResNet50作为特征提取器的混合模型，但这里的Resnet与之前讲的Resnet有些不同。</p>
<ul>
<li>这里的R50的卷积层<strong>采用的StdConv2d不是传统的Conv2d</strong>；</li>
<li>将所有的<strong>BatchNorm层替换成GroupNorm层</strong>；</li>
<li>在原Resnet50网络中，stage1重复堆叠3次，stage2重复堆叠4次，stage3重复堆叠6次，stage4重复堆叠3次，但在这里的R50中，<strong>把stage4中的3个Block移至stage3中</strong>，所以stage3中共重复堆叠9次。</li>
</ul>
<p><strong>流程概述：</strong></p>
<ul>
<li>将[224，224，3]的RGB彩色图像输入进StdConv2d卷积层中，卷积核大小为7x7，stride = 2，卷积核个数为64（<code>[224，224，3]-&gt;[112，112，64]</code>）；</li>
<li>通过GroupNorm、ReLU、MaxPool，数据的shape变为<code>[56，56，64]</code>；</li>
<li>再依次通过Stage1、Stage2、Stage3，数据shape变为<code>[14，14，1024]</code>，刚好由<code>[224，224，3]-&gt;[14，14，1024]</code>下采样16倍，刚好同ViT网络中直接通过一个卷积核大小为16x16，步距为16的下采样率一样</li>
</ul>
<blockquote>
<p>注意：在原来的ResNet50网络中Stage3为重复6次，但<strong>因为把stage4中的3个Block移至stage3中</strong>，所以stage3中共重复堆叠6+3=9次。</p>
</blockquote>
<ul>
<li>之后通过Patch Embedding层，这里的Conv2d和刚刚的不一样，刚刚的是16x16，stride = 16，这里为<strong>1x1，stride = 1</strong>（目的是调节特征矩阵的channel）<code>[14，14，1024]-&gt;[14，14，768]</code>；</li>
<li>之后同前面ViT中讲的完全一样，就不在赘述。</li>
</ul>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/ResNet-50+ViT-B16-hybrid-model.png" alt="ResNet-50+ViT-B/16 hybrid model"></p>
<h1>ViT模型搭建参数</h1>
<ul>
<li><code>Layers</code>是<strong>Transformer Encoder中重复堆叠Encoder Block的次数</strong>；</li>
<li><code>Hidden Size</code>是<strong>通过Embedding层后每个token的dim</strong> (向量的长度)；</li>
<li><code>MLP size</code>是Transformer Encoder中<strong>MLP Block第一个全连接的节点个数(是Hidden Size的四倍)</strong>；</li>
<li><code>Heads</code>代表Transformer中<strong>Multi-Head Attention的heads数</strong></li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Model</th>
<th style="text-align:center">Patch Size</th>
<th style="text-align:center">Layers</th>
<th style="text-align:center">Hidden Size D</th>
<th style="text-align:center">MLP size</th>
<th style="text-align:center">Heads</th>
<th style="text-align:center">Params</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ViT-Base</td>
<td style="text-align:center">16x16</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">3072</td>
<td style="text-align:center">12</td>
<td style="text-align:center">86M</td>
</tr>
<tr>
<td style="text-align:center">ViT-Large</td>
<td style="text-align:center">16x16</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">4096</td>
<td style="text-align:center">16</td>
<td style="text-align:center">307M</td>
</tr>
<tr>
<td style="text-align:center">ViT-Huge</td>
<td style="text-align:center">14x14</td>
<td style="text-align:center">32</td>
<td style="text-align:center">1280</td>
<td style="text-align:center">5120</td>
<td style="text-align:center">16</td>
<td style="text-align:center">632M</td>
</tr>
</tbody>
</table>
<h1>论文中的网络性能对比</h1>
<p>下表是论文用来对比ViT，Resnet（和刚刚讲的一样，使用的卷积层和Norm层都进行了修改）以及Hybrid模型的效果。通过对比发现，<strong>在训练epoch较少时Hybrid优于ViT，但当epoch增大后ViT优于Hybrid</strong>。</p>
<p><img src="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E8%AE%BA%E6%96%87%E4%B8%AD%E5%90%8C%E4%BB%A5%E5%BE%80%E7%B3%BB%E5%88%97%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="论文中的网络性能对比"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>Vision Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（二十二）使用pytorch搭建Vision Transformer(vit)模型</title>
    <url>/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1>工程目录</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── vision transformer</span><br><span class="line">	├── vit_model.py（模型文件）  </span><br><span class="line">	├── my_dataset.py（数据处理文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,vision_transformer.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── vit_base_patch16_224_in21k.pth（迁移学习，提前下载好vit_base_patch16_224_in21k.pth权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h1>vit_model.py</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">original code from rwightman:</span></span><br><span class="line"><span class="string">https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">768</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 dim,   <span class="comment"># 输入token的dim</span></span></span><br><span class="line"><span class="params">                 num_heads=<span class="number">8</span>,</span></span><br><span class="line"><span class="params">                 qkv_bias=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 proj_drop_ratio=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mlp</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 dim,</span></span><br><span class="line"><span class="params">                 num_heads,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>,</span></span><br><span class="line"><span class="params">                 qkv_bias=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 drop_path_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 act_layer=nn.GELU,</span></span><br><span class="line"><span class="params">                 norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VisionTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, num_classes=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>, num_heads=<span class="number">12</span>, mlp_ratio=<span class="number">4.0</span>, qkv_bias=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>, representation_size=<span class="literal">None</span>, distilled=<span class="literal">False</span>, drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>, drop_path_ratio=<span class="number">0.</span>, embed_layer=PatchEmbed, norm_layer=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 act_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_init_vit_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch16_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch16_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch32_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch32_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_large_patch16_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_large_patch16_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_large_patch32_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_huge_patch14_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h2 id="DropPath类">DropPath类</h2>
<p>DropPath类在正向传播过程中直接调用drop_path方法，就是一个Stochastic Depth，在EfficientNet中有详细讲解，这里照搬过来。</p>
<blockquote>
<p>正向传播过程中将输入的特征矩阵经历了一个又一个block，每一个block都可以认为是一个残差结构。例如主分支通过$f$函数进行输出，shortcut直接从输入引到输出，在此过程中，会以一定的概率来对主分支进行丢弃（直接放弃整个主分支，相当于直接将上一层的输出引入到下一层的输入，相当于没有这一层）。即Stochastic Depth（随机深度，指的是网络的depth，因为会随机丢弃任意一层block）。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).</span></span><br><span class="line"><span class="string">    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,</span></span><br><span class="line"><span class="string">    the original name is misleading as &#x27;Drop Connect&#x27; is a different form of dropout in a separate paper...</span></span><br><span class="line"><span class="string">    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I&#x27;ve opted for</span></span><br><span class="line"><span class="string">    changing the layer and argument names to &#x27;drop path&#x27; rather than mix DropConnect as a layer name and use</span></span><br><span class="line"><span class="string">    &#x27;survival rate&#x27; as the argument.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> drop_prob == <span class="number">0.</span> <span class="keyword">or</span> <span class="keyword">not</span> training:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    keep_prob = <span class="number">1</span> - drop_prob</span><br><span class="line">    shape = (x.shape[<span class="number">0</span>],) + (<span class="number">1</span>,) * (x.ndim - <span class="number">1</span>)  <span class="comment"># work with diff dim tensors, not just 2D ConvNets</span></span><br><span class="line">    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)</span><br><span class="line">    random_tensor.floor_()  <span class="comment"># binarize</span></span><br><span class="line">    output = x.div(keep_prob) * random_tensor</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DropPath, self).__init__()</span><br><span class="line">        self.drop_prob = drop_prob</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> drop_path(x, self.drop_prob, self.training)</span><br></pre></td></tr></table></figure>
<h2 id="PatchEmbed类">PatchEmbed类</h2>
<p>对应Patch Embedding层（经过一个卷积核大小为16x16，stride = 16的卷积层，再进行一个Flatten展平处理，使得输入的RGB彩色图像shape从<code>[224，224，3]-&gt;[14，14，768]-&gt;[196，768]</code>）</p>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/Patch-Embedding%E5%B1%82.png" alt="Patch-Embedding层"></p>
<h3 id="初始化函数">初始化函数</h3>
<ul>
<li><code>grid_size</code>：img_size除以patch_size，即224 // 16 = 14，因此grid_size为14x14，对应卷积层输出的特征矩阵宽高；</li>
<li><code>num_patches</code>：计算patches的数目，即14x14 = 196；</li>
<li><code>proj</code>：定义卷积层；</li>
<li><code>norm</code>：norm_layer默认为None，如果有传入norm_layer，则会初始化norm_layer，如果没有传入，则nn.Identity()表示不做处理。</li>
</ul>
<h3 id="正向传播函数">正向传播函数</h3>
<p>将特征矩阵传入正向传播函数，首先对输入x进行判断，如果输入特征矩阵的宽、高与预先设定的值不一样的话，程序会报错处理。</p>
<blockquote>
<p>注意：这里所讲的ViT模型，并不与之前所讲的CNN模型那样，可以更改输入图片的大小的。<strong>在ViT模型中，输入图片大小必须是固定的（因为之后的全连接层并没有再特殊处理，所以要求图片大小固定）</strong>。</p>
</blockquote>
<p>接下来将传入的数据走到卷积层得到的Tensor是[B，C，H，W]（Batch，Channel，Height，Width），之后进行flatten展平处理（<code>flatten(2)</code>：将位置在2及以后的信息进行展平，该处意为将H和W进行展平，即<code>[B，C，H，W]-&gt;[B，C，HW]</code>），再通过transpose多个位置替换函数（<code>transpose（1，2）</code>的1和2位置交换，该处意为C和HW交换，即<code>[B，C，HW]-&gt;[B，HW，C]</code>） 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    2D Image to Patch Embedding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">768</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        img_size = (img_size, img_size)</span><br><span class="line">        patch_size = (patch_size, patch_size)</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        <span class="comment"># 14x14</span></span><br><span class="line">        self.grid_size = (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># 14x14 = 196</span></span><br><span class="line">        self.num_patches = self.grid_size[<span class="number">0</span>] * self.grid_size[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 相当于将一整张图片分成14个大小为16x16的patch</span></span><br><span class="line">        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)</span><br><span class="line">        <span class="comment"># 因为norm_layer=None，所以不做任何处理</span></span><br><span class="line">        self.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># batch，3，224，224</span></span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        <span class="keyword">assert</span> H == self.img_size[<span class="number">0</span>] <span class="keyword">and</span> W == self.img_size[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">f&quot;Input image size (<span class="subst">&#123;H&#125;</span>*<span class="subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="subst">&#123;self.img_size[<span class="number">0</span>]&#125;</span>*<span class="subst">&#123;self.img_size[<span class="number">1</span>]&#125;</span>).&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># flatten: [B, C, H, W] -&gt; [B, C, HW] == [B，768，14，14]-&gt;[B,768,196]</span></span><br><span class="line">        <span class="comment"># transpose: [B, C, HW] -&gt; [B, HW, C] == [B,768,196]-&gt;[B,196,768]</span></span><br><span class="line">        x = self.proj(x).flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="Attention类">Attention类</h2>
<p>用来实现Transformer当中的Muti-Head Transformer模块。</p>
<h3 id="初始化函数-2">初始化函数</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 dim,   <span class="comment"># 输入token的dim</span></span></span><br><span class="line"><span class="params">                 num_heads=<span class="number">8</span>,</span></span><br><span class="line"><span class="params">                 qkv_bias=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 proj_drop_ratio=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        head_dim = dim // num_heads</span><br><span class="line">        self.scale = qk_scale <span class="keyword">or</span> head_dim ** -<span class="number">0.5</span></span><br><span class="line">        self.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=qkv_bias)</span><br><span class="line">        self.attn_drop = nn.Dropout(attn_drop_ratio)</span><br><span class="line">        self.proj = nn.Linear(dim, dim)</span><br><span class="line">        self.proj_drop = nn.Dropout(proj_drop_ratio)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>dim</code>：token的dimension；</li>
<li><code>qkv_bias</code>：生成qkv时是否使用偏置；</li>
<li><code>head_dim</code>：针对每一个head的dimension，就是传入的dim // num_heads = 768//8=96；</li>
</ul>
<blockquote>
<p>通过$W^q$，$W^k$，$W^v$来生成$q$，$k$，$v$，接着根据head的数目，将$q$，$k$，$v$均分成多少份（例如下图有2个head，则将$q$，$k$，$v$均分为2部分。针对每一个部分也就是每一个head所采用的$qkv$的dimension = 最开始的dimension除以$qkv$的个数），即<code>head_dim = dim // num_heads</code>，得到了每一个head的$qkv$所对应的dimension。</p>
<p>dim即自己设定的总编码的大小（这里为768），除以heads就是表示用几个att分别得到的子编码来组成这个768</p>
</blockquote>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/Muti-Head_Transformer.png" alt="Muti-Head_Transformer中的head"></p>
<ul>
<li><code>qk_scale</code>：如果传入了qk_scale，则将<code>self.scale = qk_scale</code>，否则self.scale = head_dim的开平方分之一，即$self.scale = 1/\sqrt head_dim$；</li>
</ul>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/Attention%E5%85%AC%E5%BC%8F.png" alt="Attention公式"></p>
<ul>
<li><code>self.qkv</code>：$qkv$生成是直接通过一个全连接层实现的。</li>
</ul>
<blockquote>
<p>注意：在其他人源码中有些是需要通过三个全连接层来分别得到$qkv$，但是在此处，直接使用一个全连接层直接得到$qkv$。实际上没有区别，因此此处的全连接层的节点个数是dim*3，和使用3个节点个数为dim的全连接层的效果是一样的（分为3个可能是为了并行化效果更好）。</p>
</blockquote>
<ul>
<li><code>attn_drop</code>：定义一个Dropout层，失活性为传入的attn_drop_ratio；</li>
<li><code>proj</code>：再定义一个全连接层，输入输出节点个数都是dim；</li>
</ul>
<blockquote>
<p>在Muti-Head Transformer中，会将每一个得到的head进行concat拼接，之后用一个$W^o$进行映射</p>
</blockquote>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/Muti-Head_Transformer%E4%B8%ADconcat%E6%8B%BC%E6%8E%A5.png" alt="Muti-Head_Transformer中concat拼接"></p>
<ul>
<li><code>proj_drop</code>：再定义一个Dropout层，失活性为传入的proj_drop_ratio。</li>
</ul>
<h3 id="正向传播函数-2">正向传播函数</h3>
<p>传入的x实际上为<code>[batch_size, num_patches + 1, total_embed_dim]</code>。<code>batch_size</code>指训练时这一批数据传入的图片的数目；<code>num_patches</code>指传入图片高宽除以Patches高宽的得数（这里即$（224 // 16）^2 = (14*14)^2 = 196$），+1是指经过Patch Embedding层之后会拼接上[class]token，即196+1 = 197；<code>total_embed_dim</code>指768。</p>
<p><code>qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)</code></p>
<blockquote>
<p>qkv()：先通过qkv全连接层生成qkv（<code>qkv(): -&gt; [batch_size, num_patches + 1, 3 * total_embed_dim]</code>）；</p>
<p>reshape: -&gt; [batch_size, num_patches + 1, 3, num_heads, embed_dim_per_head]；</p>
<p>permute: -&gt; [3, batch_size, num_heads, num_patches + 1, embed_dim_per_head]（permute函数可批量调整顺序，这里这么改是为了方便后续做运算），第<strong>一个维度3，表示包含三个张量，分别对应Queries（Q）、Keys（K）、Values（V）</strong></p>
</blockquote>
<p><code>q, k, v = qkv[0], qkv[1], qkv[2]</code>：通过切片的方式拿到qkv的数据</p>
<blockquote>
<p>q, k, v此时的shape为[batch_size, num_heads, num_patches + 1, embed_dim_per_head]</p>
</blockquote>
<ul>
<li>transpose函数：可将其中两个位置相互交换；</li>
</ul>
<blockquote>
<p>例如：transpose(-2, -1)：将最后两个维度进行调换。transpose: -&gt; [batch_size, num_patches + 1, num_heads, embed_dim_per_head]</p>
</blockquote>
<ul>
<li>permute函数：批量调整顺序</li>
</ul>
<p><code>attn = (q @ k.transpose(-2, -1)) * self.scale</code>。</p>
<blockquote>
<p><code>@</code>：矩阵乘法的符号</p>
<p>k的shape为[batch_size, num_heads, num_patches + 1, embed_dim_per_head]，经过transpose函数将最后两个维度调换之后，为[batch_size, num_heads, embed_dim_per_head, num_patches+ 1 ]，<strong>即实现矩阵的转置</strong>；</p>
<p>经过<strong>q与k的转置矩阵相乘</strong>之后（实际为最后两个维度相乘），即[batch_size, num_heads, num_patches + 1, embed_dim_per_head]*[batch_size, num_heads, embed_dim_per_head, num_patches+ 1 ] = [batch_size, num_heads, <strong>num_patches + 1, num_patches+ 1</strong> ]（<strong>因为矩阵中，axb的矩阵乘以bxa的矩阵，得出来的值为axa</strong>）</p>
<p>之后再乘上scale，再经过softmax处理，最终呈现的原理就是下图所示</p>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/Attention%E5%85%AC%E5%BC%8F.png" alt="Attention公式"></p>
</blockquote>
<p><code>attn.softmax(dim=-1)</code>：其中的<code>dim = -1</code>指的是在矩阵的每一行进行softmax处理，如果是<code>dim = -2</code>，则是在每一列进行softmax处理。</p>
<p>之后再根据每个v的权重经过Dropout层。</p>
<p>为了实现上图的公式，还需要根据softmax之后，针对每一个V的权重来进行加权求和的操作。即<code>(attn @ v).transpose(1, 2).reshape(B, N, C)</code>中的<code>attn @ v</code>。这里经过加权求和之后，shape变为[batch_size, num_heads, num_patches + 1, embed_dim_per_head]。最后经过reshape操作，就是将最后两个维度拼接在一起。</p>
<p><code>self.proj(x)</code>：有时候需要通过一个$W^o$去映射，因此这里通过proj全连接层得到结果；</p>
<p><code>proj_drop</code>：再通过一个Dropout层得到最终输出</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># [batch_size, num_patches + 1, total_embed_dim]</span></span><br><span class="line">    <span class="comment"># [224,197,768]</span></span><br><span class="line">    B, N, C = x.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)</span></span><br><span class="line">    <span class="comment"># qkv(): -&gt; [batch_size, num_patches + 1, 3 * total_embed_dim]</span></span><br><span class="line">    <span class="comment"># reshape: -&gt; [batch_size, num_patches + 1, 3, num_heads, embed_dim_per_head]</span></span><br><span class="line">    <span class="comment"># permute: -&gt; [3, batch_size, num_heads, num_patches + 1, embed_dim_per_head]</span></span><br><span class="line">    qkv = self.qkv(x).reshape(B, N, <span class="number">3</span>, self.num_heads, C // self.num_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="comment"># [batch_size, num_heads, num_patches + 1, embed_dim_per_head] = [batch，8，197，96]</span></span><br><span class="line">    q, k, v = qkv[<span class="number">0</span>], qkv[<span class="number">1</span>], qkv[<span class="number">2</span>]  <span class="comment"># make torchscript happy (cannot use tensor as tuple)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># transpose（转置）: -&gt; [batch_size, num_heads, embed_dim_per_head, num_patches + 1]</span></span><br><span class="line">    <span class="comment"># @: 矩阵相乘multiply -&gt; [batch_size, num_heads, num_patches + 1, num_patches + 1]</span></span><br><span class="line">    attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * self.scale</span><br><span class="line">    attn = attn.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">    attn = self.attn_drop(attn)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># attn @ v这一步结束公式，之后的操作是还原Tensor通道排列顺序</span></span><br><span class="line">    <span class="comment"># @: multiply -&gt; [batch_size, num_heads, num_patches + 1, embed_dim_per_head]</span></span><br><span class="line">    <span class="comment"># transpose: -&gt; [batch_size, num_patches + 1, num_heads, embed_dim_per_head]</span></span><br><span class="line">    <span class="comment"># reshape: -&gt; [batch_size, num_patches + 1, total_embed_dim]</span></span><br><span class="line">    x = (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B, N, C)</span><br><span class="line">    x = self.proj(x)</span><br><span class="line">    x = self.proj_drop(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="Mlp类">Mlp类</h2>
<p>对应为上一篇文中所讲的Encoder Block中的MLP Block，也就是下图所示的结构：</p>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/MLP_Block%E7%BB%93%E6%9E%84.png" alt="MLP Block结构"></p>
<ul>
<li><code>hidden_features</code>：对应的是第一个全连接层的节点个数，通常为in_features节点个数的4倍；</li>
<li><code>out_features</code>：和in_features节点个数一致</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Mlp</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    MLP as used in Vision Transformer, MLP-Mixer and related networks</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># Block类中没有输入out_features，所以默认out_features=None</span></span><br><span class="line">        <span class="comment"># 所以这条语句out_features = in_features</span></span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features</span><br><span class="line">        <span class="comment"># hidden_features = hidden_features = 3072</span></span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features</span><br><span class="line">        self.fc1 = nn.Linear(in_features, hidden_features)</span><br><span class="line">        self.act = act_layer()</span><br><span class="line">        self.fc2 = nn.Linear(hidden_features, out_features)</span><br><span class="line">        self.drop = nn.Dropout(drop)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="Block类">Block类</h2>
<p>对应为上一篇文中所讲的Encoder Block，结构如下图所示：</p>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/Encoder_Block%E7%BB%93%E6%9E%84.png" alt="Encoder Block结构"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 dim,</span></span><br><span class="line"><span class="params">                 num_heads,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>,</span></span><br><span class="line"><span class="params">                 qkv_bias=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 <span class="comment"># 在VisionTransoformer类中传入值为从0到drop_path_ratio的12次等差数列</span></span></span><br><span class="line"><span class="params">                 drop_path_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 act_layer=nn.GELU,</span></span><br><span class="line"><span class="params">                 norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="built_in">super</span>(Block, self).__init__()</span><br><span class="line">        self.norm1 = norm_layer(dim)</span><br><span class="line">        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,</span><br><span class="line">                              attn_drop_ratio=attn_drop_ratio, proj_drop_ratio=drop_ratio)</span><br><span class="line">        <span class="comment"># <span class="doctag">NOTE:</span> drop path for stochastic depth, we shall see if this is better than dropout here</span></span><br><span class="line">        self.drop_path = DropPath(drop_path_ratio) <span class="keyword">if</span> drop_path_ratio &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        self.norm2 = norm_layer(dim)</span><br><span class="line">        <span class="comment"># mlp_hidden_dim = 768*4=3072</span></span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)</span><br><span class="line">        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop_ratio)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 两个残差结构</span></span><br><span class="line">        x = x + self.drop_path(self.attn(self.norm1(x)))</span><br><span class="line">        x = x + self.drop_path(self.mlp(self.norm2(x)))</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="VisionTransformer类">VisionTransformer类</h2>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/ResNet-50+ViT-B16-hybrid-model.png" alt="VisionTransformer模型结构"></p>
<h3 id="初始化函数-3">初始化函数</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VisionTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, num_classes=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>, num_heads=<span class="number">12</span>, mlp_ratio=<span class="number">4.0</span>, qkv_bias=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 qk_scale=<span class="literal">None</span>, representation_size=<span class="literal">None</span>, distilled=<span class="literal">False</span>, drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 attn_drop_ratio=<span class="number">0.</span>, drop_path_ratio=<span class="number">0.</span>, embed_layer=PatchEmbed, norm_layer=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 act_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            img_size (int, tuple): input image size</span></span><br><span class="line"><span class="string">            patch_size (int, tuple): patch size</span></span><br><span class="line"><span class="string">            in_c (int): number of input channels</span></span><br><span class="line"><span class="string">            num_classes (int): number of classes for classification head</span></span><br><span class="line"><span class="string">            embed_dim (int): embedding dimension</span></span><br><span class="line"><span class="string">            depth (int): depth of transformer</span></span><br><span class="line"><span class="string">            num_heads (int): number of attention heads</span></span><br><span class="line"><span class="string">            mlp_ratio (int): ratio of mlp hidden dim to embedding dim</span></span><br><span class="line"><span class="string">            qkv_bias (bool): enable bias for qkv if True</span></span><br><span class="line"><span class="string">            qk_scale (float): override default qk scale of head_dim ** -0.5 if set</span></span><br><span class="line"><span class="string">            representation_size (Optional[int]): enable and set representation layer (pre-logits) to this value if set</span></span><br><span class="line"><span class="string">            distilled (bool): model includes a distillation token and head as in DeiT models</span></span><br><span class="line"><span class="string">            drop_ratio (float): dropout rate</span></span><br><span class="line"><span class="string">            attn_drop_ratio (float): attention dropout rate</span></span><br><span class="line"><span class="string">            drop_path_ratio (float): stochastic depth rate</span></span><br><span class="line"><span class="string">            embed_layer (nn.Module): patch embedding layer</span></span><br><span class="line"><span class="string">            norm_layer: (nn.Module): normalization layer</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(VisionTransformer, self).__init__()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.num_features = self.embed_dim = embed_dim  <span class="comment"># num_features for consistency with other models</span></span><br><span class="line">        self.num_tokens = <span class="number">2</span> <span class="keyword">if</span> distilled <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        norm_layer = norm_layer <span class="keyword">or</span> partial(nn.LayerNorm, eps=<span class="number">1e-6</span>)</span><br><span class="line">        act_layer = act_layer <span class="keyword">or</span> nn.GELU</span><br><span class="line"></span><br><span class="line">        <span class="comment"># embed_layer=PatchEmbed</span></span><br><span class="line">        self.patch_embed = embed_layer(img_size=img_size, patch_size=patch_size, in_c=in_c, embed_dim=embed_dim)</span><br><span class="line">        <span class="comment"># num_patches = 196</span></span><br><span class="line">        num_patches = self.patch_embed.num_patches</span><br><span class="line"></span><br><span class="line">        self.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim))</span><br><span class="line">        self.dist_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim)) <span class="keyword">if</span> distilled <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        <span class="comment"># num_patches + self.num_tokens = 196+1=197</span></span><br><span class="line">        self.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + self.num_tokens, embed_dim))</span><br><span class="line">        self.pos_drop = nn.Dropout(p=drop_ratio)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># dpr是一个列表，按次序递增的drop_path_ratio等差数列。</span></span><br><span class="line">        <span class="comment"># x.item()就是指for x in torch.linspace(0, drop_path_ratio, depth)中的x，只不过item()更精确</span></span><br><span class="line">        dpr = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_ratio, depth)]  <span class="comment"># stochastic depth decay rule</span></span><br><span class="line">        <span class="comment"># 进入Encoder Block（depth = 12，所以重复12次）</span></span><br><span class="line">        self.blocks = nn.Sequential(*[</span><br><span class="line">            Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,</span><br><span class="line">                  drop_ratio=drop_ratio, attn_drop_ratio=attn_drop_ratio, drop_path_ratio=dpr[i],</span><br><span class="line">                  norm_layer=norm_layer, act_layer=act_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)</span><br><span class="line">        ])</span><br><span class="line">        self.norm = norm_layer(embed_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Representation layer</span></span><br><span class="line">        <span class="comment"># representation_size=None, distilled=False</span></span><br><span class="line">        <span class="keyword">if</span> representation_size <span class="keyword">and</span> <span class="keyword">not</span> distilled:</span><br><span class="line">            self.has_logits = <span class="literal">True</span></span><br><span class="line">            self.num_features = representation_size</span><br><span class="line">            self.pre_logits = nn.Sequential(OrderedDict([</span><br><span class="line">                (<span class="string">&quot;fc&quot;</span>, nn.Linear(embed_dim, representation_size)),</span><br><span class="line">                (<span class="string">&quot;act&quot;</span>, nn.Tanh())</span><br><span class="line">            ]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.has_logits = <span class="literal">False</span></span><br><span class="line">            self.pre_logits = nn.Identity()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Classifier head(s)</span></span><br><span class="line">        self.head = nn.Linear(self.num_features, num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        self.head_dist = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> distilled:</span><br><span class="line">            self.head_dist = nn.Linear(self.embed_dim, self.num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Weight init</span></span><br><span class="line">        nn.init.trunc_normal_(self.pos_embed, std=<span class="number">0.02</span>)</span><br><span class="line">        <span class="keyword">if</span> self.dist_token <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.trunc_normal_(self.dist_token, std=<span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line">        nn.init.trunc_normal_(self.cls_token, std=<span class="number">0.02</span>)</span><br><span class="line">        self.apply(_init_vit_weights)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>depth</code>：在Transformer Encoder中重复Encoder Block多少次，这里为12次；</li>
<li><code>representation_size</code>：对应MLP Head中的Pre-Logits当中全连接层的节点个数，如果为None，则不会构建MLP Head中的Pre-Logits，即在MLP Head中只有一个全连接层；</li>
<li><code>embed_layer</code>：指Patch Embedding层。</li>
</ul>
<p><code>norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)</code>：默认为norm_layer ，使用partial函数将nn.LayerNorm传入的eps默认参数改为1e-6</p>
<blockquote>
<p>nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True, device=None, dtype=None)</p>
<p>LayerNorm也是归一化的一种方法，与BatchNorm不同的是它是对每单个batch进行的归一化，而batchnorm是对所有batch一起进行归一化的</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">norm_layer = norm_layer <span class="keyword">or</span> partial(nn.LayerNorm, eps=<span class="number">1e-6</span>)</span><br></pre></td></tr></table></figure>
<p><code>self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))</code>：通过nn.Parameter构建了一个可训练的参数，直接使用一个零矩阵进行初始化，shape大小为[1，1，embed_dim]（batch维度，[class]token中1x768的1，768）；</p>
<p><code>self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + self.num_tokens, embed_dim))</code>：结构图中，Position Embedding的shape是和拼接之后的shape一样，都是[197，768]。同样根据nn.Parameter构建了一个可训练的参数，直接使用一个零矩阵进行初始化，第一个1是batch维度（可以不用管），<code>num_patches + self.num_tokens</code>=<code>14x14+1</code> = <code>196+1=197</code>，embed_dim即传入值；</p>
<p><code>self.pos_drop = nn.Dropout(p=drop_ratio)</code>：此处的Dropout层指的是Transformer Encoder之前的Droupout层；</p>
<p><code>dpr = [x.item() for x in torch.linspace(0, drop_path_ratio, depth)]</code>：根据传入的drop_path_ratio构建一个等差序列，范围是从0到drop_path_ratio，这个序列当中总共由depth个元素。也就是说，在Transformer Encoder当中，每一个Encoder Block所采用的drop_path方法所使用的drop_path_ratio是递增的。此刻默认为0；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.blocks = nn.Sequential(*[</span><br><span class="line">        Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, 				   		qk_scale=qk_scale,drop_ratio=drop_ratio, attn_drop_ratio=attn_drop_ratio, 							drop_path_ratio=dpr[i],norm_layer=norm_layer, act_layer=act_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)</span><br><span class="line">        ])</span><br></pre></td></tr></table></figure>
<p>构建Block，即Transformer Encoder堆叠12次。通过循环depth达到重复blocks的效果，每循环一次，都会在列表当中添加一个Block，也就是Encoder Block（）其中传入参数都是不变的，除非drop_path_ratio=dpr[i]，是递增的。再通过nn.Sequential将列表中的所有模块打包成一个整体，赋值给self.blocks；</p>
<p><code>representation_size</code>：对应MLP Head中的Pre-Logits当中全连接层的节点个数，如果为None，则不会构建MLP Head中的Pre-Logits。</p>
<blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;self.pre_logits = nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">&quot;fc&quot;</span>, nn.Linear(embed_dim, representation_size)),</span><br><span class="line">          (<span class="string">&quot;act&quot;</span>, nn.Tanh())</span><br><span class="line">      ]))</span><br></pre></td></tr></table></figure>
<p>通过nn.Sequential方法再加上OrderedDict有序字典来构造pre_logits，即一个全连接层+Tanh激活函数</p>
</blockquote>
<p><code>self.head</code>：最后的全连接层；</p>
<h3 id="正向传播函数-3">正向传播函数</h3>
<p><strong>forward_features函数</strong></p>
<ul>
<li>首先将输入x传递给patch_embed，即对应着Patch Embedding结构；</li>
<li>接下来将cls_token进行expand处理，在之前构建的cls_token的shape为[1，1，768]，那么这条语句会根据传入的batch_size的个数去expand这的cls_token，也就是说将cls_token在batch维度复制batch_size份，即shape变成了[B，1，768]；</li>
<li>self.dist_token在这默认为None，即对cls_token与x在1维度进行拼接，即196的维度，[B，197，768]；</li>
<li>将拼接之后得出的数据加上self.pos_embed，再通过一个pos.drop，即dropout层；</li>
<li><code>self.pre_logits(x[:, 0])</code>：通过该条语句获取输出，将x参数的第二个维度（除开第一个维度的batch）上的索引为0的数据</li>
</ul>
<p><strong>forward函数</strong></p>
<p>直接forward_features函数处理，最后的<code>x = self.head(x)</code>，即结构图中最后一个全连接层。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># [B, C, H, W] -&gt; [B, num_patches, embed_dim]</span></span><br><span class="line">    x = self.patch_embed(x)  <span class="comment"># [B, 196, 768]</span></span><br><span class="line">    <span class="comment"># [1, 1, 768] -&gt; [B, 1, 768]</span></span><br><span class="line">    cls_token = self.cls_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> self.dist_token <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        x = torch.cat((cls_token, x), dim=<span class="number">1</span>)  <span class="comment"># [B, 197, 768]</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x = torch.cat((cls_token, self.dist_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>), x), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x = self.pos_drop(x + self.pos_embed)</span><br><span class="line">    x = self.blocks(x)</span><br><span class="line">    x = self.norm(x)</span><br><span class="line">    <span class="keyword">if</span> self.dist_token <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> self.pre_logits(x[:, <span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x[:, <span class="number">0</span>], x[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    x = self.forward_features(x)</span><br><span class="line">    <span class="keyword">if</span> self.head_dist <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        x, x_dist = self.head(x[<span class="number">0</span>]), self.head_dist(x[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> <span class="keyword">not</span> torch.jit.is_scripting():</span><br><span class="line">            <span class="comment"># during inference, return the average of both classifier predictions</span></span><br><span class="line">            <span class="keyword">return</span> x, x_dist</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (x + x_dist) / <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x = self.head(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="实例化模型">实例化模型</h2>
<ul>
<li><code>Layers</code>是<strong>Transformer Encoder中重复堆叠Encoder Block的次数</strong>；</li>
<li><code>Hidden Size</code>是<strong>通过Embedding层后每个token的dim</strong> (向量的长度)；</li>
<li><code>MLP size</code>是Transformer Encoder中<strong>MLP Block第一个全连接的节点个数(是Hidden Size的四倍)</strong>；</li>
<li><code>Heads</code>代表Transformer中<strong>Multi-Head Attention的heads数</strong></li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Model</th>
<th style="text-align:center">Patch Size</th>
<th style="text-align:center">Layers</th>
<th style="text-align:center">Hidden Size D</th>
<th style="text-align:center">MLP size</th>
<th style="text-align:center">Heads</th>
<th style="text-align:center">Params</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ViT-Base</td>
<td style="text-align:center">16x16</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">3072</td>
<td style="text-align:center">12</td>
<td style="text-align:center">86M</td>
</tr>
<tr>
<td style="text-align:center">ViT-Large</td>
<td style="text-align:center">16x16</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">4096</td>
<td style="text-align:center">16</td>
<td style="text-align:center">307M</td>
</tr>
<tr>
<td style="text-align:center">ViT-Huge</td>
<td style="text-align:center">14x14</td>
<td style="text-align:center">32</td>
<td style="text-align:center">1280</td>
<td style="text-align:center">5120</td>
<td style="text-align:center">16</td>
<td style="text-align:center">632M</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch16_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).</span></span><br><span class="line"><span class="string">    ImageNet-1k weights @ 224x224, source https://github.com/google-research/vision_transformer.</span></span><br><span class="line"><span class="string">    weights ported from official Google JAX impl:</span></span><br><span class="line"><span class="string">    链接: https://pan.baidu.com/s/1zqb08naP0RPqqfSXfkB2EA  密码: eu9f</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">16</span>,</span><br><span class="line">                              embed_dim=<span class="number">768</span>,</span><br><span class="line">                              depth=<span class="number">12</span>,</span><br><span class="line">                              num_heads=<span class="number">12</span>,</span><br><span class="line">                              representation_size=<span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch16_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).</span></span><br><span class="line"><span class="string">    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.</span></span><br><span class="line"><span class="string">    weights ported from official Google JAX impl:</span></span><br><span class="line"><span class="string">    https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_patch16_224_in21k-e5005f0a.pth</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">16</span>,</span><br><span class="line">                              embed_dim=<span class="number">768</span>,</span><br><span class="line">                              depth=<span class="number">12</span>,</span><br><span class="line">                              num_heads=<span class="number">12</span>,</span><br><span class="line">                              representation_size=<span class="number">768</span> <span class="keyword">if</span> has_logits <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch32_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).</span></span><br><span class="line"><span class="string">    ImageNet-1k weights @ 224x224, source https://github.com/google-research/vision_transformer.</span></span><br><span class="line"><span class="string">    weights ported from official Google JAX impl:</span></span><br><span class="line"><span class="string">    链接: https://pan.baidu.com/s/1hCv0U8pQomwAtHBYc4hmZg  密码: s5hl</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">32</span>,</span><br><span class="line">                              embed_dim=<span class="number">768</span>,</span><br><span class="line">                              depth=<span class="number">12</span>,</span><br><span class="line">                              num_heads=<span class="number">12</span>,</span><br><span class="line">                              representation_size=<span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch32_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).</span></span><br><span class="line"><span class="string">    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.</span></span><br><span class="line"><span class="string">    weights ported from official Google JAX impl:</span></span><br><span class="line"><span class="string">    https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_patch32_224_in21k-8db57226.pth</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">32</span>,</span><br><span class="line">                              embed_dim=<span class="number">768</span>,</span><br><span class="line">                              depth=<span class="number">12</span>,</span><br><span class="line">                              num_heads=<span class="number">12</span>,</span><br><span class="line">                              representation_size=<span class="number">768</span> <span class="keyword">if</span> has_logits <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_large_patch16_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).</span></span><br><span class="line"><span class="string">    ImageNet-1k weights @ 224x224, source https://github.com/google-research/vision_transformer.</span></span><br><span class="line"><span class="string">    weights ported from official Google JAX impl:</span></span><br><span class="line"><span class="string">    链接: https://pan.baidu.com/s/1cxBgZJJ6qUWPSBNcE4TdRQ  密码: qqt8</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">16</span>,</span><br><span class="line">                              embed_dim=<span class="number">1024</span>,</span><br><span class="line">                              depth=<span class="number">24</span>,</span><br><span class="line">                              num_heads=<span class="number">16</span>,</span><br><span class="line">                              representation_size=<span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_large_patch16_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).</span></span><br><span class="line"><span class="string">    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.</span></span><br><span class="line"><span class="string">    weights ported from official Google JAX impl:</span></span><br><span class="line"><span class="string">    https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_patch16_224_in21k-606da67d.pth</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">16</span>,</span><br><span class="line">                              embed_dim=<span class="number">1024</span>,</span><br><span class="line">                              depth=<span class="number">24</span>,</span><br><span class="line">                              num_heads=<span class="number">16</span>,</span><br><span class="line">                              representation_size=<span class="number">1024</span> <span class="keyword">if</span> has_logits <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_large_patch32_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).</span></span><br><span class="line"><span class="string">    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.</span></span><br><span class="line"><span class="string">    weights ported from official Google JAX impl:</span></span><br><span class="line"><span class="string">    https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_patch32_224_in21k-9046d2e7.pth</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">32</span>,</span><br><span class="line">                              embed_dim=<span class="number">1024</span>,</span><br><span class="line">                              depth=<span class="number">24</span>,</span><br><span class="line">                              num_heads=<span class="number">16</span>,</span><br><span class="line">                              representation_size=<span class="number">1024</span> <span class="keyword">if</span> has_logits <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vit_huge_patch14_224_in21k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21843</span>, has_logits: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ViT-Huge model (ViT-H/14) from original paper (https://arxiv.org/abs/2010.11929).</span></span><br><span class="line"><span class="string">    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.</span></span><br><span class="line"><span class="string">    NOTE: converted weights not currently available, too large for github release hosting.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">14</span>,</span><br><span class="line">                              embed_dim=<span class="number">1280</span>,</span><br><span class="line">                              depth=<span class="number">32</span>,</span><br><span class="line">                              num_heads=<span class="number">16</span>,</span><br><span class="line">                              representation_size=<span class="number">1280</span> <span class="keyword">if</span> has_logits <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h1><a href="http://train.py">train.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.optim.lr_scheduler <span class="keyword">as</span> lr_scheduler</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> vit_model <span class="keyword">import</span> vit_base_patch16_224_in21k <span class="keyword">as</span> create_model</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                                   transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    model = create_model(num_classes=args.num_classes, has_logits=<span class="literal">False</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">assert</span> os.path.exists(args.weights), <span class="string">&quot;weights file: &#x27;&#123;&#125;&#x27; not exist.&quot;</span>.<span class="built_in">format</span>(args.weights)</span><br><span class="line">        weights_dict = torch.load(args.weights, map_location=device)</span><br><span class="line">        <span class="comment"># 删除不需要的权重</span></span><br><span class="line">        del_keys = [<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>] <span class="keyword">if</span> model.has_logits \</span><br><span class="line">            <span class="keyword">else</span> [<span class="string">&#x27;pre_logits.fc.weight&#x27;</span>, <span class="string">&#x27;pre_logits.fc.bias&#x27;</span>, <span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>]</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> del_keys:</span><br><span class="line">            <span class="keyword">del</span> weights_dict[k]</span><br><span class="line">        <span class="built_in">print</span>(model.load_state_dict(weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除head, pre_logits外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;head&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name <span class="keyword">and</span> <span class="string">&quot;pre_logits&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;training &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">    pg = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.SGD(pg, lr=args.lr, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">5E-5</span>)</span><br><span class="line">    <span class="comment"># Scheduler https://arxiv.org/pdf/1812.01187.pdf</span></span><br><span class="line">    lf = <span class="keyword">lambda</span> x: ((<span class="number">1</span> + math.cos(x * math.pi / args.epochs)) / <span class="number">2</span>) * (<span class="number">1</span> - args.lrf) + args.lrf  <span class="comment"># cosine</span></span><br><span class="line">    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        train_loss, train_acc = train_one_epoch(model=model,</span><br><span class="line">                                                optimizer=optimizer,</span><br><span class="line">                                                data_loader=train_loader,</span><br><span class="line">                                                device=device,</span><br><span class="line">                                                epoch=epoch)</span><br><span class="line"></span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        val_loss, val_acc = evaluate(model=model,</span><br><span class="line">                                     data_loader=val_loader,</span><br><span class="line">                                     device=device,</span><br><span class="line">                                     epoch=epoch)</span><br><span class="line"></span><br><span class="line">        tags = [<span class="string">&quot;train_loss&quot;</span>, <span class="string">&quot;train_acc&quot;</span>, <span class="string">&quot;val_loss&quot;</span>, <span class="string">&quot;val_acc&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], train_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], train_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], val_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">3</span>], val_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">4</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;./weights/model-&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.001</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lrf&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--model-name&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;create model name&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预训练权重路径，如果不想载入就设置为空字符</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./vit_base_patch16_224_in21k.pth&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    <span class="comment"># 是否冻结权重</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<p><strong>训练结果</strong></p>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h1><a href="http://predict.py">predict.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> vit_model <span class="keyword">import</span> vit_base_patch16_224_in21k <span class="keyword">as</span> create_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="number">256</span>),</span><br><span class="line">         transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = create_model(num_classes=<span class="number">5</span>, has_logits=<span class="literal">False</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/model-9.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p><strong>预测结果</strong></p>
<p><img src="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
<h1><a href="http://flops.py">flops.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> fvcore.nn <span class="keyword">import</span> FlopCountAnalysis</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> vit_model <span class="keyword">import</span> Attention</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># Self-Attention</span></span><br><span class="line">    a1 = Attention(dim=<span class="number">512</span>, num_heads=<span class="number">1</span>)</span><br><span class="line">    a1.proj = torch.nn.Identity()  <span class="comment"># remove Wo</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Multi-Head Attention</span></span><br><span class="line">    a2 = Attention(dim=<span class="number">512</span>, num_heads=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [batch_size, num_tokens, total_embed_dim]</span></span><br><span class="line">    t = (torch.rand(<span class="number">32</span>, <span class="number">1024</span>, <span class="number">512</span>),)</span><br><span class="line"></span><br><span class="line">    flops1 = FlopCountAnalysis(a1, t)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Self-Attention FLOPs:&quot;</span>, flops1.total())</span><br><span class="line"></span><br><span class="line">    flops2 = FlopCountAnalysis(a2, t)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Multi-Head Attention FLOPs:&quot;</span>, flops2.total())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h1><a href="http://utils.py">utils.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_split_data</span>(<span class="params">root: <span class="built_in">str</span>, val_rate: <span class="built_in">float</span> = <span class="number">0.2</span></span>):</span><br><span class="line">    random.seed(<span class="number">0</span>)  <span class="comment"># 保证随机结果可复现</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(root), <span class="string">&quot;dataset root: &#123;&#125; does not exist.&quot;</span>.<span class="built_in">format</span>(root)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历文件夹，一个文件夹对应一个类别</span></span><br><span class="line">    flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(root) <span class="keyword">if</span> os.path.isdir(os.path.join(root, cla))]</span><br><span class="line">    <span class="comment"># 排序，保证各平台顺序一致</span></span><br><span class="line">    flower_class.sort()</span><br><span class="line">    <span class="comment"># 生成类别名称以及对应的数字索引</span></span><br><span class="line">    class_indices = <span class="built_in">dict</span>((k, v) <span class="keyword">for</span> v, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(flower_class))</span><br><span class="line">    json_str = json.dumps(<span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> class_indices.items()), indent=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">    train_images_path = []  <span class="comment"># 存储训练集的所有图片路径</span></span><br><span class="line">    train_images_label = []  <span class="comment"># 存储训练集图片对应索引信息</span></span><br><span class="line">    val_images_path = []  <span class="comment"># 存储验证集的所有图片路径</span></span><br><span class="line">    val_images_label = []  <span class="comment"># 存储验证集图片对应索引信息</span></span><br><span class="line">    every_class_num = []  <span class="comment"># 存储每个类别的样本总数</span></span><br><span class="line">    supported = [<span class="string">&quot;.jpg&quot;</span>, <span class="string">&quot;.JPG&quot;</span>, <span class="string">&quot;.png&quot;</span>, <span class="string">&quot;.PNG&quot;</span>]  <span class="comment"># 支持的文件后缀类型</span></span><br><span class="line">    <span class="comment"># 遍历每个文件夹下的文件</span></span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        cla_path = os.path.join(root, cla)</span><br><span class="line">        <span class="comment"># 遍历获取supported支持的所有文件路径</span></span><br><span class="line">        images = [os.path.join(root, cla, i) <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(cla_path)</span><br><span class="line">                  <span class="keyword">if</span> os.path.splitext(i)[-<span class="number">1</span>] <span class="keyword">in</span> supported]</span><br><span class="line">        <span class="comment"># 排序，保证各平台顺序一致</span></span><br><span class="line">        images.sort()</span><br><span class="line">        <span class="comment"># 获取该类别对应的索引</span></span><br><span class="line">        image_class = class_indices[cla]</span><br><span class="line">        <span class="comment"># 记录该类别的样本数量</span></span><br><span class="line">        every_class_num.append(<span class="built_in">len</span>(images))</span><br><span class="line">        <span class="comment"># 按比例随机采样验证样本</span></span><br><span class="line">        val_path = random.sample(images, k=<span class="built_in">int</span>(<span class="built_in">len</span>(images) * val_rate))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> img_path <span class="keyword">in</span> images:</span><br><span class="line">            <span class="keyword">if</span> img_path <span class="keyword">in</span> val_path:  <span class="comment"># 如果该路径在采样的验证集样本中则存入验证集</span></span><br><span class="line">                val_images_path.append(img_path)</span><br><span class="line">                val_images_label.append(image_class)</span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># 否则存入训练集</span></span><br><span class="line">                train_images_path.append(img_path)</span><br><span class="line">                train_images_label.append(image_class)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images were found in the dataset.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">sum</span>(every_class_num)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images for training.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(train_images_path)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(val_images_path)))</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(train_images_path) &gt; <span class="number">0</span>, <span class="string">&quot;number of training images must greater than 0.&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(val_images_path) &gt; <span class="number">0</span>, <span class="string">&quot;number of validation images must greater than 0.&quot;</span></span><br><span class="line"></span><br><span class="line">    plot_image = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> plot_image:</span><br><span class="line">        <span class="comment"># 绘制每种类别个数柱状图</span></span><br><span class="line">        plt.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(flower_class)), every_class_num, align=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">        <span class="comment"># 将横坐标0,1,2,3,4替换为相应的类别名称</span></span><br><span class="line">        plt.xticks(<span class="built_in">range</span>(<span class="built_in">len</span>(flower_class)), flower_class)</span><br><span class="line">        <span class="comment"># 在柱状图上添加数值标签</span></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(every_class_num):</span><br><span class="line">            plt.text(x=i, y=v + <span class="number">5</span>, s=<span class="built_in">str</span>(v), ha=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置x坐标</span></span><br><span class="line">        plt.xlabel(<span class="string">&#x27;image class&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置y坐标</span></span><br><span class="line">        plt.ylabel(<span class="string">&#x27;number of images&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置柱状图的标题</span></span><br><span class="line">        plt.title(<span class="string">&#x27;flower class distribution&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_images_path, train_images_label, val_images_path, val_images_label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_data_loader_image</span>(<span class="params">data_loader</span>):</span><br><span class="line">    batch_size = data_loader.batch_size</span><br><span class="line">    plot_num = <span class="built_in">min</span>(batch_size, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), json_path + <span class="string">&quot; does not exist.&quot;</span></span><br><span class="line">    json_file = <span class="built_in">open</span>(json_path, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    class_indices = json.load(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(plot_num):</span><br><span class="line">            <span class="comment"># [C, H, W] -&gt; [H, W, C]</span></span><br><span class="line">            img = images[i].numpy().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 反Normalize操作</span></span><br><span class="line">            img = (img * [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>] + [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]) * <span class="number">255</span></span><br><span class="line">            label = labels[i].item()</span><br><span class="line">            plt.subplot(<span class="number">1</span>, plot_num, i+<span class="number">1</span>)</span><br><span class="line">            plt.xlabel(class_indices[<span class="built_in">str</span>(label)])</span><br><span class="line">            plt.xticks([])  <span class="comment"># 去掉x轴的刻度</span></span><br><span class="line">            plt.yticks([])  <span class="comment"># 去掉y轴的刻度</span></span><br><span class="line">            plt.imshow(img.astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_pickle</span>(<span class="params">list_info: <span class="built_in">list</span>, file_name: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(list_info, f)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_pickle</span>(<span class="params">file_name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">list</span>:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        info_list = pickle.load(f)</span><br><span class="line">        <span class="keyword">return</span> info_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">model, optimizer, data_loader, device, epoch</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    loss_function = torch.nn.CrossEntropyLoss()</span><br><span class="line">    accu_loss = torch.zeros(<span class="number">1</span>).to(device)  <span class="comment"># 累计损失</span></span><br><span class="line">    accu_num = torch.zeros(<span class="number">1</span>).to(device)   <span class="comment"># 累计预测正确的样本数</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    sample_num = <span class="number">0</span></span><br><span class="line">    data_loader = tqdm(data_loader, file=sys.stdout)</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        images, labels = data</span><br><span class="line">        sample_num += images.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        pred = model(images.to(device))</span><br><span class="line">        pred_classes = torch.<span class="built_in">max</span>(pred, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        accu_num += torch.eq(pred_classes, labels.to(device)).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        loss = loss_function(pred, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        accu_loss += loss.detach()</span><br><span class="line"></span><br><span class="line">        data_loader.desc = <span class="string">&quot;[train epoch &#123;&#125;] loss: &#123;:.3f&#125;, acc: &#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,</span><br><span class="line">                                                                               accu_loss.item() / (step + <span class="number">1</span>),</span><br><span class="line">                                                                               accu_num.item() / sample_num)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> torch.isfinite(loss):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;WARNING: non-finite loss, ending training &#x27;</span>, loss)</span><br><span class="line">            sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> accu_loss.item() / (step + <span class="number">1</span>), accu_num.item() / sample_num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, data_loader, device, epoch</span>):</span><br><span class="line">    loss_function = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    accu_num = torch.zeros(<span class="number">1</span>).to(device)   <span class="comment"># 累计预测正确的样本数</span></span><br><span class="line">    accu_loss = torch.zeros(<span class="number">1</span>).to(device)  <span class="comment"># 累计损失</span></span><br><span class="line"></span><br><span class="line">    sample_num = <span class="number">0</span></span><br><span class="line">    data_loader = tqdm(data_loader, file=sys.stdout)</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        images, labels = data</span><br><span class="line">        sample_num += images.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        pred = model(images.to(device))</span><br><span class="line">        pred_classes = torch.<span class="built_in">max</span>(pred, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        accu_num += torch.eq(pred_classes, labels.to(device)).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        loss = loss_function(pred, labels.to(device))</span><br><span class="line">        accu_loss += loss</span><br><span class="line"></span><br><span class="line">        data_loader.desc = <span class="string">&quot;[valid epoch &#123;&#125;] loss: &#123;:.3f&#125;, acc: &#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,</span><br><span class="line">                                                                               accu_loss.item() / (step + <span class="number">1</span>),</span><br><span class="line">                                                                               accu_num.item() / sample_num)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> accu_loss.item() / (step + <span class="number">1</span>), accu_num.item() / sample_num</span><br></pre></td></tr></table></figure>
<h1>my_dataset.py</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;自定义数据集&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, images_path: <span class="built_in">list</span>, images_class: <span class="built_in">list</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.images_path = images_path</span><br><span class="line">        self.images_class = images_class</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        img = Image.<span class="built_in">open</span>(self.images_path[item])</span><br><span class="line">        <span class="comment"># RGB为彩色图片，L为灰度图片</span></span><br><span class="line">        <span class="keyword">if</span> img.mode != <span class="string">&#x27;RGB&#x27;</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;image: &#123;&#125; isn&#x27;t RGB mode.&quot;</span>.<span class="built_in">format</span>(self.images_path[item]))</span><br><span class="line">        label = self.images_class[item]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):</span><br><span class="line">        <span class="comment"># 官方实现的default_collate可以参考</span></span><br><span class="line">        <span class="comment"># https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py</span></span><br><span class="line">        images, labels = <span class="built_in">tuple</span>(<span class="built_in">zip</span>(*batch))</span><br><span class="line"></span><br><span class="line">        images = torch.stack(images, dim=<span class="number">0</span>)</span><br><span class="line">        labels = torch.as_tensor(labels)</span><br><span class="line">        <span class="keyword">return</span> images, labels</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>Vision Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（二十三）Swin Transformer网络结构详解</title>
    <url>/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1>前言</h1>
<p>Swin Transformer是2021年微软研究院发表在ICCV上的一篇文章，并且已经获得<code>ICCV 2021 best paper</code>的荣誉称号。Swin Transformer网络是Transformer模型在视觉领域的又一次碰撞。该论文一经发表就已在多项视觉任务中霸榜（下图<code>State of the Art</code>表示第一）。原论文：<a href="https://arxiv.org/abs/2103.14030">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Swin-Transformer%E5%B1%A0%E6%A6%9C.png" alt="Swin Transformer屠榜"></p>
<h1>网络整体框架</h1>
<p>下图（左）是Swin Transformer，下图（右）是之前讲的Vision Transformer。通过对比至少可以看出两点不同：</p>
<ul>
<li>Swin Transformer使用了<strong>类似卷积神经网络中的层次化构建方法（Hierarchical feature maps）</strong>，比如特征图尺寸中有对图像下采样4倍的，8倍的以及16倍的，这样的<strong>backbone有助于在此基础上构建目标检测、实例分割等任务</strong>。而在之前的Vision Transformer中是一开始就直接下采样16倍，后面的特征图也是维持这个下采样率不变。</li>
<li>在Swin Transformer中使用一个个窗口的形式将图片分隔开，窗口和窗口之间没有重叠，即Windows Multi-Head Self-Attention(W-MSA)的概念，比如在下图的4倍下采样和8倍下采样中，将特征图划分成了多个不相交的区域（Window），并且Multi-Head Self-Attention只在每个窗口（Window）内进行。相对于Vision Transformer中直接对整个（Global）特征图进行分割，即Multi-Head Self-Attention，这样做的目的<strong>是能够减少计算量的，尤其是在浅层特征图很大的时候</strong>。这样做<strong>虽然减少了计算量但也会隔绝不同窗口之间的信息传递，所以在论文中作者又提出了 Shifted Windows Multi-Head Self-Attention(SW-MSA)的概念，通过此方法能够让信息在相邻的窗口中进行传递</strong>。</li>
</ul>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Swin-Transformer%E5%92%8CVision-Transformer%E7%9A%84%E5%AF%B9%E6%AF%94.png" alt="Swin Transformer和Vision Transformer的对比"></p>
<p>原论文中给出的关于<strong>Swin Transformer（Swin-T）网络的架构图</strong>。通过图(a)可以看出<strong>整个框架的基本流程</strong>如下：</p>
<ul>
<li>首先<strong>将图片输入到Patch Partition模块中进行分块，即每4x4相邻的像素为一个Patch，然后在channel方向展平（flatten）</strong>。假设输入的是RGB三通道图片，那么每个patch就有4x4=16个像素，然后每个像素有R、G、B三个值所以展平后是16x3=48，所以通过Patch Partition后图像shape由<code> [H, W, 3]</code>变成了 <code>[H/4, W/4, 48]</code>。然后在通过Linear Embedding层对每个像素的channel数据做线性变换，由48变成C，即图像shape再由 <code>[H/4, W/4, 48]</code>变成了<code> [H/4, W/4, C]</code>。其实在源码中Patch Partition和Linear Embedding就是直接通过一个卷积层实现的，和之前Vision Transformer中讲的 Embedding层结构一模一样。</li>
</ul>
<blockquote>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Patch-Patition.png" alt="Patch Partition和Linear Embedding"></p>
</blockquote>
<ul>
<li>
<p>然后就是<strong>通过四个Stage构建不同大小的特征图，除了Stage1中先通过一个Linear Embeding层外，剩下三个stage都是先通过一个Patch Merging层进行下采样</strong>，然后都是重复堆叠Swin Transformer Block注意这里的Block其实有两种结构，如图(b)中所示，这两种结构的不同之处仅在于一个使用了W-MSA结构，一个使用了SW-MSA结构。而且这两个结构是成对使用的，先使用一个W-MSA结构再使用一个SW-MSA结构。所以会发现<strong>堆叠Swin Transformer Block的次数都是偶数（因为成对使用下图b）</strong>。</p>
</li>
<li>
<p>最后对于分类网络，在Stage4之后还会接上一个Layer Norm层、全局池化层以及全连接层得到最终输出。</p>
</li>
</ul>
<p>接下来，在分别对Patch Merging、W-MSA、SW-MSA以及使用到的相对位置偏执（relative position bias）进行详解。关于Swin Transformer Block中的MLP结构和Vision Transformer中的结构是一样的，所以这里也不在赘述。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Swin-Transformer网络架构图"></p>
<h1>Patch Merging详解</h1>
<p>即上图的Stage2、3、4。在每个Stage中首先要通过一个Patch Merging层进行下采样（Stage1除外）。如下图所示，假设输入Patch Merging的是一个4x4大小的单通道特征图（feature map），Patch Merging会将每个2x2的相邻像素划分为一个patch，然后将每个patch中相同位置（同一颜色）<code>像素</code>给拼在一起就得到了4个feature map。接着将这四个feature map在深度方向进行concat拼接，然后在通过一个LayerNorm层。最后通过一个全连接层在feature map的深度方向做线性变化，将feature map的深度由C变成C/2。通过这个简单的例子可以看出，<strong>通过Patch Merging层后，feature map的高和宽会减半，深度会翻倍</strong>。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Patch-Merging.png" alt="Patch Merging"></p>
<h1>W-MSA详解</h1>
<ul>
<li>目的：减少计算量；</li>
<li>缺点：窗口之间无法进行信息交互；</li>
</ul>
<p>引入Windows Multi-head Self-Attention（W-MSA）模块是<strong>为了减少计算量</strong>。如下图所示，左侧使用的是普通的Multi-head Self-Attention（MSA）模块，对于feature map中的每个像素（或称作token，patch）在Self-Attention计算过程中需要和所有的像素去计算。但在图右侧，在<strong>使用Windows Multi-head Self-Attention（W-MSA）模块时，首先将feature map按照MxM（例子中的M=2）大小划分成一个个Windows，然后单独对每个Windows内部进行Self-Attention</strong>。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/W-MSA.png" alt="W-MSA"></p>
<p>两者的计算量具体差多少呢？原论文中有给出下面两个公式，这里忽略了Softmax的计算复杂度。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/MSA%E5%92%8CW-SMA%E5%88%86%E5%88%AB%E7%9A%84%E8%AE%A1%E7%AE%97%E9%87%8F%E5%85%AC%E5%BC%8F.png" alt="MSA和W-MSA分别的计算量公式"></p>
<ul>
<li>h代表feature map的高度</li>
<li>w代表feature map的宽度</li>
<li>C代表feature map的深度</li>
<li>M代表每个窗口（Windows）的大小</li>
</ul>
<p>h = w = 112，M= 7，C = 128，节省40124743680 FLOPS</p>
<p><strong>Self-Attention公式</strong></p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Attention%E5%85%AC%E5%BC%8F.png" alt="Self-Attention公式"></p>
<h2 id="MSA模块计算量">MSA模块计算量</h2>
<p>对于feature map中的每个像素（或称作token，patch），都要通过$W_q$，$W_k$，$W_v$生成对应的query(q)，key(k)以及value(v)。这里假设q, k, v的向量长度与feature map的深度C保持一致。那么对应所有像素生成Q的过程如下式：</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E5%AF%B9%E5%BA%94%E6%89%80%E6%9C%89%E5%83%8F%E7%B4%A0%E7%94%9F%E6%88%90Q%E7%9A%84%E5%85%AC%E5%BC%8F.png" alt="MSA计算量-1"></p>
<ul>
<li>$A^{hw*C}$：将所有像素（token）拼接在一起得到的矩阵（一共有hw个像素，每个像素的深度为C）；</li>
<li>$W_q^{C*C}$：生成query的变换矩阵；</li>
<li>$Q^{hw<em>C}$：所有像素通过$W_q^{C</em>C}$得到的query拼接后的矩阵</li>
</ul>
<blockquote>
<p>矩阵乘法当中，<strong>$A^{a<em>b}·B^{b</em>c}$的FLOPs为a x b x c</strong></p>
</blockquote>
<p>根据矩阵运算的计算量公式可以得到生成Q的计算量为hw x C x C，，生成K和V同理都是$hwC^2$，那么总共是$3hwC^2$。接下来$Q$和$K$相乘，对应计算量为$(hw)^2C$：</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/MSA%E8%AE%A1%E7%AE%97%E9%87%8F2.png" alt="MSA计算量-2"></p>
<p>接下来忽略除以$\sqrt{d}$以及softmax的计算量，假设得到$Λ^{hw * hw}$（通过softmax之后得到的输出），最后还要乘以V，对应的计算量为$(hw)^2C$：</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/MSA%E8%AE%A1%E7%AE%97%E9%87%8F3.png" alt="MSA计算量-3"></p>
<p>那么对应单头的Self-Attention模块，总共需要$3hwC^2+(hw)^2C+(hw)^2C=3hwC^2+2(hw)^2C$。而在实际使用过程中，使用的是多头的Multi-head Self-Attention模块，<strong>多头注意力模块相比单头注意力模块的计算量仅多了最后一个融合矩阵$W^o$的计算量$(hw)^2C$</strong>。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/MSA%E8%AE%A1%E7%AE%97%E9%87%8F4.png" alt="MSA计算量-4"></p>
<p><strong>所以总共加起来是</strong>：$4hwC^2+2(hw)^2C$</p>
<h2 id="W-MSA模块计算量">W-MSA模块计算量</h2>
<p>对于W-MSA模块首先要将feature map划分到一个个窗口（Windows）中，假设每个窗口的宽高都是M，那么总共会得到$\frac{h}{M}✖\frac{w}{M}$个窗口，然后对每个窗口内使用多头注意力模块。刚刚计算高为h，宽为w，深度为C的feature map的计算量为$4hwC^2+2(hw)^2C$，这里每个窗口的高为M宽为M，带入公式得：</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/W-SMA%E8%AE%A1%E7%AE%97%E9%87%8F1.png" alt="W-SMA计算量-1"></p>
<p>又因为有$\frac{h}{M}✖\frac{w}{M}$个窗口，则：：</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/W-SMA%E8%AE%A1%E7%AE%97%E9%87%8F2.png" alt="W-SMA计算量-2"></p>
<p>故使用W-MSA模块的计算量为：</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/W-SMA%E8%AE%A1%E7%AE%97%E9%87%8F3.png" alt="W-SMA计算量-3"></p>
<p>假设feature map的h、w都为112，M=7，C=128，采用W-MSA模块相比MSA模块能够节省约40124743680 FLOPs：$4(hw)^2C-2M^2hwC = 2✖112^4✖128-2✖7^2✖112^2✖128 = 40124743680$</p>
<h1>SW-MSA详解</h1>
<p>采用W-MSA模块时，只会在每个窗口内进行自注意力计算，所以窗口与窗口之间是无法进行信息传递的。为了解决这个问题，作者引入了<strong>Shifted Windows Multi-Head Self-Attention（SW-MSA）模块，即进行偏移的W-MSA</strong>。</p>
<p>如下图所示，左侧使用的是刚刚讲的W-MSA（假设是第L层），那么根据之前介绍的W-MSA和SW-MSA是成对使用的，那么第L+1层使用的就是SW-MSA（右侧图）。根据左右两幅图对比能够发现窗口（Windows）发生了偏移（可以理解成<strong>窗口从左上角分别向右侧和下方各偏移了$\lfloor\frac{M}{2}\rfloor$个像素</strong>，up的视频有动图，十分清晰明了）。看下偏移后的窗口（右侧图），比如对于第一行第2列的2x4的窗口，它能够使第L层的第一排的两个窗口信息进行交流。再比如，第二行第二列的4x4的窗口，他能够使第L层的四个窗口信息进行交流，其他的同理。那么这就解决了不同窗口之间无法进行信息交流的问题。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E8%BF%9B%E8%A1%8C%E5%81%8F%E7%A7%BB%E7%9A%84W-SMA.png" alt="进行偏移的W-MSA"></p>
<p>根据上图，可以发现通过将窗口进行偏移后，<strong>由原来的4个窗口变成9个窗口了。后面又要对每个窗口内部进行MSA，这样做感觉又变麻烦了</strong>。为了解决这个麻烦，作者又提出而了<code>Efficient batch computation for shifted configuration</code>，一种更加高效的计算方法。下面是原论文给的示意图。<br>
<img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Efficient-batch-computation-for-shifted-configuration.png" alt="Efficient batch computation for shifted configuration"></p>
<p><strong>为描述上图Efficient batch computation for shifted configuration的过程</strong>，up画了下面几幅图来更清晰的讲解。</p>
<p>下图左侧是刚刚通过偏移窗口后得到的新窗口，右侧是为了方便大家理解，对每个窗口加上了一个标识。然后0对应的窗口标记为区域A，3和6对应的窗口标记为区域B，1和2对应的窗口标记为区域C。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Shifted-Window-1.png" alt="Shifted Window-1"></p>
<p>然后先将区域A和C移到最下方。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Shifted-Window-2.png" alt="Shifted Window-2"></p>
<p>接着，再将区域A和B移至最右侧。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Shifted-Window-3.png" alt="Shifted Window-3"></p>
<p>移动完后，4是一个单独的窗口；将3和5合并成一个窗口；7和1合并成一个窗口；8、6、2和0合并成一个窗口。这样又和原来一样是4个4x4的窗口了，<strong>所以能够保证计算量是一样的</strong>。这里肯定有人会想，把不同的区域合并在一起（比如5和3）进行MSA，这信息不就乱窜了吗？是的，为了防止这个问题，在实际计算中使用的是<code>masked MSA即带蒙板mask的MSA</code>，这样就<strong>能够通过设置蒙板来隔绝不同区域的信息了</strong>。关于mask如何使用，可以看下图，下图是以上面的区域5和区域3为例。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E5%B8%A6%E8%92%99%E6%9D%BFmask%E7%9A%84MSA.png" alt="带蒙板mask的MSA"></p>
<p><strong>对于该窗口内的每一个像素（或称token，patch）在进行MSA计算时，都要先生成对应的query(q)，key(k)，value(v)</strong>。假设对于上图的像素0而言，得到$q^0$后要与每一个像素的k进行匹配（match），假设$\alpha_{0,0}$代表$q^0$与像素0对应的$k^0$进行匹配的结果，那么同理可以得到$\alpha_{0,0}$至$\alpha_{0,15}$。按照普通的MSA计算，接下来就是SoftMax操作了。</p>
<p>但对于这里的<code>masked MSA</code>，像素0是属于区域5的，<strong>我们只想让它和区域5内的像素进行匹配</strong>（只想计算区域5内部的MSA计算，不希望引入区域3的信息）。<strong>那么我们可以将像素0与区域3中的所有像素匹配结果都减去100（例如$\alpha_{0,2}$，$\alpha_{0,3}$，$\alpha_{0,6}$，$\alpha_{0,7}$，由于$\alpha$的值都很小，一般都是零点几的数，将其中一些数减去100后在通过SoftMax得到对应的权重都等于0了。所以对于像素0而言实际上还是只和区域5内的像素进行了MSA</strong>。对于其他像素也是同理。</p>
<p><strong>注意，在计算完后还要把数据给挪回到原来的位置上（例如上上图的A，B，C区域）。</strong></p>
<h2 id="举例实操SW-MSA">举例实操SW-MSA</h2>
<p>偏移量为M/2向下取整，下图中M = 3，所以偏移量为1，因此需要改动下图（左）的第一行和第一列，改动完之后是下图（右），将第一行补到最后一行，第一列补到最后一列。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%8E%9F%E6%95%B0%E6%8D%AE.png" alt="举例SW-MSA-原数据"></p>
<p>对于上图（右）黑色的分割线对应的是上一层的分割线（即还没有使用偏移量的分割线），此时在挪动了feature map上使用3x3的window（窗口）来进行分割，即如下图所示。</p>
<p>对于4个橙色的window区域，可以直接进行MSA操作，因为每个window内部数据本身是连续的，且通过window分割之后会发现每个window都能和融合上一层4个window的信息。</p>
<p>对于紫色的window区域，因为并不是连续的，所以需要用到具有masked的MSA</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%81%8F%E7%A7%BB%E5%88%86%E5%89%B2%E4%B9%8B%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE.png" alt="举例SW-MSA-偏移分割之后的数据"></p>
<h1>Relative Position Bias详解</h1>
<p>关于相对位置偏执，使用了相对位置偏执后给够带来明显的提升。根据原论文中的表4可以看出，在Imagenet数据集上如果不使用任何位置偏执，top-1为80.1，但使用了相对位置偏执（rel. pos.）后top-1为83.3，提升还是很明显的。（w/o：without）</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB.png" alt="相对位置偏移-性能对比"></p>
<p>那这个相对位置偏执是加在哪的呢，根据论文中提供的公式可知是在Q和K进行匹配并除以$\sqrt d $后加上了相对位置偏执B。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E5%85%AC%E5%BC%8F.png" alt="相对位置偏移-公式"></p>
<p>如下图，假设输入的feature map高宽都为2，那么首先可以构建出每个像素的绝对位置（左下方的矩阵），<strong>对于每个像素的绝对位置是使用行号和列号表示的</strong>。比如蓝色的像素对应的是第0行第0列所以<strong>绝对位置索引是( 0 , 0 )</strong> 。接下来再看看相对位置索引，首先看下蓝色的像素，在蓝色像素使用q与所有像素k进行匹配过程中，是以蓝色像素为参考点。然后<strong>用蓝色像素的绝对位置索引与其他位置索引进行相减，就得到其他位置相对蓝色像素的<code>相对位置索引</code></strong>。例如黄色像素的绝对位置索引是( 0 , 1 )，则它相对蓝色像素的相对位置索引为<code>（0，0）-（0，1）=（0，-1）</code>。那么同理可以得到其他位置相对蓝色像素的<code>相对位置索引矩阵</code>。同样，也能得到相对黄色，红色以及绿色像素的相对位置索引矩阵。接下来将每个相对位置索引矩阵<code>按行展平</code>，并拼接在一起可以得到下面的4x4矩阵 。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-1.png" alt="相对位置偏移-1"></p>
<p>请注意，<strong>这里描述的一直是相对位置索引，并不是相对位置偏执参数</strong>。因为后面会根据相对位置索引去取对应的参数。比如说黄色像素是在蓝色像素的右边，所以相对蓝色像素的相对位置索引为( 0 , − 1 ) 。绿色像素是在红色像素的右边，所以相对红色像素的相对位置索引为( 0 , − 1 ) 。可以发现这两者的相对位置索引都是( 0 , − 1 ) ，所以他们使用的相对位置偏执参数都是一样的。</p>
<p>但在源码中<strong>作者为了方便把二维索引给转成了一维索引</strong>。<strong>首先在原始的相对位置索引上加上M-1(M为窗口的大小，在本示例中M=2)，加上之后索引中就不会有负数了</strong>。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-2.png" alt="相对位置偏移-2"></p>
<p>接着将所有的行标都乘上2M-1。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-3.png" alt="相对位置偏移-3"></p>
<p>最后将行标和列标进行相加。这样即保证了相对位置关系，而且不会出现仅仅将相对位置信息左简单相加而导致0 + ( − 1 ) = ( − 1 ) + 0的问题了。</p>
<blockquote>
<p>这是一种从向量化索引角度出发的计算方式，不理解的用二维方式来理解：</p>
<ul>
<li>二维的相对偏移不过就是上下、左右两类，这两类的偏移距离范围都是**[-M+1，M-1]**；</li>
<li>那么我们可以构建一个（2M-1）x（2M-1）大小的矩阵，其中的值表示position bias；</li>
<li>以上述构建的矩阵为table，针对不同相对位置，直接以（上下偏移距离，左右偏移距离）为索引去这个table里取值，就是我们要的relative position bias。</li>
</ul>
<p>当把上述3步都理解之后，再用向量化的方式理解，就清晰为什么作者这么做了。</p>
</blockquote>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-4.png" alt="相对位置偏移-4"></p>
<p>之前计算的是<strong>相对位置索引</strong>，并不是<strong>相对位置偏执参数</strong>。真正使用到的可训练参数$\widehat B$是保存在relative position bias table表里的，这个表的长度是等于（2M-1）x（2M-1）的。那么上述公式中的相对位置偏执参数B是根据上面的相对位置索引表根据查<code>relative position bias table</code>表得到的，如下图所示。</p>
<p><code>（2M-1）x（2M-1）</code>：行和列的范围都是[-M+1，M-1]，以M = 2为例，范围都是[-1，1]，可以取到的值为-1，0，1三种，所以进行行和列的排列组合之后一共会有3x3=9中可能，即对应（2M-1）x（2M-1），也就是下图中relative position bias table的个数。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB%E5%8F%82%E6%95%B0.png" alt="相对位置偏移参数"></p>
<p><strong>注意：上图中得到的relative position bias才是最终要带入下图公式的B</strong>，也就是说最终训练过程中用到的参数实际上是relative position bias table对应的参数。而relative position index只要窗口大小是固定的，那么它本身也会是固定的。</p>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E5%85%AC%E5%BC%8F.png" alt="相对位置偏移-公式"></p>
<h1>模型详细配置参数</h1>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Swin Transformer网络架构图"></p>
<p>下图（表7）是原论文中给出的关于不同Swin Transformer的配置，T(Tiny)，S(Small)，B(Base)，L(Large)，其中：</p>
<ul>
<li>concat 4x4，96-d，LN<code>：Patch Partition+Linear Embedding，相当于Stage2、3、4中的Patch Partition，都是对输入特征矩阵进行下采样以及调整特征矩阵的channel，再通过一个Linear Norm进行输出，</code>4x4<code>即将高和宽下采样4倍，</code>96`即通过Linear Embedding之后特征矩阵channel变为96；</li>
<li><code>win. sz. 7x7</code>：使用的窗口（Windows）的大小；</li>
<li><code>dim</code>：feature map的channel深度（或者说token的向量长度），例如<code>dim 96</code>即通过swin transformer block之后输出的特征矩阵的channel是96；</li>
<li><code>head</code>：多头注意力模块中head的个数。</li>
</ul>
<p><img src="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/%E6%A8%A1%E5%9E%8B%E8%AF%A6%E7%BB%86%E5%8F%82%E6%95%B0.png" alt="模型详细参数"></p>
<p>注意：<strong>Swin Transformer Block在堆叠过程当中是两两一组，即W-MSA和SW-MSA，所以堆叠Block都是偶数倍</strong>。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>Swin Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（二十四）使用Pytorch搭建Swin Transformer网络</title>
    <url>/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1>工程目录</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── swin_transformer</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── my_dataset.py（数据处理文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,swin transformer.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── swin_tiny_patch4_window7_224.pth（迁移学习，提前下载好swin_tiny_patch4_window7_224.pth权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h1>Swin-T网络结构</h1>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Swin Transformer网络架构图"></p>
<h1>Swin Transformer网络参数表</h1>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E8%AF%A6%E7%BB%86%E5%8F%82%E6%95%B0.png" alt="Swin Transformer网络参数表"></p>
<h1>模型文件</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; Swin Transformer</span></span><br><span class="line"><span class="string">A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`</span></span><br><span class="line"><span class="string">    - https://arxiv.org/pdf/2103.14030</span></span><br><span class="line"><span class="string">Code/weights from https://github.com/microsoft/Swin-Transformer</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.utils.checkpoint <span class="keyword">as</span> checkpoint</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path_f</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">window_partition</span>(<span class="params">x, window_size: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">window_reverse</span>(<span class="params">windows, window_size: <span class="built_in">int</span>, H: <span class="built_in">int</span>, W: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size=<span class="number">4</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">96</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PatchMerging</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mlp</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WindowAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, window_size, num_heads, qkv_bias=<span class="literal">True</span>, attn_drop=<span class="number">0.</span>, proj_drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, num_heads, window_size=<span class="number">7</span>, shift_size=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>, drop_path=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 act_layer=nn.GELU, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, attn_mask</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, depth, num_heads, window_size,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 drop_path=<span class="number">0.</span>, norm_layer=nn.LayerNorm, downsample=<span class="literal">None</span>, use_checkpoint=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_mask</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size=<span class="number">4</span>, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">96</span>, depths=(<span class="params"><span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">2</span></span>), num_heads=(<span class="params"><span class="number">3</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span></span>),</span></span><br><span class="line"><span class="params">                 window_size=<span class="number">7</span>, mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 drop_rate=<span class="number">0.</span>, attn_drop_rate=<span class="number">0.</span>, drop_path_rate=<span class="number">0.1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer=nn.LayerNorm, patch_norm=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 use_checkpoint=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self, m</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_tiny_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_small_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window12_384</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window7_224_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window12_384_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_large_patch4_window7_224_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_large_patch4_window12_384_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h2 id="Swin-Transformer类">Swin Transformer类</h2>
<p>SwinTransformer类继承来自于官方的nn.Module父类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformer</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; Swin Transformer</span></span><br><span class="line"><span class="string">        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -</span></span><br><span class="line"><span class="string">          https://arxiv.org/pdf/2103.14030</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        patch_size (int | tuple(int)): Patch size. Default: 4</span></span><br><span class="line"><span class="string">        in_chans (int): Number of input image channels. Default: 3</span></span><br><span class="line"><span class="string">        num_classes (int): Number of classes for classification head. Default: 1000</span></span><br><span class="line"><span class="string">        embed_dim (int): Patch embedding dimension. Default: 96</span></span><br><span class="line"><span class="string">        depths (tuple(int)): Depth of each Swin Transformer layer.</span></span><br><span class="line"><span class="string">        num_heads (tuple(int)): Number of attention heads in different layers.</span></span><br><span class="line"><span class="string">        window_size (int): Window size. Default: 7</span></span><br><span class="line"><span class="string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4</span></span><br><span class="line"><span class="string">        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True</span></span><br><span class="line"><span class="string">        drop_rate (float): Dropout rate. Default: 0</span></span><br><span class="line"><span class="string">        attn_drop_rate (float): Attention dropout rate. Default: 0</span></span><br><span class="line"><span class="string">        drop_path_rate (float): Stochastic depth rate. Default: 0.1</span></span><br><span class="line"><span class="string">        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.</span></span><br><span class="line"><span class="string">        patch_norm (bool): If True, add normalization after patch embedding. Default: True</span></span><br><span class="line"><span class="string">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="初始化函数"><strong>初始化函数</strong></h3>
<p><strong>传入的参数：</strong></p>
<ul>
<li><code>patch_size</code>：在Swin Transformer网络架构图中，<strong>经过Stage1前面的Patch Partition之后下采样多少倍</strong>，根据网络架构图，为下采样4倍，也就是高度和宽度都下采样4倍，因此patch_size = 4；</li>
<li><code>in_chans</code>：输入图片的深度，该处输入的为RGB彩色图像，因此in_chans = 3；</li>
<li><code>num_classes</code>：分类类别数；</li>
<li><code>embed_dim</code>：指通过Stage1的Linear Embedding之后映射得到的，即<strong>Swin Transformer网络架构图中的C</strong>，因此在通过Stage1的Linear Embedding之后的搭配的C为96，且之后的Stage输出的channel直接翻倍即可；</li>
<li><code>depths</code>：对应<strong>每一个Stage当中重复使用Swin Transformer Block的次数</strong>，例如对应Swin-T此处为（2，2，6，2）；</li>
<li><code>num_heads</code>：<strong>在Swin Transformer Block中所采用的Muti-Head self-Attention的head个数</strong>，对应Swin-T的网络参数表的head个数为（3，6，12，24）；</li>
<li><code>window_size</code>：对应W-MSA和SW-MSA所采用window的大小；</li>
<li><code>mlp_ratio</code>：在Mlp模块当中，第一个全连接层将channel给翻多少倍；</li>
<li><code>qkv_bias</code>：在Muti-Head self-Attention模块当中是否使用偏置；</li>
<li><code>drop_rate</code>：第一个drop_rate除了在pos_drop中使用到，还在mlp以及其他地方使用到；</li>
<li><code>attn_drop_rate</code>：对应在Muti-Head self-Attention模块当中所采用的drop_rate；</li>
<li><code>drop_path_rate</code>：对应每一个Swin Transformer Block所采用的drop_rate（注意：<strong>drop_path_rate在Swin Transformer Block当中是递增的</strong>）；</li>
<li><code>norm_layer</code>：默认使用LayerNorm；</li>
<li><code>patch_norm</code>：如果使用的话，会在patch embedding之后使用；</li>
<li><code>use_checkpoint：</code>官方给出介绍是使用的话会减少内存的，但官方代码False；</li>
</ul>
<p><strong>代码语句解释：</strong></p>
<p><code>self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))</code>：stage4输出特征矩阵的channels = C * 2^3 = 8C；</p>
<p><code>self.patch_embed = PatchEmbed(...)</code>：将图片划分为一个个没有重叠的patches，对应的是Stage1前面的Patch Partition以及STage1的Patch Embedding（具体实现方式可看后文PatchEmbed类）；</p>
<p><code>dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]</code>：关于drop_path_rate的设置，对于一系列Swin Transformer Block当中，所采用的drop_rate是从0慢慢增长到所指定的drop_path_rate。此处直接使用官方的linspace方法，指定初始的数值0，以及末尾的数值drop_path_rate，和步数sum(depths)，即会自动生成针对每一个Swin Transformer Block所采用的drop_rate；</p>
<p>创建一个<code>self.layers = nn.ModuleList()</code>，将会通过一个循环来遍历生成每个Stage；</p>
<blockquote>
<p>注意：<strong>代码与Swub-T的网络结构图有些差异</strong>。</p>
<p>在图中每个Stage是<strong>先进行Patch Merging之后接着一个Swin Transformer Block</strong>（Stage1是先进行Linear Embedding之后接着一个Swin Transformer Block），也就是图中虚线的部分。</p>
<p>但在源码中，在通过循环来遍历生成每个Stage中，是<strong>先进行Swin Transformer Block，后接着一个Patch Merging</strong>（在Stage4的Swin Transformer Block后已经没有Patch Merging，所以只有Swin Transformer Block），等于是将图中的虚线向右平移了一个模块。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layers = BasicLayer(dim=<span class="built_in">int</span>(embed_dim * <span class="number">2</span> ** i_layer),</span><br><span class="line">                        depth=depths[i_layer],</span><br><span class="line">                        num_heads=num_heads[i_layer],</span><br><span class="line">                        window_size=window_size,</span><br><span class="line">                        mlp_ratio=self.mlp_ratio,</span><br><span class="line">                        qkv_bias=qkv_bias,</span><br><span class="line">                        drop=drop_rate,</span><br><span class="line">                        attn_drop=attn_drop_rate,</span><br><span class="line">                        drop_path=dpr[<span class="built_in">sum</span>(depths[:i_layer]):<span class="built_in">sum</span>(depths[:i_layer + <span class="number">1</span>])],</span><br><span class="line">                        norm_layer=norm_layer,</span><br><span class="line">                        downsample=PatchMerging <span class="keyword">if</span> (i_layer &lt; self.num_layers - <span class="number">1</span>) <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                        use_checkpoint=use_checkpoint)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>dim=int(embed_dim * 2 ** i_layer)</code>：对于每一个Stage而言，所传入的特征矩阵的dimension都是前一个Stage的dimension的2倍；</li>
<li><code>depth=depths[i_layer]</code>：在当前的Stage当中，要重复堆叠多少次Swin Transformer Block，即可在depths列表中取对应索引的元素；</li>
<li><code>downsample=PatchMerging if (i_layer &lt; self.num_layers - 1) else None</code>：针对每一个Stage所包含的Patch Merging是接在Swin Transformer Block后面的（也就是前文提到的原码与网络结构图不相符的地方），<strong>因此进行了判断，如果当前在Stage1、2、3，则需要使用Patch Merging，如果是Stage4，则不需要使用</strong>（详细可看后文的PatchMerging类详解）；</li>
</ul>
<p>对于之后的classifier分类层而言，还需通过一个norm层、自适应全局平均池化、全连接层进行输出。</p>
<p><code>self.apply(self._init_weights)</code>：之后通过apply方法调用_init_weights对模型进行权重初始化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size=<span class="number">4</span>, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">96</span>, depths=(<span class="params"><span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">2</span></span>), num_heads=(<span class="params"><span class="number">3</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span></span>),</span></span><br><span class="line"><span class="params">                 window_size=<span class="number">7</span>, mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 drop_rate=<span class="number">0.</span>, attn_drop_rate=<span class="number">0.</span>, drop_path_rate=<span class="number">0.1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer=nn.LayerNorm, patch_norm=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 use_checkpoint=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.num_layers = <span class="built_in">len</span>(depths)</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.patch_norm = patch_norm</span><br><span class="line">        <span class="comment"># stage4输出特征矩阵的channels = C * 2^3 = 8C</span></span><br><span class="line">        self.num_features = <span class="built_in">int</span>(embed_dim * <span class="number">2</span> ** (self.num_layers - <span class="number">1</span>))</span><br><span class="line">        self.mlp_ratio = mlp_ratio</span><br><span class="line"></span><br><span class="line">        <span class="comment"># split image into non-overlapping patches</span></span><br><span class="line">        self.patch_embed = PatchEmbed(</span><br><span class="line">            patch_size=patch_size, in_c=in_chans, embed_dim=embed_dim,</span><br><span class="line">            norm_layer=norm_layer <span class="keyword">if</span> self.patch_norm <span class="keyword">else</span> <span class="literal">None</span>)</span><br><span class="line">        self.pos_drop = nn.Dropout(p=drop_rate)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># stochastic depth</span></span><br><span class="line">        dpr = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, <span class="built_in">sum</span>(depths))]  <span class="comment"># stochastic depth decay rule</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># build layers</span></span><br><span class="line">        self.layers = nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> i_layer <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layers):</span><br><span class="line">            <span class="comment"># 注意这里构建的stage和论文图中有些差异</span></span><br><span class="line">            <span class="comment"># 这里的stage不包含该stage的patch_merging层，包含的是下个stage的</span></span><br><span class="line">            layers = BasicLayer(dim=<span class="built_in">int</span>(embed_dim * <span class="number">2</span> ** i_layer),</span><br><span class="line">                                depth=depths[i_layer],</span><br><span class="line">                                num_heads=num_heads[i_layer],</span><br><span class="line">                                window_size=window_size,</span><br><span class="line">                                mlp_ratio=self.mlp_ratio,</span><br><span class="line">                                qkv_bias=qkv_bias,</span><br><span class="line">                                drop=drop_rate,</span><br><span class="line">                                attn_drop=attn_drop_rate,</span><br><span class="line">                                drop_path=dpr[<span class="built_in">sum</span>(depths[:i_layer]):<span class="built_in">sum</span>(depths[:i_layer + <span class="number">1</span>])],</span><br><span class="line">                                norm_layer=norm_layer,</span><br><span class="line">                                downsample=PatchMerging <span class="keyword">if</span> (i_layer &lt; self.num_layers - <span class="number">1</span>) <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                                use_checkpoint=use_checkpoint)</span><br><span class="line">            self.layers.append(layers)</span><br><span class="line"></span><br><span class="line">        self.norm = norm_layer(self.num_features)</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool1d(<span class="number">1</span>)</span><br><span class="line">        self.head = nn.Linear(self.num_features, num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">        self.apply(self._init_weights)</span><br></pre></td></tr></table></figure>
<p><strong>初始化权重函数</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self, m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">            nn.init.trunc_normal_(m.weight, std=<span class="number">.02</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear) <span class="keyword">and</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.LayerNorm):</span><br><span class="line">            nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            nn.init.constant_(m.weight, <span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="正向传播函数"><strong>正向传播函数</strong></h3>
<p>首先对于传入的x先进行patch_embed方法对图像进行下采样4倍，然后就得到输出特征矩阵和对应的H，W（此时x对应的通道排列顺序是<code>[B, L, C]</code>）。</p>
<p>之后通过Dropout层按照一定的比例随机丢失一部分输入。</p>
<p>之后遍历初始化函数中创建的layers，也就是nn.ModuleList()。遍历之后就能将数据依次通过Stage1、2、3、4，对应每一个Stage将x和当前的H，W传入，就能得到该Stage之后得到的x输出以及H，W，然后再传入到下一个Stage当中。</p>
<p>当得到Stage4的输出之后，进行一个LayerNorm层（此时x对应的通道排列顺序是<code>[B, L, C]</code>）。通过transpose方法将L和C互换位置（此时x对应的通道排列顺序是<code>[B, C, L]</code>），通过自适应的平均池化avgpool，将L池化为1（此时x对应的通道排列顺序是<code>[B, C, 1]</code>）。</p>
<p>再通过flatten方法从C维度开始向后展平（此时x对应的通道排列顺序是<code>[B, C]</code>），最后再通过一个head全连接层得到输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x: [B, L, C]</span></span><br><span class="line">        x, H, W = self.patch_embed(x)</span><br><span class="line">        x = self.pos_drop(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x, H, W = layer(x, H, W)</span><br><span class="line"></span><br><span class="line">        x = self.norm(x)  <span class="comment"># [B, L, C]</span></span><br><span class="line">        x = self.avgpool(x.transpose(<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># [B, C, 1]</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.head(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="PatchEmbed类">PatchEmbed类</h2>
<ul>
<li><code>patch_size</code>：下采样的倍率；</li>
<li><code>in_c</code>：输入图像的深度；</li>
<li><code>embed_dim</code>：通过Stage1的Linear Embedding之后映射得到的深度；</li>
<li><code>norm_layer</code>：传入的LayerNorm</li>
</ul>
<p><strong>初始化函数</strong></p>
<p>创建一个卷积层，下采样其实就是通过卷积层实现的，因此输入特征矩阵的channel为in_c，输出特征矩阵的channel为embed_dim，卷积核大小为patch_size，步距也为patch_size。</p>
<p>如果有传入norm_layer则直接使用传入的，如果没有传入则直接做线性映射（指不做处理）</p>
<p><strong>正向传播函数</strong></p>
<p>首先获取传入图像的高宽，之后进行判断（如果图像的高度或者宽度不是patch_size的整数倍，则需要进行padding）。如果pad_input = True的话，也就是说明高或者宽不是patch_size的整数倍，需要进行padding，则直接使用官方的pad方法对x进行padding。</p>
<blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># (W_left, W_right, H_top,H_bottom, C_front, C_back)</span></span><br><span class="line"><span class="comment"># 左右上下前后</span></span><br><span class="line">x = F.pad(x, (<span class="number">0</span>, self.patch_size[<span class="number">1</span>] - W % self.patch_size[<span class="number">1</span>],</span><br><span class="line">                       <span class="number">0</span>, self.patch_size[<span class="number">0</span>] - H % self.patch_size[<span class="number">0</span>],</span><br><span class="line">                       <span class="number">0</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>会对宽度方向的右侧以及高度方向的底部padding</p>
</blockquote>
<p>经过padding之后H，W即为patch_size的整数倍，则可以直接使用下采样层（也就是卷积层）。下采样之后，记录以下此刻的H，W。再对x进行维度2上开始展平处理（即<code>flatten: [B, C, H, W] -&gt; [B, C, HW]</code>），再通过transpose将位置1，2上的数据进行交换（即<code>transpose: [B, C, HW] -&gt; [B, HW, C]</code>）。</p>
<p>最后再用LayerNorm层对channel维度做LayerNorm的处理之后，返回此时的特征矩阵，以及通过下采样之后的H，W。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    2D Image to Patch Embedding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size=<span class="number">4</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">96</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        patch_size = (patch_size, patch_size)</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        self.in_chans = in_c</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)</span><br><span class="line">        self.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        _, _, H, W = x.shape</span><br><span class="line"></span><br><span class="line">        <span class="comment"># padding</span></span><br><span class="line">        <span class="comment"># 如果输入图片的H，W不是patch_size的整数倍，需要进行padding</span></span><br><span class="line">        pad_input = (H % self.patch_size[<span class="number">0</span>] != <span class="number">0</span>) <span class="keyword">or</span> (W % self.patch_size[<span class="number">1</span>] != <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> pad_input:</span><br><span class="line">            <span class="comment"># to pad the last 3 dimensions,</span></span><br><span class="line">            <span class="comment"># (W_left, W_right, H_top,H_bottom, C_front, C_back)</span></span><br><span class="line">            x = F.pad(x, (<span class="number">0</span>, self.patch_size[<span class="number">1</span>] - W % self.patch_size[<span class="number">1</span>],</span><br><span class="line">                          <span class="number">0</span>, self.patch_size[<span class="number">0</span>] - H % self.patch_size[<span class="number">0</span>],</span><br><span class="line">                          <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下采样patch_size倍</span></span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        <span class="comment"># 224,224 -&gt; 56,56</span></span><br><span class="line">        _, _, H, W = x.shape</span><br><span class="line">        <span class="comment"># flatten: [B, C, H, W] -&gt; [B, C, HW] = [B,96,4,4] -&gt; [B,96,56x56]</span></span><br><span class="line">        <span class="comment"># transpose: [B, C, HW] -&gt; [B, HW, C] = [B,96,16] -&gt; [B,56x56,96]</span></span><br><span class="line">        x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> x, H, W</span><br></pre></td></tr></table></figure>
<h2 id="PatchMerfing类">PatchMerfing类</h2>
<p><strong>初始化函数</strong></p>
<p><code>self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)</code>：创建全连接层，输入的dimension是4倍的dim，输出的dimension是2倍的dim</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Patch-Merging.png" alt="Patch Merging"></p>
<p>如上图所示，在Patch Merging中，首先是把输入的feature map每2x2做一个窗口进行分割，分割之后同样位置上的元素进行拼接得到4个特征矩阵（上图（上中）），再通过channel方向进行concat拼接（上图（上右）），拼接之后在channel方向进行LayerNorm处理（上图（下右）），最后再通过全连接Linear层做一个线性的映射（上图（下中））。</p>
<p>对于全连接层而言，输入特征矩阵的channel = 最原始（上图（上左））的feature map的channel = 4，因此设置为4*dim。输出的特征矩阵channel是将上图（下右）的特征矩阵channel减半，也就是从4*dim变为2*dim。</p>
<p><code>self.norm = norm_layer(4 * dim)</code>：对应的是上图（下右），因此使用4*dim。</p>
<p><strong>正向传播函数</strong></p>
<p><code>forward(self, x, H, W)</code>：x为输入的数据，H，W为记录输入当前特征矩阵的高宽。因为当前输入的特征矩阵的通道排列顺序是x: B, H*W, C，所以只知道高和宽的乘积，并不知道分别的数是多少；</p>
<p><code>pad_input = (H % 2 == 1) or (W % 2 == 1)</code>：因为在PatchMerfing当中是需要下采样2倍的，如果传入的x的高和宽不是2的整数倍的话，需要进行padding；</p>
<blockquote>
<p>如果H或者W不是2的整数倍的话，pad_input = True，则需要进行padding。注意此时x的通道排列顺序是[B，H，W，C]，pad方法是pad最后三个维度，也就是这里的H，W，C。</p>
<p><code>x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))</code>：这里给出的参数，是从最后一个维度向前设置的。也就是说<code>(0, 0, 0, W % 2, 0, H % 2)</code>最前面的0，0是针对C维度上的padding的参数，后面两个0, W % 2是针对在W方向上padding的参数（宽度方向的右侧补一列0），0, H % 2是针对在H方向上padding的参数（高度方向的底部补一行0）。</p>
<p>即保证H，W是2的整数倍，就可以进行下采样了。</p>
</blockquote>
<p>因为是要把输入的feature map分成一个个窗口，再将相同位置处拼接在一起（<strong>此时x的通道排列顺序是[B，H，W，C]</strong>）。以上文x0为例，batch维度取所有值，在高度和宽度方向首先都从0开始，所对应的就是上图（上左）中蓝色区域的位置，在高度和宽度方向上都是以2为间隔进行采样的，在channel维度上也是取所有值，因此<code>x0 = x[:, 0::2, 0::2, :]</code>，于是就可以构建上图（上中）蓝色的feature map。</p>
<ul>
<li><code>x1 = x[:, 1::2, 0::2, :]</code>：在x1中对应的的绿色的区域，高度1，宽度0，在高度和宽度方向上都是以2为间隔进行采样的，拼接之后输出为<code>[B, H/2, W/2, C]</code>；</li>
<li><code>x2 = x[:, 0::2, 1::2, :]</code>：在x2中对应的的黄色的区域，高度0，宽度1，在高度和宽度方向上都是以2为间隔进行采样的，拼接之后输出为<code>[B, H/2, W/2, C]</code>；</li>
<li><code>x3 = x[:, 1::2, 1::2, :]</code>：在x3中对应的的红色的区域，高度1，宽度1，在高度和宽度方向上都是以2为间隔进行采样的，拼接之后输出为<code>[B, H/2, W/2, C]</code>；</li>
</ul>
<p><code>x = torch.cat([x0, x1, x2, x3], -1)</code>：之后就可以在channel维度上进行concat拼接了，-1指的是最后一个维度，最后一个维度也就是深度channel维度，拼接之后输出为<code>[B, H/2, W/2, 4*C]</code>。</p>
<p><code>x = x.view(B, -1, 4 * C)</code>：再通过view函数进行展平处理，展平之后输出为<code>[B, H/2*W/2, 4*C]</code></p>
<p><code>x = self.reduction(x)</code>：最后通过创建的全连接层，将<code>[B, H/2*W/2, 4*C]-&gt;[B, H/2*W/2, 2*C]</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchMerging</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; Patch Merging Layer.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.reduction = nn.Linear(<span class="number">4</span> * dim, <span class="number">2</span> * dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.norm = norm_layer(<span class="number">4</span> * dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        x: B, H*W, C</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, L, C = x.shape</span><br><span class="line">        <span class="keyword">assert</span> L == H * W, <span class="string">&quot;input feature has wrong size&quot;</span></span><br><span class="line"></span><br><span class="line">        x = x.view(B, H, W, C)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># padding</span></span><br><span class="line">        <span class="comment"># 如果输入feature map的H，W不是2的整数倍，需要进行padding</span></span><br><span class="line">        pad_input = (H % <span class="number">2</span> == <span class="number">1</span>) <span class="keyword">or</span> (W % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> pad_input:</span><br><span class="line">            <span class="comment"># to pad the last 3 dimensions, starting from the last dimension and moving forward.</span></span><br><span class="line">            <span class="comment"># (C_front, C_back, W_left, W_right, H_top, H_bottom)</span></span><br><span class="line">            <span class="comment"># 注意这里的Tensor通道是[B, H, W, C]，所以会和官方文档有些不同</span></span><br><span class="line">            x = F.pad(x, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, W % <span class="number">2</span>, <span class="number">0</span>, H % <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        x0 = x[:, <span class="number">0</span>::<span class="number">2</span>, <span class="number">0</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">        x1 = x[:, <span class="number">1</span>::<span class="number">2</span>, <span class="number">0</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">        x2 = x[:, <span class="number">0</span>::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">        x3 = x[:, <span class="number">1</span>::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">        x = torch.cat([x0, x1, x2, x3], -<span class="number">1</span>)  <span class="comment"># [B, H/2, W/2, 4*C]</span></span><br><span class="line">        x = x.view(B, -<span class="number">1</span>, <span class="number">4</span> * C)  <span class="comment"># [B, H/2*W/2, 4*C]</span></span><br><span class="line"></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        x = self.reduction(x)  <span class="comment"># [B, H/2*W/2, 2*C]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="BasicLayer类">BasicLayer类</h2>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Swin Transformer-T网络架构图"></p>
<p>在这个类当中就是实现每一个Stage，在这个类当中，有传入一系列参数，前文有提到，这里不再赘述。</p>
<p>注意：<code>shift_size</code>：比如说我们在使用SW-MSA模块时，要将窗口向右以及向下偏移多少个像素，所以这里是<code>self.shift_size = window_size // 2</code>（上篇文章有讲）。</p>
<p>创建一个nn.ModuleList的blocks，这里的blocks存储的是在当前Stage中所构建的所有的Swin Transformer Block。那么对于Swin Transformer Block有传入<code>dim、num_heads、window_size、shift_size......</code>。</p>
<p>（注意：<strong>对于Swin Transformer Block而言，需要依次使用上图（b）的两个block，W-MSA和SW-MSA，这二者间是成对使用的</strong>），因此<code>shift_size=0 if (i % 2 == 0) else self.shift_size</code>存在判断，通过循环遍历depth次<code>for i in range(depth)</code>。比如说对于Stage1而言，这里是2次的话，这里的range循环就是两次，就用i对2取余数。<strong>比如说当i == 0时，对2取余为0，就意味着当前这个block所采用的是W-MSA；当i == 1的时候，就会将self.shift_size定为它本身，之后会通过判断self.shift_size是否等于0来判断去判断使用的是W-MSA还是SW-MSA</strong>。</p>
<p><code>downsample</code>：对应的是patch merging类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicLayer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A basic Swin Transformer layer for one stage.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        depth (int): Number of blocks.</span></span><br><span class="line"><span class="string">        num_heads (int): Number of attention heads.</span></span><br><span class="line"><span class="string">        window_size (int): Local window size.</span></span><br><span class="line"><span class="string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.</span></span><br><span class="line"><span class="string">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True</span></span><br><span class="line"><span class="string">        drop (float, optional): Dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        attn_drop (float, optional): Attention dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0</span></span><br><span class="line"><span class="string">        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm</span></span><br><span class="line"><span class="string">        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None</span></span><br><span class="line"><span class="string">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, depth, num_heads, window_size,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 drop_path=<span class="number">0.</span>, norm_layer=nn.LayerNorm, downsample=<span class="literal">None</span>, use_checkpoint=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.depth = depth</span><br><span class="line">        self.window_size = window_size</span><br><span class="line">        self.use_checkpoint = use_checkpoint</span><br><span class="line">        self.shift_size = window_size // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># build blocks</span></span><br><span class="line">        self.blocks = nn.ModuleList([</span><br><span class="line">            SwinTransformerBlock(</span><br><span class="line">                dim=dim,</span><br><span class="line">                num_heads=num_heads,</span><br><span class="line">                window_size=window_size,</span><br><span class="line">                shift_size=<span class="number">0</span> <span class="keyword">if</span> (i % <span class="number">2</span> == <span class="number">0</span>) <span class="keyword">else</span> self.shift_size,</span><br><span class="line">                mlp_ratio=mlp_ratio,</span><br><span class="line">                qkv_bias=qkv_bias,</span><br><span class="line">                drop=drop,</span><br><span class="line">                attn_drop=attn_drop,</span><br><span class="line">                drop_path=drop_path[i] <span class="keyword">if</span> <span class="built_in">isinstance</span>(drop_path, <span class="built_in">list</span>) <span class="keyword">else</span> drop_path,</span><br><span class="line">                norm_layer=norm_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># patch merging layer</span></span><br><span class="line">        <span class="keyword">if</span> downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.downsample = downsample(dim=dim, norm_layer=norm_layer)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.downsample = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_mask</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line">     </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h3 id="create-mask">create_mask</h3>
<p>为了防止传入的H和W不是window_size的整数倍，所以会首先将H和W分别除以self.window_size然后向上取整，之后再乘以self.window_size，得到新的H padding之后的值以及W padding之后的值（对于mask而言）。</p>
<p>之后创建一个<code>img_mask</code>，通过zero方法来初始化，shape为<code>1，Hp，Wp，1</code>，设备与传入的x的设备一致（设置为这样的shape是因为：在后面window partition方法中所要求传入的Tensor的shape是这样的）</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%8E%9F%E6%95%B0%E6%8D%AE.png" alt="举例SW-MSA-原数据"></p>
<p>接下来是<code>h_slices</code>和<code>w_slices</code>，二者是一样的，以h_slices为例子。首先通过slice（切片）方法，以上图为例，假设输入的是9x9的feature map，窗口是3x3的，假设需要使用一个shifted window的话，首先用m/2向下取整，再通过指定的window去重新划分window（下图所示）。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%81%8F%E7%A7%BB%E5%88%86%E5%89%B2%E4%B9%8B%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE.png" alt="举例SW-MSA-偏移分割之后的数据"></p>
<p>由代码来看，一共由3个切片，<strong>slice（a，b），a取b不取</strong>。</p>
<blockquote>
<p>以h_slices举例：</p>
<p>第一个切片是从0到-window_size。对于下图的例子而言window_size = 3，也就是从0到-3，从下图来看，0是第一行第一列，-1是第一列最后一行，-2是第一列倒数第二行，-3是第一列倒数第三行，因此需要取黄色区域就是0到-3；</p>
<p>第二个切片是从-window_size到-self.shift_size，shift_size也就是m/2向下取整，对于下图例子而言，也就是-3到-1，也就是-3是第一列倒数第三行，-1是第一列最后一行，即紫色区域；</p>
<p>第三个切片是从-shift_size到None（末尾），对于下图例子而言，也就是-1到最后，即绿色区域；</p>
<p>w_slices同理，对应的区域就是下图中横着的大括号区域。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">h_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">w_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%88%87%E7%89%87.png" alt="举例SW-MSA-切片"></p>
<p>之后进入一个循环，首先将cnt设置为0，然后遍历h_slices，当h为第一个切片的时候（0到-window_size，对应上图竖着的最大的大括号），再遍历w_slices（0到-window_size，对应上图横着的最大的大括号），那么在对应img_mask给定的h和w切片设置为cnt的数值，最开始cnt=0，当进行完一个区域的循环之后，会进行cnt+1。</p>
<p>因此，经过上一段对切片循环的操作，可以给同一块区域的格子赋值为同一个数字，又可以保证不同区域的数值不一样，也就是上图（右）所示（<strong>相同的数字对应的是连续的区域</strong>）。</p>
<p><code>mask_windows = window_partition(img_mask, self.window_size)</code>：接下来通过window_partition方法对img_mask划分为一个一个窗口，这里除了传入img_mask之外，还传入了window_size，也就是窗口的尺寸。</p>
<p>通过<code>window_partition</code>函数之后就将根据mask按照所指定的window_size划分成一个个窗口了，也就是下图中，将其划分为一个个窗口的形式。例子中是大小3x3的窗口尺寸，因此这里有9个window。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%88%92%E5%88%86%E7%AA%97%E5%8F%A3%E5%BD%A2%E5%BC%8F.png" alt="举例SW-MSA-划分窗口形式"></p>
<p>因为刚刚通过window_partition处理输出的通道排列顺序是<code>[nW, Mh, Mw, 1]</code>，因为window_partition所返回的第一个维度是<code>batch*num_windows</code>，又因为这里的batch = 1，所以这里第一个维度就是对应的<code>num_windows</code>，之后对应的是窗口的高度，窗口的宽度，和最后的维度1。</p>
<p>所以接下来进行view处理，将后三个维度展平成一个维度，即<code>[nW, Mh, Mw, 1]-&gt;[nW, Mh*Mw]</code>，第一个维度自己去推理，第二个维度就是window_size*window_size，即Mh*Mw。</p>
<p>接下来再将<code>mask_windows</code>用<code>unsqueeze</code>方法在维度1上新加一个维度，也就是在nW和Mh*Mw之间新增一个维度。然后减去<code>mask_windows.unsqueeze(2)</code>，也就是在Mh*Mw后面这个地方新增一个维度。然后让这两个数据进行相减，得到attn_mask。</p>
<blockquote>
<p>以下图来作解释。在刚刚以及划分了9个窗口，再通过<code>mask_windows = mask_windows.view(-1, self.window_size * self.window_size)</code>之后是将高度宽度全部展平，因此以及将每一个window全部展平了（下图右），按行展平得到1-9个行向量。</p>
<p>对于第一个特征矩阵<code>mask_windows.unsqueeze(1)</code>，shape对应的是<code>[nW, 1, Mh*Mw]</code>，对于第二个特征矩阵<code>mask_windows.unsqueeze(2)</code>，shape对应的是<code>[nW, Mh*Mw, 1]</code>，<strong>这二者相减就会设计一个广播机制了</strong>。</p>
<p>对于第一个矩阵而言，<strong>会将<code>[nW, 1, Mh*Mw]</code>最后这个维度给复制<code>Mh*Mw</code>次，相当于将下图每一个行向量给复制<code>Mh*Mw</code>次（即一个窗口内像素的个数，例子中为9）</strong>，对于第二个矩阵，会在<code>[nW, Mh*Mw, 1]</code>最后这个维度给复制<code>Mh*Mw</code>次。</p>
</blockquote>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%B1%95%E5%B9%B3.png" alt="举例SW-MSA-展平"></p>
<p>以上图最后一个行向量为例（最复杂），下图为已经将最后一行行向量复制9次了，下图右为对应第二个特征矩阵<code>mask_windows.unsqueeze(2)</code>，将下图（左）红色框内复制9次（<strong>其实就是将1行9列的tensor按行复制9次，将9行1列的tensor按列复制9次，再相减</strong>）</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E8%A1%8C%E5%90%91%E9%87%8F%E5%A4%8D%E5%88%B69%E6%AC%A1.png" alt="举例SW-MSA-最后一个行向量复制9次"></p>
<p>之后将上图左边的矩阵减去上图右边的矩阵，第一行而言，其实就是对第一个元素进行Attention的求解，相同数字对应的同一块区域，所以做Attention其实就是想和所有数字为4的去做一个Attention。因此在第一行，会让所有数字-4。相减之后将所有数字相减成功后会得到下图的结果。</p>
<p>也就是说，同一个区域的就是用0来表示，不同的区域就是一些非零的数字。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E4%B8%A4%E4%B8%AA%E7%9F%A9%E9%98%B5%E7%9B%B8%E5%87%8F%E4%B9%8B%E5%90%8E.png" alt="举例SW-MSA-两个矩阵相减之后"></p>
<p>之后会用<code>masked_fill</code>来进一步处理，对于不等于0的区域，会填入-100，对于等于0的区域，直接写入0。比如对于上图第一行，标0的就是和当前mask同区域的元素，非0都会设置为-100。上图（右）每一行对应的就是当前这个窗口当中对应某一个像素的计算Attention时所采用的mask蒙版</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_mask</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># calculate attention mask for SW-MSA</span></span><br><span class="line">        <span class="comment"># 保证Hp和Wp是window_size的整数倍</span></span><br><span class="line">        Hp = <span class="built_in">int</span>(np.ceil(H / self.window_size)) * self.window_size</span><br><span class="line">        Wp = <span class="built_in">int</span>(np.ceil(W / self.window_size)) * self.window_size</span><br><span class="line">        <span class="comment"># 拥有和feature map一样的通道排列顺序，方便后续window_partition</span></span><br><span class="line">        img_mask = torch.zeros((<span class="number">1</span>, Hp, Wp, <span class="number">1</span>), device=x.device)  <span class="comment"># [1, Hp, Wp, 1]</span></span><br><span class="line">        h_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">                    <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">                    <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">        w_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">                    <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">                    <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">        cnt = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> h_slices:</span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> w_slices:</span><br><span class="line">                img_mask[:, h, w, :] = cnt</span><br><span class="line">                cnt += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        mask_windows = window_partition(img_mask, self.window_size)  <span class="comment"># [nW, Mh, Mw, 1]</span></span><br><span class="line">        mask_windows = mask_windows.view(-<span class="number">1</span>, self.window_size * self.window_size)  <span class="comment"># [nW, Mh*Mw]</span></span><br><span class="line">        attn_mask = mask_windows.unsqueeze(<span class="number">1</span>) - mask_windows.unsqueeze(<span class="number">2</span>)  <span class="comment"># [nW, 1, Mh*Mw] - [nW, Mh*Mw, 1]</span></span><br><span class="line">        <span class="comment"># [nW, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        attn_mask = attn_mask.masked_fill(attn_mask != <span class="number">0</span>, <span class="built_in">float</span>(-<span class="number">100.0</span>)).masked_fill(attn_mask == <span class="number">0</span>, <span class="built_in">float</span>(<span class="number">0.0</span>))</span><br><span class="line">        <span class="keyword">return</span> attn_mask</span><br></pre></td></tr></table></figure>
<p><strong>正向传播函数</strong></p>
<p>传入x和其对应的高和宽。</p>
<p><code>attn_mask = self.create_mask(x, H, W) </code>：这里首先会根据传入的x，H，W去创建create_mask，<code>create_mask</code>就是在使用SW-MSA时所采用的mask蒙版。</p>
<blockquote>
<p>因为对于一个Stage而言，假设看Stage3，会重复堆叠Swin Transformer Block6次，又<strong>因为W-MSA和SW-MSA是成对使用的，也就是说在Stage3当中会使用3次W-MSA和3次SW-MSA</strong>。又由于Swin Transformer Block不会改变特征矩阵的高宽，所以当前Stage中所使用的W-MSA和SW-MSA的mask都是一样的，所以对于当前的Stage只需要创建一次即可。</p>
</blockquote>
<p>此处<code>attn_mask = self.create_mask(x, H, W)</code>放的位置和作者源码放的不一样，因为如果输入不同尺寸的图像的话，是可以根据传入的x，H，W取重新生成mask蒙版的。但是对于源码而言，有一个input resolution，会根据这个参数一开始就将mask固定了，如果后面像传入一个其他尺寸的图片的话就会报错。因此为了解决多尺寸图片问题，就将该条代码的位置调整到这来了。</p>
<p>通过遍历初始化函数创建的blocks列表，对应的是Swin Transformer Block。</p>
<p><code>blk.H, blk.W = H, W</code>：那么通过遍历它，首先将当前这个block添加一个高度和宽度的属性，也就是这里的H，W。</p>
<p>之后进行判断，如果当前不是scripting模式并且使用这个checkpoint方法的话，就会使用pytorch官方使用的checkpoint方法（默认不使用）。直接到<code>x = blk(x, attn_mask)</code>，将传入的x以及刚刚创建的mask给传入进去，即能得到当前block的输出了。</p>
<p>通过遍历，能够将输入传递给每一个Swin Transformer Block得到对应的输出。</p>
<p>接着再判断downsample是否为None，如果不为None的话，就进行下采样操作，也就是Patch merging层（Stage4为None）</p>
<p>通过下采样之后特征矩阵的高度和宽度就是下采样的2倍，所以需要重新计算H和W，<code>H, W = (H + 1) // 2, (W + 1) // 2</code>（<strong>这里是为了防止H或者W如果是奇数的话，是要进行padding的。所以如果是奇数的话，进行+1操作再除以2就刚好等于新的H，W</strong>，如果是偶数的话，+1之后再除以2向下取整还是原来的一半）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        attn_mask = self.create_mask(x, H, W)  <span class="comment"># [nW, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> self.blocks:</span><br><span class="line">            blk.H, blk.W = H, W</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> torch.jit.is_scripting() <span class="keyword">and</span> self.use_checkpoint:</span><br><span class="line">                x = checkpoint.checkpoint(blk, x, attn_mask)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x = blk(x, attn_mask)</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.downsample(x, H, W)</span><br><span class="line">            H, W = (H + <span class="number">1</span>) // <span class="number">2</span>, (W + <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, H, W</span><br></pre></td></tr></table></figure>
<h4 id="window-partition">window_partition</h4>
<p>将feature map或者说时刚刚的img_mask按照window_size划分为一个个没有重叠的window。</p>
<p>首先获取传入进来x的shape，对应的维度是<code>(B, H, W, C)</code></p>
<p>通过view方法将<code>(B, H, W, C)</code>变为<code>[B, H//Mh, Mh, W//Mw, Mw, C] </code>，也就是<code>batch，高度除上窗口高度，窗口高度，宽度除以窗口宽度，窗口宽度，channel</code>。</p>
<p>接下来再通过permute方法调换2和3这两个维度的数据，因此<code> [B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H//Mh, W//Mh, Mw, Mw, C]</code>。因为通过permute之后数据不再连续，所以需要调用contiguous将数据再变为内存连续的数据。之后再通过view方法<code>(-1, window_size, window_size, C)</code>，第一个维度让其自动推理，因此<code>[B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B*num_windows, Mh, Mw, C]</code></p>
<blockquote>
<p>发现<code>H//Mh</code>乘上<code>W//Mw</code>正好等于window的个数，因此通过view之后，就将前三个维度划分在一起了，即变成了<code>B*num_windows</code>，之后的<code>M，M，C</code>分别对应的是<code>窗口的高度、窗口的高度、channel</code>，精确的写法为Mh和Mw</p>
</blockquote>
<p>根据如上处理后，得到的就是指定的window_size划分为一个个窗口之后的数据，并且num_windows和batch是放在一起的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">window_partition</span>(<span class="params">x, window_size: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    将feature map按照window_size划分成一个个没有重叠的window</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: (B, H, W, C)</span></span><br><span class="line"><span class="string">        window_size (int): window size(M)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        windows: (num_windows*B, window_size, window_size, C)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    B, H, W, C = x.shape</span><br><span class="line">    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)</span><br><span class="line">    <span class="comment"># permute: [B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H//Mh, W//Mh, Mw, Mw, C]</span></span><br><span class="line">    <span class="comment"># view: [B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B*num_windows, Mh, Mw, C]</span></span><br><span class="line">    windows = x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>).contiguous().view(-<span class="number">1</span>, window_size, window_size, C)</span><br><span class="line">    <span class="keyword">return</span> windows</span><br></pre></td></tr></table></figure>
<h4 id="window-reverse">window_reverse</h4>
<p>这里将一个个窗口再还原为一个feature map。</p>
<p>传入的参数有windows，window_size，H，W。H和W对应的是分割之前feature map的H和W。</p>
<p>首先计算batch维度，在window_partition输出中，第一个维度将batch和num_windows放在一起了，也就是<code>windows: (num_windows*B, window_size, window_size, C)</code>，所以如果要求B的话，需要使用<code>windows.shape[0]</code>（<code>num_windows*B</code>）除以windows的个数（<code>num_windows</code>），那么$num_windows = H/window_size*W/window_size)$。</p>
<p>再通过view方法调整通道排列顺序：<code>view: [B*num_windows, Mh, Mw, C] -&gt; [B, H//Mh, W//Mw, Mh, Mw, C]</code></p>
<p>再通过permute方法将2和3两个维度进行调换，即<code>[B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B, H//Mh, Mh, W//Mw, Mw, C]</code>，同样需要通过contiguous方法将它变为内存连续的形式，在进行view，即<code>[B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H, W, C]</code>。即与window_partition输入的shape是一样的，因此这两个函数是一个正向操作和一个反向操作的关系。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">window_reverse</span>(<span class="params">windows, window_size: <span class="built_in">int</span>, H: <span class="built_in">int</span>, W: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    将一个个window还原成一个feature map</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        windows: (num_windows*B, window_size, window_size, C)</span></span><br><span class="line"><span class="string">        window_size (int): Window size(M)</span></span><br><span class="line"><span class="string">        H (int): Height of image</span></span><br><span class="line"><span class="string">        W (int): Width of image</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        x: (B, H, W, C)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    B = <span class="built_in">int</span>(windows.shape[<span class="number">0</span>] / (H * W / window_size / window_size))</span><br><span class="line">    <span class="comment"># view: [B*num_windows, Mh, Mw, C] -&gt; [B, H//Mh, W//Mw, Mh, Mw, C]</span></span><br><span class="line">    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># permute: [B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B, H//Mh, Mh, W//Mw, Mw, C]</span></span><br><span class="line">    <span class="comment"># view: [B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H, W, C]</span></span><br><span class="line">    x = x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>).contiguous().view(B, H, W, -<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="SwinTransformerBlock">SwinTransformerBlock</h3>
<p>构建每一个swin transformer block方法。</p>
<p><strong>初始化函数</strong></p>
<p><code>WindowAttention</code>也就是对应的W-MSA或者SW-MSA。<strong>对于block而言，和下图的 Encoder Block是一样的，唯一不同在于将Muti-Head Attention换成了W-MSA或者SW-MSA</strong>。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Transformer-Encoder%E5%B1%82.png" alt="Transformer-Encoder层"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; Swin Transformer Block.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        num_heads (int): Number of attention heads.</span></span><br><span class="line"><span class="string">        window_size (int): Window size.</span></span><br><span class="line"><span class="string">        shift_size (int): Shift size for SW-MSA.</span></span><br><span class="line"><span class="string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.</span></span><br><span class="line"><span class="string">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True</span></span><br><span class="line"><span class="string">        drop (float, optional): Dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        attn_drop (float, optional): Attention dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        drop_path (float, optional): Stochastic depth rate. Default: 0.0</span></span><br><span class="line"><span class="string">        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU</span></span><br><span class="line"><span class="string">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, num_heads, window_size=<span class="number">7</span>, shift_size=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>, drop_path=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 act_layer=nn.GELU, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.window_size = window_size</span><br><span class="line">        self.shift_size = shift_size</span><br><span class="line">        self.mlp_ratio = mlp_ratio</span><br><span class="line">        <span class="keyword">assert</span> <span class="number">0</span> &lt;= self.shift_size &lt; self.window_size, <span class="string">&quot;shift_size must in 0-window_size&quot;</span></span><br><span class="line"></span><br><span class="line">        self.norm1 = norm_layer(dim)</span><br><span class="line">        self.attn = WindowAttention(</span><br><span class="line">            dim, window_size=(self.window_size, self.window_size), num_heads=num_heads, qkv_bias=qkv_bias,</span><br><span class="line">            attn_drop=attn_drop, proj_drop=drop)</span><br><span class="line"></span><br><span class="line">        self.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        self.norm2 = norm_layer(dim)</span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)</span><br><span class="line">        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)</span><br></pre></td></tr></table></figure>
<p><strong>正向传播函数</strong></p>
<p>正向传播过程中有传入x和attn_mask，首先取到当前输入的feature map的高宽，因为传入的x的shape是B、L、C，L对应的是H*W，因此有记录下H和W的值，也就是BasicLayer正向传播过程中的<code>blk.H, blk.W = H, W</code>。</p>
<p>接下来将x赋值给shortcut，之后进行<code>self.norm1(x)</code>，对应上图中的第一个LayerNorm。</p>
<p>再对x进行view处理，即<code>[B, L, C]-&gt;[B, H, W, C]</code></p>
<p>之后对传入的Hp和和Wp进行判断，对高度方向的下侧和宽度方向的右侧去判定是否要及逆行padding操作，因此先将<code>pad_l = pad_t = 0</code>，之后进行计算padding的数量。</p>
<p><code>_, Hp, Wp, _ = x.shape</code>获取在经过padding之后新的Hp和Wp。</p>
<p>对<code>shift_size</code>进行判断，如果大于0，则进行SW-MSA，如果等于0，则进行W-MSA。</p>
<blockquote>
<p>SW-MSA也就是需要将划分窗口之后的矩阵进行滑动窗口之后移动。</p>
</blockquote>
<p><code>shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))</code>需要将最上侧移到最下侧，最左侧移到最右侧。因此此处传入x，将dimension设置为1和2（也就是H，W），从上往下移即<code>-self.shift_size</code>，从左往右移即<code>-self.shift_size</code>（如果是正的，就是从下往上和从右往左）。</p>
<p>移动之后通过<code>window_partition</code>发给发将shifted划分为一个个窗口，划分之后得到的通道排列顺序为<code>[nW*B, Mh, Mw, C]</code>，再通过view方法，变为<code>[nW*B, Mh*Mw, C]</code>。</p>
<p>之后将W-MSA或者SW-MSA输入到sttn方法当中（Attention）进行正向传播，则得到输出Attention Window。</p>
<p>进行view处理，变回<code>[nW*B, Mh, Mw, C]</code>，再通过<code>window_reverse</code>方法将一个个window拼回一个feature map。得到的通道为<code>[B, H', W', C]</code></p>
<p><code>if self.shift_size &gt; 0</code>如果当前block使用了SW-MSA的话，需要将计算号的数据给还原回去，所以同样通过<code>roll</code>方法，再高度和宽度分别以shift_size行和shift_size列（因为是还原，将下侧移到上侧，将右侧移到左侧，所以为正数）。</p>
<p><code>if pad_r &gt; 0 or pad_b &gt; 0</code>：如果有进行padding的话，也需要将pad的数给移除掉。所以只取这个feature map的前H行和前W列，再通过contiguous方法让它百年城内存中连续的一个数据来。</p>
<p>再通过view方法将通道变为<code>[B, H * W, C]</code>（B，L，C）。</p>
<p>接下来将x通过<code>drop_path</code>和shortcut进行相加得到x，也就是对应上图block第一个shortcut相加。</p>
<p>再将x通过norm2和drop_path再将x进行相加得到最终的输出（这一步相当于上图block的上半部分全部做完了）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, attn_mask</span>):</span><br><span class="line">    H, W = self.H, self.W</span><br><span class="line">    B, L, C = x.shape</span><br><span class="line">    <span class="keyword">assert</span> L == H * W, <span class="string">&quot;input feature has wrong size&quot;</span></span><br><span class="line"></span><br><span class="line">    shortcut = x</span><br><span class="line">    x = self.norm1(x)</span><br><span class="line">    x = x.view(B, H, W, C)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pad feature maps to multiples of window size</span></span><br><span class="line">    <span class="comment"># 把feature map给pad到window size的整数倍</span></span><br><span class="line">    pad_l = pad_t = <span class="number">0</span></span><br><span class="line">    pad_r = (self.window_size - W % self.window_size) % self.window_size</span><br><span class="line">    pad_b = (self.window_size - H % self.window_size) % self.window_size</span><br><span class="line">    x = F.pad(x, (<span class="number">0</span>, <span class="number">0</span>, pad_l, pad_r, pad_t, pad_b))</span><br><span class="line">    _, Hp, Wp, _ = x.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># cyclic shift</span></span><br><span class="line">    <span class="keyword">if</span> self.shift_size &gt; <span class="number">0</span>:</span><br><span class="line">        shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shifted_x = x</span><br><span class="line">            attn_mask = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># partition windows</span></span><br><span class="line">            x_windows = window_partition(shifted_x, self.window_size)  <span class="comment"># [nW*B, Mh, Mw, C]</span></span><br><span class="line">            x_windows = x_windows.view(-<span class="number">1</span>, self.window_size * self.window_size, C)  <span class="comment"># [nW*B, Mh*Mw, C]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># W-MSA/SW-MSA</span></span><br><span class="line">            attn_windows = self.attn(x_windows, mask=attn_mask)  <span class="comment"># [nW*B, Mh*Mw, C]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># merge windows</span></span><br><span class="line">            attn_windows = attn_windows.view(-<span class="number">1</span>, self.window_size, self.window_size, C)  <span class="comment"># [nW*B, Mh, Mw, C]</span></span><br><span class="line">            shifted_x = window_reverse(attn_windows, self.window_size, Hp, Wp)  <span class="comment"># [B, H&#x27;, W&#x27;, C]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># reverse cyclic shift</span></span><br><span class="line">            <span class="keyword">if</span> self.shift_size &gt; <span class="number">0</span>:</span><br><span class="line">                x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    x = shifted_x</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> pad_r &gt; <span class="number">0</span> <span class="keyword">or</span> pad_b &gt; <span class="number">0</span>:</span><br><span class="line">                        <span class="comment"># 把前面pad的数据移除掉</span></span><br><span class="line">                        x = x[:, :H, :W, :].contiguous()</span><br><span class="line"></span><br><span class="line">                        x = x.view(B, H * W, C)</span><br><span class="line"></span><br><span class="line">                        <span class="comment"># FFN</span></span><br><span class="line">                        x = shortcut + self.drop_path(x)</span><br><span class="line">                        x = x + self.drop_path(self.mlp(self.norm2(x)))</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="Mlp">Mlp</h4>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Transformer-Encoder%E5%B1%82.png" alt="Transformer-Encoder层"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Mlp</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; MLP as used in Vision Transformer, MLP-Mixer and related networks</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features</span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(in_features, hidden_features)</span><br><span class="line">        self.act = act_layer()</span><br><span class="line">        self.drop1 = nn.Dropout(drop)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_features, out_features)</span><br><span class="line">        self.drop2 = nn.Dropout(drop)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.drop1(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.drop2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="WindowAttention">WindowAttention</h4>
<h5 id="初始化函数-2">初始化函数</h5>
<p>实现了W-MSA和SW-MSA的部分功能</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E5%B8%A6%E8%92%99%E6%9D%BFmask%E7%9A%84MSA.png" alt="SW-MSA"></p>
<p><code>self.scale = head_dim ** -0.5</code>对应$1/\sqrt d$</p>
<p>创建<code>relative_position_bias_table</code>，直接通过nn.Parameter来创建这个参数，其长度为（2M-1）X（2M-1），所以使用一个零矩阵来初始化relative_position_bias_table，因为长度很多，所以采用<code>num_heads</code>多头机制。也就是说针对每一个所采用的relative_position_bias_table都是不一样的</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB%E5%8F%82%E6%95%B0.png" alt="相对位置偏移参数"></p>
<p>下面几行代码就是生成<code>relative_position_index</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get pair-wise relative position index for each token inside the window</span></span><br><span class="line">coords_h = torch.arange(self.window_size[<span class="number">0</span>])</span><br><span class="line">coords_w = torch.arange(self.window_size[<span class="number">1</span>])</span><br><span class="line">coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=<span class="string">&quot;ij&quot;</span>))  <span class="comment"># [2, Mh, Mw]</span></span><br><span class="line">coords_flatten = torch.flatten(coords, <span class="number">1</span>)  <span class="comment"># [2, Mh*Mw]</span></span><br><span class="line"><span class="comment"># [2, Mh*Mw, 1] - [2, 1, Mh*Mw]</span></span><br><span class="line">relative_coords = coords_flatten[:, :, <span class="literal">None</span>] - coords_flatten[:, <span class="literal">None</span>, :]  <span class="comment"># [2, Mh*Mw, Mh*Mw]</span></span><br><span class="line">relative_coords = relative_coords.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).contiguous()  <span class="comment"># [Mh*Mw, Mh*Mw, 2]</span></span><br><span class="line">relative_coords[:, :, <span class="number">0</span>] += self.window_size[<span class="number">0</span>] - <span class="number">1</span>  <span class="comment"># shift to start from 0</span></span><br><span class="line">relative_coords[:, :, <span class="number">1</span>] += self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">relative_coords[:, :, <span class="number">0</span>] *= <span class="number">2</span> * self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">relative_position_index = relative_coords.<span class="built_in">sum</span>(-<span class="number">1</span>)  <span class="comment"># [Mh*Mw, Mh*Mw]</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>举个栗子，首先通过<code>torch.arange</code>方法传入<code>window_size</code>生成<code>coords_h</code>和<code>coords_w</code>。假设window_size = 2，则coords_h=[0，1]，coords_w=[0，1]。再通过<code>torch.meshgrid</code>方法（生成网格的方法），第一个元素对应高度的范围，第二个元素对应宽度的范围，<code>indexing=&quot;ij&quot;</code>也就是创建的这个网格所对应的坐标是以行和列的形式来表示的。<code>meshgrid</code>方法返回的是两个tensor，所以通过<code>stack</code>方法进行拼接之后就变成了<code>[2, Mh, Mw]</code>。</p>
<p>再对第一个维度开始展平，得到<code>[2, Mh*Mw]</code>。<strong>得到的形式为下图（最左），第一行像素对应的是feature map上每一个像素对应的行标，第二行圆度对应的是feature map上每一个像素对应的列标，对应的是绝对位置索引</strong>。</p>
<p><code>relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]</code>对第一个矩阵在最后一个新加一个维度，对第二个矩阵在中间新增一个维度，二者相减得到<code>[2, Mh*Mw, Mh*Mw]</code>，即下图（中和右）。</p>
<p>为了使二者之间能够进行相减，因此需要用到广播机制，也就是前者的1维度要复制4次（）每一个行标复制4次），后者的1维度也要复制4次（每一个列标复制4次），箭头下方对应的就是分别复制4次之后的结果。</p>
</blockquote>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%B4%A2%E5%BC%95%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png" alt="绝对位置索引计算过程"></p>
<p>相减的过程怎么理解：想要构建相对位置索引的矩阵，假设以第一个像素为例的话，需要用它所对应的绝对索引去减去feature map每一个像素的绝对位置索引。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%87%8F%E8%BF%87%E7%A8%8B.png" alt="绝对位置索引相减过程"></p>
<p>那么得到上面相减之后的矩阵之后，<code>relative_coords = relative_coords.permute(1, 2, 0).contiguous()</code>中进行permute处理，将0维度挪到最后，即<code>[2, Mh*Mw, Mh*Mw]-&gt;[Mh*Mw, Mh*Mw, 2]</code>。又通过contiguous变为内存连续的形式。</p>
<p>接下来就是将二元索引变为医院索引的过程。将行标加上window_size[0] - 1，列标加上window_size[1] - 1，行标乘上2倍的window_size[1]之后 - 1，之后在最后一个维度上求和，对应的是<code>[Mh*Mw, Mh*Mw, 2]</code>中2这个维度，也就是行标与列标相加</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">relative_coords[:, :, <span class="number">0</span>] += self.window_size[<span class="number">0</span>] - <span class="number">1</span>  <span class="comment"># shift to start from 0</span></span><br><span class="line">relative_coords[:, :, <span class="number">1</span>] += self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">relative_coords[:, :, <span class="number">0</span>] *= <span class="number">2</span> * self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">relative_position_index = relative_coords.<span class="built_in">sum</span>(-<span class="number">1</span>)  <span class="comment"># [Mh*Mw, Mh*Mw]</span></span><br></pre></td></tr></table></figure>
<p>上面代码对应的就是将下图（左）矩阵首先通过permute来变成下图（中）的形式。以列表中index = 0的列表为例，指的就是下图（右）蓝色像素为参考点时所求得的相对位置索引，index = 1的列表对应的是以橙色像素为参考点时所求得的相对位置索引，依次为红色、绿色。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB.png" alt="相对位置索引"></p>
<p>在行标加上M-1</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87+M-1.png" alt="相对位置索引-行标+M-1"></p>
<p>列标加上M-1</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E5%88%97%E6%A0%87+M-1.png" alt="相对位置索引-列标+M-1"></p>
<p>对行标乘以（2M-1）</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87%E4%B9%98%E4%BB%A52M-1.png" alt="相对位置索引-行标乘以（2M-1）"></p>
<p>再将行标和列标相加，即得到下图（右）的结果，同上篇文举的例子最终结果一样。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87%E5%92%8C%E5%88%97%E6%A0%87%E7%9B%B8%E5%8A%A0.png" alt="相对位置索引-行标和列标相加"></p>
<p><code>relative_position_index = relative_coords.sum(-1)</code>即为上图（右）得到的情况，构建好的相对位置索引。</p>
<p><code>self.register_buffer(&quot;relative_position_index&quot;, relative_position_index)</code>通过<code>register_buffer</code>将<code>relative_position_index</code>放进模型的缓存当中。因为relative_position_index的参数是一个固定的值，一旦创建就不需要去修改了，真正需要训练修改的是relative position table。</p>
<p><code>self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)</code>通过Linear创建qkv，和vision transformer是一样的。</p>
<p><code>self.proj = nn.Linear(dim, dim)</code>对应的是多头输出进行融合的过程</p>
<p><code>nn.init.trunc_normal_(self.relative_position_bias_table, std=.02)</code>：对relative_position_bias_table进行初始化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">WindowAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; Window based multi-head self attention (W-MSA) module with relative position bias.</span></span><br><span class="line"><span class="string">    It supports both of shifted and non-shifted window.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        window_size (tuple[int]): The height and width of the window.</span></span><br><span class="line"><span class="string">        num_heads (int): Number of attention heads.</span></span><br><span class="line"><span class="string">        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True</span></span><br><span class="line"><span class="string">        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0</span></span><br><span class="line"><span class="string">        proj_drop (float, optional): Dropout ratio of output. Default: 0.0</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, window_size, num_heads, qkv_bias=<span class="literal">True</span>, attn_drop=<span class="number">0.</span>, proj_drop=<span class="number">0.</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.window_size = window_size  <span class="comment"># [Mh, Mw]</span></span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        head_dim = dim // num_heads</span><br><span class="line">        self.scale = head_dim ** -<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># define a parameter table of relative position bias</span></span><br><span class="line">        self.relative_position_bias_table = nn.Parameter(</span><br><span class="line">            torch.zeros((<span class="number">2</span> * window_size[<span class="number">0</span>] - <span class="number">1</span>) * (<span class="number">2</span> * window_size[<span class="number">1</span>] - <span class="number">1</span>), num_heads))  <span class="comment"># [2*Mh-1 * 2*Mw-1, nH]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># get pair-wise relative position index for each token inside the window</span></span><br><span class="line">        coords_h = torch.arange(self.window_size[<span class="number">0</span>])</span><br><span class="line">        coords_w = torch.arange(self.window_size[<span class="number">1</span>])</span><br><span class="line">        coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=<span class="string">&quot;ij&quot;</span>))  <span class="comment"># [2, Mh, Mw]</span></span><br><span class="line">        coords_flatten = torch.flatten(coords, <span class="number">1</span>)  <span class="comment"># [2, Mh*Mw]</span></span><br><span class="line">        <span class="comment"># [2, Mh*Mw, 1] - [2, 1, Mh*Mw]</span></span><br><span class="line">        relative_coords = coords_flatten[:, :, <span class="literal">None</span>] - coords_flatten[:, <span class="literal">None</span>, :]  <span class="comment"># [2, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        relative_coords = relative_coords.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).contiguous()  <span class="comment"># [Mh*Mw, Mh*Mw, 2]</span></span><br><span class="line">        relative_coords[:, :, <span class="number">0</span>] += self.window_size[<span class="number">0</span>] - <span class="number">1</span>  <span class="comment"># shift to start from 0</span></span><br><span class="line">        relative_coords[:, :, <span class="number">1</span>] += self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">        relative_coords[:, :, <span class="number">0</span>] *= <span class="number">2</span> * self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">        relative_position_index = relative_coords.<span class="built_in">sum</span>(-<span class="number">1</span>)  <span class="comment"># [Mh*Mw, Mh*Mw]</span></span><br><span class="line">        self.register_buffer(<span class="string">&quot;relative_position_index&quot;</span>, relative_position_index)</span><br><span class="line"></span><br><span class="line">        self.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=qkv_bias)</span><br><span class="line">        self.attn_drop = nn.Dropout(attn_drop)</span><br><span class="line">        self.proj = nn.Linear(dim, dim)</span><br><span class="line">        self.proj_drop = nn.Dropout(proj_drop)</span><br><span class="line"></span><br><span class="line">        nn.init.trunc_normal_(self.relative_position_bias_table, std=<span class="number">.02</span>)</span><br><span class="line">        self.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h5 id="正向传播函数-2">正向传播函数</h5>
<p>有传入x和mask。</p>
<p>首先获取x的shape，<code>B_, N, C = x.shape</code>对应的通道为<code>[batch_size*num_windows, Mh*Mw, total_embed_dim]</code>。</p>
<p>将x通过qkv这个Linear就得到qkv的数据，再进行reshape处理</p>
<ul>
<li><code>qkv(): -&gt; [batch_size*num_windows, Mh*Mw, 3 * total_embed_dim]</code></li>
<li><code>reshape: -&gt; [batch_size*num_windows, Mh*Mw, 3, num_heads, embed_dim_per_head]</code></li>
<li><code>permute: -&gt; [3, batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</code></li>
</ul>
<p>通过unbind方法分别获得q，k，v的值。</p>
<p>与在vision transformer不一样的是，这里的q先乘上scale<code>q = q * self.scale</code>，之后再乘以k的转置<code>attn = (q @ k.transpose(-2, -1))</code>。</p>
<blockquote>
<p><code>transpose: -&gt; [batch_size*num_windows, num_heads, embed_dim_per_head, Mh*Mw]</code></p>
<p><code>@: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, Mh*Mw]</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.relative_position_bias_table[self.relative_position_index.view(-<span class="number">1</span>)].view(</span><br><span class="line">        self.window_size[<span class="number">0</span>] * self.window_size[<span class="number">1</span>], self.window_size[<span class="number">0</span>] * self.window_size[<span class="number">1</span>], -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>通过view函数将relative_position_index全部展平，展平之后就在relative_position_bias_table当中去取对应的参数，即<code>relative_position_bias_table.view: [Mh*Mw*Mh*Mw,nH] -&gt; [Mh*Mw,Mh*Mw,nH]</code></p>
<p>之后通过permute方法去调整一下数据的排列顺序<code>[Mh*Mw,Mh*Mw,nH]-&gt;[nH, Mh*Mw, Mh*Mw]</code></p>
<p><code>attn = attn + relative_position_bias.unsqueeze(0)</code>再通过Attention加上relative_position_bias，这一步对应的就是公式里加上B这个矩阵的过程。attn的通道排列顺序为<code>[batch_size*num_windows, num_heads, Mh*Mw, Mh*Mw]</code>，relative_position_bias的通道排列顺序为<code>[Mh*Mw,Mh*Mw,nH]</code>，二者间相差一个Batch，因此这里会通过<code>unsqueeze（0）</code>来给<code>relative_position_bias</code>加上一个batch维度。这样就能通过广播机制进行相加。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E5%85%AC%E5%BC%8F.png" alt="相对位置偏移-公式"></p>
<p>接下来判断mask是否为None，如果为None的话，即直接通过softmax处理；如果不为None的话，首先拿到mask的window个数<code>nW = mask.shape[0]</code>。</p>
<p>接着对attn进行view处理<code>attn.view: [batch_size, num_windows, num_heads, Mh*Mw, Mh*Mw]</code>，由于和mask的通道排列顺序不相对，所以给mask先再1处加入新的维度，之后又在加了维度的基础上再0的位置加入新的维度，即<code>mask.unsqueeze: [1, nW, 1, Mh*Mw, Mh*Mw]</code>，此时可以通过广播机制进行相加。</p>
<blockquote>
<p>注意：构建mask时，在一个window内，对于相同区域的元素是用0来表示的，对于不同区域的是用-100表示的，所以当attn和mask相加之后，对于加上0（相同区域）的数值是没有任何影响的，但是对于不同区域的attn数值都加上-100之后就变成一个非常大的负数，接下来再通过softmax处理，对于不同区域的 权重就会全部变为0了。</p>
</blockquote>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E5%B8%A6%E8%92%99%E6%9D%BFmask%E7%9A%84MSA.png" alt="Attention+mask"></p>
<p>再通过Dropout层，再将attn乘上V（这里对应的是上图公式里通过softmax处理之后乘上V的操作），接着通过transpose和reshape，即<code>transpose: -&gt; [batch_size*num_windows, Mh*Mw, num_heads, embed_dim_per_head]</code>，<code>reshape: -&gt; [batch_size*num_windows, Mh*Mw, total_embed_dim]</code>。</p>
<p>最后通过proj也就是线性层对多个head的输出进行一个融合，融合之后再通过一个Dropout层，就得到最终Attention模块的输出了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: input features with shape of (num_windows*B, Mh*Mw, C)</span></span><br><span class="line"><span class="string">        mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># [batch_size*num_windows, Mh*Mw, total_embed_dim]</span></span><br><span class="line">    B_, N, C = x.shape</span><br><span class="line">    <span class="comment"># qkv(): -&gt; [batch_size*num_windows, Mh*Mw, 3 * total_embed_dim]</span></span><br><span class="line">    <span class="comment"># reshape: -&gt; [batch_size*num_windows, Mh*Mw, 3, num_heads, embed_dim_per_head]</span></span><br><span class="line">    <span class="comment"># permute: -&gt; [3, batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span></span><br><span class="line">    qkv = self.qkv(x).reshape(B_, N, <span class="number">3</span>, self.num_heads, C // self.num_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="comment"># [batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span></span><br><span class="line">    q, k, v = qkv.unbind(<span class="number">0</span>)  <span class="comment"># make torchscript happy (cannot use tensor as tuple)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># transpose: -&gt; [batch_size*num_windows, num_heads, embed_dim_per_head, Mh*Mw]</span></span><br><span class="line">    <span class="comment"># @: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, Mh*Mw]</span></span><br><span class="line">    q = q * self.scale</span><br><span class="line">    attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># relative_position_bias_table.view: [Mh*Mw*Mh*Mw,nH] -&gt; [Mh*Mw,Mh*Mw,nH]</span></span><br><span class="line">    relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-<span class="number">1</span>)].view(</span><br><span class="line">        self.window_size[<span class="number">0</span>] * self.window_size[<span class="number">1</span>], self.window_size[<span class="number">0</span>] * self.window_size[<span class="number">1</span>], -<span class="number">1</span>)</span><br><span class="line">    relative_position_bias = relative_position_bias.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).contiguous()  <span class="comment"># [nH, Mh*Mw, Mh*Mw]</span></span><br><span class="line">    attn = attn + relative_position_bias.unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># mask: [nW, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        nW = mask.shape[<span class="number">0</span>]  <span class="comment"># num_windows</span></span><br><span class="line">        <span class="comment"># attn.view: [batch_size, num_windows, num_heads, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        <span class="comment"># mask.unsqueeze: [1, nW, 1, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        attn = attn.view(-<span class="number">1</span>, self.num_heads, N, N)</span><br><span class="line">        attn = self.softmax(attn)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            attn = self.softmax(attn)</span><br><span class="line"></span><br><span class="line">            attn = self.attn_drop(attn)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># @: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span></span><br><span class="line">            <span class="comment"># transpose: -&gt; [batch_size*num_windows, Mh*Mw, num_heads, embed_dim_per_head]</span></span><br><span class="line">            <span class="comment"># reshape: -&gt; [batch_size*num_windows, Mh*Mw, total_embed_dim]</span></span><br><span class="line">            x = (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B_, N, C)</span><br><span class="line">            x = self.proj(x)</span><br><span class="line">            x = self.proj_drop(x)</span><br><span class="line">            <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h1>实例化模型</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">swin_tiny_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-1K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">96</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">3</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_small_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-1K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">96</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">3</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-1K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">128</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window12_384</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-1K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">12</span>,</span><br><span class="line">                            embed_dim=<span class="number">128</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window7_224_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-22K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">128</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window12_384_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-22K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">12</span>,</span><br><span class="line">                            embed_dim=<span class="number">128</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_large_patch4_window7_224_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-22K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22k.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">192</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>, <span class="number">48</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_large_patch4_window12_384_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-22K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">12</span>,</span><br><span class="line">                            embed_dim=<span class="number">192</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>, <span class="number">48</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h1><a href="http://train.py">train.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> swin_tiny_patch4_window7_224 <span class="keyword">as</span> create_model</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(img_size),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.143</span>)),</span><br><span class="line">                                   transforms.CenterCrop(img_size),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    model = create_model(num_classes=args.num_classes).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">assert</span> os.path.exists(args.weights), <span class="string">&quot;weights file: &#x27;&#123;&#125;&#x27; not exist.&quot;</span>.<span class="built_in">format</span>(args.weights)</span><br><span class="line">        weights_dict = torch.load(args.weights, map_location=device)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        <span class="comment"># 删除有关分类类别的权重</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">list</span>(weights_dict.keys()):</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;head&quot;</span> <span class="keyword">in</span> k:</span><br><span class="line">                <span class="keyword">del</span> weights_dict[k]</span><br><span class="line">        <span class="built_in">print</span>(model.load_state_dict(weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除head外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;head&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;training &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">    pg = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=<span class="number">5E-2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        train_loss, train_acc = train_one_epoch(model=model,</span><br><span class="line">                                                optimizer=optimizer,</span><br><span class="line">                                                data_loader=train_loader,</span><br><span class="line">                                                device=device,</span><br><span class="line">                                                epoch=epoch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        val_loss, val_acc = evaluate(model=model,</span><br><span class="line">                                     data_loader=val_loader,</span><br><span class="line">                                     device=device,</span><br><span class="line">                                     epoch=epoch)</span><br><span class="line"></span><br><span class="line">        tags = [<span class="string">&quot;train_loss&quot;</span>, <span class="string">&quot;train_acc&quot;</span>, <span class="string">&quot;val_loss&quot;</span>, <span class="string">&quot;val_acc&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], train_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], train_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], val_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">3</span>], val_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">4</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;./weights/model-&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预训练权重路径，如果不想载入就设置为空字符</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./swin_tiny_patch4_window7_224.pth&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    <span class="comment"># 是否冻结权重</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<h2 id="训练结果">训练结果</h2>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h1><a href="http://predict.py">predict.py</a></h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> swin_tiny_patch4_window7_224 <span class="keyword">as</span> create_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.14</span>)),</span><br><span class="line">         transforms.CenterCrop(img_size),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = create_model(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/model-9.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="预测结果">预测结果</h2>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>Swin Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（二十五）ConvNeXt网络讲解及使用Pytorch搭建</title>
    <url>/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h1>网络结构学习</h1>
<h2 id="前言">前言</h2>
<p>自从<code>ViT(Vision Transformer)</code>在CV领域大放异彩，越来越多的研究人员开始拥入<code>Transformer</code>的怀抱，而卷积神经网络已经开始慢慢淡出舞台中央。20221月，Facebook AI Research和UC Berkeley一起发表了一篇文章<a href="https://arxiv.org/abs/2201.03545">A ConvNet for the 2020s</a>，在文章中提出了ConvNeXt纯卷积神经网络，它对标的是2021年非常火的Swin Transformer，通过一系列实验比对，在相同的FLOPs下，ConvNeXt相比Swin Transformer拥有更快的推理速度以及更高的准确率，在ImageNet 22K上ConvNeXt-XL达到了87.8%的准确率（下图所示）。</p>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/ConvNeXt%E5%AF%B9%E6%AF%94Swin-Tranformer%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="ConvNeXt对比Swin-Tranformer的性能对比"></p>
<p><code>ConvNeXt</code>其实“毫无亮点”，因为它使用的全部都是现有的结构和方法，没有任何结构或者方法的创新。而且源码也非常的精简，100多行代码就能搭建完成。而<code>Swin Transformer</code>的滑动窗口，相对位置索引等不仅原理理解起来很吃力，源码也非常多，但<code>Swin Transformer</code>确实十分成功并且设计的非常巧妙。</p>
<p>作者认为，基于<code>Transformer</code>架构的模型效果比卷积神经网络要好的原因可能在于随着技术的不断发展，各种新的架构以及优化策略促使<code>Transformer</code>模型的效果更好。所以作者想要使用相同的策略去训练卷积神经网络看看能不能达到和Transformer一样的效果，因此做了一系列实验。</p>
<h2 id="设计方案">设计方案</h2>
<p>作者首先利用训练<code>vision Transformers</code>的策略去训练原始的<code>ResNet50</code>模型，得出效果为78.8，并将此结果作为后续实验的基准<code>baseline</code>。如下图所示，ConvNeXt-T/B达到的精度有82.0%，Swin-T/B为81.3%。</p>
<p>ConvNeXt设计与实验：</p>
<ul>
<li>Macro design</li>
<li>ResNeXt</li>
<li>Inverted bottleneck</li>
<li>Large kerner size</li>
<li>Various layer-wise micro designs</li>
</ul>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/%E4%B8%80%E7%B3%BB%E5%88%97%E5%AE%9E%E9%AA%8C%E5%87%86%E7%A1%AE%E7%8E%87%E5%AF%B9%E6%AF%94.png" alt="一系列实验准确率对比"></p>
<h2 id="Macro-design">Macro design</h2>
<p>如上图所示，分为两个小部分，分别是stage ratio和“patchify” stem。对应的举措分别是讲ResNet-50中堆叠的底数由<code>（3，4，6，3）</code>调整为<code>（3，3，9，3）</code>（为了能和Swin Tranformer中的比例保持一致）、将<code>stem换成卷积核大小为4且步距为4</code>的卷积层。</p>
<p><strong>Changing stage compute ratio</strong>，在原<code>ResNet</code>网络中，一般<code>conv4_x</code>（即<code>stage3</code>）堆叠的block的次数是最多的。如下图中的<code>ResNet50</code>中<code>stage1</code>到<code>stage4</code>堆叠block的次数是<code>(3, 4, 6, 3)</code>比例大概是<code>1:1:2:1</code>，但在<code>Swin Transformer</code>中，比如<code>Swin-T</code>的比例是<code>1:1:3:1</code>，<code>Swin-L</code>的比例是<code>1:1:9:1</code>。很明显，在<code>Swin Transformer</code>中，<code>stage3</code>堆叠block的占比更高。所以作者就将<code>ResNet50</code>中的堆叠次数由<code>(3, 4, 6, 3)</code>调整成<code>(3, 3, 9, 3)</code>，和<code>Swin-T</code>拥有相似的<code>FLOPs</code>。进行调整后，准确率由<code>78.8%</code>提升到了<code>79.4%</code>。</p>
<p><strong>Changing stem to “Patchify”</strong>，在之前的卷积神经网络中，一般最初的下采样模块<code>stem</code>一般都是通过一个卷积核大小为<code>7x7</code>步距为2的卷积层以及一个步距为2的最大池化下采样共同组成，高和宽都下采样4倍。但在<code>Transformer</code>模型中一般都是通过一个卷积核非常大且相邻窗口之间没有重叠的（<code>即stride等于kernel_size</code>）卷积层进行下采样。比如在<code>Swin Transformer</code>中采用的是一个卷积核大小为<code>4x4</code>步距为4的卷积层构成<code>patchify</code>，同样是下采样4倍。所以作者将<code>ResNet</code>中的<code>stem</code>也换成了和<code>Swin Transformer</code>一样的<code>patchify</code>。替换后准确率从<code>79.4%</code> 提升到<code>79.5%</code>，并且FLOPs也降低了一点。</p>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/%E4%BF%AE%E6%94%B9%E7%89%88ResNet.png" alt="修改版ResNet"></p>
<h2 id="ResNeXt">ResNeXt</h2>
<p><strong>Depth conv</strong></p>
<p>作者借鉴了<code>ResNeXt</code>中的组卷积<code>grouped convolution</code>，因为<code>ResNeXt</code>相比普通的<code>ResNet</code>而言在FLOPs以及accuracy之间做到了更好的平衡。这里作者采用的是更激进的<code>depthwise convolution</code>（<strong>groups数和输入特征矩阵的深度相等</strong>），即group数和通道数channel相同，且作者认为<code>depthwise convolution</code>和<code>self-attention</code>中的加权求和操作很相似。</p>
<p>下图（上左）所采用的是ResNet所采用的瓶颈结构，即两头粗中间细的结构（<code>256-&gt;64-&gt;256</code>）。而在ResNeXt中采用的是下图（上右）的结构。二者之间唯一的区别就是在中间3x3的卷积层部分，在ResNet中，3x3的卷积层就是一个普通卷积层，但在ResNeXt中采用的是组卷积。</p>
<p>DW卷积如下图（下）所示，这里就不细讲了，可以回到ResNeXt中去看看详细过程。</p>
<p>通过上述改成激进的DW卷积之后，准确率从<code>79.5%</code>降到了<code>78%</code>。</p>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/dw%E5%8D%B7%E7%A7%AF.png" alt="DW卷积"></p>
<p><strong>增大width（图片channel）</strong>，将ResNet50对标Swin-T，前者第一个Stage输入特征矩阵的深度为64，后者第一个Stage输入的channel为96。因此，作者将ResNet的每一个Stage的输入特征矩阵的channel与Swin-T中每个Stage的输入特征矩阵的channel保持一致。于是准确率从<code>78%</code>升到了<code>80.5%</code>，虽然同时FLOPs也增长了很多。</p>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/%E4%BF%AE%E6%94%B9ResNet-%E5%A2%9E%E5%A4%A7%E6%B7%B1%E5%BA%A6.png" alt="修改ResNet-增大深度"></p>
<h2 id="Inverted-Bottleneck">Inverted Bottleneck</h2>
<p>作者认为<code>Transformer block</code>中的<code>MLP</code>模块非常像<code>MobileNetV2</code>中的<code>Inverted Bottleneck</code>模块，即两头细中间粗。下图a是<code>ReNet</code>中采用的<code>Bottleneck</code>模块，b是<code>MobileNetV2</code>采用的<code>Inverted Botleneck</code>模块，c是<code>ConvNeXt</code>采用的是<code>Inverted Bottleneck</code>模块。</p>
<p>作者采用<code>Inverted Bottleneck</code>模块后，在较小的模型上准确率由<code>80.5%</code>提升到了<code>80.6%</code>，在较大的模型上准确率由<code>81.9%</code>提升到<code>82.6%</code>。</p>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/%E4%BF%AE%E6%94%B9Inverted-Bottleneck.png" alt="修改Inverted Bottleneck"></p>
<h2 id="Large-Kernel-Sizes">Large Kernel Sizes</h2>
<p>在<code>Transformer</code>中一般都是对全局做<code>self-attention</code>，比如<code>Vision Transformer</code>。即使是<code>Swin Transformer</code>也有<code>7x7</code>大小的窗口。但现在主流的卷积神经网络都是采用<code>3x3</code>大小的窗口，因为之前<code>VGG</code>论文中说通过堆叠多个<code>3x3</code>的窗口可以替代一个更大的窗口，而且现在的GPU设备针对<code>3x3</code>大小的卷积核做了很多的优化，所以会更高效。接着作者做了如下两个改动：</p>
<p><strong>Moving up depthwise conv layer</strong>，即将<code>depthwise conv</code>模块上移，原来是先通过<code>1x1 conv</code> -&gt; 再<code>depthwise conv</code> -&gt;然后 <code>1x1 conv</code>，现在变成了<code>depthwise conv</code> -&gt; <code>1x1 conv</code> -&gt; <code>1x1 conv</code>。这么做是因为在<code>Transformer</code>中，<code>MSA</code>模块是放在<code>MLP</code>模块之前的，所以这里进行效仿，将<code>depthwise conv</code>上移（也就是上图c）。这样改动后，准确率由<code>80.6%</code>下降到了<code>79.9%</code>，同时FLOPs也减小了。</p>
<p><strong>Increasing the kernel size</strong>，接着将<code>depthwise conv</code>的卷积核大小由<code>3x3</code>改成了<code>7x7</code>（和<code>Swin Transformer</code>一样），作者也做了一系列实验，除了3x3之外，还包括<code> 5, 7, 9, 11</code>发现取到7时准确率就达到了饱和。并且准确率从<code>79.9% (3×3)</code> 增长到 <code>80.6% (7×7)</code>（正好和Swin Transformer里的窗口大小是一致的，简直是玄学）。</p>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/Large_kerner_size.png" alt="Large kerner size"></p>
<h2 id="Micro-Design">Micro Design</h2>
<p>接下来作者在聚焦到一些更细小的差异，比如激活函数将ReLU更改为GELU以及Normalization。</p>
<ul>
<li><strong>Replacing ReLU with GELU</strong>，在<code>Transformer</code>中激活函数基本用的都是<code>GELU</code>，而在卷积神经网络中最常用的是<code>ReLU</code>，于是作者将激活函数替换成了<code>GELU</code>，发现准确率没变化。</li>
<li><strong>Fewer activation functions</strong>，使用更少的激活函数。在卷积神经网络中，一般会在每个卷积层或全连接后都接上一个激活函数。但在<code>Transformer</code>中并不是每个模块后都跟有激活函数（如下图），比如<code>MLP</code>中只有第一个全连接层后跟了<code>GELU</code>激活函数。接着作者在<code>ConvNeXt Block</code>中也减少激活函数的使用，如下图所示，减少后发现准确率从<code>80.6%</code>增长到<code>81.3%</code>。</li>
<li><strong>Fewer normalization layers</strong>，使用更少的Normalization Layer。同样在<code>Transformer</code>中，Normalization使用的也比较少，接着作者也减少了<code>ConvNeXt Block</code>中的Normalization层，只保留了<code>depthwise conv</code>后的Normalization层。此时准确率已经达到了<code>81.4%</code>，已经超过了<code>Swin-T</code>。</li>
<li><strong>Substituting BN with LN</strong>，将BN替换成LN。Batch Normalization（BN）在卷积神经网络中是非常常用的模块，它可以加速网络的收敛并减少过拟合（但用的不好也是个大坑）。但在<code>Transformer</code>中基本都用的Layer Normalization（LN），因为最开始<code>Transformer</code>是应用在NLP领域的，BN又不适用于NLP相关任务。接着作者将BN全部替换成了LN，发现准确率提升达到了<code>81.5%</code>。</li>
</ul>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/Swin-Transformer-Block%E5%92%8CResNet-Block%E4%BB%A5%E5%8F%8AConvNeXt-Block%E7%BB%93%E6%9E%84.png" alt="Swin Transformer Block和ResNet Block以及ConvNeXt Block结构"></p>
<ul>
<li><strong>Separate downsampling layers</strong>，单独的下采样层。在<code>ResNet</code>网络中<code>stage2-4</code>的第一个block都具有下采样功能（下图左），且都是通过将主分支上<code>3x3</code>的卷积层步距设置成2，捷径分支上<code>1x1</code>的卷积层步距设置成2进行下采样的。但在<code>Swin Transformer</code>中是通过一个单独的<code>Patch Merging</code>实现的（下图右）。接着作者就为<code>ConvNext</code>网络单独使用了一个下采样层，就是通过一个Laryer Normalization加上一个卷积核大小为2步距为2的卷积层构成。更改后准确率就提升到了<code>82.0%</code>，对应的就是ConvNeXt-T这个精度。</li>
</ul>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/%E4%BF%AE%E6%94%B9ResNet-%E4%B8%8B%E9%87%87%E6%A0%B7%E5%B1%82.png" alt="修改ResNet-下采样层"></p>
<h2 id="ConvNeXt参数">ConvNeXt参数</h2>
<p>对于<code>ConvNeXt</code>网络，作者提出了<code>T/S/B/L</code>四个版本，计算复杂度刚好和<code>Swin Transformer</code>中的<code>T/S/B/L</code>相似。C代表4个<code>stage</code>中输入的通道数，B代表每个<code>stage</code>重复堆叠block的次数。</p>
<ul>
<li><strong>ConvNeXt-T</strong>: C = (96, 192, 384, 768), B = (3, 3, 9, 3)</li>
<li><strong>ConvNeXt-S</strong>: C = (96, 192, 384, 768), B = (3, 3, 27, 3)</li>
<li><strong>ConvNeXt-B</strong>: C = (128, 256, 512, 1024), B = (3, 3, 27, 3)</li>
<li><strong>ConvNeXt-L</strong>: C = (192, 384, 768, 1536), B = (3, 3, 27, 3)</li>
<li><strong>ConvNeXt-XL</strong>: C = (256, 512, 1024, 2048), B = (3, 3, 27, 3)</li>
</ul>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/ConvNeXt-T%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%A1%A8.png" alt="ConvNeXt-T配置参数表"></p>
<h2 id="ConvNeXt-T结构图">ConvNeXt-T结构图</h2>
<p>up根据官方源码手绘的<code>ConvNeXt-T</code>网络结构图，仔细观察<code>ConvNeXt Block</code>会发现其中还有一个<code>Layer Scale</code>操作（论文中并没有提到），<strong>其实它就是将输入的特征层乘上一个可训练的参数，该参数就是一个向量</strong>，元素个数与特征层channel相同，即对每个channel的数据进行缩放。</p>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/ConvNeXt-T%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="ConvNeXt-T结构图"></p>
<h1>工程目录</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test14_ConvNeXt</span><br><span class="line">	├── model.py（模型文件）   </span><br><span class="line">	├── my_dataset.py（数据处理文件）    </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,ConvNeXt.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）  </span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── convnext_tiny_1k_224_ema.pth（迁移学习，提前下载好convnext_tiny_1k_224_ema.pth权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h1>搭建网络</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">original code from facebook research:</span></span><br><span class="line"><span class="string">https://github.com/facebookresearch/ConvNeXt</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, normalized_shape, eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_last&quot;</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, drop_rate=<span class="number">0.</span>, layer_scale_init_value=<span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNeXt</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_chans: <span class="built_in">int</span> = <span class="number">3</span>, num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, depths: <span class="built_in">list</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 dims: <span class="built_in">list</span> = <span class="literal">None</span>, drop_path_rate: <span class="built_in">float</span> = <span class="number">0.</span>, layer_scale_init_value: <span class="built_in">float</span> = <span class="number">1e-6</span>,</span></span><br><span class="line"><span class="params">                 head_init_scale: <span class="built_in">float</span> = <span class="number">1.</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self, m</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_tiny</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_small</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_base</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_large</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_xlarge</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h2 id="模型文件">模型文件</h2>
<h3 id="DropPath类">DropPath类</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).</span></span><br><span class="line"><span class="string">    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,</span></span><br><span class="line"><span class="string">    the original name is misleading as &#x27;Drop Connect&#x27; is a different form of dropout in a separate paper...</span></span><br><span class="line"><span class="string">    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I&#x27;ve opted for</span></span><br><span class="line"><span class="string">    changing the layer and argument names to &#x27;drop path&#x27; rather than mix DropConnect as a layer name and use</span></span><br><span class="line"><span class="string">    &#x27;survival rate&#x27; as the argument.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> drop_prob == <span class="number">0.</span> <span class="keyword">or</span> <span class="keyword">not</span> training:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    keep_prob = <span class="number">1</span> - drop_prob</span><br><span class="line">    shape = (x.shape[<span class="number">0</span>],) + (<span class="number">1</span>,) * (x.ndim - <span class="number">1</span>)  <span class="comment"># work with diff dim tensors, not just 2D ConvNets</span></span><br><span class="line">    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)</span><br><span class="line">    random_tensor.floor_()  <span class="comment"># binarize</span></span><br><span class="line">    output = x.div(keep_prob) * random_tensor</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DropPath, self).__init__()</span><br><span class="line">        self.drop_prob = drop_prob</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> drop_path(x, self.drop_prob, self.training)</span><br></pre></td></tr></table></figure>
<h3 id="LayerNorm类">LayerNorm类</h3>
<p>实际上，官方有现成的LayerNorm方法，但是Pytorch实现的LayerNorm方法默认是从最后一个维度开始做Normalization。在ConvNeXt网络当中，是对channel维度进行LayerNorm处理的，如果说channel是放在最后一个维度的话，就可以用官方给的LayerNorm方法，但如果channel这个维度没有放在最后的话，就不能使用官方的方法，所以作者重写了LayerNorm方法。</p>
<p><code>data_format</code>有两种形式，分别为<code>channels_last</code>和<code>channels_first</code>，分别对应着channel这个维度放在最后面（<code>batch_size, height, width, channels</code>）和没有放在最后一个位置（<code>batch_size, channels, height, width</code>，这通常是Pytorch默认的通道排列顺序）。</p>
<p><code>weight</code>和<code>bias</code>分别对应着LayerNorm过程中的$\alpha$和$\beta$。</p>
<p>如果data_format是channels_first时，作者重写了这块的代码，首先对channel这个维度求均值（也就是对应dim为1的位置）得到<code>mean</code>，接下来求方差<code>var</code>，以及<code>标准差</code>处理。</p>
<p>最后再乘以<code>weight</code>并加上<code>bias</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; LayerNorm that supports two data formats: channels_last (default) or channels_first.</span></span><br><span class="line"><span class="string">    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with</span></span><br><span class="line"><span class="string">    shape (batch_size, height, width, channels) while channels_first corresponds to inputs</span></span><br><span class="line"><span class="string">    with shape (batch_size, channels, height, width).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, normalized_shape, eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_last&quot;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.ones(normalized_shape), requires_grad=<span class="literal">True</span>)</span><br><span class="line">        self.bias = nn.Parameter(torch.zeros(normalized_shape), requires_grad=<span class="literal">True</span>)</span><br><span class="line">        self.eps = eps</span><br><span class="line">        self.data_format = data_format</span><br><span class="line">        <span class="keyword">if</span> self.data_format <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;channels_last&quot;</span>, <span class="string">&quot;channels_first&quot;</span>]:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;not support data format &#x27;<span class="subst">&#123;self.data_format&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        self.normalized_shape = (normalized_shape,)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="keyword">if</span> self.data_format == <span class="string">&quot;channels_last&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)</span><br><span class="line">        <span class="keyword">elif</span> self.data_format == <span class="string">&quot;channels_first&quot;</span>:</span><br><span class="line">            <span class="comment"># [batch_size, channels, height, width]</span></span><br><span class="line">            mean = x.mean(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">            var = (x - mean).<span class="built_in">pow</span>(<span class="number">2</span>).mean(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">            x = (x - mean) / torch.sqrt(var + self.eps)</span><br><span class="line">            x = self.weight[:, <span class="literal">None</span>, <span class="literal">None</span>] * x + self.bias[:, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">            <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="Block类">Block类</h3>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/ConvNeXt-Block%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="ConvNeXt Block结构图"></p>
<p><code>self.gamma</code>对应的是上图的<code>Layer Scale</code>，元素个数和输入特征层channel的个数是相同的（<strong>其实它就是将输入的特征层乘上一个可训练的参数，该参数就是一个向量</strong>，元素个数与特征层channel相同，即对每个channel的数据进行缩放）</p>
<p>在正向传播过程中，通过第一个<code>permute</code>方法调换Pytorch默认的通道排列顺序，即<code>[N, C, H, W] -&gt; [N, H, W, C]</code>，再通过第二个<code>permute</code>方法将修改后的通道排列顺序给还原回去，即<code>[N, H, W, C] -&gt; [N, C, H, W]</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; ConvNeXt Block. There are two equivalent implementations:</span></span><br><span class="line"><span class="string">    (1) DwConv -&gt; LayerNorm (channels_first) -&gt; 1x1 Conv -&gt; GELU -&gt; 1x1 Conv; all in (N, C, H, W)</span></span><br><span class="line"><span class="string">    (2) DwConv -&gt; Permute to (N, H, W, C); LayerNorm (channels_last) -&gt; Linear -&gt; GELU -&gt; Linear; Permute back</span></span><br><span class="line"><span class="string">    We use (2) as we find it slightly faster in PyTorch</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        drop_rate (float): Stochastic depth rate. Default: 0.0</span></span><br><span class="line"><span class="string">        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, drop_rate=<span class="number">0.</span>, layer_scale_init_value=<span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dwconv = nn.Conv2d(dim, dim, kernel_size=<span class="number">7</span>, padding=<span class="number">3</span>, groups=dim)  <span class="comment"># depthwise conv</span></span><br><span class="line">        self.norm = LayerNorm(dim, eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_last&quot;</span>)</span><br><span class="line">        self.pwconv1 = nn.Linear(dim, <span class="number">4</span> * dim)  <span class="comment"># pointwise/1x1 convs, implemented with linear layers</span></span><br><span class="line">        self.act = nn.GELU()</span><br><span class="line">        self.pwconv2 = nn.Linear(<span class="number">4</span> * dim, dim)</span><br><span class="line">        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim,)),</span><br><span class="line">                                  requires_grad=<span class="literal">True</span>) <span class="keyword">if</span> layer_scale_init_value &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        self.drop_path = DropPath(drop_rate) <span class="keyword">if</span> drop_rate &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        shortcut = x</span><br><span class="line">        x = self.dwconv(x)</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)  <span class="comment"># [N, C, H, W] -&gt; [N, H, W, C]</span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        x = self.pwconv1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.pwconv2(x)</span><br><span class="line">        <span class="keyword">if</span> self.gamma <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.gamma * x</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [N, H, W, C] -&gt; [N, C, H, W]</span></span><br><span class="line"></span><br><span class="line">        x = shortcut + self.drop_path(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="ConvNeXt类">ConvNeXt类</h3>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/ConvNeXt-T%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="ConvNeXt-T结构图"></p>
<p><strong>ConvNeXt-T</strong>: C = (96, 192, 384, 768), B = (3, 3, 9, 3)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNeXt</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; ConvNeXt</span></span><br><span class="line"><span class="string">        A PyTorch impl of : `A ConvNet for the 2020s`  -</span></span><br><span class="line"><span class="string">          https://arxiv.org/pdf/2201.03545.pdf</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        in_chans (int): Number of input image channels. Default: 3</span></span><br><span class="line"><span class="string">        num_classes (int): Number of classes for classification head. Default: 1000</span></span><br><span class="line"><span class="string">        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]</span></span><br><span class="line"><span class="string">        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]</span></span><br><span class="line"><span class="string">        drop_path_rate (float): Stochastic depth rate. Default: 0.</span></span><br><span class="line"><span class="string">        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.</span></span><br><span class="line"><span class="string">        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_chans: <span class="built_in">int</span> = <span class="number">3</span>, num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, depths: <span class="built_in">list</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 dims: <span class="built_in">list</span> = <span class="literal">None</span>, drop_path_rate: <span class="built_in">float</span> = <span class="number">0.</span>, layer_scale_init_value: <span class="built_in">float</span> = <span class="number">1e-6</span>,</span></span><br><span class="line"><span class="params">                 head_init_scale: <span class="built_in">float</span> = <span class="number">1.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.downsample_layers = nn.ModuleList()  <span class="comment"># stem and 3 intermediate downsampling conv layers</span></span><br><span class="line">        stem = nn.Sequential(nn.Conv2d(in_chans, dims[<span class="number">0</span>], kernel_size=<span class="number">4</span>, stride=<span class="number">4</span>),</span><br><span class="line">                             LayerNorm(dims[<span class="number">0</span>], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>))</span><br><span class="line">        self.downsample_layers.append(stem)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对应stage2-stage4前的3个downsample</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            downsample_layer = nn.Sequential(LayerNorm(dims[i], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>),</span><br><span class="line">                                             nn.Conv2d(dims[i], dims[i+<span class="number">1</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">            self.downsample_layers.append(downsample_layer)</span><br><span class="line"></span><br><span class="line">        self.stages = nn.ModuleList()  <span class="comment"># 4 feature resolution stages, each consisting of multiple blocks</span></span><br><span class="line">        <span class="comment"># 等差数列</span></span><br><span class="line">        dp_rates = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, <span class="built_in">sum</span>(depths))]</span><br><span class="line">        cur = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 构建每个stage中堆叠的block</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            stage = nn.Sequential(</span><br><span class="line">                *[Block(dim=dims[i], drop_rate=dp_rates[cur + j], layer_scale_init_value=layer_scale_init_value)</span><br><span class="line">                  <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(depths[i])]</span><br><span class="line">            )</span><br><span class="line">            self.stages.append(stage)</span><br><span class="line">            <span class="comment"># cur代表在当前Stage之前构建好了的block的个数</span></span><br><span class="line">            cur += depths[i]</span><br><span class="line"></span><br><span class="line">        self.norm = nn.LayerNorm(dims[-<span class="number">1</span>], eps=<span class="number">1e-6</span>)  <span class="comment"># final norm layer</span></span><br><span class="line">        self.head = nn.Linear(dims[-<span class="number">1</span>], num_classes)</span><br><span class="line">        self.apply(self._init_weights)</span><br><span class="line">        <span class="comment"># 对head，也就是Linear层对weight和bias乘上了head_init_scale（默认为1）</span></span><br><span class="line">        self.head.weight.data.mul_(head_init_scale)</span><br><span class="line">        self.head.bias.data.mul_(head_init_scale)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self, m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</span><br><span class="line">            nn.init.trunc_normal_(m.weight, std=<span class="number">0.2</span>)</span><br><span class="line">            nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            x = self.downsample_layers[i](x)</span><br><span class="line">            x = self.stages[i](x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 相当于做了个Goble Avg Pooling操作</span></span><br><span class="line">        <span class="keyword">return</span> self.norm(x.mean([-<span class="number">2</span>, -<span class="number">1</span>]))  <span class="comment"># global average pooling, (N, C, H, W) -&gt; (N, C)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        x = self.forward_features(x)</span><br><span class="line">        x = self.head(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="实例化模型">实例化模型</h3>
<ul>
<li><strong>ConvNeXt-T</strong>: C = (96, 192, 384, 768), B = (3, 3, 9, 3)</li>
<li><strong>ConvNeXt-S</strong>: C = (96, 192, 384, 768), B = (3, 3, 27, 3)</li>
<li><strong>ConvNeXt-B</strong>: C = (128, 256, 512, 1024), B = (3, 3, 27, 3)</li>
<li><strong>ConvNeXt-L</strong>: C = (192, 384, 768, 1536), B = (3, 3, 27, 3)</li>
<li><strong>ConvNeXt-XL</strong>: C = (256, 512, 1024, 2048), B = (3, 3, 27, 3)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_tiny</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth</span></span><br><span class="line">    model = ConvNeXt(depths=[<span class="number">3</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">3</span>],</span><br><span class="line">                     dims=[<span class="number">96</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">768</span>],</span><br><span class="line">                     num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_small</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth</span></span><br><span class="line">    model = ConvNeXt(depths=[<span class="number">3</span>, <span class="number">3</span>, <span class="number">27</span>, <span class="number">3</span>],</span><br><span class="line">                     dims=[<span class="number">96</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">768</span>],</span><br><span class="line">                     num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_base</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth</span></span><br><span class="line">    <span class="comment"># https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth</span></span><br><span class="line">    model = ConvNeXt(depths=[<span class="number">3</span>, <span class="number">3</span>, <span class="number">27</span>, <span class="number">3</span>],</span><br><span class="line">                     dims=[<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>],</span><br><span class="line">                     num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_large</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth</span></span><br><span class="line">    <span class="comment"># https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth</span></span><br><span class="line">    model = ConvNeXt(depths=[<span class="number">3</span>, <span class="number">3</span>, <span class="number">27</span>, <span class="number">3</span>],</span><br><span class="line">                     dims=[<span class="number">192</span>, <span class="number">384</span>, <span class="number">768</span>, <span class="number">1536</span>],</span><br><span class="line">                     num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convnext_xlarge</span>(<span class="params">num_classes: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth</span></span><br><span class="line">    model = ConvNeXt(depths=[<span class="number">3</span>, <span class="number">3</span>, <span class="number">27</span>, <span class="number">3</span>],</span><br><span class="line">                     dims=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</span><br><span class="line">                     num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure>
<h2 id="train">train</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> convnext_tiny <span class="keyword">as</span> create_model</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, create_lr_scheduler, get_params_groups, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;using <span class="subst">&#123;device&#125;</span> device.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(img_size),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.143</span>)),</span><br><span class="line">                                   transforms.CenterCrop(img_size),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    model = create_model(num_classes=args.num_classes).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">assert</span> os.path.exists(args.weights), <span class="string">&quot;weights file: &#x27;&#123;&#125;&#x27; not exist.&quot;</span>.<span class="built_in">format</span>(args.weights)</span><br><span class="line">        weights_dict = torch.load(args.weights, map_location=device)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        <span class="comment"># 删除有关分类类别的权重</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">list</span>(weights_dict.keys()):</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;head&quot;</span> <span class="keyword">in</span> k:</span><br><span class="line">                <span class="keyword">del</span> weights_dict[k]</span><br><span class="line">        <span class="built_in">print</span>(model.load_state_dict(weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除head外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;head&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;training &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pg = [p for p in model.parameters() if p.requires_grad]</span></span><br><span class="line">    pg = get_params_groups(model, weight_decay=args.wd)</span><br><span class="line">    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=args.wd)</span><br><span class="line">    lr_scheduler = create_lr_scheduler(optimizer, <span class="built_in">len</span>(train_loader), args.epochs,</span><br><span class="line">                                       warmup=<span class="literal">True</span>, warmup_epochs=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    best_acc = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        train_loss, train_acc = train_one_epoch(model=model,</span><br><span class="line">                                                optimizer=optimizer,</span><br><span class="line">                                                data_loader=train_loader,</span><br><span class="line">                                                device=device,</span><br><span class="line">                                                epoch=epoch,</span><br><span class="line">                                                lr_scheduler=lr_scheduler)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        val_loss, val_acc = evaluate(model=model,</span><br><span class="line">                                     data_loader=val_loader,</span><br><span class="line">                                     device=device,</span><br><span class="line">                                     epoch=epoch)</span><br><span class="line"></span><br><span class="line">        tags = [<span class="string">&quot;train_loss&quot;</span>, <span class="string">&quot;train_acc&quot;</span>, <span class="string">&quot;val_loss&quot;</span>, <span class="string">&quot;val_acc&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], train_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], train_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], val_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">3</span>], val_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">4</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> best_acc &lt; val_acc:</span><br><span class="line">            torch.save(model.state_dict(), <span class="string">&quot;./weights/best_model.pth&quot;</span>)</span><br><span class="line">            best_acc = val_acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">3</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">5e-4</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--wd&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">5e-2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预训练权重路径，如果不想载入就设置为空字符</span></span><br><span class="line">    <span class="comment"># 链接: https://pan.baidu.com/s/1aNqQW4n_RrUlWUBNlaJRHA  密码: i83t</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./convnext_tiny_1k_224_ema.pth&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    <span class="comment"># 是否冻结head以外所有权重</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<h3 id="训练结果">训练结果</h3>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h2 id="predict">predict</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> convnext_tiny <span class="keyword">as</span> create_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;using <span class="subst">&#123;device&#125;</span> device.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    num_classes = <span class="number">5</span></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.14</span>)),</span><br><span class="line">         transforms.CenterCrop(img_size),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = create_model(num_classes=num_classes).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/best_model.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h3 id="预测结果">预测结果</h3>
<p><img src="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>ConvNeXt</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型之CNN（二十六）MobileViT网络讲解及通过Pytorch搭建</title>
    <url>/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p>MobileViT是CNN和Transformer的混合架构模型，原论文：<a href="https://arxiv.org/abs/2110.02178">MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer</a></p>
<h1>网络架构学习</h1>
<h2 id="前言">前言</h2>
<p>当前纯Transformer模型存在的问题：</p>
<ul>
<li>参数多，算力要求高（比如ViT-L Patch16模型，仅权重模型就有1G多）；</li>
<li>缺少空间归纳偏置；</li>
<li>迁移到其他任务比较繁琐（相对于CNN）；</li>
</ul>
<blockquote>
<p>为什么会繁琐？</p>
<p>主要由于位置偏置导致的，比如在Vision Transformer当中采用的是绝对位置偏置，那么绝对位置偏置的序列长度是和输入token的序列长度保持一致的。<strong>也就是说在训练模型的时候，在指定了输入图像尺寸之后，绝对位置偏置所对应的序列长度其实就固定了</strong>，如果后期要更改输入图片的尺寸的话，会发现通过图片生成的token序列长度和绝对位置偏置的序列长度是不一致的。这样就没法进行一个相加以及后续的处理了。</p>
<p>针对这个问题，现有的问题最简单的就是去进行一个差值。也就是说将绝对位置编码给差值到与输入token数据序列相同的一个长度，那么差值之后呢，又会引入另外一个新的问题。就是说一般我们将差值之后的模型拿来直接用的话，会发现可能会出现掉点的情况。但是对于CNN模型，比如在224x224的图片尺寸上进行训练，然后在384x384的尺寸上进行验证，一般是会出现一个长点的情况，比如在ImageNet上可能会涨一个点左右。但是对于Transformer的模型，如果简单通过差值的方式在一个相对更高的分辨率上进行验证，会发现可能会掉点。</p>
<p><strong>所以说一般对Transformer的绝对位置偏置进行差值之后，还要进行一个微调</strong>。但如果每次修改了图片尺寸之后都要重新对绝对位置偏置进行一个差值和微调，就会太麻烦了一点。</p>
<p>有人会说，可以采用像Swin Transformer当中所采用的相对位置偏执。的确如此，在Swin Transformer当中的相对位置偏执，对输入图片尺寸并不敏感，只对设置的window的大小有关。但如果训练的模型的输入图片尺寸和迁移到其他任务的图片尺寸相差比较大的话，其实一般还是会对window的尺寸进行一个调整的。比如说先在ImageNet上进行一个预训练，那么训练的时候可能输入的图片大小为224x224，假设要迁移到目标检测任务中，那么此时输入的图像分辨率可能是1280x1280，那么很明显，从224到1280，图像尺寸发生非常大的变化。<strong>如果此时不去调整window的尺寸大小的话，那么效果依旧会受到影响。所以一般针对这个情况，还是会去将window的尺寸给设置的更大一点</strong>。一旦window的尺寸发生变化，那么相对位置编码的序列长度也会发生变化，那么还是遇见更改提到的问题。</p>
<p>因此当前所采用的这些位置编码其实有很多值得优化的地方，比如在Swin TransformerV2的论文当中，其实就针对Swin Transformerv1当中所采用的相对位置编码进行了优化。</p>
</blockquote>
<ul>
<li>模型训练困难（相对于CNN）</li>
</ul>
<blockquote>
<p>根据现有的一些经验，训练一个Transformer往往需要更多训练数据和迭代更多的epoch，需要更大的L2正则，需要更多的数据增强，并且对数据增强是比较敏感的。</p>
</blockquote>
<p>针对以上提出的几点问题，现有一个很好的解决办法就是可以将CNN架构和Transformer架构进行一个混合使用。因为CNN架构本身就带有空间归纳偏置，如果使用它之后就不需要单独去加上位置偏置或者位置编码。并且加入CNN之后是能够加速网络的收敛，使整个网络的训练过程更加稳定。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E4%BB%A5%E5%8F%8A%E5%BD%93%E5%B9%B4%E6%AF%94%E8%BE%83%E4%B8%BB%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E8%BD%BB%E9%87%8F%E7%9A%84ViT%E6%A8%A1%E5%9E%8B.png" alt="对比MobileViT以及当年比较主流的一些相对轻量的ViT模型"></p>
<p>在上图中，Augmentation指数据增强的两种方式，一个是比较基础的basic，另一个是更加先进的advance。basic就代表采用的使像ResNet那样的一个比较简单的数据增强，也就是随机裁剪加一个水平方向的随机翻转。但对advance所包含的数据增强方式就非常的多。</p>
<p>根据上图（b）表可以看出，MobileViT尽管采用的Augmentation中的basic，但是Top-1还是能达到74.8和78.4，也说明MobileViT对数据增强没有那么敏感，而且学习能力也是比较强的。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E4%BB%A5%E5%8F%8A%E5%BD%93%E5%B9%B4%E6%AF%94%E8%BE%83%E4%B8%BB%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E8%BD%BB%E9%87%8F%E5%92%8C%E9%87%8D%E9%87%8F%E7%9A%84CNN%E6%A8%A1%E5%9E%8B.png" alt="对比MobileViT以及当年比较主流的一些相对轻量和重量的CNN模型"></p>
<p>根据上图MobileViT与比较轻量和重的模型对比，能够看出来CNN和Transformer所结合的MobileViT模型确实效果是非常不错的。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E7%9A%84%E6%80%A7%E8%83%BD.png" alt="对比MobileViT与CNN网络的训练速度"></p>
<h2 id="模型结构解析">模型结构解析</h2>
<h3 id="Vision-Transformer结构简介">Vision Transformer结构简介</h3>
<p>这是论文当中作者所给的标准的Vision Transformer视觉模型结构，和之前讲过的Vision Transformer有一点点的不一样。最主要这里并没有Vision Transformer里面所提到的class token。其实class token就是参考BERT网络，但是对于视觉任务而言，其实class token并不是必须的，所以下图所展示的是一个更加标准的针对视觉的一个Vision Transformer架构。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Standard_visual_transformer.png" alt="Standard visual transformer(ViT)"></p>
<p>首先可以看到我们是针对输入的图片划分为一个一个patch，然后将每个patch的数据进行展平，展平之后再通过一个线性映射得到针对每一个patch所对应的token（其实每一个token对应的也就是一个向量而已），那么将这些token放在一起就得到一个token序列（在网络实际搭建过程当中，其实关于这一步也就是<strong>展平加线性映射这一块</strong>是可以直接通过一个卷积操作实现的），然后再加上一个位置编码或者说位置偏置（可以采用绝对位置偏置或者相对位置偏置），接着再通过L x Transformer Block（其实可以在Transformer Block和全连接层之间加一个全局池化层），再通过一个全连接层就得到输出。</p>
<h3 id="MobileViT介绍">MobileViT介绍</h3>
<h4 id="整体架构">整体架构</h4>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MobileViT_visual_transformer.png" alt="MobileViT visual transformer"></p>
<h4 id="MV2">MV2</h4>
<p>相当于MobileNet v2当中提出的Inverted Residual Block。有些MV2会有向下的箭头，这代表这个模块是需要对特征图进行一个下采样的。</p>
<h4 id="MobileViT-block"><strong>MobileViT block</strong></h4>
<p>首先输入一个$H✖W✖C$的特征图，先做一个局部的表征或者说做一个局部的建模（<code>Local representations</code>，<strong>其实就是通过一个卷积核大小为$n✖n$的卷积层实现的。在代码当中就是一个3x3的卷积层，然后再通过一个1x1的卷积层去调整通道数</strong>）。</p>
<p>调整完之后，进行一个全局表征或者说全局的建模（<code>global representations</code>，<strong>其实就是通过一个Unfold，再通过L个Transformer Block，然后再通过Fold折叠回特征图</strong>）。</p>
<p>接着再通过一个1x1的卷积层去调整通道数，将通道数又还原回了C，也就是和输入的特征图的通道数保持一致。接着通过一个shortcut将更改得到的特征图和输入特征图进行concat拼接，拼接玩完之后通道数为2C，再通过一个$n✖n$的卷积层进行一个特征融合（在源码中，这里的n对应的是3x3）。</p>
<p>这就是整一个<code>MobileViT block</code>的结构，核心其实还是有关全局表征这部分</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MV2%E5%92%8CMobile_ViT_Block.png" alt="MV2和Mobile ViT Block"></p>
<h4 id="全局表征中的Transformer"><strong>全局表征中的Transformer</strong></h4>
<p>下图（中）为方便忽略channel，对于输入transformer block或者说transformer encoder，一般将特征图直接展平成一个序列，然后再输入到transformer block当中。</p>
<p>在做Self-Attention的时候，图中的每一个像素或者说每一个token是需要和所有的token进行一个Self-Attention的。<strong>但是在MobileViT当中，并不是这么去做的</strong>。</p>
<p>首先会将输入特征图划分成一个个patch，在下图（中）中以2x2大小的patch为例。</p>
<p><strong>划分完之后在实际做Attention时，其实是将每一个patch当中对应相同位置的token去做self Attention，也就是说，下图（中）这些颜色相同的token才会去所self Attention，那么通过这么个方式，就能减少Attention的计算量</strong>。</p>
<blockquote>
<p>对于原始的self Attention这段计算过程（也就是说每一个token都要和所有的token去进行一个Attention），假设计算某一个token与其他所有token进行Attention的计算量，记为$WHC$，因为要和每一个token都去进行self Attention；</p>
<p>但是在MobileViT当中，只是让颜色相同的这些token去做self Attention，以下图2x2的patch为例，对于每一个token做self Attention的时候，实际计算量为$\frac{HWC}{4}$，因为这里的patch大小为2x2，所以计算量缩减为原来的$\frac{1}{4}$。</p>
</blockquote>
<p>其实这样做只能减少在做self Attention时的计算量。对于transformer block或者说transformer encoder的其他部分的计算量是没有任何变化的。因为像下图（左）中这些像Norm以及MLP其实是针对token去做处理的。</p>
<blockquote>
<p>为什么可以这么做呢？</p>
<p>因为在对图像进行处理中，是存在非常多的冗余数据，特别是对于图像分辨率较高的一个情况。对于相对底层的特征图也就是说当H和W比较大的时候，相邻像素之间的一个信息差异其实是比较小的。如果在做self Attention的时候，每一个token都要去看一遍的话，还是挺浪费算力的。</p>
<p>但并不是说去看相邻的像素或者token没有意义，只是说在分辨率较高的特征图上，收益可能很低，那么增加了这些计算成本远大于ACC上的收益。而且在做全局表征之前，也就是<code>Local representations</code>，已经提前做了一个局部表征，后面做全局表征的时候其实就没必要那么细了。</p>
</blockquote>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81.png" alt="全局表征中的Transformer block"></p>
<h4 id="全局表征中的Unfold和Fold">全局表征中的Unfold和Fold</h4>
<p>在MovileViT中，只是将这些颜色相同的token去做Attention，颜色不同的token是不做信息交互的，所以在论文当中，这里的<code>Unfold</code>就是将颜色相同的这些token给拼成一个序列。比如将patch设置为2x2的话，通过Unfold可以得到4个序列。</p>
<p>之后将每个序列输入到<code>Transformer Block</code>当中进行全局建模。这里的每一个序列在输入Transformer Block时，是可以进行并行计算的，所以速度还是非常快的。</p>
<p>最后再通过<code>Fold</code>方法将这些特征折叠回原特征图的一个形式。</p>
<p><strong>所以全局表征中的Unfold和Fold就是对特征图进行一个拆分和重新折叠的过程</strong>。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81%E4%B8%AD%E7%9A%84Unfold%E5%92%8CFold.png" alt="全局表征中的Unfold和Fold"></p>
<h3 id="Patch-Size对性能的影响">Patch Size对性能的影响</h3>
<p>作者有做两组对比实验，<strong>分别对应的Patch Size时8，4，2和2，2，2</strong>。这三个数字分别对应的是针对下采样的8倍，16倍以及32倍的 特征图。并且如下图所示，分别在分类、目标检测和分割任务上进行了对比。横坐标对应的时推理时间，希望越小越好，纵坐标对应的时在各项任务上的一个指标，一般都是越大越好。所以越靠近坐标的左上方代表模型的综合性能越好。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Patch_size%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D.png" alt="Patch Size对性能的影响（两组实验）"></p>
<h2 id="模型详细配置">模型详细配置</h2>
<p>一共有三类模型配置：</p>
<ul>
<li>MobileViT-S(small)；</li>
<li>MobileViT-XS(extra small)；</li>
<li>MobileViT-XXS(extra extra small)</li>
</ul>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE-MobileViT-XXS.png" alt="模型配置-MobileViT-XXS"></p>
<ul>
<li><code>out_channels</code>：每一个layer输出的一个特征图的通道数；</li>
<li><code>mv2_exp</code>：在Inverted Residual模块当中的expansion ratio；</li>
<li><code>transformer_channels</code>：输入transformer block的一个token的向量长度或者输入特征图的通道数；</li>
<li><code>ffn_dim</code>：transformer block MLP中间层的一个节点个数；</li>
<li><code>patch_h</code>和<code>patch_w</code>：patch size的大小；</li>
<li><code>num_heads</code>：transformer block当中的Muti-Head Self-Attention的header的个数。</li>
</ul>
<h1>Pytorch搭建</h1>
<h2 id="工程目录">工程目录</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── Test15_MobileViT</span><br><span class="line">	├── model.py（模型文件）   </span><br><span class="line">	├── my_dataset.py（数据处理文件）    </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,mobilevit.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── model_config.py（三种模型的详细参数）</span><br><span class="line">	├── transformer.py</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）  </span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── mobilevit_xxs.pt（迁移学习，提前下载好mobilevit_xxs.pt权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h2 id="model">model</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">original code from apple:</span></span><br><span class="line"><span class="string">https://github.com/apple/ml-cvnets/blob/main/cvnets/models/classification/mobilevit.py</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span>, <span class="type">Tuple</span>, <span class="type">Union</span>, <span class="type">Dict</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformer <span class="keyword">import</span> TransformerEncoder</span><br><span class="line"><span class="keyword">from</span> model_config <span class="keyword">import</span> get_config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_divisible</span>(<span class="params"></span></span><br><span class="line"><span class="params">    v: <span class="type">Union</span>[<span class="built_in">float</span>, <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">    divisor: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">    min_value: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">float</span>, <span class="built_in">int</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Union</span>[<span class="built_in">float</span>, <span class="built_in">int</span>]:</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        kernel_size: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">        stride: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]]] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        groups: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        bias: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        use_norm: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        use_act: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        expand_ratio: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">        skip_connection: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor, *args, **kwargs</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MobileViTBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        transformer_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        ffn_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        n_transformer_blocks: <span class="built_in">int</span> = <span class="number">2</span>,</span></span><br><span class="line"><span class="params">        head_dim: <span class="built_in">int</span> = <span class="number">32</span>,</span></span><br><span class="line"><span class="params">        attn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        ffn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        patch_h: <span class="built_in">int</span> = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        patch_w: <span class="built_in">int</span> = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        conv_ksize: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">        *args,</span></span><br><span class="line"><span class="params">        **kwargs</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">unfolding</span>(<span class="params">self, x: Tensor</span>) -&gt; <span class="type">Tuple</span>[Tensor, <span class="type">Dict</span>]:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">folding</span>(<span class="params">self, x: Tensor, info_dict: <span class="type">Dict</span></span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MobileViT</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_cfg: <span class="type">Dict</span>, num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, input_channel, cfg: <span class="type">Dict</span></span>) -&gt; <span class="type">Tuple</span>[nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_mobilenet_layer</span>(<span class="params">input_channel: <span class="built_in">int</span>, cfg: <span class="type">Dict</span></span>) -&gt; <span class="type">Tuple</span>[nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_mit_layer</span>(<span class="params">input_channel: <span class="built_in">int</span>, cfg: <span class="type">Dict</span></span>) -&gt; [nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_parameters</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mobile_vit_xx_small</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mobile_vit_x_small</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mobile_vit_small</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h3 id="ConvLayer类">ConvLayer类</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLayer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Applies a 2D convolution over an input</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        in_channels (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, C_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        out_channels (int): :math:`C_&#123;out&#125;` from an expected output of size :math:`(N, C_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`</span></span><br><span class="line"><span class="string">        kernel_size (Union[int, Tuple[int, int]]): Kernel size for convolution.</span></span><br><span class="line"><span class="string">        stride (Union[int, Tuple[int, int]]): Stride for convolution. Default: 1</span></span><br><span class="line"><span class="string">        groups (Optional[int]): Number of groups in convolution. Default: 1</span></span><br><span class="line"><span class="string">        bias (Optional[bool]): Use bias. Default: ``False``</span></span><br><span class="line"><span class="string">        use_norm (Optional[bool]): Use normalization layer after convolution. Default: ``True``</span></span><br><span class="line"><span class="string">        use_act (Optional[bool]): Use activation layer after convolution (or convolution and normalization).</span></span><br><span class="line"><span class="string">                                Default: ``True``</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`</span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        For depth-wise convolution, `groups=C_&#123;in&#125;=C_&#123;out&#125;`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        kernel_size: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">        stride: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]]] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        groups: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        bias: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        use_norm: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        use_act: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(kernel_size, <span class="built_in">int</span>):</span><br><span class="line">            kernel_size = (kernel_size, kernel_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(stride, <span class="built_in">int</span>):</span><br><span class="line">            stride = (stride, stride)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(kernel_size, <span class="type">Tuple</span>)</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(stride, <span class="type">Tuple</span>)</span><br><span class="line"></span><br><span class="line">        padding = (</span><br><span class="line">            <span class="built_in">int</span>((kernel_size[<span class="number">0</span>] - <span class="number">1</span>) / <span class="number">2</span>),</span><br><span class="line">            <span class="built_in">int</span>((kernel_size[<span class="number">1</span>] - <span class="number">1</span>) / <span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        block = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        conv_layer = nn.Conv2d(</span><br><span class="line">            in_channels=in_channels,</span><br><span class="line">            out_channels=out_channels,</span><br><span class="line">            kernel_size=kernel_size,</span><br><span class="line">            stride=stride,</span><br><span class="line">            groups=groups,</span><br><span class="line">            padding=padding,</span><br><span class="line">            bias=bias</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        block.add_module(name=<span class="string">&quot;conv&quot;</span>, module=conv_layer)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_norm:</span><br><span class="line">            norm_layer = nn.BatchNorm2d(num_features=out_channels, momentum=<span class="number">0.1</span>)</span><br><span class="line">            block.add_module(name=<span class="string">&quot;norm&quot;</span>, module=norm_layer)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_act:</span><br><span class="line">            act_layer = nn.SiLU()</span><br><span class="line">            block.add_module(name=<span class="string">&quot;act&quot;</span>, module=act_layer)</span><br><span class="line">		</span><br><span class="line">        <span class="comment"># 返回的Sequential的类</span></span><br><span class="line">        self.block = block</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">return</span> self.block(x)</span><br></pre></td></tr></table></figure>
<h3 id="MV2（InvertedResidual类）">MV2（InvertedResidual类）</h3>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MV2%E5%92%8CMobile_ViT_Block.png" alt="MV2和Mobile ViT Block"></p>
<p><code>skip_connection</code>：是否使用shortcut</p>
<p><code>hidden_dim</code>：通过第一个1x1卷积层之后将特征图的通道数调整为多少</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class implements the inverted residual block, as described in `MobileNetv2 &lt;https://arxiv.org/abs/1801.04381&gt;`_ paper</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        in_channels (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, C_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        out_channels (int): :math:`C_&#123;out&#125;` from an expected output of size :math:`(N, C_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out)`</span></span><br><span class="line"><span class="string">        stride (int): Use convolutions with a stride. Default: 1</span></span><br><span class="line"><span class="string">        expand_ratio (Union[int, float]): Expand the input channels by this factor in depth-wise conv</span></span><br><span class="line"><span class="string">        skip_connection (Optional[bool]): Use skip-connection. Default: True</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`</span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        If `in_channels =! out_channels` and `stride &gt; 1`, we set `skip_connection=False`</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        expand_ratio: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">        skip_connection: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">assert</span> stride <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">        hidden_dim = make_divisible(<span class="built_in">int</span>(<span class="built_in">round</span>(in_channels * expand_ratio)), <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        block = nn.Sequential()</span><br><span class="line">        <span class="keyword">if</span> expand_ratio != <span class="number">1</span>:</span><br><span class="line">            block.add_module(</span><br><span class="line">                name=<span class="string">&quot;exp_1x1&quot;</span>,</span><br><span class="line">                module=ConvLayer(</span><br><span class="line">                    in_channels=in_channels,</span><br><span class="line">                    out_channels=hidden_dim,</span><br><span class="line">                    kernel_size=<span class="number">1</span></span><br><span class="line">                ),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        block.add_module(</span><br><span class="line">            name=<span class="string">&quot;conv_3x3&quot;</span>,</span><br><span class="line">            module=ConvLayer(</span><br><span class="line">                in_channels=hidden_dim,</span><br><span class="line">                out_channels=hidden_dim,</span><br><span class="line">                stride=stride,</span><br><span class="line">                kernel_size=<span class="number">3</span>,</span><br><span class="line">                groups=hidden_dim</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        block.add_module(</span><br><span class="line">            <span class="comment"># dw卷积</span></span><br><span class="line">            name=<span class="string">&quot;red_1x1&quot;</span>,</span><br><span class="line">            module=ConvLayer(</span><br><span class="line">                in_channels=hidden_dim,</span><br><span class="line">                out_channels=out_channels,</span><br><span class="line">                kernel_size=<span class="number">1</span>,</span><br><span class="line">                use_act=<span class="literal">False</span>,</span><br><span class="line">                use_norm=<span class="literal">True</span>,</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.block = block</span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.out_channels = out_channels</span><br><span class="line">        self.exp = expand_ratio</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.use_res_connect = (</span><br><span class="line">            self.stride == <span class="number">1</span> <span class="keyword">and</span> in_channels == out_channels <span class="keyword">and</span> skip_connection</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor, *args, **kwargs</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">if</span> self.use_res_connect:</span><br><span class="line">            <span class="keyword">return</span> x + self.block(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.block(x)</span><br></pre></td></tr></table></figure>
<h3 id="MobileViTBlock">MobileViTBlock</h3>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Mobile_ViT_Block.png" alt="MobileViT Block"></p>
<p><code>transformer_dim</code>：输入到Transformer Encoder Block中每个token所对应的序列长度；</p>
<p><code>ffn_dim</code>：Transformer Encoder Block中MLP结构的第一个全连接层的节点个数；</p>
<p><code>n_transformer_blocks</code>：global representations当中重复堆叠Transformer Encoder Block的次数；</p>
<p><code>head_dim</code>：在做Muti-Head Self-Attention时每个header所对应的dimension；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MobileViTBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class defines the `MobileViT block &lt;https://arxiv.org/abs/2110.02178?context=cs.LG&gt;`_</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        opts: command line arguments</span></span><br><span class="line"><span class="string">        in_channels (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, C_&#123;in&#125;, H, W)`</span></span><br><span class="line"><span class="string">        transformer_dim (int): Input dimension to the transformer unit</span></span><br><span class="line"><span class="string">        ffn_dim (int): Dimension of the FFN block</span></span><br><span class="line"><span class="string">        n_transformer_blocks (int): Number of transformer blocks. Default: 2</span></span><br><span class="line"><span class="string">        head_dim (int): Head dimension in the multi-head attention. Default: 32</span></span><br><span class="line"><span class="string">        attn_dropout (float): Dropout in multi-head attention. Default: 0.0</span></span><br><span class="line"><span class="string">        dropout (float): Dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        ffn_dropout (float): Dropout between FFN layers in transformer. Default: 0.0</span></span><br><span class="line"><span class="string">        patch_h (int): Patch height for unfolding operation. Default: 8</span></span><br><span class="line"><span class="string">        patch_w (int): Patch width for unfolding operation. Default: 8</span></span><br><span class="line"><span class="string">        transformer_norm_layer (Optional[str]): Normalization layer in the transformer block. Default: layer_norm</span></span><br><span class="line"><span class="string">        conv_ksize (int): Kernel size to learn local representations in MobileViT block. Default: 3</span></span><br><span class="line"><span class="string">        no_fusion (Optional[bool]): Do not combine the input and output feature maps. Default: False</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        transformer_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        ffn_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        n_transformer_blocks: <span class="built_in">int</span> = <span class="number">2</span>,</span></span><br><span class="line"><span class="params">        head_dim: <span class="built_in">int</span> = <span class="number">32</span>,</span></span><br><span class="line"><span class="params">        attn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        ffn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        patch_h: <span class="built_in">int</span> = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        patch_w: <span class="built_in">int</span> = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        conv_ksize: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">        *args,</span></span><br><span class="line"><span class="params">        **kwargs</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        conv_3x3_in = ConvLayer(</span><br><span class="line">            in_channels=in_channels,</span><br><span class="line">            out_channels=in_channels,</span><br><span class="line">            kernel_size=conv_ksize,</span><br><span class="line">            stride=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        conv_1x1_in = ConvLayer(</span><br><span class="line">            in_channels=in_channels,</span><br><span class="line">            out_channels=transformer_dim,</span><br><span class="line">            kernel_size=<span class="number">1</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            use_norm=<span class="literal">False</span>,</span><br><span class="line">            use_act=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        conv_1x1_out = ConvLayer(</span><br><span class="line">            in_channels=transformer_dim,</span><br><span class="line">            out_channels=in_channels,</span><br><span class="line">            kernel_size=<span class="number">1</span>,</span><br><span class="line">            stride=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        conv_3x3_out = ConvLayer(</span><br><span class="line">            in_channels=<span class="number">2</span> * in_channels,</span><br><span class="line">            out_channels=in_channels,</span><br><span class="line">            kernel_size=conv_ksize,</span><br><span class="line">            stride=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.local_rep = nn.Sequential()</span><br><span class="line">        self.local_rep.add_module(name=<span class="string">&quot;conv_3x3&quot;</span>, module=conv_3x3_in)</span><br><span class="line">        self.local_rep.add_module(name=<span class="string">&quot;conv_1x1&quot;</span>, module=conv_1x1_in)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> transformer_dim % head_dim == <span class="number">0</span></span><br><span class="line">        num_heads = transformer_dim // head_dim</span><br><span class="line"></span><br><span class="line">        global_rep = [</span><br><span class="line">            TransformerEncoder(</span><br><span class="line">                embed_dim=transformer_dim,</span><br><span class="line">                ffn_latent_dim=ffn_dim,</span><br><span class="line">                num_heads=num_heads,</span><br><span class="line">                attn_dropout=attn_dropout,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                ffn_dropout=ffn_dropout</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_transformer_blocks)</span><br><span class="line">        ]</span><br><span class="line">        global_rep.append(nn.LayerNorm(transformer_dim))</span><br><span class="line">        self.global_rep = nn.Sequential(*global_rep)</span><br><span class="line"></span><br><span class="line">        self.conv_proj = conv_1x1_out</span><br><span class="line">        self.fusion = conv_3x3_out</span><br><span class="line"></span><br><span class="line">        self.patch_h = patch_h</span><br><span class="line">        self.patch_w = patch_w</span><br><span class="line">        self.patch_area = self.patch_w * self.patch_h</span><br><span class="line"></span><br><span class="line">        self.cnn_in_dim = in_channels</span><br><span class="line">        self.cnn_out_dim = transformer_dim</span><br><span class="line">        self.n_heads = num_heads</span><br><span class="line">        self.ffn_dim = ffn_dim</span><br><span class="line">        self.dropout = dropout</span><br><span class="line">        self.attn_dropout = attn_dropout</span><br><span class="line">        self.ffn_dropout = ffn_dropout</span><br><span class="line">        self.n_blocks = n_transformer_blocks</span><br><span class="line">        self.conv_ksize = conv_ksize</span><br></pre></td></tr></table></figure>
<h4 id="unfolding函数">unfolding函数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">unfolding</span>(<span class="params">self, x: Tensor</span>) -&gt; <span class="type">Tuple</span>[Tensor, <span class="type">Dict</span>]:</span><br><span class="line">    patch_w, patch_h = self.patch_w, self.patch_h</span><br><span class="line">    patch_area = patch_w * patch_h</span><br><span class="line">    batch_size, in_channels, orig_h, orig_w = x.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 向上取整</span></span><br><span class="line">    new_h = <span class="built_in">int</span>(math.ceil(orig_h / self.patch_h) * self.patch_h)</span><br><span class="line">    new_w = <span class="built_in">int</span>(math.ceil(orig_w / self.patch_w) * self.patch_w)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过差值的形式，将特征图给差值到刚刚计算得到的new_h和new_w，以保证特征图能够被patch完整划分的</span></span><br><span class="line">    interpolate = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> new_w != orig_w <span class="keyword">or</span> new_h != orig_h:</span><br><span class="line">        <span class="comment"># Note: Padding can be done, but then it needs to be handled in attention function.</span></span><br><span class="line">        x = F.interpolate(x, size=(new_h, new_w), mode=<span class="string">&quot;bilinear&quot;</span>, align_corners=<span class="literal">False</span>)</span><br><span class="line">        interpolate = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># number of patches along width and height</span></span><br><span class="line">    num_patch_w = new_w // patch_w  <span class="comment"># n_w</span></span><br><span class="line">    num_patch_h = new_h // patch_h  <span class="comment"># n_h</span></span><br><span class="line">    num_patches = num_patch_h * num_patch_w  <span class="comment"># N</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将相同颜色的token给抽离出来</span></span><br><span class="line">    <span class="comment"># [B, C, H, W] -&gt; [B * C * n_h, p_h, n_w, p_w]</span></span><br><span class="line">    x = x.reshape(batch_size * in_channels * num_patch_h, patch_h, num_patch_w, patch_w)</span><br><span class="line">    <span class="comment"># [B * C * n_h, p_h, n_w, p_w] -&gt; [B * C * n_h, n_w, p_h, p_w]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># [B * C * n_h, n_w, p_h, p_w] -&gt; [B, C, N, P] where P = p_h * p_w and N = n_h * n_w</span></span><br><span class="line">    x = x.reshape(batch_size, in_channels, num_patches, patch_area)</span><br><span class="line">    <span class="comment"># [B, C, N, P] -&gt; [B, P, N, C]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># [B, P, N, C] -&gt; [BP, N, C]</span></span><br><span class="line">    x = x.reshape(batch_size * patch_area, num_patches, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    info_dict = &#123;</span><br><span class="line">        <span class="string">&quot;orig_size&quot;</span>: (orig_h, orig_w),</span><br><span class="line">        <span class="string">&quot;batch_size&quot;</span>: batch_size,</span><br><span class="line">        <span class="string">&quot;interpolate&quot;</span>: interpolate,</span><br><span class="line">        <span class="string">&quot;total_patches&quot;</span>: num_patches,</span><br><span class="line">        <span class="string">&quot;num_patches_w&quot;</span>: num_patch_w,</span><br><span class="line">        <span class="string">&quot;num_patches_h&quot;</span>: num_patch_h,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x, info_dict</span><br></pre></td></tr></table></figure>
<h4 id="folding函数">folding函数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">folding</span>(<span class="params">self, x: Tensor, info_dict: <span class="type">Dict</span></span>) -&gt; Tensor:</span><br><span class="line">    n_dim = x.dim()</span><br><span class="line">    <span class="keyword">assert</span> n_dim == <span class="number">3</span>, <span class="string">&quot;Tensor should be of shape BPxNxC. Got: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        x.shape</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># [BP, N, C] --&gt; [B, P, N, C]</span></span><br><span class="line">    x = x.contiguous().view(</span><br><span class="line">        info_dict[<span class="string">&quot;batch_size&quot;</span>], self.patch_area, info_dict[<span class="string">&quot;total_patches&quot;</span>], -<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    batch_size, pixels, num_patches, channels = x.size()</span><br><span class="line">    num_patch_h = info_dict[<span class="string">&quot;num_patches_h&quot;</span>]</span><br><span class="line">    num_patch_w = info_dict[<span class="string">&quot;num_patches_w&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [B, P, N, C] -&gt; [B, C, N, P]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># [B, C, N, P] -&gt; [B*C*n_h, n_w, p_h, p_w]</span></span><br><span class="line">    x = x.reshape(batch_size * channels * num_patch_h, num_patch_w, self.patch_h, self.patch_w)</span><br><span class="line">    <span class="comment"># [B*C*n_h, n_w, p_h, p_w] -&gt; [B*C*n_h, p_h, n_w, p_w]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># [B*C*n_h, p_h, n_w, p_w] -&gt; [B, C, H, W]</span></span><br><span class="line">    x = x.reshape(batch_size, channels, num_patch_h * self.patch_h, num_patch_w * self.patch_w)</span><br><span class="line">    <span class="keyword">if</span> info_dict[<span class="string">&quot;interpolate&quot;</span>]:</span><br><span class="line">        x = F.interpolate(</span><br><span class="line">            x,</span><br><span class="line">            size=info_dict[<span class="string">&quot;orig_size&quot;</span>],</span><br><span class="line">            mode=<span class="string">&quot;bilinear&quot;</span>,</span><br><span class="line">            align_corners=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="正向传播函数">正向传播函数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">    res = x</span><br><span class="line"></span><br><span class="line">    fm = self.local_rep(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># convert feature map to patches</span></span><br><span class="line">    patches, info_dict = self.unfolding(fm)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># learn global representations</span></span><br><span class="line">    <span class="keyword">for</span> transformer_layer <span class="keyword">in</span> self.global_rep:</span><br><span class="line">        patches = transformer_layer(patches)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [B x Patch x Patches x C] -&gt; [B x C x Patches x Patch]</span></span><br><span class="line">    fm = self.folding(x=patches, info_dict=info_dict)</span><br><span class="line"></span><br><span class="line">    fm = self.conv_proj(fm)</span><br><span class="line"></span><br><span class="line">    fm = self.fusion(torch.cat((res, fm), dim=<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> fm</span><br></pre></td></tr></table></figure>
<h3 id="MobileViT类">MobileViT类</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MobileViT</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class implements the `MobileViT architecture &lt;https://arxiv.org/abs/2110.02178?context=cs.LG&gt;`_</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_cfg: <span class="type">Dict</span>, num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        image_channels = <span class="number">3</span></span><br><span class="line">        out_channels = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">        self.conv_1 = ConvLayer(</span><br><span class="line">            in_channels=image_channels,</span><br><span class="line">            out_channels=out_channels,</span><br><span class="line">            kernel_size=<span class="number">3</span>,</span><br><span class="line">            stride=<span class="number">2</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.layer_1, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer1&quot;</span>])</span><br><span class="line">        self.layer_2, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer2&quot;</span>])</span><br><span class="line">        self.layer_3, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer3&quot;</span>])</span><br><span class="line">        self.layer_4, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer4&quot;</span>])</span><br><span class="line">        self.layer_5, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer5&quot;</span>])</span><br><span class="line"></span><br><span class="line">        exp_channels = <span class="built_in">min</span>(model_cfg[<span class="string">&quot;last_layer_exp_factor&quot;</span>] * out_channels, <span class="number">960</span>)</span><br><span class="line">        self.conv_1x1_exp = ConvLayer(</span><br><span class="line">            in_channels=out_channels,</span><br><span class="line">            out_channels=exp_channels,</span><br><span class="line">            kernel_size=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Sequential()</span><br><span class="line">        self.classifier.add_module(name=<span class="string">&quot;global_pool&quot;</span>, module=nn.AdaptiveAvgPool2d(<span class="number">1</span>))</span><br><span class="line">        self.classifier.add_module(name=<span class="string">&quot;flatten&quot;</span>, module=nn.Flatten())</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0.0</span> &lt; model_cfg[<span class="string">&quot;cls_dropout&quot;</span>] &lt; <span class="number">1.0</span>:</span><br><span class="line">            self.classifier.add_module(name=<span class="string">&quot;dropout&quot;</span>, module=nn.Dropout(p=model_cfg[<span class="string">&quot;cls_dropout&quot;</span>]))</span><br><span class="line">        self.classifier.add_module(name=<span class="string">&quot;fc&quot;</span>, module=nn.Linear(in_features=exp_channels, out_features=num_classes))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># weight init</span></span><br><span class="line">        self.apply(self.init_parameters)</span><br></pre></td></tr></table></figure>
<h4 id="make-layer函数">_make_layer函数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, input_channel, cfg: <span class="type">Dict</span></span>) -&gt; <span class="type">Tuple</span>[nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">    block_type = cfg.get(<span class="string">&quot;block_type&quot;</span>, <span class="string">&quot;mobilevit&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> block_type.lower() == <span class="string">&quot;mobilevit&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> self._make_mit_layer(input_channel=input_channel, cfg=cfg)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> self._make_mobilenet_layer(input_channel=input_channel, cfg=cfg)</span><br></pre></td></tr></table></figure>
<h5 id="make-mobilenet-layer函数"><strong>_make_mobilenet_layer函数</strong></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_make_mobilenet_layer</span>(<span class="params">input_channel: <span class="built_in">int</span>, cfg: <span class="type">Dict</span></span>) -&gt; <span class="type">Tuple</span>[nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">    output_channels = cfg.get(<span class="string">&quot;out_channels&quot;</span>)</span><br><span class="line">    num_blocks = cfg.get(<span class="string">&quot;num_blocks&quot;</span>, <span class="number">2</span>)</span><br><span class="line">    expand_ratio = cfg.get(<span class="string">&quot;expand_ratio&quot;</span>, <span class="number">4</span>)</span><br><span class="line">    block = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">        stride = cfg.get(<span class="string">&quot;stride&quot;</span>, <span class="number">1</span>) <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        layer = InvertedResidual(</span><br><span class="line">            in_channels=input_channel,</span><br><span class="line">            out_channels=output_channels,</span><br><span class="line">            stride=stride,</span><br><span class="line">            expand_ratio=expand_ratio</span><br><span class="line">        )</span><br><span class="line">        block.append(layer)</span><br><span class="line">        input_channel = output_channels</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*block), input_channel</span><br></pre></td></tr></table></figure>
<h5 id="make-mit-layer函数"><strong>_make_mit_layer函数</strong></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_make_mit_layer</span>(<span class="params">input_channel: <span class="built_in">int</span>, cfg: <span class="type">Dict</span></span>) -&gt; [nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">    stride = cfg.get(<span class="string">&quot;stride&quot;</span>, <span class="number">1</span>)</span><br><span class="line">    block = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> stride == <span class="number">2</span>:</span><br><span class="line">        layer = InvertedResidual(</span><br><span class="line">            in_channels=input_channel,</span><br><span class="line">            out_channels=cfg.get(<span class="string">&quot;out_channels&quot;</span>),</span><br><span class="line">            stride=stride,</span><br><span class="line">            expand_ratio=cfg.get(<span class="string">&quot;mv_expand_ratio&quot;</span>, <span class="number">4</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        block.append(layer)</span><br><span class="line">        input_channel = cfg.get(<span class="string">&quot;out_channels&quot;</span>)</span><br><span class="line"></span><br><span class="line">    transformer_dim = cfg[<span class="string">&quot;transformer_channels&quot;</span>]</span><br><span class="line">    ffn_dim = cfg.get(<span class="string">&quot;ffn_dim&quot;</span>)</span><br><span class="line">    num_heads = cfg.get(<span class="string">&quot;num_heads&quot;</span>, <span class="number">4</span>)</span><br><span class="line">    head_dim = transformer_dim // num_heads</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> transformer_dim % head_dim != <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Transformer input dimension should be divisible by head dimension. &quot;</span></span><br><span class="line">                         <span class="string">&quot;Got &#123;&#125; and &#123;&#125;.&quot;</span>.<span class="built_in">format</span>(transformer_dim, head_dim))</span><br><span class="line"></span><br><span class="line">    block.append(MobileViTBlock(</span><br><span class="line">        in_channels=input_channel,</span><br><span class="line">        transformer_dim=transformer_dim,</span><br><span class="line">        ffn_dim=ffn_dim,</span><br><span class="line">        n_transformer_blocks=cfg.get(<span class="string">&quot;transformer_blocks&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        patch_h=cfg.get(<span class="string">&quot;patch_h&quot;</span>, <span class="number">2</span>),</span><br><span class="line">        patch_w=cfg.get(<span class="string">&quot;patch_w&quot;</span>, <span class="number">2</span>),</span><br><span class="line">        dropout=cfg.get(<span class="string">&quot;dropout&quot;</span>, <span class="number">0.1</span>),</span><br><span class="line">        ffn_dropout=cfg.get(<span class="string">&quot;ffn_dropout&quot;</span>, <span class="number">0.0</span>),</span><br><span class="line">        attn_dropout=cfg.get(<span class="string">&quot;attn_dropout&quot;</span>, <span class="number">0.1</span>),</span><br><span class="line">        head_dim=head_dim,</span><br><span class="line">        conv_ksize=<span class="number">3</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*block), input_channel</span><br></pre></td></tr></table></figure>
<h4 id="init-parameters函数">init_parameters函数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_parameters</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">        <span class="keyword">if</span> m.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.kaiming_normal_(m.weight, mode=<span class="string">&quot;fan_out&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, (nn.LayerNorm, nn.BatchNorm2d)):</span><br><span class="line">        <span class="keyword">if</span> m.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.ones_(m.weight)</span><br><span class="line">        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, (nn.Linear,)):</span><br><span class="line">        <span class="keyword">if</span> m.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.trunc_normal_(m.weight, mean=<span class="number">0.0</span>, std=<span class="number">0.02</span>)</span><br><span class="line">        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h4 id="forward函数">forward函数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">    x = self.conv_1(x)</span><br><span class="line">    x = self.layer_1(x)</span><br><span class="line">    x = self.layer_2(x)</span><br><span class="line"></span><br><span class="line">    x = self.layer_3(x)</span><br><span class="line">    x = self.layer_4(x)</span><br><span class="line">    x = self.layer_5(x)</span><br><span class="line">    x = self.conv_1x1_exp(x)</span><br><span class="line">    x = self.classifier(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="transformer">transformer</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This layer applies a multi-head self- or cross-attention as described in</span></span><br><span class="line"><span class="string">    `Attention is all you need &lt;https://arxiv.org/abs/1706.03762&gt;`_ paper</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        embed_dim (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, P, C_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        num_heads (int): Number of heads in multi-head attention</span></span><br><span class="line"><span class="string">        attn_dropout (float): Attention dropout. Default: 0.0</span></span><br><span class="line"><span class="string">        bias (bool): Use bias or not. Default: ``True``</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, P, C_&#123;in&#125;)` where :math:`N` is batch size, :math:`P` is number of patches,</span></span><br><span class="line"><span class="string">        and :math:`C_&#123;in&#125;` is input embedding dim</span></span><br><span class="line"><span class="string">        - Output: same shape as the input</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self,</span></span><br><span class="line"><span class="params">            embed_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">            num_heads: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">            attn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">            bias: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">            *args,</span></span><br><span class="line"><span class="params">            **kwargs</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> embed_dim % num_heads != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">&quot;Embedding dim must be divisible by number of heads in &#123;&#125;. Got: embed_dim=&#123;&#125; and num_heads=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                    self.__class__.__name__, embed_dim, num_heads</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        self.qkv_proj = nn.Linear(in_features=embed_dim, out_features=<span class="number">3</span> * embed_dim, bias=bias)</span><br><span class="line"></span><br><span class="line">        self.attn_dropout = nn.Dropout(p=attn_dropout)</span><br><span class="line">        self.out_proj = nn.Linear(in_features=embed_dim, out_features=embed_dim, bias=bias)</span><br><span class="line"></span><br><span class="line">        self.head_dim = embed_dim // num_heads</span><br><span class="line">        self.scaling = self.head_dim ** -<span class="number">0.5</span></span><br><span class="line">        self.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_q: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># [N, P, C]</span></span><br><span class="line">        b_sz, n_patches, in_channels = x_q.shape</span><br><span class="line"></span><br><span class="line">        <span class="comment"># self-attention</span></span><br><span class="line">        <span class="comment"># [N, P, C] -&gt; [N, P, 3C] -&gt; [N, P, 3, h, c] where C = hc</span></span><br><span class="line">        qkv = self.qkv_proj(x_q).reshape(b_sz, n_patches, <span class="number">3</span>, self.num_heads, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N, P, 3, h, c] -&gt; [N, h, 3, P, C]</span></span><br><span class="line">        qkv = qkv.transpose(<span class="number">1</span>, <span class="number">3</span>).contiguous()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N, h, 3, P, C] -&gt; [N, h, P, C] x 3</span></span><br><span class="line">        query, key, value = qkv[:, :, <span class="number">0</span>], qkv[:, :, <span class="number">1</span>], qkv[:, :, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        query = query * self.scaling</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N h, P, c] -&gt; [N, h, c, P]</span></span><br><span class="line">        key = key.transpose(-<span class="number">1</span>, -<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># QK^T</span></span><br><span class="line">        <span class="comment"># [N, h, P, c] x [N, h, c, P] -&gt; [N, h, P, P]</span></span><br><span class="line">        attn = torch.matmul(query, key)</span><br><span class="line">        attn = self.softmax(attn)</span><br><span class="line">        attn = self.attn_dropout(attn)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># weighted sum</span></span><br><span class="line">        <span class="comment"># [N, h, P, P] x [N, h, P, c] -&gt; [N, h, P, c]</span></span><br><span class="line">        out = torch.matmul(attn, value)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N, h, P, c] -&gt; [N, P, h, c] -&gt; [N, P, C]</span></span><br><span class="line">        out = out.transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(b_sz, n_patches, -<span class="number">1</span>)</span><br><span class="line">        out = self.out_proj(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerEncoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class defines the pre-norm `Transformer encoder &lt;https://arxiv.org/abs/1706.03762&gt;`_</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        embed_dim (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, P, C_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        ffn_latent_dim (int): Inner dimension of the FFN</span></span><br><span class="line"><span class="string">        num_heads (int) : Number of heads in multi-head attention. Default: 8</span></span><br><span class="line"><span class="string">        attn_dropout (float): Dropout rate for attention in multi-head attention. Default: 0.0</span></span><br><span class="line"><span class="string">        dropout (float): Dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        ffn_dropout (float): Dropout between FFN layers. Default: 0.0</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, P, C_&#123;in&#125;)` where :math:`N` is batch size, :math:`P` is number of patches,</span></span><br><span class="line"><span class="string">        and :math:`C_&#123;in&#125;` is input embedding dim</span></span><br><span class="line"><span class="string">        - Output: same shape as the input</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self,</span></span><br><span class="line"><span class="params">            embed_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">            ffn_latent_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">            num_heads: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">            attn_dropout: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">            dropout: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">            ffn_dropout: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">            *args,</span></span><br><span class="line"><span class="params">            **kwargs</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        attn_unit = MultiHeadAttention(</span><br><span class="line">            embed_dim,</span><br><span class="line">            num_heads,</span><br><span class="line">            attn_dropout=attn_dropout,</span><br><span class="line">            bias=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.pre_norm_mha = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(embed_dim),</span><br><span class="line">            attn_unit,</span><br><span class="line">            nn.Dropout(p=dropout)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.pre_norm_ffn = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(embed_dim),</span><br><span class="line">            nn.Linear(in_features=embed_dim, out_features=ffn_latent_dim, bias=<span class="literal">True</span>),</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Dropout(p=ffn_dropout),</span><br><span class="line">            nn.Linear(in_features=ffn_latent_dim, out_features=embed_dim, bias=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=dropout)</span><br><span class="line">        )</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.ffn_dim = ffn_latent_dim</span><br><span class="line">        self.ffn_dropout = ffn_dropout</span><br><span class="line">        self.std_dropout = dropout</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># multi-head attention</span></span><br><span class="line">        res = x</span><br><span class="line">        x = self.pre_norm_mha(x)</span><br><span class="line">        x = x + res</span><br><span class="line"></span><br><span class="line">        <span class="comment"># feed forward network</span></span><br><span class="line">        x = x + self.pre_norm_ffn(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="unfold-test">unfold_test</h2>
<p>up将把token按照相同颜色抽离出来的那部分代码自己重新写了，会更加容易理解。（这一块看图理解了，但代码是怎么据图片那样将颜色相同的token拼接成一个向量的，还没搞明白）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">8</span></span><br><span class="line">in_channels = <span class="number">32</span></span><br><span class="line">patch_h = <span class="number">2</span></span><br><span class="line">patch_w = <span class="number">2</span></span><br><span class="line">num_patch_h = <span class="number">16</span></span><br><span class="line">num_patch_w = <span class="number">16</span></span><br><span class="line">num_patches = num_patch_h * num_patch_w</span><br><span class="line">patch_area = patch_h * patch_w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">official</span>(<span class="params">x: torch.Tensor</span>):</span><br><span class="line">    <span class="comment"># [B, C, H, W] -&gt; [B * C * n_h, p_h, n_w, p_w]</span></span><br><span class="line">    x = x.reshape(batch_size * in_channels * num_patch_h, patch_h, num_patch_w, patch_w)</span><br><span class="line">    <span class="comment"># [B * C * n_h, p_h, n_w, p_w] -&gt; [B * C * n_h, n_w, p_h, p_w]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># [B * C * n_h, n_w, p_h, p_w] -&gt; [B, C, N, P] where P = p_h * p_w and N = n_h * n_w</span></span><br><span class="line">    x = x.reshape(batch_size, in_channels, num_patches, patch_area)</span><br><span class="line">    <span class="comment"># [B, C, N, P] -&gt; [B, P, N, C]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># [B, P, N, C] -&gt; [BP, N, C]</span></span><br><span class="line">    x = x.reshape(batch_size * patch_area, num_patches, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_self</span>(<span class="params">x: torch.Tensor</span>):</span><br><span class="line">    <span class="comment"># [B, C, H, W] -&gt; [B, C, n_h, p_h, n_w, p_w]</span></span><br><span class="line">    x = x.reshape(batch_size, in_channels, num_patch_h, patch_h, num_patch_w, patch_w)</span><br><span class="line">    <span class="comment"># [B, C, n_h, p_h, n_w, p_w] -&gt; [B, C, n_h, n_w, p_h, p_w]</span></span><br><span class="line">    x = x.transpose(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="comment"># [B, C, n_h, n_w, p_h, p_w] -&gt; [B, C, N, P] where P = p_h * p_w and N = n_h * n_w</span></span><br><span class="line">    x = x.reshape(batch_size, in_channels, num_patches, patch_area)</span><br><span class="line">    <span class="comment"># [B, C, N, P] -&gt; [B, P, N, C]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># [B, P, N, C] -&gt; [BP, N, C]</span></span><br><span class="line">    x = x.reshape(batch_size * patch_area, num_patches, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t = torch.randn(batch_size, in_channels, num_patch_h * patch_h, num_patch_w * patch_w)</span><br><span class="line">    <span class="built_in">print</span>(torch.equal(official(t), my_self(t)))</span><br><span class="line"></span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">        official(t)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;official time: <span class="subst">&#123;time.time() - t1&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">        my_self(t)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;self time: <span class="subst">&#123;time.time() - t1&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="model-config">model_config</h2>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE-MobileViT-XXS.png" alt="模型配置-MobileViT-XXS"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_config</span>(<span class="params">mode: <span class="built_in">str</span> = <span class="string">&quot;xxs&quot;</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&quot;xx_small&quot;</span>:</span><br><span class="line">        mv2_exp_mult = <span class="number">2</span></span><br><span class="line">        config = &#123;</span><br><span class="line">            <span class="string">&quot;layer1&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">16</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer2&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">24</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer3&quot;</span>: &#123;  <span class="comment"># 28x28</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">48</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">64</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">128</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,  <span class="comment"># 8,</span></span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,  <span class="comment"># 8,</span></span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer4&quot;</span>: &#123;  <span class="comment"># 14x14</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">64</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">80</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">160</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,  <span class="comment"># 4,</span></span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,  <span class="comment"># 4,</span></span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer5&quot;</span>: &#123;  <span class="comment"># 7x7</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">80</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">96</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">192</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;last_layer_exp_factor&quot;</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="string">&quot;cls_dropout&quot;</span>: <span class="number">0.1</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">&quot;x_small&quot;</span>:</span><br><span class="line">        mv2_exp_mult = <span class="number">4</span></span><br><span class="line">        config = &#123;</span><br><span class="line">            <span class="string">&quot;layer1&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">32</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer2&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">48</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer3&quot;</span>: &#123;  <span class="comment"># 28x28</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">64</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">96</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">192</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer4&quot;</span>: &#123;  <span class="comment"># 14x14</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">80</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">120</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">240</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer5&quot;</span>: &#123;  <span class="comment"># 7x7</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">96</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">144</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">288</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;last_layer_exp_factor&quot;</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="string">&quot;cls_dropout&quot;</span>: <span class="number">0.1</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">&quot;small&quot;</span>:</span><br><span class="line">        mv2_exp_mult = <span class="number">4</span></span><br><span class="line">        config = &#123;</span><br><span class="line">            <span class="string">&quot;layer1&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">32</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer2&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">64</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer3&quot;</span>: &#123;  <span class="comment"># 28x28</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">96</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">144</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">288</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer4&quot;</span>: &#123;  <span class="comment"># 14x14</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">128</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">192</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">384</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer5&quot;</span>: &#123;  <span class="comment"># 7x7</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">160</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">240</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">480</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;last_layer_exp_factor&quot;</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="string">&quot;cls_dropout&quot;</span>: <span class="number">0.1</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&quot;layer1&quot;</span>, <span class="string">&quot;layer2&quot;</span>, <span class="string">&quot;layer3&quot;</span>, <span class="string">&quot;layer4&quot;</span>, <span class="string">&quot;layer5&quot;</span>]:</span><br><span class="line">        config[k].update(&#123;<span class="string">&quot;dropout&quot;</span>: <span class="number">0.1</span>, <span class="string">&quot;ffn_dropout&quot;</span>: <span class="number">0.0</span>, <span class="string">&quot;attn_dropout&quot;</span>: <span class="number">0.0</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure>
<h2 id="train">train</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> mobile_vit_xx_small <span class="keyword">as</span> create_model</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(img_size),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.143</span>)),</span><br><span class="line">                                   transforms.CenterCrop(img_size),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    model = create_model(num_classes=args.num_classes).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">assert</span> os.path.exists(args.weights), <span class="string">&quot;weights file: &#x27;&#123;&#125;&#x27; not exist.&quot;</span>.<span class="built_in">format</span>(args.weights)</span><br><span class="line">        weights_dict = torch.load(args.weights, map_location=device)</span><br><span class="line">        weights_dict = weights_dict[<span class="string">&quot;model&quot;</span>] <span class="keyword">if</span> <span class="string">&quot;model&quot;</span> <span class="keyword">in</span> weights_dict <span class="keyword">else</span> weights_dict</span><br><span class="line">        <span class="comment"># 删除有关分类类别的权重</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">list</span>(weights_dict.keys()):</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;classifier&quot;</span> <span class="keyword">in</span> k:</span><br><span class="line">                <span class="keyword">del</span> weights_dict[k]</span><br><span class="line">        <span class="built_in">print</span>(model.load_state_dict(weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除head外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;classifier&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;training &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">    pg = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=<span class="number">1E-2</span>)</span><br><span class="line"></span><br><span class="line">    best_acc = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        train_loss, train_acc = train_one_epoch(model=model,</span><br><span class="line">                                                optimizer=optimizer,</span><br><span class="line">                                                data_loader=train_loader,</span><br><span class="line">                                                device=device,</span><br><span class="line">                                                epoch=epoch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        val_loss, val_acc = evaluate(model=model,</span><br><span class="line">                                     data_loader=val_loader,</span><br><span class="line">                                     device=device,</span><br><span class="line">                                     epoch=epoch)</span><br><span class="line"></span><br><span class="line">        tags = [<span class="string">&quot;train_loss&quot;</span>, <span class="string">&quot;train_acc&quot;</span>, <span class="string">&quot;val_loss&quot;</span>, <span class="string">&quot;val_acc&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], train_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], train_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], val_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">3</span>], val_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">4</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> val_acc &gt; best_acc:</span><br><span class="line">            best_acc = val_acc</span><br><span class="line">            torch.save(model.state_dict(), <span class="string">&quot;./weights/best_model.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;./weights/latest_model.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0002</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预训练权重路径，如果不想载入就设置为空字符</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./mobilevit_xxs.pt&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    <span class="comment"># 是否冻结权重</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<h3 id="训练结果">训练结果</h3>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h2 id="predict">predict</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> mobile_vit_xx_small <span class="keyword">as</span> create_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.14</span>)),</span><br><span class="line">         transforms.CenterCrop(img_size),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = create_model(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/best_model.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h3 id="预测结果">预测结果</h3>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>Pytorch搭建CNN</tag>
        <tag>MobileViT</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer中Self-Attention以及Multi-Head Attention详解</title>
    <url>/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1>前言</h1>
<p>Transformer是2017年Google在<code>Computation and Language</code>上发表的，当时主要是针对自然语言处理领域提出的（之前的RNN模型记忆长度有限且无法并行化，只有计算完$t_i$时刻后的数据才能计算$t_{i+1}$时刻的数据，但<strong>Transformer都可以做到</strong>）。在这篇文章中作者提出了Self-Attention的概念，然后在此基础上提出Multi-Head Attention，所以本文对<code>Self-Attention</code>以及<code>Multi-Head Attention</code>的理论进行学习。原论文：<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Self-Attention.png" alt="Self-Attention"></p>
<h1>Self-Attention</h1>
<p>假设输入的序列长度为2，输入就两个节点$x_1$，$x_2$，然后通过Input Embedding也就是图中的f(x)将输入映射到$a_1$，$a_2$。紧接着分别将$a_1$，$a_2$分别通过三个变换矩阵$W_q$，$W_k$，$W_v$（这三个参数是可训练的，是共享的）得到对应的$q^i$，$k^i$，$v^i$（这里在源码中是直接使用全连接层实现的，这里为了方便理解，忽略偏执）。</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Self-Attention%E8%A7%A3%E9%87%8A1.png" alt="Self-Attention解释-1"></p>
<ul>
<li>$q$代表query，后续会去和每一个$k$进行匹配</li>
<li>$k$代表key，后续会被每个$q$匹配</li>
<li>$v$代表从$a$中提取得到的信息</li>
<li>后续$q$和$k$匹配的过程可以理解成计算两者的相关性，相关性越大对应$v$的权重也就越大</li>
</ul>
<p>假设$a_1=(1，1)$，$a_2=(1，0)$，$W_q=\left(\begin{matrix} 1 &amp; 1\\ 0 &amp; 1\end{matrix}\right)$，那么：$$q^1=(1，1)\left(\begin{matrix} 1 &amp; 1\\ 0 &amp; 1\end{matrix}\right)=(1，2),\quad q^2=(1，0)\left(\begin{matrix} 1 &amp; 1\\ 0 &amp; 1\end{matrix}\right)=(1，1)$$</p>
<p>前面有说Transformer是可以并行化的，所以可以直接写成：$$\left(\begin{matrix} q^1\\ q^2\end{matrix}\right)=\left(\begin{matrix} 1 &amp; 1\\ 1 &amp; 0\end{matrix}\right)\left(\begin{matrix} 1 &amp; 1\\ 0 &amp; 1\end{matrix}\right)=\left(\begin{matrix} 1 &amp; 2\\ 1 &amp; 1\end{matrix}\right)$$</p>
<p>同理我们可以得到$\left(\begin{matrix} k^1\\ k^2\end{matrix}\right)$和$\left(\begin{matrix} v^1\\ v^2\end{matrix}\right)$，那么求得的$\left(\begin{matrix} q^1\\ q^2\end{matrix}\right)$就是原论文中的$Q$，$\left(\begin{matrix} k^1\\ k^2\end{matrix}\right)$就是$K$，$\left(\begin{matrix} v^1\\ v^2\end{matrix}\right)$就是$V$。接着先拿$q^1$和每个$k$进行match，点乘操作（<strong>向量点乘值越大表示向量间的夹角越小，也就表示向量越接近</strong>），接着除以$\sqrt d$得到对应的$\alpha$，其中$d$代表向量$k^i$的长度，在本示例中等于2，除以$\sqrt d$的原因在论文中的解释是“进行点乘后的数值很大，导致通过softmax后梯度变的很小”，所以通过除以$\sqrt d$来进行缩放。比如计算$\alpha_{1,i}$：</p>
<p>$$\alpha_{1,1}=\frac{q^1\cdot k^1}{\sqrt d} =\frac{1 \times 1 + 2 \times 0}{\sqrt 2}=0.71$$</p>
<p>$$\alpha_{1,2}=\frac{q^1\cdot k^2}{\sqrt d} =\frac{1 \times 0 + 2 \times 1}{\sqrt 2}=1.41$$</p>
<p>同理拿$q^2$去匹配所有的$k$能得到$\alpha_{2,i}$，统一写成矩阵乘法形式：</p>
<p>$$\left(\begin{matrix} \alpha_{1,1} &amp; \alpha_{1,2} \\ \alpha_{2,1} &amp; \alpha_{2,2}\end{matrix}\right)=\frac{\left(\begin{matrix} q^1\\ q^2\end{matrix}\right) \left(\begin{matrix} k^1\\ k^2\end{matrix}\right)^T}{\sqrt d}$$</p>
<p>接着对每一行即$\left(\begin{matrix} \alpha_{1,1},\alpha_{1,2}\end{matrix}\right)$和$\left(\begin{matrix} \alpha_{2,1},\alpha_{2,2}\end{matrix}\right)$分别进行softmax处理得到$(\hat{\alpha}_{1,1},\hat{\alpha}_{1,2})$和$(\hat{\alpha}_{2,1},\hat{\alpha}_{2,2})$，<strong>这里的$\hat{\alpha}$相当于计算得到针对每个$v$的权重</strong>。到这我们就完成了$Attention(Q,K,V)$公式中**$softmax(\frac{QK^T}{\sqrt d_k})$**部分。</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Self-Attention%E8%A7%A3%E9%87%8A2.png" alt="Self-Attention解释-2"></p>
<p>上面<strong>已经计算得到$\alpha$，即针对每个$v$的权重</strong>，接着进行加权得到最终结果：</p>
<p>$$b_1=\hat{\alpha}_{1,1} \times v^1 + \hat{\alpha}_{1,2}\times v^2=(0.33,0.67)$$</p>
<p>$$b_2=\hat{\alpha}_{2,1} \times v^1 + \hat{\alpha}_{2,2}\times v^2=(0.50,0.50)$$</p>
<p>统一写成矩阵乘法形式：$$\left(\begin{matrix} b^1\\ b^2\end{matrix}\right)=\left(\begin{matrix} \hat{\alpha}_{1,1} &amp; \hat{\alpha}_{1,2}\\ \hat{\alpha}_{2,1} &amp; \hat{\alpha}_{2,2}\end{matrix}\right)\left(\begin{matrix} v^1\\ v^2\end{matrix}\right)$$</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Self-Attention%E8%A7%A3%E9%87%8A3.png" alt="Self-Attention解释-3"></p>
<p>到这，<code>Self-Attention</code>的内容就讲完了。总结下来就是论文中的一个公式：$$Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt d_k})V$$</p>
<h1>Multi-Head Attention</h1>
<p>实际使用中基本使用的还是Multi-Head Attention模块。原论文中说使用多头注意力机制能够联合来自不同head部分学习到的信息。<code>Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions</code>。其实只要懂了Self-Attention模块Multi-Head Attention模块就非常简单了。</p>
<p>首先还是和Self-Attention模块一样将$a_i$分别通过$W_q$，$W_k$，$W_v$得到对应的$q^i$，$k^i$，$v^i$，然后再根据使用的head的数目$h$进一步把得到的$q^i$，$k^i$，$v^i$均分成$h$份。比如下图中假设$h=2$然后$q^1$拆分成$q^{1,1}$和$q^{1,2}$，那么$q^{1,1}$就属于head1，$q^{1,2}$就属于head2。</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Muti-Head-Self-Attention%E8%A7%A3%E9%87%8A1.png" alt="Muti-Head Self-Attention解释-1"></p>
<p>论文中是写的通过$W_i^Q$，$W_i^K$，$W_i^V$映射得到每个head的$Q_i$，$K_i$，$V_i$：$head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)$。但在github上看的一些源码中就是简单的进行均分，其实也可以将$W_i^Q$，$W_i^K$，$W_i^V$设置成对应值来实现均分，比如下图中的$Q$通过$W_1^Q$就能得到均分后的$Q_1$。</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Muti-Head-Self-Attention%E8%A7%A3%E9%87%8A2.png" alt="Muti-Head Self-Attention解释-2"></p>
<p>通过上述方法就能得到每个$head_i$对应的$Q^i$，$K^i$，$V^i$参数，接下来针对每个head使用和Self-Attention中相同的方法即可得到对应的结果。$$Attention(Q_i,K_i,V_i)=softmax(\frac{Q_iK_i^T}{\sqrt d_k})V_i$$</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Muti-Head-Self-Attention%E8%A7%A3%E9%87%8A3.png" alt="Muti-Head Self-Attention解释-3"></p>
<p>接着将每个head得到的结果进行concat拼接，比如下图中$b_{1,1}$（$head_1$得到的$b_1$）和$b_{1,2}$（$head_2$得到的$b_1$）拼接在一起，$b_{2,1}$（$head_1$得到的$b_2$）和$b_{2,2}$（$head_2$得到的$b_2$）拼接在一起。</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Muti-Head-Self-Attention%E8%A7%A3%E9%87%8A4.png" alt="Muti-Head Self-Attention解释-4"></p>
<p>接着将拼接后的结果通过$W^O$（可学习的参数）进行融合，如下图所示，融合后得到最终的结果$b_1$，$b_2$。</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Muti-Head-Self-Attention%E8%A7%A3%E9%87%8A5.png" alt="Muti-Head Self-Attention解释-5"></p>
<p>到这，<code>Multi-Head Attention</code>的内容就讲完了。总结下来就是论文中的两个公式：</p>
<p>$$MultHead(Q,K,V)=Concat(head_1,…,head_h)W^O $$</p>
<p>$$ where \space head_i =Attenttion(QW_i^Q,KW_i^K,VW_i^V)$$</p>
<h1>Positional Encoding</h1>
<p>刚刚讲的Self-Attention和Multi-Head Attention模块，在计算中是没有考虑到位置信息的。假设在Self-Attention模块中，输入$a_1$，$a_2$，$a_3$得到$b_1$，$b_2$，$b_3$。对于$a_1$而言$a_2$和$a_3$ 离它都是一样近的而且没有先后顺序。假设将输入的顺序改为$a_1$，$a_3$，$a_2$ ，对结果$b_1$是没有任何影响的。（相当于说“我爱你”和“你爱我”意思等同，这样是不对的）</p>
<p>为了引入位置信息，在原论文中引入了位置编码<code>positional encodings</code>。<code>To this end, we add &quot;positional encodings&quot; to the input embeddings at the bottoms of the encoder and decoder stacks</code>.如下图所示，位置编码是直接加在输入的$a={a_1,…a_n}$中的，即$pe={pe_1,…pe_n}$和$a={a_1,…a_n}$拥有相同的维度大小。关于位置编码在原论文中有提出两种方案，一种是原论文中使用的固定编码，即论文中给出的<code>sine and cosine functions</code>方法，按照该方法可计算出位置编码；另一种是可训练的位置编码，作者说尝试了两种方法发现结果差不多（但在ViT论文中使用的是可训练的位置编码）。</p>
<p><img src="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/Position-Endoding.png" alt="Position Endoding"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>CNN网络详解</tag>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensor的维度变换</title>
    <url>/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/</url>
    <content><![CDATA[<p>Tensor通道排列顺序： <strong>[ batch, channel, height, width ]</strong></p>
<h1>view和reshape</h1>
<p>从功能上来看，它们的作用是相同的，都是用来重塑 Tensor 的 shape 的。view 只适合对满足<strong>连续性条件</strong> (contiguous) 的 Tensor进行操作，而reshape 同时还可以对<strong>不满足连续性条件</strong>的 Tensor 进行操作，具有更好的鲁棒性。view 能干的 reshape都能干，如果 view 不能干就可以用 reshape 来处理。</p>
<p>简单来说就是<strong>reshape是view的大哥，大哥都能干（满足或不满足连续性条件），小弟只能干一部分（只满足连续性条件）</strong>，如果想简单了事，就直接用reshape，但个人觉得最好还是通过contiguous()之后在同view。</p>
<p>因为当不满足连续条件时，需要先使用 <code>contiguous() </code>方法将原始 Tensor 转换为满足连续条件的 Tensor，然后就可以使用 view 方法进行 shape 变换了。或者直接使用 <code>reshape</code> 方法进行维度变换，但这种方法变换后的 Tensor 就<strong>不是与原始 Tensor共享内存了，而是被重新开辟了一个空间</strong>。</p>
<blockquote>
<p><strong>a.reshape = a.view() + a.contiguous().view()</strong></p>
</blockquote>
<p>view 的存在可以显示地表示对这个 Tensor 的操作**只能是视图操作而非拷贝操作，只能是浅拷贝而非深拷贝操作。**这对于代码的可读性以及后续可能的 bug 的查找比较友好，可以避免不必要的显存开销。</p>
<ul>
<li><strong>例子1：height × width</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">a.view(<span class="number">2</span>,<span class="number">4</span>*<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>解读：将图片的通道数、图片的像素行列值都拼接在一起，成为[4，784]，适合全连接层的输入</p>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/view-1.png" alt="view-1"></p>
<ul>
<li><strong>例子2：batch × channel</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">a.view(<span class="number">2</span>*<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>解读：表示我们现在只关注<code>feature map</code>这个属性，而不关注它来自哪个图片的哪个通道</p>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/view-2.png" alt="view-2"></p>
<p><strong>注意：在view之后如果想恢复到原来的维数是要进行记录的，否则直接恢复是不行的</strong>。</p>
<h1>squeeze和unsqueeze</h1>
<h2 id="squeeze">squeeze</h2>
<p>进行维度压缩，去掉 tensor 中维数为1的维度（如果设置dim=a，就是去掉指定维度中维数为1的）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor([[[<span class="number">1</span>],[<span class="number">2</span>]],[[<span class="number">3</span>],[<span class="number">4</span>]]])</span><br><span class="line"><span class="comment"># x: tensor([[[1],</span></span><br><span class="line"><span class="comment">#         [2]],</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#         [[3],</span></span><br><span class="line"><span class="comment">#         [4]]])</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x:&#x27;</span>,x)</span><br><span class="line">x1 = x.squeeze()</span><br><span class="line"><span class="comment"># x1: tensor([[1, 2],</span></span><br><span class="line"><span class="comment">#         [3, 4]])</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x1:&#x27;</span>,x1)</span><br><span class="line">x2 = x.squeeze(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># x2: tensor([[1, 2],</span></span><br><span class="line"><span class="comment">#         [3, 4]])</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x2:&#x27;</span>,x2)</span><br></pre></td></tr></table></figure>
<h2 id="unsqueeze">unsqueeze</h2>
<p>进行维度扩充，在指定位置加上维数为1的维度（如果设置dim=a，就是在维度为a的位置进行扩充）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment"># x: tensor([1, 2, 3, 4])</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">x1 = x.unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># x1: tensor([[1, 2, 3, 4]]) 深度增加</span></span><br><span class="line"><span class="built_in">print</span>(x1)</span><br><span class="line">x2 = x.unsqueeze(dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># x2: tensor([[1],</span></span><br><span class="line"><span class="comment">#        [2],</span></span><br><span class="line"><span class="comment">#        [3],</span></span><br><span class="line"><span class="comment">#        [4]]) </span></span><br><span class="line"><span class="built_in">print</span>(x2)</span><br><span class="line"> </span><br><span class="line">y = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">9</span>,<span class="number">8</span>,<span class="number">7</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="comment"># y: tensor([[1, 2, 3, 4],</span></span><br><span class="line"><span class="comment">#        [9, 8, 7, 6]])</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line">y1 = y.unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># y1: tensor([[[1, 2, 3, 4],</span></span><br><span class="line"><span class="comment">#         [9, 8, 7, 6]]])</span></span><br><span class="line"><span class="built_in">print</span>(y1)</span><br><span class="line">y2 = y.unsqueeze(dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># y2: tensor([[[1, 2, 3, 4]],</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#        [[9, 8, 7, 6]]])</span></span><br><span class="line"><span class="built_in">print</span>(y2)</span><br></pre></td></tr></table></figure>
<p>例子：f表示2张4*4的拥有3个通道的图片，而b表示给图片的每个channel上的所有的像素添加一个偏置，我们的目标就是把b叠加在f上面，所以要将b的维度变换与f相同才可以进行，然后再进行b的扩张。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b = torch.rand(<span class="number">2</span>)</span><br><span class="line">f = torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">b = b.unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">2</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># [3]      [3,1]      [3,1,1]       [1,3,1,1]</span></span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/unsqueeze.png" alt="unsqueeze"></p>
<h1>expand和repeat</h1>
<p>进行维度的扩展，就像前面的b [1，3，4，4]，要想与 f [2，3，4，4]进行相加的话，b就要进行维度的扩展。</p>
<p>区别：两种方法在效果方面是等效的，但是<code>expand只在需要的时候进行数据的复制，而repeat会直接复制数据</code>。所以推荐使用expand</p>
<h2 id="expand">expand</h2>
<p><strong>例子1</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">b.expand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># [2,3,4,4]</span></span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/expand.png" alt="expand-1"></p>
<p><strong>局限性：</strong></p>
<ul>
<li>要求expand之前之后的dimension必须一样。</li>
<li>只能在之前<strong>维数为1</strong>的地方进行expand，而如果之前的维数为3是没有办法扩张到m的。</li>
</ul>
<p>[ 3，3，4，4 ]——b.expand(4,3,4,4)报错</p>
<p><strong>例子2：不想进行变动的地方使用-1代替就可以</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b = torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">b.expand(<span class="number">2</span>,-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># [2,1,2,2]</span></span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/expand-2.png" alt="expand-2"></p>
<h2 id="repeat">repeat</h2>
<p>repeat的参数表示你要在该维数位置进行多少次复制</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">b.repeat(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#[ 2 , 6 , 1 , 1 ]</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>表示：1复制4次变为4，32复制32次变为1024，其它没变</strong></p>
</blockquote>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/repeat.png" alt="repeat"></p>
<h1>.t()转置</h1>
<p>进行tensor的转置，但是要注意：<strong>只能进行2D tensor的转置，即矩阵的转置</strong>。</p>
<h2 id="transpose转置">transpose转置</h2>
<p>进行某几维之间的相互交换</p>
<p><strong>例子1</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">b = b.transpose(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># [1,2,2,3]</span></span><br><span class="line"><span class="comment"># 0  1  2  3</span></span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/transpose-1.png" alt="transpose-1"></p>
<p><strong>例子2：这样变换前后的二者是一样的(contiguous()表示进行transpose之后数据不再是按顺序存放的，使用该方法进行顺序的调整)</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a2 = b.transpose(<span class="number">1</span>,<span class="number">3</span>).contiguous().view(<span class="number">2</span>,<span class="number">3</span>*<span class="number">2</span>*<span class="number">2</span>).view(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>).transpose(<span class="number">1</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/transpose-2.png" alt="transpose-2"></p>
<p>注意：<strong>[ B C H W ] → [ B W H C] → [ B W * H * C ] →[ B C W H ]这样的变换是不行的 W与H的顺序变换了，图像也会处出现变换</strong></p>
<p><strong>例子3</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>)<span class="comment">#[B C H W]</span></span><br><span class="line">a.transpose(<span class="number">1</span>,<span class="number">3</span>)<span class="comment">#[B W H C]</span></span><br><span class="line">a.transpose(<span class="number">1</span>,<span class="number">2</span>)<span class="comment">#[B H W C]</span></span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/transpose-3.png" alt="transpose-3"></p>
<p><strong>由于[B H W C]是numpy中储存图片的方式，所以这样变换以后才能导出numpy</strong></p>
<h2 id="permute函数">permute函数</h2>
<p>transpose中的例子3使用permute函数进行简单的一步变换：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># a.transpose(1,3).transpose(1,2) = a.permute(0,2,3,1)</span></span><br><span class="line">a = torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>)<span class="comment">#[B C H W]</span></span><br><span class="line">a.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)<span class="comment">#[B H W C]</span></span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/permute.png" alt="permute"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识补充</tag>
      </tags>
  </entry>
  <entry>
    <title>一些函数解释（更新ing）</title>
    <url>/2023/06/15/%E8%A1%A5%E5%85%85%E4%B9%8B%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%E8%A7%A3%E9%87%8A/</url>
    <content><![CDATA[<h1>assert</h1>
<p>用于程序调试</p>
<p>使用assert断言语句是一个非常好的习惯，python assert断言句语格式及用法很简单。<strong>在没完善一个程序之前，我们不知道程序在哪里会出错，与其让它在运行到最后崩溃，不如在出现错误条件时就崩溃</strong>，这样在跑大规模程序的时候不会过多的浪费时间和计算资源，这时候就需要assert断言的帮助。</p>
<p><strong>例子1</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression</span><br></pre></td></tr></table></figure>
<p>该形式用来测试断言的expression语句，如果expression是True，那么什么反应都没有。但是如果expression是False，那么会报错AssertionError。</p>
<p>如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 出错时</span></span><br><span class="line"><span class="keyword">assert</span> <span class="number">1</span>==<span class="number">0</span></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AssertionError                            Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">4</span>-b09d6b060198&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> <span class="keyword">assert</span> <span class="number">1</span>==<span class="number">0</span>,</span><br><span class="line"></span><br><span class="line">AssertionError:</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line"><span class="comment"># 没有出错时什么也不反应</span></span><br><span class="line"><span class="keyword">assert</span> <span class="number">1</span>==<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><strong>例子2</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression1, expression2</span><br></pre></td></tr></table></figure>
<p>assert断言语句可以添加异常参数，也就是在断言表达式后添加字符串信息，用来解释断言并更好的知道是哪里出了问题。格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression [, arguments]</span><br><span class="line"><span class="keyword">assert</span> 表达式 [, 参数]</span><br></pre></td></tr></table></figure>
<p>如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 出错时</span></span><br><span class="line"><span class="keyword">assert</span> <span class="number">1</span>==<span class="number">0</span>, <span class="string">&quot;出错了&quot;</span></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AssertionError                            Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">4</span>-b09d6b060198&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> <span class="keyword">assert</span> <span class="number">1</span>==<span class="number">0</span>, <span class="string">&quot;出错了&quot;</span></span><br><span class="line"></span><br><span class="line">AssertionError: 出错了</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line"><span class="comment"># 没有出错时依旧什么也不反应</span></span><br><span class="line"><span class="keyword">assert</span> <span class="number">1</span>==<span class="number">1</span>, <span class="string">&quot;出错了&quot;</span></span><br></pre></td></tr></table></figure>
<h1>nn.Parameter()</h1>
<p>parameter，中文意为参数。我们知道，使用PyTorch训练神经网络时，本质上就是训练一个函数，这个函数输入一个数据（如CV中输入一张图像），输出一个预测（如输出这张图像中的物体是属于什么类别）。而在我们给定这个函数的结构（如卷积、全连接等）之后，能学习的就是这个函数的参数了，我们设计一个损失函数，配合梯度下降法，使得我们学习到的函数（神经网络）能够尽量准确地完成预测任务。</p>
<p>通常，我们的参数都是一些常见的结构（卷积、全连接等）里面的计算参数。而当我们的网络有一些其他的设计时，会需要一些额外的参数同样很着整个网络的训练进行学习更新，最后得到最优的值，经典的例子有注意力机制中的权重参数、Vision Transformer中的class token和positional embedding等。</p>
<blockquote>
<p>首先可以把这个函数理解为类型转换函数，将一个不可训练的类型<code>Tensor</code>转换成可以训练的类型<code>parameter</code>并将这个<code>parameter</code>绑定到这个<code>module</code>里面(<code>net.parameter()</code>中就有这个绑定的<code>parameter</code>，所以在参数优化的时候可以进行优化的)，所以经过类型转换这个<code>self.v</code>变成了模型的一部分，成为了模型中根据训练可以改动的参数了。使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化。</p>
</blockquote>
<h2 id="ViT中nn-Parameter">ViT中nn.Parameter()</h2>
<p>在ViT中，positonal embedding和class token是两个需要随着网络训练学习的参数，但是它们又不属于FC、MLP、MSA等运算的参数，在这时，就可以用nn.Parameter()来将这个随机初始化的Tensor注册为可学习的参数Parameter。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">self.pos_embedding = nn.Parameter(torch.randn(<span class="number">1</span>, num_patches+<span class="number">1</span>, dim))</span><br><span class="line">self.cls_token = nn.Parameter(torch.randn(<span class="number">1</span>, <span class="number">1</span>, dim))</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p><strong>举个栗子</strong></p>
<p>指定这两个参数的初始数值为0.98，并打印迭代器net.Parameters()。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">self.pos_embedding = nn.Parameter(torch.ones(<span class="number">1</span>, num_patches+<span class="number">1</span>, dim) * <span class="number">0.98</span>)</span><br><span class="line">self.cls_token = nn.Parameter(torch.ones(<span class="number">1</span>, <span class="number">1</span>, dim) * <span class="number">0.98</span>)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>实例化一个ViT模型并打印net.Parameters()：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net_vit = ViT(</span><br><span class="line">        image_size = <span class="number">256</span>,</span><br><span class="line">        patch_size = <span class="number">32</span>,</span><br><span class="line">        num_classes = <span class="number">1000</span>,</span><br><span class="line">        dim = <span class="number">1024</span>,</span><br><span class="line">        depth = <span class="number">6</span>,</span><br><span class="line">        heads = <span class="number">16</span>,</span><br><span class="line">        mlp_dim = <span class="number">2048</span>,</span><br><span class="line">        dropout = <span class="number">0.1</span>,</span><br><span class="line">        emb_dropout = <span class="number">0.1</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> para <span class="keyword">in</span> net_vit.parameters():</span><br><span class="line">        <span class="built_in">print</span>(para.data)</span><br></pre></td></tr></table></figure>
<p>输出结果中可以看到，最前两行就是我们显式指定为0.98的两个参数pos_embedding和cls_token：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor([[[<span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>,  ..., <span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>],</span><br><span class="line">         [<span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>,  ..., <span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>],</span><br><span class="line">         [<span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>,  ..., <span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>],</span><br><span class="line">         ...,</span><br><span class="line">         [<span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>,  ..., <span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>],</span><br><span class="line">         [<span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>,  ..., <span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>],</span><br><span class="line">         [<span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>,  ..., <span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>]]])</span><br><span class="line">tensor([[[<span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>,  ..., <span class="number">0.9800</span>, <span class="number">0.9800</span>, <span class="number">0.9800</span>]]])</span><br><span class="line">tensor([[-<span class="number">0.0026</span>, -<span class="number">0.0064</span>,  <span class="number">0.0111</span>,  ...,  <span class="number">0.0091</span>, -<span class="number">0.0041</span>, -<span class="number">0.0060</span>],</span><br><span class="line">        [ <span class="number">0.0003</span>,  <span class="number">0.0115</span>,  <span class="number">0.0059</span>,  ..., -<span class="number">0.0052</span>, -<span class="number">0.0056</span>,  <span class="number">0.0010</span>],</span><br><span class="line">        [ <span class="number">0.0079</span>,  <span class="number">0.0016</span>, -<span class="number">0.0094</span>,  ...,  <span class="number">0.0174</span>,  <span class="number">0.0065</span>,  <span class="number">0.0001</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [-<span class="number">0.0110</span>, -<span class="number">0.0137</span>,  <span class="number">0.0102</span>,  ...,  <span class="number">0.0145</span>, -<span class="number">0.0105</span>, -<span class="number">0.0167</span>],</span><br><span class="line">        [-<span class="number">0.0116</span>, -<span class="number">0.0147</span>,  <span class="number">0.0030</span>,  ...,  <span class="number">0.0087</span>,  <span class="number">0.0022</span>,  <span class="number">0.0108</span>],</span><br><span class="line">        [-<span class="number">0.0079</span>,  <span class="number">0.0033</span>, -<span class="number">0.0087</span>,  ..., -<span class="number">0.0174</span>,  <span class="number">0.0103</span>,  <span class="number">0.0021</span>]])</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>这就可以确定nn.Parameter()添加的参数确实是被添加到了Parameters列表中，会被送入优化器中随训练一起学习更新。</p>
<h1>.item()</h1>
<p>取出单元素张量的元素值并返回该值，保持原元素类型不变。,即：原张量元素为整形，则返回整形，原张量元素为浮点型则返回浮点型，etc</p>
<p><strong>x[1,1] VS x.item()</strong>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.randn(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># x[1,1]</span></span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># x[1,1].item()</span></span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">1</span>,<span class="number">1</span>].item())</span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/15/%E8%A1%A5%E5%85%85%E4%B9%8B%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%E8%A7%A3%E9%87%8A/item%E5%87%BD%E6%95%B0.png" alt=".item()的作用"></p>
<h1>numpy.pad()</h1>
<p>在卷积神经网络中，为了避免因为卷积运算导致输出图像缩小和图像边缘信息丢失，常常采用图像边缘填充技术，<strong>即在图像四周边缘填充0</strong>，使得卷积运算后图像大小不会缩小，同时也不会丢失边缘和角落的信息。在Python的numpy库中，常常采用numpy.pad()进行填充操作。</p>
<p>*<em>numpy.pad(array, pad_width, mode=‘constant’, *<em>kwargs)</em></em></p>
<p><strong>array</strong></p>
<blockquote>
<p>表示需要填充的数组。</p>
</blockquote>
<p><strong>pad_width</strong></p>
<blockquote>
<p>表示每个轴（axis）边缘需要填充的数值数目。</p>
<p>参数输入方式为：（(before_1, after_1), … (before_N, after_N)），其中(before_1, after_1)表示第1轴两边缘分别填充before_1个和after_1个数值。</p>
</blockquote>
<p><strong>mode</strong></p>
<blockquote>
<p>表示填充的方式（取值：str字符串或用户提供的函数），总共有12种填充模式。</p>
<p>默认为’constant’方式填充。</p>
</blockquote>
<p>*<strong>*kwargs</strong></p>
<blockquote>
<p>表示关键字参数，它本质上是一个dict。</p>
<ol>
<li>constant_values : sequence or scalar, optional。用于‘constant’填充方式指定的填充值。</li>
<li>stat_length : sequence or int, optional。用于 ‘maximum’, ‘mean’, ‘median’,和‘minimum’填充方式中。每个轴边缘用于计算统计量的数据个数，默认用到整个轴。</li>
<li>end_values : sequence or scalar, optional。用于 ‘linear_ramp’填充方式，设定结束值。</li>
<li>reflect_type : {‘even’, ‘odd’}, optional，默认为‘even’。</li>
</ol>
</blockquote>
<p>Swin Transformer中需要对输入图片进行padding处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pad_input = (H % self.patch_size[<span class="number">0</span>] != <span class="number">0</span>) <span class="keyword">or</span> (W % self.patch_size[<span class="number">1</span>] != <span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> pad_input:</span><br><span class="line">    <span class="comment"># to pad the last 3 dimensions,</span></span><br><span class="line">    <span class="comment"># (W_left, W_right, H_top,H_bottom, C_front, C_back)</span></span><br><span class="line">    x = F.pad(x, (<span class="number">0</span>, self.patch_size[<span class="number">1</span>] - W % self.patch_size[<span class="number">1</span>],</span><br><span class="line">                  <span class="number">0</span>, self.patch_size[<span class="number">0</span>] - H % self.patch_size[<span class="number">0</span>],</span><br><span class="line">                  <span class="number">0</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<h1>torch.meshgrid（）</h1>
<p>torch.meshgrid（）的功能是生成网格，可以用于生成坐标。函数输入两个数据类型相同的一维张量，两个输出张量的行数为第一个输入张量的元素个数，列数为第二个输入张量的元素个数，当两个输入张量数据类型不同或维度不是一维时会报错。</p>
<p>其中第一个输出张量填充第一个输入张量中的元素，各行元素相同；第二个输出张量填充第二个输入张量中的元素各列元素相同。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 【1】</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">b = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line">x, y = torch.meshgrid(a, b)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"> </span><br><span class="line">结果显示：</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line">tensor([[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 【2】</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">b = torch.tensor([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>])</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line">x, y = torch.meshgrid(a, b)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"> </span><br><span class="line">结果显示：</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">tensor([ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>])</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>]])</span><br><span class="line">tensor([[ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>],</span><br><span class="line">        [ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>],</span><br><span class="line">        [ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>],</span><br><span class="line">        [ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>],</span><br><span class="line">        [ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>],</span><br><span class="line">        [ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>]])</span><br></pre></td></tr></table></figure>
<h1>torch.stack（）</h1>
<p><code>stack（tensors,dim=0,out=None）</code>在维度上连接（<strong>concatenate</strong>）若干个张量。(这些张量形状相同）。</p>
<p>将若干个张量在dim维度上连接,生成一个扩维的张量，比如说原来你有若干个2维张量，连接可以得到一个3维的张量。</p>
<p>设待连接张量维度为n，dim取值范围为-n-1~n，这里得提一下为负的意义：-i为倒数第i个维度。举个例子，对于2维的待连接张量，-1维即3维，-2维即2维。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">b=torch.tensor([[<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>],[<span class="number">40</span>,<span class="number">50</span>,<span class="number">60</span>]])</span><br><span class="line">c=torch.tensor([[<span class="number">100</span>,<span class="number">200</span>,<span class="number">300</span>],[<span class="number">400</span>,<span class="number">500</span>,<span class="number">600</span>]])</span><br><span class="line"><span class="built_in">print</span>(torch.stack([a,b,c],dim=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.stack([a,b,c],dim=<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.stack([a,b,c],dim=<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(torch.stack([a,b,c],dim=<span class="number">0</span>).size())</span><br><span class="line"><span class="built_in">print</span>(torch.stack([a,b,c],dim=<span class="number">1</span>).size())</span><br><span class="line"><span class="built_in">print</span>(torch.stack([a,b,c],dim=<span class="number">2</span>).size())</span><br><span class="line"><span class="comment">#输出结果为：</span></span><br><span class="line">tensor([[[  <span class="number">1</span>,   <span class="number">2</span>,   <span class="number">3</span>],</span><br><span class="line">         [  <span class="number">4</span>,   <span class="number">5</span>,   <span class="number">6</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">10</span>,  <span class="number">20</span>,  <span class="number">30</span>],</span><br><span class="line">         [ <span class="number">40</span>,  <span class="number">50</span>,  <span class="number">60</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">100</span>, <span class="number">200</span>, <span class="number">300</span>],</span><br><span class="line">         [<span class="number">400</span>, <span class="number">500</span>, <span class="number">600</span>]]])</span><br><span class="line">tensor([[[  <span class="number">1</span>,   <span class="number">2</span>,   <span class="number">3</span>],</span><br><span class="line">         [ <span class="number">10</span>,  <span class="number">20</span>,  <span class="number">30</span>],</span><br><span class="line">         [<span class="number">100</span>, <span class="number">200</span>, <span class="number">300</span>]],</span><br><span class="line"></span><br><span class="line">        [[  <span class="number">4</span>,   <span class="number">5</span>,   <span class="number">6</span>],</span><br><span class="line">         [ <span class="number">40</span>,  <span class="number">50</span>,  <span class="number">60</span>],</span><br><span class="line">         [<span class="number">400</span>, <span class="number">500</span>, <span class="number">600</span>]]])</span><br><span class="line">tensor([[[  <span class="number">1</span>,  <span class="number">10</span>, <span class="number">100</span>],</span><br><span class="line">         [  <span class="number">2</span>,  <span class="number">20</span>, <span class="number">200</span>],</span><br><span class="line">         [  <span class="number">3</span>,  <span class="number">30</span>, <span class="number">300</span>]],</span><br><span class="line"></span><br><span class="line">        [[  <span class="number">4</span>,  <span class="number">40</span>, <span class="number">400</span>],</span><br><span class="line">         [  <span class="number">5</span>,  <span class="number">50</span>, <span class="number">500</span>],</span><br><span class="line">         [  <span class="number">6</span>,  <span class="number">60</span>, <span class="number">600</span>]]])</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识补充</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学深度学习v2（一）数据操作及数据预处理</title>
    <url>/2023/06/17/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0v2-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h1>数据操作及数据预处理</h1>
<h2 id="N维数组">N维数组</h2>
<p>N维数组是机器学习和神经网络的主要数据结构</p>
<p><img src="/2023/06/17/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0v2-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E7%9F%A9%E9%98%B5%E7%9F%A5%E8%AF%86.png" alt="数组"></p>
<p>0-维数组叫做<strong>标量</strong>，如上图所示最简单的是1.0（一个浮点运算），可能表示一个物体的类别；</p>
<p>1-维数组叫做向量，如上图所示的三个数字，代表着一个特征向量，也就是样本抽象为一行数字；</p>
<p>2-维数组叫做矩阵，如上图所示有三行三列，可以是一个样本的特征矩阵，这就表示有3个样本，每一行表示一个样本，每一列表示样本的某特征。</p>
<p><img src="/2023/06/17/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0v2-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E6%95%B0%E7%BB%84%E7%9F%A5%E8%AF%86.png" alt="数组-2"></p>
<p>3-维数组最简单的就是一个RGB彩色图片，也是一个3维数组，有宽度（列的个数），有高度（行的个数），又因为有RGB3个通道，所以是一个3维数组；</p>
<p>4-维表示N个3维的数组放在一起，即一个RGB图片的批量；</p>
<p>5-维数组表示的是一个视频的批量，即有很多张图片，但还加上了时间的维度，所以是批量大小x时间x宽x高x通道的5-d数组</p>
<h2 id="创建数组">创建数组</h2>
<p>创建数组需要：</p>
<ul>
<li>形状：例如3x4矩阵；</li>
<li>每个元素的数据类型：例如32位浮点数；</li>
<li>每个元素的值，例如全是0，或者随机数</li>
</ul>
<p><img src="/2023/06/17/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0v2-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%92%8C%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83.png" alt="正态分布和均匀分布"></p>
<h2 id="访问元素">访问元素</h2>
<p><img src="/2023/06/17/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0v2-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E8%AE%BF%E9%97%AE%E5%85%83%E7%B4%A0.png" alt="访问元素"></p>
<h2 id="数据操作">数据操作</h2>
<p>把多个张量连结在一起</p>
<p><strong>dim = 0表示在行上拼接（堆起来），dim = 1表示在列上拼接</strong></p>
<p><img src="/2023/06/17/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0v2-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E6%95%B0%E7%BB%84%E6%8B%BC%E6%8E%A5%E6%93%8D%E4%BD%9C.png" alt="数组拼接操作"></p>
<p>即使形状不同，我们仍然可以通过调用 广播机制 (broadcastinng mechanism)来执行按元素操作</p>
<p><img src="/2023/06/17/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0v2-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6.png" alt="广播机制"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>动手学深度学习v2</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch入门学习（一）Dataset类代码实战</title>
    <url>/2023/06/27/PyTorch%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89Dataset%E7%B1%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h1>前言</h1>
<p>因为在写代码的过程中发现对整体的框架使用十分不熟，所以恶补一下pytorch的入门知识。</p>
<p>运行jupyter需要在cmd上，power shell上会出错（因为不久前我将默认终端应用程序改为Windows终端，可能前期的windows powershell没有装好，导致打开cmd出错，实际上平常用的是powershell），改过去之后直接用cmd进如pytorch虚拟环境运行jupyter</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda activate pytorch</span><br><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>
<h1>加载数据</h1>
<p>在pytorch中如何读取数据主要涉及到两个类，分别是Dataset和Dataloader</p>
<p><img src="/2023/06/27/PyTorch%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89Dataset%E7%B1%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/Dataset%E5%92%8CDataloader.png" alt="Dataset和Dataloader"></p>
<h2 id="cv2和PIL的区别">cv2和PIL的区别</h2>
<p>顺便一提（在准备MICCAI中遇到读取图片用的是cv2，但之前跟着写的代码都是用PIL）<strong>cv2和PIL的区别</strong>：</p>
<ul>
<li>
<p>读取的通道不同：cv2读取图像为BGR顺序通道，PIL读取图像为RGB顺序通道；</p>
</li>
<li>
<p>读取代码不同：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cv2读取方式</span></span><br><span class="line">input1 = <span class="string">r&#x27;E:\DRPL\data\blur\1_ILSVRC2012_val_00004507_3_183.jpg&#x27;</span></span><br><span class="line">cv2img = cv2.imread(input1, flags=cv2.IMREAD_COLOR)  <span class="comment"># 默认以BGR形式打开</span></span><br><span class="line">cv2.imshow(<span class="string">&quot;cv2img&quot;</span>, cv2img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># PIL读取方式</span></span><br><span class="line">input2 = <span class="string">r&#x27;E:\DRPL\data\blur\1_ILSVRC2012_val_00004507_3_re183.jpg&#x27;</span></span><br><span class="line">pilimg = Image.<span class="built_in">open</span>(input2)</span><br><span class="line">pilimg.show()</span><br></pre></td></tr></table></figure>
<ul>
<li>读取出的图像类型以及尺度属性不同：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(cv2img.shape, cv2img.size, <span class="built_in">type</span>(cv2img))</span><br><span class="line"><span class="built_in">print</span>(pilimg.size, <span class="built_in">type</span>(pilimg))</span><br><span class="line"><span class="comment"># cv2读取出图像的类型为ndarray类型，pil读取的为PIL类型。</span></span><br><span class="line"><span class="comment"># cv2读取的图像同时拥有shape()和size()方法，pil只有size()方法。</span></span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/27/PyTorch%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89Dataset%E7%B1%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/cv2%E5%92%8CPIL%E8%AF%BB%E5%8F%96%E5%9B%BE%E7%89%87%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%B1%9E%E6%80%A7.png" alt="cv2和PIL读取图片的类型属性"></p>
<ul>
<li>将cv2和PIL转换为tensor数据类型代码对比</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trans = transforms.ToTensor()</span><br><span class="line">tensor_cv2 = trans(cv2img)</span><br><span class="line">tensor_pil = trans(pilimg)</span><br><span class="line"><span class="built_in">print</span>(tensor_cv2.shape, tensor_cv2.size(), <span class="built_in">type</span>(tensor_cv2))</span><br><span class="line"><span class="built_in">print</span>(tensor_pil.shape, tensor_pil.size(), <span class="built_in">type</span>(tensor_pil))</span><br><span class="line"><span class="comment"># 两者都可以转换为tensor数据类型</span></span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/27/PyTorch%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89Dataset%E7%B1%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/cv2%E5%92%8CPIL%E8%BD%AC%E6%8D%A2%E4%B8%BATensor%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png" alt="cv2和PIL转换为Tensor数据类型"></p>
<ul>
<li>cv2图像和PIL图像相互转换</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将PIL转换为cv2# 方法1：用numpy.asarray()函数转化类型，再用cv2.cvtColor转化RGB为BGR通道.</span></span><br><span class="line">trans_cv2img = cv2.cvtColor(numpy.asarray(pilimg), cv2.COLOR_RGB2BGR)</span><br><span class="line">cv2.imshow(<span class="string">&quot;trans_cv2img&quot;</span>, trans_cv2img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)<span class="comment"># 方法2：可以不使用cv2.cvtColor，但是show出来的图像会发蓝，因为没有变换通道</span></span><br><span class="line">trans_tocv2 = numpy.array(pilimg)</span><br><span class="line">cv2.imshow(<span class="string">&quot;transtocv2&quot;</span>, transtocv2)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>其他知识引申：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 转换RGB的方法对比cv2img1 = cv2.cvtColor(cv2img, cv2.COLOR_BGR2RGB)</span></span><br><span class="line">pilimg1 = pilimg.convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>将PILimg转换为cv2时可以使用numpy.array()，也可以使用numpy.asarray()，这两者的区别在于array会copy出一个副本，占用新的内存，但asarray不会；</p>
<p>就是说将数据源用asarray转换后赋值给新的变量，再对原始数据源进行操作修改，会影响到新的变量数据.而如果用array来转换并赋值给新变量，修改原始数据后不会对新变量造成影响。</p>
<h2 id="pycharm中读取数据">pycharm中读取数据</h2>
<p>pycharm终端可以详细显示数据类型，下图为使用PIL读取数据过程</p>
<p><img src="/2023/06/27/PyTorch%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89Dataset%E7%B1%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/pycharm%E7%BB%88%E7%AB%AF%E4%BD%BF%E7%94%A8PIL.png" alt="pycharm终端使用PIL"></p>
<p>使用os读取图片路径存进列表中</p>
<p><img src="/2023/06/27/PyTorch%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89Dataset%E7%B1%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/%E4%BD%BF%E7%94%A8os%E8%AF%BB%E5%8F%96%E5%9B%BE%E7%89%87%E8%B7%AF%E5%BE%84%E5%AD%98%E5%82%A8%E5%9C%A8%E5%88%97%E8%A1%A8%E4%B8%AD.png" alt="使用os读取图片路径存储在列表中"></p>
<h1>数据可视化</h1>
]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>数据集实战</tag>
      </tags>
  </entry>
  <entry>
    <title>开学篇之图像分类评价指标</title>
    <url>/2023/07/18/%E5%BC%80%E5%AD%A6%E7%AF%87%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<h1>分类指标</h1>
<p>二分类：分类只有2个，如0，1分类；猫狗粉来；医学疾病的二分类（注：一般0、Neg代表正常/良性；1、Pos代表癌症/恶性）等</p>
<p>多分类：比较常见，例如imageNet-1000分类问题，CIFAR-10的10分类问题等。</p>
<h1>二分类评价指标</h1>
<p>Accuracy（准确率）、Precision（精确率）、Recall（召回率）、F1-Score、AUC、ROC、P-R曲线等</p>
<table>
<thead>
<tr>
<th style="text-align:center">标签真实值</th>
<th style="text-align:center">预测-正例</th>
<th style="text-align:center">预测-负例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>正例</strong></td>
<td style="text-align:center">真正例（A） TP</td>
<td style="text-align:center">假负例（C） FN</td>
</tr>
<tr>
<td style="text-align:center"><strong>负例</strong></td>
<td style="text-align:center">假正例（B） FP</td>
<td style="text-align:center">真正例（D） TN</td>
</tr>
</tbody>
</table>
<p><strong>备注：T/F分别代表True/False，表示预测结果与标签是否一致；P/N分别代表Positives/Negatives，表示预测结果值属于正/负例</strong>。</p>
<ul>
<li>A.True Positives，TP：预测为正，实际为正，预测为正样本是对的；</li>
<li>B.False Positives，FP：预测为正，实际为负，预测为正样本是错的；</li>
<li>C.False Negatives，FN：预测为负，实际为正，预测为负样本是错的；</li>
<li>D.True Negatives，TN：预测为负，实际为负，预测为负样本是对的。</li>
</ul>
<h2 id="Accuracy（准确率-精度）">Accuracy（准确率/精度）</h2>
<p>——对于给定的数据，分类正确样本数占总样本数的比例。</p>
<p>$$Accuracy=\frac{TP+TN}{TP+TN+FN+FP}$$</p>
<p>缺陷：准确率这一指标在不平衡的数据集上的表现很差，因为如果正负样本数目差别很大（正例990个，负例10个），那么如果把样本全部预测为正例，计算得出的Acc为99%，即使表面上看Acc准确率很高，但实际上这个模型没有半点鬼用。</p>
<h2 id="Precision（准确率-查准率）">Precision（准确率/查准率）</h2>
<p>——分类正确的正样本个数占分类器所有预测正样本个数的比例。即以<strong>判断为正例</strong>作为基准：模型判别为正例的里面，实际正确的概率是多少。</p>
<p>$$Precision=\frac{TP}{TP+FP}$$</p>
<p>题外话：个人感觉目前好像没发现该指标有什么不太好的地方，毕竟当预测时，如果有10正例，990负例，那么当模型不准确时，全预测为正例，那么准确率也才10%（以正例为基准），如果全预测为负例，那么也是0%。由此得出Precision在一定程度上是能表现出模型准确度的，但看那么多资料好像都不怎么评价该指标…（可能现在学的太浅，可能后续会知道吧）。</p>
<h2 id="Recall（召回率-查全率）">Recall（召回率/查全率）</h2>
<p>分类正确的正样本个数占实际正样本个数的比例。以<strong>真实为正例</strong>作为基准：真实值的正例中，被判断出来正例的概率是多少。</p>
<p>$$Recall=\frac{TP}{TP+FN}$$</p>
<p>缺陷：假设有一样本（正例10，负例990），但是模型分类将所有样本都分为正例，即TP=10，FN=990，即此刻Recall = 100%，实际上目前模型依旧什么鬼用也没有。</p>
<h2 id="F1-Score">F1-Score</h2>
<p>为正确率和召回率的调和平均值，当数据集的类别个数不均衡时，或许是一个比单纯的Accuracy更好的指标。</p>
<p>$$F1-Score=\frac{2}{\frac{1}{Precision}+\frac{1}{Recall}}=2·\frac{Precision·Recall}{Precision+Recall}$$</p>
<h2 id="ROC-Receiver-Operating-Characteristic">ROC(Receiver Operating Characteristic)</h2>
<p>准确率、精准率、召回率和F1-Score都是单一的数值指标，如果想观察分类算法在不同的参数下的表现，可以使用ROC曲线。ROC曲线可以用评价一个分类器在不同阈值下的表现。横纵坐标均基于真实值为分母。</p>
<ul>
<li>横坐标是FPR（False Position Rate，假正率）：$\frac{FP}{N}=\frac{FP}{FP+TN}$，表示预测为正例但实际为负例的样本占所有负例样本（真实结果为负样本）的比例，FPR越大，预测正类中的实际负类就越多；</li>
<li>纵坐标是TPR（True Position Rate，真正率）：$\frac{TP}{N}=\frac{TP}{TP+FN}$，表示预测为正例且实际为正例的样本占所有正例样本（真实结果为正样本）的比例。</li>
</ul>
<p>补充：</p>
<ul>
<li>TPR又称为召回率Recall、灵敏度Sensitivity，漏诊率=1-灵敏度；</li>
<li>特异度Specifivity=1-FPR。</li>
</ul>
<p>ROC曲线有四个关键点（曲线越靠近左上角效果越好）：</p>
<ul>
<li>（0，0）：即FPR=TPR=0，即FP（False Positive）=TP（True Positive）=0，可以发现该分类器预测所有的样本都为负样本（Negative）；</li>
<li>（1，1）：即FPR=TPR=1，分类器实际上预测所有的样本都为正样本；</li>
<li>（0，1）：即FPR=0, TPR=1，这意味着FN（False Negative）=0，并且FP（False Positive）=0。意味着这是一个完美的分类器，它将所有的样本都正确分类；</li>
<li>（1，0）：即FPR=1，TPR=0，意味着这是一个糟糕的分类器，因为它成功避开了所有的正确答案。</li>
</ul>
<p>ROC曲线图中，越靠近(0,1)的点对应的模型分类性能越好，所以，可以确定的是<strong>ROC曲线图中的点对应的模型，它们的不同之处仅仅是在分类时选用的阈值(Threshold)不同，每个点所选用的阈值都对应某个样本被预测为正类的概率值</strong></p>
<p><img src="/2023/07/18/%E5%BC%80%E5%AD%A6%E7%AF%87%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/ROC%E6%9B%B2%E7%BA%BF%E4%B8%8EAUC.png" alt="ROC曲线与AUC"></p>
<p>ROC曲线有一个很好的特征：当测试集中的正负样本比例分布发生变化时，ROC曲线能够保持不变，即它对政府样本不均衡问题不敏感。所以对不均衡样本问题，通常选择ROC曲线作为评价标准；</p>
<p>ROC曲线越接近左上角，表示该分类器的性能越好，若一个分类器的ROC曲线完全包住了另一个分类器ROC曲线，那么可以判断前者的性能更好。</p>
<p>如何通过ROC曲线来判断模型好坏？</p>
<blockquote>
<p>ROC曲线没有交点：ROC曲线越靠近（0，1），则效果越好</p>
</blockquote>
<p><img src="/2023/07/18/%E5%BC%80%E5%AD%A6%E7%AF%87%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/1-Specificity.png" alt="1-Specificity"></p>
<p><img src="/2023/07/18/%E5%BC%80%E5%AD%A6%E7%AF%87%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/2-Specificity.png" alt="2-Specificity"></p>
<blockquote>
<p>ROC曲线有交点：模型A、B对应的ROC曲线相交却AUC值相等，此时就需要具体问题具体分析：当需要高Sensitivity值时，A模型好过B；当需要高Specificity值时，B模型好过A。</p>
<p>备注：</p>
<ul>
<li>TPR又称为召回率Recall、灵敏度Sensitivity，漏诊率=1-灵敏度；</li>
<li>特异度Specifivity=1-FPR。</li>
</ul>
</blockquote>
<h2 id="AUC（Area-Under-Curve）">AUC（Area Under Curve）</h2>
<p>被定义为ROC曲线下与坐标轴围成的面积（如上图），显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。AUC越接近1.0，检测方法真实性越高;等于0.5时，则真实性最低，无应用价值。</p>
<ul>
<li>AUC=1：在任何阈值下分类器都可以 100% 识别所有类别，这是理想的分类器；</li>
<li>AUC=0.5：相当于随机预测，此时分类器不可用；</li>
<li>0.5&lt;AUC&lt;1：优于随机预测，这也是实际作用中大部分分类器所处的状态；</li>
<li>AUC&lt;0.5：总是比随机预测更差；</li>
</ul>
<p>AUC 作为一个评价标准，常和 ROC 曲线一起使用，可以看作是ROC的量化表现。</p>
<h2 id="P-R曲线">P-R曲线</h2>
<p>以查准率（Precision）为纵轴、查全率（Recall）为横轴作图 ，就得到了查准率-查全率曲线，简称 “P-R曲线”。</p>
<p><img src="/2023/07/18/%E5%BC%80%E5%AD%A6%E7%AF%87%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/P-R%E6%9B%B2%E7%BA%BF.png" alt="P-R曲线"></p>
<p>如何通过P-R曲线来判断模型好坏？</p>
<blockquote>
<p>P-R曲线未发生交叉：即上图分类器A更优于分类器C，理解为可以将另一分类器在P-R图像上完全包住，可断言该分类器更优于被包住的分类器；</p>
<p>P-R曲线发生交叉：如上图分类器A和B，通常会引入平衡点（Break-Even Point，BEP）的概念，一个总和考虑查准率和查全率的性能度量（查准率==查全率时的取值）。基于BEP进行比较，可以认为上图分类器A比B效果更好。</p>
</blockquote>
<h2 id="AP（Average-Precision）">AP（Average Precision）</h2>
<p>就是Precision-Recall 曲线下围成的面积，通常来说一个越好的分类器，AP值越高。而mAP（mean average precision）是多个类别AP的平均值。</p>
<h1>多分类评价指标</h1>
<h2 id="混淆矩阵（confusion-matrix）">混淆矩阵（confusion matrix）</h2>
<p><img src="/2023/07/18/%E5%BC%80%E5%AD%A6%E7%AF%87%E4%B9%8B%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/confusion_matrix.png" alt="confusion matrix"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># eg：preds=[0,1,3,2,4,2,...],labels=[0,1,3,4,2,1,...]</span></span><br><span class="line"><span class="comment"># result()是自定义的预测相关函数，返回预测列表和所对应的真实label值列表</span></span><br><span class="line">preds,labels = result()</span><br><span class="line">C = confusion_matrix(labels, preds)</span><br><span class="line"><span class="built_in">print</span>(C)</span><br><span class="line"><span class="comment"># 图片对应的矩阵</span></span><br><span class="line"><span class="comment"># [[357   7   0   0   0]</span></span><br><span class="line"><span class="comment">#  [  3 364   3   1   0]</span></span><br><span class="line"><span class="comment">#  [  0   6 192   4   0]</span></span><br><span class="line"><span class="comment">#  [  0   0   0  50   4]</span></span><br><span class="line"><span class="comment">#  [  0   0   0   0  39]]</span></span><br><span class="line">plt.matshow(C, cmap=plt.cm.Reds)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(C)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(C)):</span><br><span class="line">        plt.annotate(C[j, i], xy=(i, j), horizontalalignment=<span class="string">&#x27;center&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.ylabel(<span class="string">&#x27;True labels&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predict labels&#x27;</span>)</span><br><span class="line">plt.savefig(os.path.join(data2_path,<span class="string">&quot;utils_images/confusion_matrix.png&quot;</span>))</span><br></pre></td></tr></table></figure>
<h2 id="Accuracy之top1和top5">Accuracy之top1和top5</h2>
<p>在前面accuracy中已经有详细的解释（计算指定阈值的前k精度），这里把宏观上的公式展示出来</p>
<p>$$Acc-top1=\frac{第一个正确的个数和}{总数}$$</p>
<p>$$Acc-top5=\frac{前五之一正确的个数和}{总数}$$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">labels = np.asarray([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">preds = np.asarray([</span><br><span class="line">    [<span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.1</span>],</span><br><span class="line">    [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.2</span>],</span><br><span class="line">    [<span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.2</span>, <span class="number">0.1</span>],</span><br><span class="line">    [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.1</span>, <span class="number">0.9</span>]</span><br><span class="line">])</span><br><span class="line">accuracy = Accuracy(topk=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(accuracy(preds, labels))</span><br><span class="line"><span class="comment"># &#123;&#x27;top1&#x27;: 0.5, &#x27;top2&#x27;: 0.75, &#x27;top3&#x27;: 1.0&#125;</span></span><br><span class="line">accuracy = Accuracy(topk=<span class="number">2</span>, thrs=(<span class="number">0.1</span>, <span class="number">0.5</span>))</span><br><span class="line"><span class="built_in">print</span>(accuracy(preds, labels))</span><br><span class="line"><span class="comment"># &#123;&#x27;top2_thr-0.10&#x27;: 0.75, &#x27;top2_thr-0.50&#x27;: 0.5&#125;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>对于<code>Accuracy(topk=(1, 2, 3))</code>，对应结果为top1、top2、top3，以top1和top3作为栗子。</li>
</ul>
<blockquote>
<p>top1即指精度为1，也就是在preds找出每一行中从大到小的第1个的index，栗子中即为[0，2，1，3]，top1就是求前者与labels=[0，1，2，3]的acuracy，即（1+0+0+1）/4=0.5；</p>
<p>top3即指精度为3，也就是在preds找出每一行中从大到小的前3名的index，栗子中即为[[0，1，2],[1，2，3],[，0，1，2],[0，2，3]]，top3就是求前者中每个向量（应该叫这个，就是列表里面的每一个列表）是否存在对应的label值，对应即为1，即（1+1+1+1）/4=1</p>
</blockquote>
<ul>
<li>对于<code>Accuracy(topk=2, thrs=(0.1, 0.5))</code>，对应为top2_thr-0.10、top2_thr-0.50。</li>
</ul>
<blockquote>
<p>top2_thr-0.10即指在top2的前提下，对还剩余的值分别与thr的值（0.10）做对比。将preds中的每个预测值和thr对比，大于thr的设为1，小于等于thr的设为0。得到preds_new=[[1，0，0，0],[0，1，1，1],[1，1，1，0],[0，0，0，1]]；再根据topk=2，得到[[0，1],[1，2],[0，1],[0，3]]，所以（1+1+0+1）/4=0.75；</p>
<p>top2_thr-0.50即指在top2的前提下，对还剩余的值分别与thr的值（0.50）做对比。将preds中的每个预测值和thr对比，大于thr的设为1，小于等于thr的设为0。得到pred_new=[[1，0，0，0],[0，0，0，0],[0，0，0，0],[0，0，0，1]]；再根据topk=2，得到[[0，1],[0，1],[0，1],[0，3]]，所以（1+0+0+1）/4=0.5.</p>
</blockquote>
<h2 id="macro-F1">macro-F1</h2>
<p>类比二分类指标，大体原则是每类计算对应指标，再求平均。其中每个类别的<strong>precision</strong>分别是对角线元素除以该元素所在的<strong>列元素之和</strong>；<strong>recall</strong>则是除以该类别所在<strong>行元素之和</strong>。</p>
<p>由上图图例confusion matrix所示，类别1的Precision_1=364/(7+364+6+0+0)=0.9655；Recall_1=364/(3+364+3+1+0)=0.9811。</p>
<p>计算方式（本处先对每类做R和R求平均，再代入F1；其他有是先对每类做F1，再求平均）：</p>
<p>1）对各类别对Precision的Recall求平均：</p>
<p>$$Precision_{macro}=\frac{\sum_{i=1}^nPrecision_i}{n}$$</p>
<p>$$Recall_{macro}=\frac{\sum_{i=1}^nRecall_i}{n}$$</p>
<p>2）然后利用F1计算公式计算出来的F1值即为Macro-F1:</p>
<p>$$F1_{macro}=\frac{2}{\frac{1}{macro_P}+\frac{1}{macro_R}}=2·\frac{Precision_{macro}·Recall_{macro}}{Precision_{macro}+Recall_{macro}}$$</p>
<p>简而言之：就是<strong>先对每一个类别的Precision和Recall分别求平均，得到平均的Precision和Recall</strong>，之后带入macro-F1的公式得到结果。</p>
<p>注意：因为对各类别的Precision和Recall求了平均，所以并没有考虑到数据数量的问题。在这种情况下，Precision和Recall较高的类别对F1的影响会较大。</p>
<h2 id="micro-F1">micro-F1</h2>
<p>与上面的macro不同，微查准查全，先将多个混淆矩阵的TP，FP，TN，FN对应位置求平均，然后按照Percision和Recall的公式求得micro-P和micro-R，最后根据micro-P和micro-R求得micro-F1。</p>
<p>计算方式：</p>
<p>1）先计算出所有类别的总的Precision和Recall：</p>
<p>$$Precision_{micro}=\frac{\sum_{i=1}^nTP_i}{\sum_{i=1}^nTP_i+\sum_{i=1}^nFN_i}$$</p>
<p>$$Recall_{micro}=\frac{\sum_{i=1}^nTP_i}{\sum_{i=1}^nTP_i+\sum_{i=1}^nFN_i}$$</p>
<p>2）利用F1计算公式计算出来的F1值即为Micro-F1:</p>
<p>$$F1_{micro}=2·\frac{Precision_{micro}·Recall_{micro}}{Precision_{micro}+Recall_{micro}}$$</p>
<p>简而言之：就是将每个类别的Precision和Recall做求和，再代入micro-F1公式中。</p>
<p>注意：因为其考虑了各种类别的数量，所以更适用于数据分布不平衡的情况。在这种情况下，数量较多的类别对F1的影响会较大。</p>
<h2 id="mAP（mean-Average-Precision）">mAP（mean Average Precision）</h2>
<p>mAP（mean Accuracy Precision）一般而言，全类平均正确率（mAP，又称全类平均精度）是将所有类别的平均正确率（AP）进行综合加权平均而得到的。在<strong>目标检测领域</strong>使用更为普遍（目标检测那块再详细说明，因为暂时还没了解目标检测）。</p>
<p>$$mAP=\frac{1}{n}\sum(AP)_i$$</p>
<p>为什么要使用AP或者mAP？</p>
<blockquote>
<p>我们希望一个模型的Precision和Recall都很高，所以需要综合考虑这两个因素，我们可以联想到用调和平均数F1-beta值来衡量，另一种方法正是PR曲线下的面积AUC，这也就是AP。AUC面积越接近1性能越好。曲线下的面积理解为不同召回值的情况下所有精度的平均值。</p>
</blockquote>
<h2 id="混淆矩阵kappa系数">混淆矩阵kappa系数</h2>
<p>使用在统计学中评估一致性的一种方法，取值范围[-1,1]，世纪应用中，一般是[0,1]，与ROC曲线中一般不会出现下凸形曲线的原理类似。这个系数的值越高，则代表模型实现的分类准确度越高。基于混淆矩阵的kappa系数计算公式如下：</p>
<p>$$kappa=\frac{p_0-p_e}{1-p_e}$$</p>
<p>其中：</p>
<p>$p_0=\frac{对角线之和}{整个矩阵元素之和}$，也就是Accuracy</p>
<p>$p_e=\frac{\sum_i第i行元素和*第i列元素和}{(整个矩阵元素之和)^2}$</p>
<p>意义：根据kappa的计算公式，越不平衡的混淆矩阵，$p_e$越高，kappa的值就可能越低，正好能够给“偏向性”强的模型打低分，是一种能够惩罚模型的“偏向性”的指标来代替accuracy</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> cohen_kappa_score</span><br><span class="line">kappa = cohen_kappa_score(y_true,y_pred，label=<span class="literal">None</span>) <span class="comment">#(label除非是你想计算其中的分类子集的kappa系数，否则不需要设置)</span></span><br></pre></td></tr></table></figure>
<h1>性能指标（待补充）</h1>
<h2 id="机器性能FLOPS">机器性能FLOPS</h2>
<ul>
<li>
<p>OPS(Operations Per Second) ，每秒的操作次数</p>
</li>
<li>
<ul>
<li>MOPS（Million Operation Per Second）：每秒钟可进行一百万次（10^6）操作</li>
<li>GOPS（Giga Operations Per Second）每秒钟可进行十亿次（10^9）操作</li>
<li>TOPS（Tera Operations Per Second）每秒钟可进行一万亿次（10^12）操作</li>
<li>POPS（peta Operations Per Second）每秒钟可进行一千万亿（=10^15）操作</li>
</ul>
</li>
<li>
<p><strong>FLOPS</strong>: (Floating Point operations per second), S大写， 指每秒浮点运算的次数，可以理解为运算的速度，是衡量<strong>硬件</strong>性能的一个指标。MFLOPS, GFLOPS, TFLOPS, PFLOPS 意义同上。</p>
</li>
</ul>
<h2 id="算法性能FLOPs">算法性能FLOPs</h2>
<p><strong>FLOPs</strong>：(Floating Point Operations) s小写，指浮点运算数，理解为计算量。可以用来衡量<strong>算法/模型</strong>的复杂度。（<strong>模型</strong>） 在论文中常用GFLOPs（1 GFLOPs = 10^9 FLOPs）。其它前缀单位意义同上。</p>
<p>一般计算FLOPs来衡量模型的复杂度，FLOPs越小时，表示模型所需计算量越小，运行起来时速度更快。</p>
<p><strong>MAC(memory access cost, 内存访问成本</strong>)即存储该模型所需的存储空间。以卷积来举例：理解为卷积的总计算量需要访问内存，输出的结果需要存储，权重需要存储。也会被用来衡量模型的运行速度。</p>
<p>有一个基于pytorch的<strong>torch stat包</strong>，可以计算模型的FLOPs数，参数大小等指标</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchstat <span class="keyword">import</span> stat</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line">model = model.alexnet()</span><br><span class="line">stat(model, (<span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>性能指标</category>
      </categories>
      <tags>
        <tag>图像分类指标</tag>
      </tags>
  </entry>
</search>
