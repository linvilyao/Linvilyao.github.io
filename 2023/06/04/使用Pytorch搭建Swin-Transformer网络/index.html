<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_logosc/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_logosc/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"linvilyao.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":14,"offset":10},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础12.2》，作为随堂笔记。学习使用Pytorch搭建Swin-Transformer网络（学到人傻了，后续需要不断完善这篇博文）">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习模型之CNN（二十四）使用Pytorch搭建Swin-Transformer网络">
<meta property="og:url" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="Linvil&#39;s Blog">
<meta property="og:description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础12.2》，作为随堂笔记。学习使用Pytorch搭建Swin-Transformer网络（学到人傻了，后续需要不断完善这篇博文）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E8%AF%A6%E7%BB%86%E5%8F%82%E6%95%B0.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Patch-Merging.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%8E%9F%E6%95%B0%E6%8D%AE.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%81%8F%E7%A7%BB%E5%88%86%E5%89%B2%E4%B9%8B%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%88%87%E7%89%87.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%88%92%E5%88%86%E7%AA%97%E5%8F%A3%E5%BD%A2%E5%BC%8F.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%B1%95%E5%B9%B3.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E8%A1%8C%E5%90%91%E9%87%8F%E5%A4%8D%E5%88%B69%E6%AC%A1.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E4%B8%A4%E4%B8%AA%E7%9F%A9%E9%98%B5%E7%9B%B8%E5%87%8F%E4%B9%8B%E5%90%8E.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Transformer-Encoder%E5%B1%82.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Transformer-Encoder%E5%B1%82.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E5%B8%A6%E8%92%99%E6%9D%BFmask%E7%9A%84MSA.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB%E5%8F%82%E6%95%B0.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%B4%A2%E5%BC%95%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%87%8F%E8%BF%87%E7%A8%8B.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87+M-1.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E5%88%97%E6%A0%87+M-1.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87%E4%B9%98%E4%BB%A52M-1.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87%E5%92%8C%E5%88%97%E6%A0%87%E7%9B%B8%E5%8A%A0.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E5%85%AC%E5%BC%8F.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E5%B8%A6%E8%92%99%E6%9D%BFmask%E7%9A%84MSA.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png">
<meta property="article:published_time" content="2023-06-04T02:11:45.000Z">
<meta property="article:modified_time" content="2023-06-04T13:16:12.624Z">
<meta property="article:author" content="Linvil Yao">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="Pytorch搭建CNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png">


<link rel="canonical" href="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/","path":"2023/06/04/使用Pytorch搭建Swin-Transformer网络/","title":"深度学习模型之CNN（二十四）使用Pytorch搭建Swin-Transformer网络"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>深度学习模型之CNN（二十四）使用Pytorch搭建Swin-Transformer网络 | Linvil's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Linvil's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">这是一个用来记录的博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">3</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">5</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">36</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">工程目录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">Swin-T网络结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">Swin Transformer网络参数表</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">模型文件</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Swin-Transformer%E7%B1%BB"><span class="nav-number">4.1.</span> <span class="nav-text">Swin Transformer类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%87%BD%E6%95%B0"><span class="nav-number">4.1.1.</span> <span class="nav-text">初始化函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E5%87%BD%E6%95%B0"><span class="nav-number">4.1.2.</span> <span class="nav-text">正向传播函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PatchEmbed%E7%B1%BB"><span class="nav-number">4.2.</span> <span class="nav-text">PatchEmbed类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PatchMerfing%E7%B1%BB"><span class="nav-number">4.3.</span> <span class="nav-text">PatchMerfing类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BasicLayer%E7%B1%BB"><span class="nav-number">4.4.</span> <span class="nav-text">BasicLayer类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#create-mask"><span class="nav-number">4.4.1.</span> <span class="nav-text">create_mask</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#window-partition"><span class="nav-number">4.4.1.1.</span> <span class="nav-text">window_partition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#window-reverse"><span class="nav-number">4.4.1.2.</span> <span class="nav-text">window_reverse</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SwinTransformerBlock"><span class="nav-number">4.4.2.</span> <span class="nav-text">SwinTransformerBlock</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Mlp"><span class="nav-number">4.4.2.1.</span> <span class="nav-text">Mlp</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#WindowAttention"><span class="nav-number">4.4.2.2.</span> <span class="nav-text">WindowAttention</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%87%BD%E6%95%B0-2"><span class="nav-number">4.4.2.2.1.</span> <span class="nav-text">初始化函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E5%87%BD%E6%95%B0-2"><span class="nav-number">4.4.2.2.2.</span> <span class="nav-text">正向传播函数</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">实例化模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">6.</span> <span class="nav-text">train.py</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C"><span class="nav-number">6.1.</span> <span class="nav-text">训练结果</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">7.</span> <span class="nav-text">predict.py</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="nav-number">7.1.</span> <span class="nav-text">预测结果</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Linvil Yao"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Linvil Yao</p>
  <div class="site-description" itemprop="description">Welcome to Linvil's Blog!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">36</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


        </div>
      </div>


  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      最近文章
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/" title="2023&#x2F;06&#x2F;05&#x2F;ConvNeXt网络讲解及使用Pytorch搭建&#x2F;">深度学习模型之CNN（二十五）ConvNeXt网络讲解及使用Pytorch搭建</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/" title="2023&#x2F;06&#x2F;04&#x2F;使用Pytorch搭建Swin-Transformer网络&#x2F;">深度学习模型之CNN（二十四）使用Pytorch搭建Swin-Transformer网络</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/" title="2023&#x2F;06&#x2F;03&#x2F;Swin-Transformer网络结构详解&#x2F;">深度学习模型之CNN（二十三）Swin-Transformer网络结构详解</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/01/%E4%BD%BF%E7%94%A8pytorch%E6%90%AD%E5%BB%BAVisionTransformer-vit%E6%A8%A1%E5%9E%8B/" title="2023&#x2F;06&#x2F;01&#x2F;使用pytorch搭建VisionTransformer-vit模型&#x2F;">深度学习模型之CNN（二十二）使用pytorch搭建VisionTransformer_vit模型</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/05/31/Transformer-vit%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/" title="2023&#x2F;05&#x2F;31&#x2F;Transformer-vit网络详解&#x2F;">深度学习模型之CNN（二十一）Transformer_vit网络详解</a>
        </li>
    </ul>
  </div>
    </div>


    



  </aside>






    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://linvilyao.github.io/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Linvil Yao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linvil's Blog">
      <meta itemprop="description" content="Welcome to Linvil's Blog!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="深度学习模型之CNN（二十四）使用Pytorch搭建Swin-Transformer网络 | Linvil's Blog">
      <meta itemprop="description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础12.2》，作为随堂笔记。学习使用Pytorch搭建Swin-Transformer网络（学到人傻了，后续需要不断完善这篇博文）">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习模型之CNN（二十四）使用Pytorch搭建Swin-Transformer网络
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-06-04 10:11:45 / 修改时间：21:16:12" itemprop="dateCreated datePublished" datetime="2023-06-04T10:11:45+08:00">2023-06-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
    <span id="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/" class="post-meta-item leancloud_visitors" data-flag-title="深度学习模型之CNN（二十四）使用Pytorch搭建Swin-Transformer网络" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Valine：</span>
  
    <a title="valine" href="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>47k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>43 分钟</span>
    </span>
</div>

            <div class="post-description">本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础12.2》，作为随堂笔记。学习使用Pytorch搭建Swin-Transformer网络（学到人傻了，后续需要不断完善这篇博文）</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1>工程目录</h1>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">├── swin_transformer</span><br><span class="line">	├── model.py（模型文件）  </span><br><span class="line">	├── my_dataset.py（数据处理文件）  </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,swin transformer.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）</span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── swin_tiny_patch4_window7_224.pth（迁移学习，提前下载好swin_tiny_patch4_window7_224.pth权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h1>Swin-T网络结构</h1>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Swin Transformer网络架构图"></p>
<h1>Swin Transformer网络参数表</h1>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E8%AF%A6%E7%BB%86%E5%8F%82%E6%95%B0.png" alt="Swin Transformer网络参数表"></p>
<h1>模型文件</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; Swin Transformer</span></span><br><span class="line"><span class="string">A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`</span></span><br><span class="line"><span class="string">    - https://arxiv.org/pdf/2103.14030</span></span><br><span class="line"><span class="string">Code/weights from https://github.com/microsoft/Swin-Transformer</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.utils.checkpoint <span class="keyword">as</span> checkpoint</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path_f</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">window_partition</span>(<span class="params">x, window_size: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">window_reverse</span>(<span class="params">windows, window_size: <span class="built_in">int</span>, H: <span class="built_in">int</span>, W: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size=<span class="number">4</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">96</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PatchMerging</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mlp</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WindowAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, window_size, num_heads, qkv_bias=<span class="literal">True</span>, attn_drop=<span class="number">0.</span>, proj_drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, num_heads, window_size=<span class="number">7</span>, shift_size=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>, drop_path=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 act_layer=nn.GELU, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, attn_mask</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, depth, num_heads, window_size,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 drop_path=<span class="number">0.</span>, norm_layer=nn.LayerNorm, downsample=<span class="literal">None</span>, use_checkpoint=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_mask</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size=<span class="number">4</span>, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">96</span>, depths=(<span class="params"><span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">2</span></span>), num_heads=(<span class="params"><span class="number">3</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span></span>),</span></span><br><span class="line"><span class="params">                 window_size=<span class="number">7</span>, mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 drop_rate=<span class="number">0.</span>, attn_drop_rate=<span class="number">0.</span>, drop_path_rate=<span class="number">0.1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer=nn.LayerNorm, patch_norm=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 use_checkpoint=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self, m</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_tiny_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_small_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window12_384</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window7_224_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window12_384_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_large_patch4_window7_224_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_large_patch4_window12_384_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h2 id="Swin-Transformer类">Swin Transformer类</h2>
<p>SwinTransformer类继承来自于官方的nn.Module父类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformer</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; Swin Transformer</span></span><br><span class="line"><span class="string">        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -</span></span><br><span class="line"><span class="string">          https://arxiv.org/pdf/2103.14030</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        patch_size (int | tuple(int)): Patch size. Default: 4</span></span><br><span class="line"><span class="string">        in_chans (int): Number of input image channels. Default: 3</span></span><br><span class="line"><span class="string">        num_classes (int): Number of classes for classification head. Default: 1000</span></span><br><span class="line"><span class="string">        embed_dim (int): Patch embedding dimension. Default: 96</span></span><br><span class="line"><span class="string">        depths (tuple(int)): Depth of each Swin Transformer layer.</span></span><br><span class="line"><span class="string">        num_heads (tuple(int)): Number of attention heads in different layers.</span></span><br><span class="line"><span class="string">        window_size (int): Window size. Default: 7</span></span><br><span class="line"><span class="string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4</span></span><br><span class="line"><span class="string">        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True</span></span><br><span class="line"><span class="string">        drop_rate (float): Dropout rate. Default: 0</span></span><br><span class="line"><span class="string">        attn_drop_rate (float): Attention dropout rate. Default: 0</span></span><br><span class="line"><span class="string">        drop_path_rate (float): Stochastic depth rate. Default: 0.1</span></span><br><span class="line"><span class="string">        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.</span></span><br><span class="line"><span class="string">        patch_norm (bool): If True, add normalization after patch embedding. Default: True</span></span><br><span class="line"><span class="string">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="初始化函数"><strong>初始化函数</strong></h3>
<p><strong>传入的参数：</strong></p>
<ul>
<li><code>patch_size</code>：在Swin Transformer网络架构图中，<strong>经过Stage1前面的Patch Partition之后下采样多少倍</strong>，根据网络架构图，为下采样4倍，也就是高度和宽度都下采样4倍，因此patch_size = 4；</li>
<li><code>in_chans</code>：输入图片的深度，该处输入的为RGB彩色图像，因此in_chans = 3；</li>
<li><code>num_classes</code>：分类类别数；</li>
<li><code>embed_dim</code>：指通过Stage1的Linear Embedding之后映射得到的，即<strong>Swin Transformer网络架构图中的C</strong>，因此在通过Stage1的Linear Embedding之后的搭配的C为96，且之后的Stage输出的channel直接翻倍即可；</li>
<li><code>depths</code>：对应<strong>每一个Stage当中重复使用Swin Transformer Block的次数</strong>，例如对应Swin-T此处为（2，2，6，2）；</li>
<li><code>num_heads</code>：<strong>在Swin Transformer Block中所采用的Muti-Head self-Attention的head个数</strong>，对应Swin-T的网络参数表的head个数为（3，6，12，24）；</li>
<li><code>window_size</code>：对应W-MSA和SW-MSA所采用window的大小；</li>
<li><code>mlp_ratio</code>：在Mlp模块当中，第一个全连接层将channel给翻多少倍；</li>
<li><code>qkv_bias</code>：在Muti-Head self-Attention模块当中是否使用偏置；</li>
<li><code>drop_rate</code>：第一个drop_rate除了在pos_drop中使用到，还在mlp以及其他地方使用到；</li>
<li><code>attn_drop_rate</code>：对应在Muti-Head self-Attention模块当中所采用的drop_rate；</li>
<li><code>drop_path_rate</code>：对应每一个Swin Transformer Block所采用的drop_rate（注意：<strong>drop_path_rate在Swin Transformer Block当中是递增的</strong>）；</li>
<li><code>norm_layer</code>：默认使用LayerNorm；</li>
<li><code>patch_norm</code>：如果使用的话，会在patch embedding之后使用；</li>
<li><code>use_checkpoint：</code>官方给出介绍是使用的话会减少内存的，但官方代码False；</li>
</ul>
<p><strong>代码语句解释：</strong></p>
<p><code>self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))</code>：stage4输出特征矩阵的channels = C * 2^3 = 8C；</p>
<p><code>self.patch_embed = PatchEmbed(...)</code>：将图片划分为一个个没有重叠的patches，对应的是Stage1前面的Patch Partition以及STage1的Patch Embedding（具体实现方式可看后文PatchEmbed类）；</p>
<p><code>dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]</code>：关于drop_path_rate的设置，对于一系列Swin Transformer Block当中，所采用的drop_rate是从0慢慢增长到所指定的drop_path_rate。此处直接使用官方的linspace方法，指定初始的数值0，以及末尾的数值drop_path_rate，和步数sum(depths)，即会自动生成针对每一个Swin Transformer Block所采用的drop_rate；</p>
<p>创建一个<code>self.layers = nn.ModuleList()</code>，将会通过一个循环来遍历生成每个Stage；</p>
<blockquote>
<p>注意：<strong>代码与Swub-T的网络结构图有些差异</strong>。</p>
<p>在图中每个Stage是<strong>先进行Patch Merging之后接着一个Swin Transformer Block</strong>（Stage1是先进行Linear Embedding之后接着一个Swin Transformer Block），也就是图中虚线的部分。</p>
<p>但在源码中，在通过循环来遍历生成每个Stage中，是<strong>先进行Swin Transformer Block，后接着一个Patch Merging</strong>（在Stage4的Swin Transformer Block后已经没有Patch Merging，所以只有Swin Transformer Block），等于是将图中的虚线向右平移了一个模块。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">layers = BasicLayer(dim=<span class="built_in">int</span>(embed_dim * <span class="number">2</span> ** i_layer),</span><br><span class="line">                        depth=depths[i_layer],</span><br><span class="line">                        num_heads=num_heads[i_layer],</span><br><span class="line">                        window_size=window_size,</span><br><span class="line">                        mlp_ratio=self.mlp_ratio,</span><br><span class="line">                        qkv_bias=qkv_bias,</span><br><span class="line">                        drop=drop_rate,</span><br><span class="line">                        attn_drop=attn_drop_rate,</span><br><span class="line">                        drop_path=dpr[<span class="built_in">sum</span>(depths[:i_layer]):<span class="built_in">sum</span>(depths[:i_layer + <span class="number">1</span>])],</span><br><span class="line">                        norm_layer=norm_layer,</span><br><span class="line">                        downsample=PatchMerging <span class="keyword">if</span> (i_layer &lt; self.num_layers - <span class="number">1</span>) <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                        use_checkpoint=use_checkpoint)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>dim=int(embed_dim * 2 ** i_layer)</code>：对于每一个Stage而言，所传入的特征矩阵的dimension都是前一个Stage的dimension的2倍；</li>
<li><code>depth=depths[i_layer]</code>：在当前的Stage当中，要重复堆叠多少次Swin Transformer Block，即可在depths列表中取对应索引的元素；</li>
<li><code>downsample=PatchMerging if (i_layer &lt; self.num_layers - 1) else None</code>：针对每一个Stage所包含的Patch Merging是接在Swin Transformer Block后面的（也就是前文提到的原码与网络结构图不相符的地方），<strong>因此进行了判断，如果当前在Stage1、2、3，则需要使用Patch Merging，如果是Stage4，则不需要使用</strong>（详细可看后文的PatchMerging类详解）；</li>
</ul>
<p>对于之后的classifier分类层而言，还需通过一个norm层、自适应全局平均池化、全连接层进行输出。</p>
<p><code>self.apply(self._init_weights)</code>：之后通过apply方法调用_init_weights对模型进行权重初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size=<span class="number">4</span>, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">96</span>, depths=(<span class="params"><span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">2</span></span>), num_heads=(<span class="params"><span class="number">3</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span></span>),</span></span><br><span class="line"><span class="params">                 window_size=<span class="number">7</span>, mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 drop_rate=<span class="number">0.</span>, attn_drop_rate=<span class="number">0.</span>, drop_path_rate=<span class="number">0.1</span>,</span></span><br><span class="line"><span class="params">                 norm_layer=nn.LayerNorm, patch_norm=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 use_checkpoint=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.num_layers = <span class="built_in">len</span>(depths)</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.patch_norm = patch_norm</span><br><span class="line">        <span class="comment"># stage4输出特征矩阵的channels = C * 2^3 = 8C</span></span><br><span class="line">        self.num_features = <span class="built_in">int</span>(embed_dim * <span class="number">2</span> ** (self.num_layers - <span class="number">1</span>))</span><br><span class="line">        self.mlp_ratio = mlp_ratio</span><br><span class="line"></span><br><span class="line">        <span class="comment"># split image into non-overlapping patches</span></span><br><span class="line">        self.patch_embed = PatchEmbed(</span><br><span class="line">            patch_size=patch_size, in_c=in_chans, embed_dim=embed_dim,</span><br><span class="line">            norm_layer=norm_layer <span class="keyword">if</span> self.patch_norm <span class="keyword">else</span> <span class="literal">None</span>)</span><br><span class="line">        self.pos_drop = nn.Dropout(p=drop_rate)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># stochastic depth</span></span><br><span class="line">        dpr = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, <span class="built_in">sum</span>(depths))]  <span class="comment"># stochastic depth decay rule</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># build layers</span></span><br><span class="line">        self.layers = nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> i_layer <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layers):</span><br><span class="line">            <span class="comment"># 注意这里构建的stage和论文图中有些差异</span></span><br><span class="line">            <span class="comment"># 这里的stage不包含该stage的patch_merging层，包含的是下个stage的</span></span><br><span class="line">            layers = BasicLayer(dim=<span class="built_in">int</span>(embed_dim * <span class="number">2</span> ** i_layer),</span><br><span class="line">                                depth=depths[i_layer],</span><br><span class="line">                                num_heads=num_heads[i_layer],</span><br><span class="line">                                window_size=window_size,</span><br><span class="line">                                mlp_ratio=self.mlp_ratio,</span><br><span class="line">                                qkv_bias=qkv_bias,</span><br><span class="line">                                drop=drop_rate,</span><br><span class="line">                                attn_drop=attn_drop_rate,</span><br><span class="line">                                drop_path=dpr[<span class="built_in">sum</span>(depths[:i_layer]):<span class="built_in">sum</span>(depths[:i_layer + <span class="number">1</span>])],</span><br><span class="line">                                norm_layer=norm_layer,</span><br><span class="line">                                downsample=PatchMerging <span class="keyword">if</span> (i_layer &lt; self.num_layers - <span class="number">1</span>) <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                                use_checkpoint=use_checkpoint)</span><br><span class="line">            self.layers.append(layers)</span><br><span class="line"></span><br><span class="line">        self.norm = norm_layer(self.num_features)</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool1d(<span class="number">1</span>)</span><br><span class="line">        self.head = nn.Linear(self.num_features, num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">        self.apply(self._init_weights)</span><br></pre></td></tr></table></figure>
<p><strong>初始化权重函数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self, m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">            nn.init.trunc_normal_(m.weight, std=<span class="number">.02</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear) <span class="keyword">and</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.LayerNorm):</span><br><span class="line">            nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            nn.init.constant_(m.weight, <span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="正向传播函数"><strong>正向传播函数</strong></h3>
<p>首先对于传入的x先进行patch_embed方法对图像进行下采样4倍，然后就得到输出特征矩阵和对应的H，W（此时x对应的通道排列顺序是<code>[B, L, C]</code>）。</p>
<p>之后通过Dropout层按照一定的比例随机丢失一部分输入。</p>
<p>之后遍历初始化函数中创建的layers，也就是nn.ModuleList()。遍历之后就能将数据依次通过Stage1、2、3、4，对应每一个Stage将x和当前的H，W传入，就能得到该Stage之后得到的x输出以及H，W，然后再传入到下一个Stage当中。</p>
<p>当得到Stage4的输出之后，进行一个LayerNorm层（此时x对应的通道排列顺序是<code>[B, L, C]</code>）。通过transpose方法将L和C互换位置（此时x对应的通道排列顺序是<code>[B, C, L]</code>），通过自适应的平均池化avgpool，将L池化为1（此时x对应的通道排列顺序是<code>[B, C, 1]</code>）。</p>
<p>再通过flatten方法从C维度开始向后展平（此时x对应的通道排列顺序是<code>[B, C]</code>），最后再通过一个head全连接层得到输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x: [B, L, C]</span></span><br><span class="line">        x, H, W = self.patch_embed(x)</span><br><span class="line">        x = self.pos_drop(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x, H, W = layer(x, H, W)</span><br><span class="line"></span><br><span class="line">        x = self.norm(x)  <span class="comment"># [B, L, C]</span></span><br><span class="line">        x = self.avgpool(x.transpose(<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># [B, C, 1]</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.head(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="PatchEmbed类">PatchEmbed类</h2>
<ul>
<li><code>patch_size</code>：下采样的倍率；</li>
<li><code>in_c</code>：输入图像的深度；</li>
<li><code>embed_dim</code>：通过Stage1的Linear Embedding之后映射得到的深度；</li>
<li><code>norm_layer</code>：传入的LayerNorm</li>
</ul>
<p><strong>初始化函数</strong></p>
<p>创建一个卷积层，下采样其实就是通过卷积层实现的，因此输入特征矩阵的channel为in_c，输出特征矩阵的channel为embed_dim，卷积核大小为patch_size，步距也为patch_size。</p>
<p>如果有传入norm_layer则直接使用传入的，如果没有传入则直接做线性映射（指不做处理）</p>
<p><strong>正向传播函数</strong></p>
<p>首先获取传入图像的高宽，之后进行判断（如果图像的高度或者宽度不是patch_size的整数倍，则需要进行padding）。如果pad_input = True的话，也就是说明高或者宽不是patch_size的整数倍，需要进行padding，则直接使用官方的pad方法对x进行padding。</p>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = F.pad(x, (<span class="number">0</span>, self.patch_size[<span class="number">1</span>] - W % self.patch_size[<span class="number">1</span>],</span><br><span class="line">                          <span class="number">0</span>, self.patch_size[<span class="number">0</span>] - H % self.patch_size[<span class="number">0</span>],</span><br><span class="line">                          <span class="number">0</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>会对宽度方向的右侧以及高度方向的底部padding</p>
</blockquote>
<p>经过padding之后H，W即为patch_size的整数倍，则可以直接使用下采样层（也就是卷积层）。下采样之后，记录以下此刻的H，W。再对x进行维度2上开始展平处理（即<code>flatten: [B, C, H, W] -&gt; [B, C, HW]</code>），再通过transpose将位置1，2上的数据进行交换（即<code>transpose: [B, C, HW] -&gt; [B, HW, C]</code>）。</p>
<p>最后再用LayerNorm层对channel维度做LayerNorm的处理之后，返回此时的特征矩阵，以及通过下采样之后的H，W。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    2D Image to Patch Embedding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size=<span class="number">4</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">96</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        patch_size = (patch_size, patch_size)</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        self.in_chans = in_c</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)</span><br><span class="line">        self.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        _, _, H, W = x.shape</span><br><span class="line"></span><br><span class="line">        <span class="comment"># padding</span></span><br><span class="line">        <span class="comment"># 如果输入图片的H，W不是patch_size的整数倍，需要进行padding</span></span><br><span class="line">        pad_input = (H % self.patch_size[<span class="number">0</span>] != <span class="number">0</span>) <span class="keyword">or</span> (W % self.patch_size[<span class="number">1</span>] != <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> pad_input:</span><br><span class="line">            <span class="comment"># to pad the last 3 dimensions,</span></span><br><span class="line">            <span class="comment"># (W_left, W_right, H_top,H_bottom, C_front, C_back)</span></span><br><span class="line">            x = F.pad(x, (<span class="number">0</span>, self.patch_size[<span class="number">1</span>] - W % self.patch_size[<span class="number">1</span>],</span><br><span class="line">                          <span class="number">0</span>, self.patch_size[<span class="number">0</span>] - H % self.patch_size[<span class="number">0</span>],</span><br><span class="line">                          <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下采样patch_size倍</span></span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        _, _, H, W = x.shape</span><br><span class="line">        <span class="comment"># flatten: [B, C, H, W] -&gt; [B, C, HW]</span></span><br><span class="line">        <span class="comment"># transpose: [B, C, HW] -&gt; [B, HW, C]</span></span><br><span class="line">        x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> x, H, W</span><br></pre></td></tr></table></figure>
<h2 id="PatchMerfing类">PatchMerfing类</h2>
<p><strong>初始化函数</strong></p>
<p><code>self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)</code>：创建全连接层，输入的dimension是4倍的dim，输出的dimension是2倍的dim</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Patch-Merging.png" alt="Patch Merging"></p>
<p>如上图所示，在Patch Merging中，首先是把输入的feature map每2x2做一个窗口进行分割，分割之后同样位置上的元素进行拼接得到4个特征矩阵（上图（上中）），再通过channel方向进行concat拼接（上图（上右）），拼接之后在channel方向进行LayerNorm处理（上图（下右）），最后再通过全连接Linear层做一个线性的映射（上图（下中））。</p>
<p>对于全连接层而言，输入特征矩阵的channel = 最原始（上图（上左））的feature map的channel = 4，因此设置为4*dim。输出的特征矩阵channel是将上图（下右）的特征矩阵channel减半，也就是从4*dim变为2*dim。</p>
<p><code>self.norm = norm_layer(4 * dim)</code>：对应的是上图（下右），因此使用4*dim。</p>
<p><strong>正向传播函数</strong></p>
<p><code>forward(self, x, H, W)</code>：x为输入的数据，H，W为记录输入当前特征矩阵的高宽。因为当前输入的特征矩阵的通道排列顺序是x: B, H*W, C，所以只知道高和宽的乘积，并不知道分别的数是多少；</p>
<p><code>pad_input = (H % 2 == 1) or (W % 2 == 1)</code>：因为在PatchMerfing当中是需要下采样2倍的，如果传入的x的高和宽不是2的整数倍的话，需要进行padding；</p>
<blockquote>
<p>如果H或者W不是2的整数倍的话，pad_input = True，则需要进行padding。注意此时x的通道排列顺序是[B，H，W，C]，pad方法是pad最后三个维度，也就是这里的H，W，C。</p>
<p><code>x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))</code>：这里给出的参数，是从最后一个维度向前设置的。也就是说<code>(0, 0, 0, W % 2, 0, H % 2)</code>最前面的0，0是针对C维度上的padding的参数，后面两个0, W % 2是针对在W方向上padding的参数（宽度方向的右侧补一列0），0, H % 2是针对在H方向上padding的参数（高度方向的底部补一行0）。</p>
<p>即保证H，W是2的整数倍，就可以进行下采样了。</p>
</blockquote>
<p>因为是要把输入的feature map分成一个个窗口，再将相同位置处拼接在一起（<strong>此时x的通道排列顺序是[B，H，W，C]</strong>）。以上文x0为例，batch维度取所有值，在高度和宽度方向首先都从0开始，所对应的就是上图（上左）中蓝色区域的位置，在高度和宽度方向上都是以2为间隔进行采样的，在channel维度上也是取所有值，因此<code>x0 = x[:, 0::2, 0::2, :]</code>，于是就可以构建上图（上中）蓝色的feature map。</p>
<ul>
<li><code>x1 = x[:, 1::2, 0::2, :]</code>：在x1中对应的的绿色的区域，高度1，宽度0，在高度和宽度方向上都是以2为间隔进行采样的，拼接之后输出为<code>[B, H/2, W/2, C]</code>；</li>
<li><code>x2 = x[:, 0::2, 1::2, :]</code>：在x2中对应的的黄色的区域，高度0，宽度1，在高度和宽度方向上都是以2为间隔进行采样的，拼接之后输出为<code>[B, H/2, W/2, C]</code>；</li>
<li><code>x3 = x[:, 1::2, 1::2, :]</code>：在x3中对应的的红色的区域，高度1，宽度1，在高度和宽度方向上都是以2为间隔进行采样的，拼接之后输出为<code>[B, H/2, W/2, C]</code>；</li>
</ul>
<p><code>x = torch.cat([x0, x1, x2, x3], -1)</code>：之后就可以在channel维度上进行concat拼接了，-1指的是最后一个维度，最后一个维度也就是深度channel维度，拼接之后输出为<code>[B, H/2, W/2, 4*C]</code>。</p>
<p><code>x = x.view(B, -1, 4 * C)</code>：再通过view函数进行展平处理，展平之后输出为<code>[B, H/2*W/2, 4*C]</code></p>
<p><code>x = self.reduction(x)</code>：最后通过创建的全连接层，将<code>[B, H/2*W/2, 4*C]-&gt;[B, H/2*W/2, 2*C]</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchMerging</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; Patch Merging Layer.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.reduction = nn.Linear(<span class="number">4</span> * dim, <span class="number">2</span> * dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.norm = norm_layer(<span class="number">4</span> * dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        x: B, H*W, C</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, L, C = x.shape</span><br><span class="line">        <span class="keyword">assert</span> L == H * W, <span class="string">&quot;input feature has wrong size&quot;</span></span><br><span class="line"></span><br><span class="line">        x = x.view(B, H, W, C)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># padding</span></span><br><span class="line">        <span class="comment"># 如果输入feature map的H，W不是2的整数倍，需要进行padding</span></span><br><span class="line">        pad_input = (H % <span class="number">2</span> == <span class="number">1</span>) <span class="keyword">or</span> (W % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> pad_input:</span><br><span class="line">            <span class="comment"># to pad the last 3 dimensions, starting from the last dimension and moving forward.</span></span><br><span class="line">            <span class="comment"># (C_front, C_back, W_left, W_right, H_top, H_bottom)</span></span><br><span class="line">            <span class="comment"># 注意这里的Tensor通道是[B, H, W, C]，所以会和官方文档有些不同</span></span><br><span class="line">            x = F.pad(x, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, W % <span class="number">2</span>, <span class="number">0</span>, H % <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        x0 = x[:, <span class="number">0</span>::<span class="number">2</span>, <span class="number">0</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">        x1 = x[:, <span class="number">1</span>::<span class="number">2</span>, <span class="number">0</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">        x2 = x[:, <span class="number">0</span>::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">        x3 = x[:, <span class="number">1</span>::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">        x = torch.cat([x0, x1, x2, x3], -<span class="number">1</span>)  <span class="comment"># [B, H/2, W/2, 4*C]</span></span><br><span class="line">        x = x.view(B, -<span class="number">1</span>, <span class="number">4</span> * C)  <span class="comment"># [B, H/2*W/2, 4*C]</span></span><br><span class="line"></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        x = self.reduction(x)  <span class="comment"># [B, H/2*W/2, 2*C]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="BasicLayer类">BasicLayer类</h2>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Swin-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Swin Transformer-T网络架构图"></p>
<p>在这个类当中就是实现每一个Stage，在这个类当中，有传入一系列参数，前文有提到，这里不再赘述。</p>
<p>注意：<code>shift_size</code>：比如说我们在使用SW-MSA模块时，要将窗口向右以及向下偏移多少个像素，所以这里是<code>self.shift_size = window_size // 2</code>（上篇文章有讲）。</p>
<p>创建一个nn.ModuleList的blocks，这里的blocks存储的是在当前Stage中所构建的所有的Swin Transformer Block。那么对于Swin Transformer Block有传入<code>dim、num_heads、window_size、shift_size......</code>。</p>
<p>（注意：<strong>对于Swin Transformer Block而言，需要依次使用上图（b）的两个block，W-MSA和SW-MSA，这二者间是成对使用的</strong>），因此<code>shift_size=0 if (i % 2 == 0) else self.shift_size</code>存在判断，通过循环遍历depth次<code>for i in range(depth)</code>。比如说对于Stage1而言，这里是2次的话，这里的range循环就是两次，就用i对2取余数。<strong>比如说当i == 0时，对2取余为0，就意味着当前这个block所采用的是W-MSA；当i == 1的时候，就会将self.shift_size定为它本身，之后会通过判断self.shift_size是否等于0来判断去判断使用的是W-MSA还是SW-MSA</strong>。</p>
<p><code>downsample</code>：对应的是patch merging类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicLayer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A basic Swin Transformer layer for one stage.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        depth (int): Number of blocks.</span></span><br><span class="line"><span class="string">        num_heads (int): Number of attention heads.</span></span><br><span class="line"><span class="string">        window_size (int): Local window size.</span></span><br><span class="line"><span class="string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.</span></span><br><span class="line"><span class="string">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True</span></span><br><span class="line"><span class="string">        drop (float, optional): Dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        attn_drop (float, optional): Attention dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0</span></span><br><span class="line"><span class="string">        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm</span></span><br><span class="line"><span class="string">        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None</span></span><br><span class="line"><span class="string">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, depth, num_heads, window_size,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 drop_path=<span class="number">0.</span>, norm_layer=nn.LayerNorm, downsample=<span class="literal">None</span>, use_checkpoint=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.depth = depth</span><br><span class="line">        self.window_size = window_size</span><br><span class="line">        self.use_checkpoint = use_checkpoint</span><br><span class="line">        self.shift_size = window_size // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># build blocks</span></span><br><span class="line">        self.blocks = nn.ModuleList([</span><br><span class="line">            SwinTransformerBlock(</span><br><span class="line">                dim=dim,</span><br><span class="line">                num_heads=num_heads,</span><br><span class="line">                window_size=window_size,</span><br><span class="line">                shift_size=<span class="number">0</span> <span class="keyword">if</span> (i % <span class="number">2</span> == <span class="number">0</span>) <span class="keyword">else</span> self.shift_size,</span><br><span class="line">                mlp_ratio=mlp_ratio,</span><br><span class="line">                qkv_bias=qkv_bias,</span><br><span class="line">                drop=drop,</span><br><span class="line">                attn_drop=attn_drop,</span><br><span class="line">                drop_path=drop_path[i] <span class="keyword">if</span> <span class="built_in">isinstance</span>(drop_path, <span class="built_in">list</span>) <span class="keyword">else</span> drop_path,</span><br><span class="line">                norm_layer=norm_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># patch merging layer</span></span><br><span class="line">        <span class="keyword">if</span> downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.downsample = downsample(dim=dim, norm_layer=norm_layer)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.downsample = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_mask</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line">     </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h3 id="create-mask">create_mask</h3>
<p>为了防止传入的H和W不是window_size的整数倍，所以会首先将H和W分别除以self.window_size然后向上取整，之后再乘以self.window_size，得到新的H padding之后的值以及W padding之后的值（对于mask而言）。</p>
<p>之后创建一个<code>img_mask</code>，通过zero方法来初始化，shape为<code>1，Hp，Wp，1</code>，设备与传入的x的设备一致（设置为这样的shape是因为：在后面window partition方法中所要求传入的Tensor的shape是这样的）</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%8E%9F%E6%95%B0%E6%8D%AE.png" alt="举例SW-MSA-原数据"></p>
<p>接下来是<code>h_slices</code>和<code>w_slices</code>，二者是一样的，以h_slices为例子。首先通过slice（切片）方法，以上图为例，假设输入的是9x9的feature map，窗口是3x3的，假设需要使用一个shifted window的话，首先用m/2向下取整，再通过指定的window去重新划分window（下图所示）。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%81%8F%E7%A7%BB%E5%88%86%E5%89%B2%E4%B9%8B%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE.png" alt="举例SW-MSA-偏移分割之后的数据"></p>
<p>由代码来看，一共由3个切片，<strong>slice（a，b），a取b不取</strong>。</p>
<blockquote>
<p>以h_slices举例：</p>
<p>第一个切片是从0到-window_size。对于下图的例子而言window_size = 3，也就是从0到-3，从下图来看，0是第一行第一列，-1是第一列最后一行，-2是第一列倒数第二行，-3是第一列倒数第三行，因此需要取黄色区域就是0到-3；</p>
<p>第二个切片是从-window_size到-self.shift_size，shift_size也就是m/2向下取整，对于下图例子而言，也就是-3到-1，也就是-3是第一列倒数第三行，-1是第一列最后一行，即紫色区域；</p>
<p>第三个切片是从-shift_size到None（末尾），对于下图例子而言，也就是-1到最后，即绿色区域；</p>
<p>w_slices同理，对应的区域就是下图中横着的大括号区域。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">h_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">w_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">            <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%88%87%E7%89%87.png" alt="举例SW-MSA-切片"></p>
<p>之后进入一个循环，首先将cnt设置为0，然后遍历h_slices，当h为第一个切片的时候（0到-window_size，对应上图竖着的最大的大括号），再遍历w_slices（0到-window_size，对应上图横着的最大的大括号），那么在对应img_mask给定的h和w切片设置为cnt的数值，最开始cnt=0，当进行完一个区域的循环之后，会进行cnt+1。</p>
<p>因此，经过上一段对切片循环的操作，可以给同一块区域的格子赋值为同一个数字，又可以保证不同区域的数值不一样，也就是上图（右）所示（<strong>相同的数字对应的是连续的区域</strong>）。</p>
<p><code>mask_windows = window_partition(img_mask, self.window_size)</code>：接下来通过window_partition方法对img_mask划分为一个一个窗口，这里除了传入img_mask之外，还传入了window_size，也就是窗口的尺寸。</p>
<p>通过<code>window_partition</code>函数之后就将根据mask按照所指定的window_size划分成一个个窗口了，也就是下图中，将其划分为一个个窗口的形式。例子中是大小3x3的窗口尺寸，因此这里有9个window。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%88%92%E5%88%86%E7%AA%97%E5%8F%A3%E5%BD%A2%E5%BC%8F.png" alt="举例SW-MSA-划分窗口形式"></p>
<p>因为刚刚通过window_partition处理输出的通道排列顺序是<code>[nW, Mh, Mw, 1]</code>，因为window_partition所返回的第一个维度是<code>batch*num_windows</code>，又因为这里的batch = 1，所以这里第一个维度就是对应的<code>num_windows</code>，之后对应的是窗口的高度，窗口的宽度，和最后的维度1。</p>
<p>所以接下来进行view处理，将后三个维度展平成一个维度，即<code>[nW, Mh, Mw, 1]-&gt;[nW, Mh*Mw]</code>，第一个维度自己去推理，第二个维度就是window_size*window_size，即Mh*Mw。</p>
<p>接下来再将<code>mask_windows</code>用<code>unsqueeze</code>方法在维度1上新加一个维度，也就是在nW和Mh*Mw之间新增一个维度。然后减去<code>mask_windows.unsqueeze(2)</code>，也就是在Mh*Mw后面这个地方新增一个维度。然后让这两个数据进行相减，得到attn_mask。</p>
<blockquote>
<p>以下图来作解释。在刚刚以及划分了9个窗口，再通过<code>mask_windows = mask_windows.view(-1, self.window_size * self.window_size)</code>之后是将高度宽度全部展平，因此以及将每一个window全部展平了（下图右），按行展平得到1-9个行向量。</p>
<p>对于第一个特征矩阵<code>mask_windows.unsqueeze(1)</code>，shape对应的是<code>[nW, 1, Mh*Mw]</code>，对于第二个特征矩阵<code>mask_windows.unsqueeze(2)</code>，shape对应的是<code>[nW, Mh*Mw, 1]</code>，<strong>这二者相减就会设计一个广播机制了</strong>。</p>
<p>对于第一个矩阵而言，<strong>会将<code>[nW, 1, Mh*Mw]</code>最后这个维度给复制<code>Mh*Mw</code>次，相当于将下图每一个行向量给复制<code>Mh*Mw</code>次（即一个窗口内像素的个数，例子中为9）</strong>，对于第二个矩阵，会在<code>[nW, Mh*Mw, 1]</code>最后这个维度给复制<code>Mh*Mw</code>次。</p>
</blockquote>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E5%B1%95%E5%B9%B3.png" alt="举例SW-MSA-展平"></p>
<p>以上图最后一个行向量为例（最复杂），下图为已经将最后一行行向量复制9次了，下图右为对应第二个特征矩阵<code>mask_windows.unsqueeze(2)</code>，将下图（左）红色框内复制9次（<strong>其实就是将1行9列的tensor按行复制9次，将9行1列的tensor按列复制9次，再相减</strong>）</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E8%A1%8C%E5%90%91%E9%87%8F%E5%A4%8D%E5%88%B69%E6%AC%A1.png" alt="举例SW-MSA-最后一个行向量复制9次"></p>
<p>之后将上图左边的矩阵减去上图右边的矩阵，第一行而言，其实就是对第一个元素进行Attention的求解，相同数字对应的同一块区域，所以做Attention其实就是想和所有数字为4的去做一个Attention。因此在第一行，会让所有数字-4。相减之后将所有数字相减成功后会得到下图的结果。</p>
<p>也就是说，同一个区域的就是用0来表示，不同的区域就是一些非零的数字。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E4%B8%BE%E4%BE%8BSW-MSA-%E4%B8%A4%E4%B8%AA%E7%9F%A9%E9%98%B5%E7%9B%B8%E5%87%8F%E4%B9%8B%E5%90%8E.png" alt="举例SW-MSA-两个矩阵相减之后"></p>
<p>之后会用<code>masked_fill</code>来进一步处理，对于不等于0的区域，会填入-100，对于等于0的区域，直接写入0。比如对于上图第一行，标0的就是和当前mask同区域的元素，非0都会设置为-100。上图（右）每一行对应的就是当前这个窗口当中对应某一个像素的计算Attention时所采用的mask蒙版</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_mask</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        <span class="comment"># calculate attention mask for SW-MSA</span></span><br><span class="line">        <span class="comment"># 保证Hp和Wp是window_size的整数倍</span></span><br><span class="line">        Hp = <span class="built_in">int</span>(np.ceil(H / self.window_size)) * self.window_size</span><br><span class="line">        Wp = <span class="built_in">int</span>(np.ceil(W / self.window_size)) * self.window_size</span><br><span class="line">        <span class="comment"># 拥有和feature map一样的通道排列顺序，方便后续window_partition</span></span><br><span class="line">        img_mask = torch.zeros((<span class="number">1</span>, Hp, Wp, <span class="number">1</span>), device=x.device)  <span class="comment"># [1, Hp, Wp, 1]</span></span><br><span class="line">        h_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">                    <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">                    <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">        w_slices = (<span class="built_in">slice</span>(<span class="number">0</span>, -self.window_size),</span><br><span class="line">                    <span class="built_in">slice</span>(-self.window_size, -self.shift_size),</span><br><span class="line">                    <span class="built_in">slice</span>(-self.shift_size, <span class="literal">None</span>))</span><br><span class="line">        cnt = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> h_slices:</span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> w_slices:</span><br><span class="line">                img_mask[:, h, w, :] = cnt</span><br><span class="line">                cnt += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        mask_windows = window_partition(img_mask, self.window_size)  <span class="comment"># [nW, Mh, Mw, 1]</span></span><br><span class="line">        mask_windows = mask_windows.view(-<span class="number">1</span>, self.window_size * self.window_size)  <span class="comment"># [nW, Mh*Mw]</span></span><br><span class="line">        attn_mask = mask_windows.unsqueeze(<span class="number">1</span>) - mask_windows.unsqueeze(<span class="number">2</span>)  <span class="comment"># [nW, 1, Mh*Mw] - [nW, Mh*Mw, 1]</span></span><br><span class="line">        <span class="comment"># [nW, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        attn_mask = attn_mask.masked_fill(attn_mask != <span class="number">0</span>, <span class="built_in">float</span>(-<span class="number">100.0</span>)).masked_fill(attn_mask == <span class="number">0</span>, <span class="built_in">float</span>(<span class="number">0.0</span>))</span><br><span class="line">        <span class="keyword">return</span> attn_mask</span><br></pre></td></tr></table></figure>
<p><strong>正向传播函数</strong></p>
<p>传入x和其对应的高和宽。</p>
<p><code>attn_mask = self.create_mask(x, H, W) </code>：这里首先会根据传入的x，H，W去创建create_mask，<code>create_mask</code>就是在使用SW-MSA时所采用的mask蒙版。</p>
<blockquote>
<p>因为对于一个Stage而言，假设看Stage3，会重复堆叠Swin Transformer Block6次，又<strong>因为W-MSA和SW-MSA是成对使用的，也就是说在Stage3当中会使用3次W-MSA和3次SW-MSA</strong>。又由于Swin Transformer Block不会改变特征矩阵的高宽，所以当前Stage中所使用的W-MSA和SW-MSA的mask都是一样的，所以对于当前的Stage只需要创建一次即可。</p>
</blockquote>
<p>此处<code>attn_mask = self.create_mask(x, H, W)</code>放的位置和作者源码放的不一样，因为如果输入不同尺寸的图像的话，是可以根据传入的x，H，W取重新生成mask蒙版的。但是对于源码而言，有一个input resolution，会根据这个参数一开始就将mask固定了，如果后面像传入一个其他尺寸的图片的话就会报错。因此为了解决多尺寸图片问题，就将该条代码的位置调整到这来了。</p>
<p>通过遍历初始化函数创建的blocks列表，对应的是Swin Transformer Block。</p>
<p><code>blk.H, blk.W = H, W</code>：那么通过遍历它，首先将当前这个block添加一个高度和宽度的属性，也就是这里的H，W。</p>
<p>之后进行判断，如果当前不是scripting模式并且使用这个checkpoint方法的话，就会使用pytorch官方使用的checkpoint方法（默认不使用）。直接到<code>x = blk(x, attn_mask)</code>，将传入的x以及刚刚创建的mask给传入进去，即能得到当前block的输出了。</p>
<p>通过遍历，能够将输入传递给每一个Swin Transformer Block得到对应的输出。</p>
<p>接着再判断downsample是否为None，如果不为None的话，就进行下采样操作，也就是Patch merging层（Stage4为None）</p>
<p>通过下采样之后特征矩阵的高度和宽度就是下采样的2倍，所以需要重新计算H和W，<code>H, W = (H + 1) // 2, (W + 1) // 2</code>（<strong>这里是为了防止H或者W如果是奇数的话，是要进行padding的。所以如果是奇数的话，进行+1操作再除以2就刚好等于新的H，W</strong>，如果是偶数的话，+1之后再除以2向下取整还是原来的一半）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, H, W</span>):</span><br><span class="line">        attn_mask = self.create_mask(x, H, W)  <span class="comment"># [nW, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> self.blocks:</span><br><span class="line">            blk.H, blk.W = H, W</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> torch.jit.is_scripting() <span class="keyword">and</span> self.use_checkpoint:</span><br><span class="line">                x = checkpoint.checkpoint(blk, x, attn_mask)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x = blk(x, attn_mask)</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.downsample(x, H, W)</span><br><span class="line">            H, W = (H + <span class="number">1</span>) // <span class="number">2</span>, (W + <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, H, W</span><br></pre></td></tr></table></figure>
<h4 id="window-partition">window_partition</h4>
<p>将feature map或者说时刚刚的img_mask按照window_size划分为一个个没有重叠的window。</p>
<p>首先获取传入进来x的shape，对应的维度是<code>(B, H, W, C)</code></p>
<p>通过view方法将<code>(B, H, W, C)</code>变为<code>[B, H//Mh, Mh, W//Mw, Mw, C] </code>，也就是<code>batch，高度除上窗口高度，窗口高度，宽度除以窗口宽度，窗口宽度，channel</code>。</p>
<p>接下来再通过permute方法调换2和3这两个维度的数据，因此<code> [B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H//Mh, W//Mh, Mw, Mw, C]</code>。因为通过permute之后数据不再连续，所以需要调用contiguous将数据再变为内存连续的数据。之后再通过view方法<code>(-1, window_size, window_size, C)</code>，第一个维度让其自动推理，因此<code>[B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B*num_windows, Mh, Mw, C]</code></p>
<blockquote>
<p>发现<code>H//Mh</code>乘上<code>W//Mw</code>正好等于window的个数，因此通过view之后，就将前三个维度划分在一起了，即变成了<code>B*num_windows</code>，之后的<code>M，M，C</code>分别对应的是<code>窗口的高度、窗口的高度、channel</code>，精确的写法为Mh和Mw</p>
</blockquote>
<p>根据如上处理后，得到的就是指定的window_size划分为一个个窗口之后的数据，并且num_windows和batch是放在一起的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">window_partition</span>(<span class="params">x, window_size: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    将feature map按照window_size划分成一个个没有重叠的window</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: (B, H, W, C)</span></span><br><span class="line"><span class="string">        window_size (int): window size(M)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        windows: (num_windows*B, window_size, window_size, C)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    B, H, W, C = x.shape</span><br><span class="line">    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)</span><br><span class="line">    <span class="comment"># permute: [B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H//Mh, W//Mh, Mw, Mw, C]</span></span><br><span class="line">    <span class="comment"># view: [B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B*num_windows, Mh, Mw, C]</span></span><br><span class="line">    windows = x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>).contiguous().view(-<span class="number">1</span>, window_size, window_size, C)</span><br><span class="line">    <span class="keyword">return</span> windows</span><br></pre></td></tr></table></figure>
<h4 id="window-reverse">window_reverse</h4>
<p>这里将一个个窗口再还原为一个feature map。</p>
<p>传入的参数有windows，window_size，H，W。H和W对应的是分割之前feature map的H和W。</p>
<p>首先计算batch维度，在window_partition输出中，第一个维度将batch和num_windows放在一起了，也就是<code>windows: (num_windows*B, window_size, window_size, C)</code>，所以如果要求B的话，需要使用<code>windows.shape[0]</code>（<code>num_windows*B</code>）除以windows的个数（<code>num_windows</code>），那么$num_windows = H/window_size*W/window_size)$。</p>
<p>再通过view方法调整通道排列顺序：<code>view: [B*num_windows, Mh, Mw, C] -&gt; [B, H//Mh, W//Mw, Mh, Mw, C]</code></p>
<p>再通过permute方法将2和3两个维度进行调换，即<code>[B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B, H//Mh, Mh, W//Mw, Mw, C]</code>，同样需要通过contiguous方法将它变为内存连续的形式，在进行view，即<code>[B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H, W, C]</code>。即与window_partition输入的shape是一样的，因此这两个函数是一个正向操作和一个反向操作的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">window_reverse</span>(<span class="params">windows, window_size: <span class="built_in">int</span>, H: <span class="built_in">int</span>, W: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    将一个个window还原成一个feature map</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        windows: (num_windows*B, window_size, window_size, C)</span></span><br><span class="line"><span class="string">        window_size (int): Window size(M)</span></span><br><span class="line"><span class="string">        H (int): Height of image</span></span><br><span class="line"><span class="string">        W (int): Width of image</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        x: (B, H, W, C)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    B = <span class="built_in">int</span>(windows.shape[<span class="number">0</span>] / (H * W / window_size / window_size))</span><br><span class="line">    <span class="comment"># view: [B*num_windows, Mh, Mw, C] -&gt; [B, H//Mh, W//Mw, Mh, Mw, C]</span></span><br><span class="line">    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># permute: [B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B, H//Mh, Mh, W//Mw, Mw, C]</span></span><br><span class="line">    <span class="comment"># view: [B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H, W, C]</span></span><br><span class="line">    x = x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>).contiguous().view(B, H, W, -<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="SwinTransformerBlock">SwinTransformerBlock</h3>
<p>构建每一个swin transformer block方法。</p>
<p><strong>初始化函数</strong></p>
<p><code>WindowAttention</code>也就是对应的W-MSA或者SW-MSA。<strong>对于block而言，和下图的 Encoder Block是一样的，唯一不同在于将Muti-Head Attention换成了W-MSA或者SW-MSA</strong>。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Transformer-Encoder%E5%B1%82.png" alt="Transformer-Encoder层"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SwinTransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; Swin Transformer Block.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        num_heads (int): Number of attention heads.</span></span><br><span class="line"><span class="string">        window_size (int): Window size.</span></span><br><span class="line"><span class="string">        shift_size (int): Shift size for SW-MSA.</span></span><br><span class="line"><span class="string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.</span></span><br><span class="line"><span class="string">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True</span></span><br><span class="line"><span class="string">        drop (float, optional): Dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        attn_drop (float, optional): Attention dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        drop_path (float, optional): Stochastic depth rate. Default: 0.0</span></span><br><span class="line"><span class="string">        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU</span></span><br><span class="line"><span class="string">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, num_heads, window_size=<span class="number">7</span>, shift_size=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, drop=<span class="number">0.</span>, attn_drop=<span class="number">0.</span>, drop_path=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                 act_layer=nn.GELU, norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.window_size = window_size</span><br><span class="line">        self.shift_size = shift_size</span><br><span class="line">        self.mlp_ratio = mlp_ratio</span><br><span class="line">        <span class="keyword">assert</span> <span class="number">0</span> &lt;= self.shift_size &lt; self.window_size, <span class="string">&quot;shift_size must in 0-window_size&quot;</span></span><br><span class="line"></span><br><span class="line">        self.norm1 = norm_layer(dim)</span><br><span class="line">        self.attn = WindowAttention(</span><br><span class="line">            dim, window_size=(self.window_size, self.window_size), num_heads=num_heads, qkv_bias=qkv_bias,</span><br><span class="line">            attn_drop=attn_drop, proj_drop=drop)</span><br><span class="line"></span><br><span class="line">        self.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        self.norm2 = norm_layer(dim)</span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)</span><br><span class="line">        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)</span><br></pre></td></tr></table></figure>
<p><strong>正向传播函数</strong></p>
<p>正向传播过程中有传入x和attn_mask，首先取到当前输入的feature map的高宽，因为传入的x的shape是B、L、C，L对应的是H*W，因此有记录下H和W的值，也就是BasicLayer正向传播过程中的<code>blk.H, blk.W = H, W</code>。</p>
<p>接下来将x赋值给shortcut，之后进行<code>self.norm1(x)</code>，对应上图中的第一个LayerNorm。</p>
<p>再对x进行view处理，即<code>[B, L, C]-&gt;[B, H, W, C]</code></p>
<p>之后对传入的Hp和和Wp进行判断，对高度方向的下侧和宽度方向的右侧去判定是否要及逆行padding操作，因此先将<code>pad_l = pad_t = 0</code>，之后进行计算padding的数量。</p>
<p><code>_, Hp, Wp, _ = x.shape</code>获取在经过padding之后新的Hp和Wp。</p>
<p>对<code>shift_size</code>进行判断，如果大于0，则进行SW-MSA，如果等于0，则进行W-MSA。</p>
<blockquote>
<p>SW-MSA也就是需要将划分窗口之后的矩阵进行滑动窗口之后移动。</p>
</blockquote>
<p><code>shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))</code>需要将最上侧移到最下侧，最左侧移到最右侧。因此此处传入x，将dimension设置为1和2（也就是H，W），从上往下移即<code>-self.shift_size</code>，从左往右移即<code>-self.shift_size</code>（如果是正的，就是从下往上和从右往左）。</p>
<p>移动之后通过<code>window_partition</code>发给发将shifted划分为一个个窗口，划分之后得到的通道排列顺序为<code>[nW*B, Mh, Mw, C]</code>，再通过view方法，变为<code>[nW*B, Mh*Mw, C]</code>。</p>
<p>之后将W-MSA或者SW-MSA输入到sttn方法当中（Attention）进行正向传播，则得到输出Attention Window。</p>
<p>进行view处理，变回<code>[nW*B, Mh, Mw, C]</code>，再通过<code>window_reverse</code>方法将一个个window拼回一个feature map。得到的通道为<code>[B, H', W', C]</code></p>
<p><code>if self.shift_size &gt; 0</code>如果当前block使用了SW-MSA的话，需要将计算号的数据给还原回去，所以同样通过<code>roll</code>方法，再高度和宽度分别以shift_size行和shift_size列（因为是还原，将下侧移到上侧，将右侧移到左侧，所以为正数）。</p>
<p><code>if pad_r &gt; 0 or pad_b &gt; 0</code>：如果有进行padding的话，也需要将pad的数给移除掉。所以只取这个feature map的前H行和前W列，再通过contiguous方法让它百年城内存中连续的一个数据来。</p>
<p>再通过view方法将通道变为<code>[B, H * W, C]</code>（B，L，C）。</p>
<p>接下来将x通过<code>drop_path</code>和shortcut进行相加得到x，也就是对应上图block第一个shortcut相加。</p>
<p>再将x通过norm2和drop_path再将x进行相加得到最终的输出（这一步相当于上图block的上半部分全部做完了）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, attn_mask</span>):</span><br><span class="line">    H, W = self.H, self.W</span><br><span class="line">    B, L, C = x.shape</span><br><span class="line">    <span class="keyword">assert</span> L == H * W, <span class="string">&quot;input feature has wrong size&quot;</span></span><br><span class="line"></span><br><span class="line">    shortcut = x</span><br><span class="line">    x = self.norm1(x)</span><br><span class="line">    x = x.view(B, H, W, C)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pad feature maps to multiples of window size</span></span><br><span class="line">    <span class="comment"># 把feature map给pad到window size的整数倍</span></span><br><span class="line">    pad_l = pad_t = <span class="number">0</span></span><br><span class="line">    pad_r = (self.window_size - W % self.window_size) % self.window_size</span><br><span class="line">    pad_b = (self.window_size - H % self.window_size) % self.window_size</span><br><span class="line">    x = F.pad(x, (<span class="number">0</span>, <span class="number">0</span>, pad_l, pad_r, pad_t, pad_b))</span><br><span class="line">    _, Hp, Wp, _ = x.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># cyclic shift</span></span><br><span class="line">    <span class="keyword">if</span> self.shift_size &gt; <span class="number">0</span>:</span><br><span class="line">        shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shifted_x = x</span><br><span class="line">            attn_mask = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># partition windows</span></span><br><span class="line">            x_windows = window_partition(shifted_x, self.window_size)  <span class="comment"># [nW*B, Mh, Mw, C]</span></span><br><span class="line">            x_windows = x_windows.view(-<span class="number">1</span>, self.window_size * self.window_size, C)  <span class="comment"># [nW*B, Mh*Mw, C]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># W-MSA/SW-MSA</span></span><br><span class="line">            attn_windows = self.attn(x_windows, mask=attn_mask)  <span class="comment"># [nW*B, Mh*Mw, C]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># merge windows</span></span><br><span class="line">            attn_windows = attn_windows.view(-<span class="number">1</span>, self.window_size, self.window_size, C)  <span class="comment"># [nW*B, Mh, Mw, C]</span></span><br><span class="line">            shifted_x = window_reverse(attn_windows, self.window_size, Hp, Wp)  <span class="comment"># [B, H&#x27;, W&#x27;, C]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># reverse cyclic shift</span></span><br><span class="line">            <span class="keyword">if</span> self.shift_size &gt; <span class="number">0</span>:</span><br><span class="line">                x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    x = shifted_x</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> pad_r &gt; <span class="number">0</span> <span class="keyword">or</span> pad_b &gt; <span class="number">0</span>:</span><br><span class="line">                        <span class="comment"># 把前面pad的数据移除掉</span></span><br><span class="line">                        x = x[:, :H, :W, :].contiguous()</span><br><span class="line"></span><br><span class="line">                        x = x.view(B, H * W, C)</span><br><span class="line"></span><br><span class="line">                        <span class="comment"># FFN</span></span><br><span class="line">                        x = shortcut + self.drop_path(x)</span><br><span class="line">                        x = x + self.drop_path(self.mlp(self.norm2(x)))</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="Mlp">Mlp</h4>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/Transformer-Encoder%E5%B1%82.png" alt="Transformer-Encoder层"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Mlp</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; MLP as used in Vision Transformer, MLP-Mixer and related networks</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features</span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(in_features, hidden_features)</span><br><span class="line">        self.act = act_layer()</span><br><span class="line">        self.drop1 = nn.Dropout(drop)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_features, out_features)</span><br><span class="line">        self.drop2 = nn.Dropout(drop)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.drop1(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.drop2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="WindowAttention">WindowAttention</h4>
<h5 id="初始化函数-2">初始化函数</h5>
<p>实现了W-MSA和SW-MSA的部分功能</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E5%B8%A6%E8%92%99%E6%9D%BFmask%E7%9A%84MSA.png" alt="SW-MSA"></p>
<p><code>self.scale = head_dim ** -0.5</code>对应$1/\sqrt d$</p>
<p>创建<code>relative_position_bias_table</code>，直接通过nn.Parameter来创建这个参数，其长度为（2M-1）X（2M-1），所以使用一个零矩阵来初始化relative_position_bias_table，因为长度很多，所以采用<code>num_heads</code>多头机制。也就是说针对每一个所采用的relative_position_bias_table都是不一样的</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB%E5%8F%82%E6%95%B0.png" alt="相对位置偏移参数"></p>
<p>下面几行代码就是生成<code>relative_position_index</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get pair-wise relative position index for each token inside the window</span></span><br><span class="line">coords_h = torch.arange(self.window_size[<span class="number">0</span>])</span><br><span class="line">coords_w = torch.arange(self.window_size[<span class="number">1</span>])</span><br><span class="line">coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=<span class="string">&quot;ij&quot;</span>))  <span class="comment"># [2, Mh, Mw]</span></span><br><span class="line">coords_flatten = torch.flatten(coords, <span class="number">1</span>)  <span class="comment"># [2, Mh*Mw]</span></span><br><span class="line"><span class="comment"># [2, Mh*Mw, 1] - [2, 1, Mh*Mw]</span></span><br><span class="line">relative_coords = coords_flatten[:, :, <span class="literal">None</span>] - coords_flatten[:, <span class="literal">None</span>, :]  <span class="comment"># [2, Mh*Mw, Mh*Mw]</span></span><br><span class="line">relative_coords = relative_coords.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).contiguous()  <span class="comment"># [Mh*Mw, Mh*Mw, 2]</span></span><br><span class="line">relative_coords[:, :, <span class="number">0</span>] += self.window_size[<span class="number">0</span>] - <span class="number">1</span>  <span class="comment"># shift to start from 0</span></span><br><span class="line">relative_coords[:, :, <span class="number">1</span>] += self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">relative_coords[:, :, <span class="number">0</span>] *= <span class="number">2</span> * self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">relative_position_index = relative_coords.<span class="built_in">sum</span>(-<span class="number">1</span>)  <span class="comment"># [Mh*Mw, Mh*Mw]</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>举个栗子，首先通过<code>torch.arange</code>方法传入<code>window_size</code>生成<code>coords_h</code>和<code>coords_w</code>。假设window_size = 2，则coords_h=[0，1]，coords_w=[0，1]。再通过<code>torch.meshgrid</code>方法（生成网格的方法），第一个元素对应高度的范围，第二个元素对应宽度的范围，<code>indexing=&quot;ij&quot;</code>也就是创建的这个网格所对应的坐标是以行和列的形式来表示的。<code>meshgrid</code>方法返回的是两个tensor，所以通过<code>stack</code>方法进行拼接之后就变成了<code>[2, Mh, Mw]</code>。</p>
<p>再对第一个维度开始展平，得到<code>[2, Mh*Mw]</code>。<strong>得到的形式为下图（最左），第一行像素对应的是feature map上每一个像素对应的行标，第二行圆度对应的是feature map上每一个像素对应的列标，对应的是绝对位置索引</strong>。</p>
<p><code>relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]</code>对第一个矩阵在最后一个新加一个维度，对第二个矩阵在中间新增一个维度，二者相减得到<code>[2, Mh*Mw, Mh*Mw]</code>，即下图（中和右）。</p>
<p>为了使二者之间能够进行相减，因此需要用到广播机制，也就是前者的1维度要复制4次（）每一个行标复制4次），后者的1维度也要复制4次（每一个列标复制4次），箭头下方对应的就是分别复制4次之后的结果。</p>
</blockquote>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%B4%A2%E5%BC%95%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png" alt="绝对位置索引计算过程"></p>
<p>相减的过程怎么理解：想要构建相对位置索引的矩阵，假设以第一个像素为例的话，需要用它所对应的绝对索引去减去feature map每一个像素的绝对位置索引。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%BB%9D%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%87%8F%E8%BF%87%E7%A8%8B.png" alt="绝对位置索引相减过程"></p>
<p>那么得到上面相减之后的矩阵之后，<code>relative_coords = relative_coords.permute(1, 2, 0).contiguous()</code>中进行permute处理，将0维度挪到最后，即<code>[2, Mh*Mw, Mh*Mw]-&gt;[Mh*Mw, Mh*Mw, 2]</code>。又通过contiguous变为内存连续的形式。</p>
<p>接下来就是将二元索引变为医院索引的过程。将行标加上window_size[0] - 1，列标加上window_size[1] - 1，行标乘上2倍的window_size[1]之后 - 1，之后在最后一个维度上求和，对应的是<code>[Mh*Mw, Mh*Mw, 2]</code>中2这个维度，也就是行标与列标相加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">relative_coords[:, :, <span class="number">0</span>] += self.window_size[<span class="number">0</span>] - <span class="number">1</span>  <span class="comment"># shift to start from 0</span></span><br><span class="line">relative_coords[:, :, <span class="number">1</span>] += self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">relative_coords[:, :, <span class="number">0</span>] *= <span class="number">2</span> * self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">relative_position_index = relative_coords.<span class="built_in">sum</span>(-<span class="number">1</span>)  <span class="comment"># [Mh*Mw, Mh*Mw]</span></span><br></pre></td></tr></table></figure>
<p>上面代码对应的就是将下图（左）矩阵首先通过permute来变成下图（中）的形式。以列表中index = 0的列表为例，指的就是下图（右）蓝色像素为参考点时所求得的相对位置索引，index = 1的列表对应的是以橙色像素为参考点时所求得的相对位置索引，依次为红色、绿色。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB.png" alt="相对位置索引"></p>
<p>在行标加上M-1</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87+M-1.png" alt="相对位置索引-行标+M-1"></p>
<p>列标加上M-1</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E5%88%97%E6%A0%87+M-1.png" alt="相对位置索引-列标+M-1"></p>
<p>对行标乘以（2M-1）</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87%E4%B9%98%E4%BB%A52M-1.png" alt="相对位置索引-行标乘以（2M-1）"></p>
<p>再将行标和列标相加，即得到下图（右）的结果，同上篇文举的例子最终结果一样。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E8%A1%8C%E6%A0%87%E5%92%8C%E5%88%97%E6%A0%87%E7%9B%B8%E5%8A%A0.png" alt="相对位置索引-行标和列标相加"></p>
<p><code>relative_position_index = relative_coords.sum(-1)</code>即为上图（右）得到的情况，构建好的相对位置索引。</p>
<p><code>self.register_buffer(&quot;relative_position_index&quot;, relative_position_index)</code>通过<code>register_buffer</code>将<code>relative_position_index</code>放进模型的缓存当中。因为relative_position_index的参数是一个固定的值，一旦创建就不需要去修改了，真正需要训练修改的是relative position table。</p>
<p><code>self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)</code>通过Linear创建qkv，和vision transformer是一样的。</p>
<p><code>self.proj = nn.Linear(dim, dim)</code>对应的是多头输出进行融合的过程</p>
<p><code>nn.init.trunc_normal_(self.relative_position_bias_table, std=.02)</code>：对relative_position_bias_table进行初始化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">WindowAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot; Window based multi-head self attention (W-MSA) module with relative position bias.</span></span><br><span class="line"><span class="string">    It supports both of shifted and non-shifted window.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (int): Number of input channels.</span></span><br><span class="line"><span class="string">        window_size (tuple[int]): The height and width of the window.</span></span><br><span class="line"><span class="string">        num_heads (int): Number of attention heads.</span></span><br><span class="line"><span class="string">        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True</span></span><br><span class="line"><span class="string">        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0</span></span><br><span class="line"><span class="string">        proj_drop (float, optional): Dropout ratio of output. Default: 0.0</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, window_size, num_heads, qkv_bias=<span class="literal">True</span>, attn_drop=<span class="number">0.</span>, proj_drop=<span class="number">0.</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.window_size = window_size  <span class="comment"># [Mh, Mw]</span></span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        head_dim = dim // num_heads</span><br><span class="line">        self.scale = head_dim ** -<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># define a parameter table of relative position bias</span></span><br><span class="line">        self.relative_position_bias_table = nn.Parameter(</span><br><span class="line">            torch.zeros((<span class="number">2</span> * window_size[<span class="number">0</span>] - <span class="number">1</span>) * (<span class="number">2</span> * window_size[<span class="number">1</span>] - <span class="number">1</span>), num_heads))  <span class="comment"># [2*Mh-1 * 2*Mw-1, nH]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># get pair-wise relative position index for each token inside the window</span></span><br><span class="line">        coords_h = torch.arange(self.window_size[<span class="number">0</span>])</span><br><span class="line">        coords_w = torch.arange(self.window_size[<span class="number">1</span>])</span><br><span class="line">        coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=<span class="string">&quot;ij&quot;</span>))  <span class="comment"># [2, Mh, Mw]</span></span><br><span class="line">        coords_flatten = torch.flatten(coords, <span class="number">1</span>)  <span class="comment"># [2, Mh*Mw]</span></span><br><span class="line">        <span class="comment"># [2, Mh*Mw, 1] - [2, 1, Mh*Mw]</span></span><br><span class="line">        relative_coords = coords_flatten[:, :, <span class="literal">None</span>] - coords_flatten[:, <span class="literal">None</span>, :]  <span class="comment"># [2, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        relative_coords = relative_coords.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).contiguous()  <span class="comment"># [Mh*Mw, Mh*Mw, 2]</span></span><br><span class="line">        relative_coords[:, :, <span class="number">0</span>] += self.window_size[<span class="number">0</span>] - <span class="number">1</span>  <span class="comment"># shift to start from 0</span></span><br><span class="line">        relative_coords[:, :, <span class="number">1</span>] += self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">        relative_coords[:, :, <span class="number">0</span>] *= <span class="number">2</span> * self.window_size[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">        relative_position_index = relative_coords.<span class="built_in">sum</span>(-<span class="number">1</span>)  <span class="comment"># [Mh*Mw, Mh*Mw]</span></span><br><span class="line">        self.register_buffer(<span class="string">&quot;relative_position_index&quot;</span>, relative_position_index)</span><br><span class="line"></span><br><span class="line">        self.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=qkv_bias)</span><br><span class="line">        self.attn_drop = nn.Dropout(attn_drop)</span><br><span class="line">        self.proj = nn.Linear(dim, dim)</span><br><span class="line">        self.proj_drop = nn.Dropout(proj_drop)</span><br><span class="line"></span><br><span class="line">        nn.init.trunc_normal_(self.relative_position_bias_table, std=<span class="number">.02</span>)</span><br><span class="line">        self.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h5 id="正向传播函数-2">正向传播函数</h5>
<p>有传入x和mask。</p>
<p>首先获取x的shape，<code>B_, N, C = x.shape</code>对应的通道为<code>[batch_size*num_windows, Mh*Mw, total_embed_dim]</code>。</p>
<p>将x通过qkv这个Linear就得到qkv的数据，再进行reshape处理</p>
<ul>
<li><code>qkv(): -&gt; [batch_size*num_windows, Mh*Mw, 3 * total_embed_dim]</code></li>
<li><code>reshape: -&gt; [batch_size*num_windows, Mh*Mw, 3, num_heads, embed_dim_per_head]</code></li>
<li><code>permute: -&gt; [3, batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</code></li>
</ul>
<p>通过unbind方法分别获得q，k，v的值。</p>
<p>与在vision transformer不一样的是，这里的q先乘上scale<code>q = q * self.scale</code>，之后再乘以k的转置<code>attn = (q @ k.transpose(-2, -1))</code>。</p>
<blockquote>
<p><code>transpose: -&gt; [batch_size*num_windows, num_heads, embed_dim_per_head, Mh*Mw]</code></p>
<p><code>@: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, Mh*Mw]</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.relative_position_bias_table[self.relative_position_index.view(-<span class="number">1</span>)].view(</span><br><span class="line">        self.window_size[<span class="number">0</span>] * self.window_size[<span class="number">1</span>], self.window_size[<span class="number">0</span>] * self.window_size[<span class="number">1</span>], -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>通过view函数将relative_position_index全部展平，展平之后就在relative_position_bias_table当中去取对应的参数，即<code>relative_position_bias_table.view: [Mh*Mw*Mh*Mw,nH] -&gt; [Mh*Mw,Mh*Mw,nH]</code></p>
<p>之后通过permute方法去调整一下数据的排列顺序<code>[Mh*Mw,Mh*Mw,nH]-&gt;[nH, Mh*Mw, Mh*Mw]</code></p>
<p><code>attn = attn + relative_position_bias.unsqueeze(0)</code>再通过Attention加上relative_position_bias，这一步对应的就是公式里加上B这个矩阵的过程。attn的通道排列顺序为<code>[batch_size*num_windows, num_heads, Mh*Mw, Mh*Mw]</code>，relative_position_bias的通道排列顺序为<code>[Mh*Mw,Mh*Mw,nH]</code>，二者间相差一个Batch，因此这里会通过<code>unsqueeze（0）</code>来给<code>relative_position_bias</code>加上一个batch维度。这样就能通过广播机制进行相加。</p>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E7%9B%B8%E5%AF%B9%E4%BD%8D%E7%BD%AE%E5%81%8F%E7%A7%BB-%E5%85%AC%E5%BC%8F.png" alt="相对位置偏移-公式"></p>
<p>接下来判断mask是否为None，如果为None的话，即直接通过softmax处理；如果不为None的话，首先拿到mask的window个数<code>nW = mask.shape[0]</code>。</p>
<p>接着对attn进行view处理<code>attn.view: [batch_size, num_windows, num_heads, Mh*Mw, Mh*Mw]</code>，由于和mask的通道排列顺序不相对，所以给mask先再1处加入新的维度，之后又在加了维度的基础上再0的位置加入新的维度，即<code>mask.unsqueeze: [1, nW, 1, Mh*Mw, Mh*Mw]</code>，此时可以通过广播机制进行相加。</p>
<blockquote>
<p>注意：构建mask时，在一个window内，对于相同区域的元素是用0来表示的，对于不同区域的是用-100表示的，所以当attn和mask相加之后，对于加上0（相同区域）的数值是没有任何影响的，但是对于不同区域的attn数值都加上-100之后就变成一个非常大的负数，接下来再通过softmax处理，对于不同区域的 权重就会全部变为0了。</p>
</blockquote>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E5%B8%A6%E8%92%99%E6%9D%BFmask%E7%9A%84MSA.png" alt="Attention+mask"></p>
<p>再通过Dropout层，再将attn乘上V（这里对应的是上图公式里通过softmax处理之后乘上V的操作），接着通过transpose和reshape，即<code>transpose: -&gt; [batch_size*num_windows, Mh*Mw, num_heads, embed_dim_per_head]</code>，<code>reshape: -&gt; [batch_size*num_windows, Mh*Mw, total_embed_dim]</code>。</p>
<p>最后通过proj也就是线性层对多个head的输出进行一个融合，融合之后再通过一个Dropout层，就得到最终Attention模块的输出了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: input features with shape of (num_windows*B, Mh*Mw, C)</span></span><br><span class="line"><span class="string">        mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># [batch_size*num_windows, Mh*Mw, total_embed_dim]</span></span><br><span class="line">    B_, N, C = x.shape</span><br><span class="line">    <span class="comment"># qkv(): -&gt; [batch_size*num_windows, Mh*Mw, 3 * total_embed_dim]</span></span><br><span class="line">    <span class="comment"># reshape: -&gt; [batch_size*num_windows, Mh*Mw, 3, num_heads, embed_dim_per_head]</span></span><br><span class="line">    <span class="comment"># permute: -&gt; [3, batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span></span><br><span class="line">    qkv = self.qkv(x).reshape(B_, N, <span class="number">3</span>, self.num_heads, C // self.num_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="comment"># [batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span></span><br><span class="line">    q, k, v = qkv.unbind(<span class="number">0</span>)  <span class="comment"># make torchscript happy (cannot use tensor as tuple)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># transpose: -&gt; [batch_size*num_windows, num_heads, embed_dim_per_head, Mh*Mw]</span></span><br><span class="line">    <span class="comment"># @: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, Mh*Mw]</span></span><br><span class="line">    q = q * self.scale</span><br><span class="line">    attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># relative_position_bias_table.view: [Mh*Mw*Mh*Mw,nH] -&gt; [Mh*Mw,Mh*Mw,nH]</span></span><br><span class="line">    relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-<span class="number">1</span>)].view(</span><br><span class="line">        self.window_size[<span class="number">0</span>] * self.window_size[<span class="number">1</span>], self.window_size[<span class="number">0</span>] * self.window_size[<span class="number">1</span>], -<span class="number">1</span>)</span><br><span class="line">    relative_position_bias = relative_position_bias.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).contiguous()  <span class="comment"># [nH, Mh*Mw, Mh*Mw]</span></span><br><span class="line">    attn = attn + relative_position_bias.unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># mask: [nW, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        nW = mask.shape[<span class="number">0</span>]  <span class="comment"># num_windows</span></span><br><span class="line">        <span class="comment"># attn.view: [batch_size, num_windows, num_heads, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        <span class="comment"># mask.unsqueeze: [1, nW, 1, Mh*Mw, Mh*Mw]</span></span><br><span class="line">        attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        attn = attn.view(-<span class="number">1</span>, self.num_heads, N, N)</span><br><span class="line">        attn = self.softmax(attn)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            attn = self.softmax(attn)</span><br><span class="line"></span><br><span class="line">            attn = self.attn_drop(attn)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># @: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span></span><br><span class="line">            <span class="comment"># transpose: -&gt; [batch_size*num_windows, Mh*Mw, num_heads, embed_dim_per_head]</span></span><br><span class="line">            <span class="comment"># reshape: -&gt; [batch_size*num_windows, Mh*Mw, total_embed_dim]</span></span><br><span class="line">            x = (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B_, N, C)</span><br><span class="line">            x = self.proj(x)</span><br><span class="line">            x = self.proj_drop(x)</span><br><span class="line">            <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h1>实例化模型</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">swin_tiny_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-1K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">96</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">3</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_small_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-1K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">96</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">3</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window7_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-1K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">128</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window12_384</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-1K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">12</span>,</span><br><span class="line">                            embed_dim=<span class="number">128</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window7_224_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-22K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">128</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_base_patch4_window12_384_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-22K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">12</span>,</span><br><span class="line">                            embed_dim=<span class="number">128</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_large_patch4_window7_224_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-22K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22k.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">7</span>,</span><br><span class="line">                            embed_dim=<span class="number">192</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>, <span class="number">48</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swin_large_patch4_window12_384_in22k</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">21841</span>, **kwargs</span>):</span><br><span class="line">    <span class="comment"># trained ImageNet-22K</span></span><br><span class="line">    <span class="comment"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth</span></span><br><span class="line">    model = SwinTransformer(in_chans=<span class="number">3</span>,</span><br><span class="line">                            patch_size=<span class="number">4</span>,</span><br><span class="line">                            window_size=<span class="number">12</span>,</span><br><span class="line">                            embed_dim=<span class="number">192</span>,</span><br><span class="line">                            depths=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">2</span>),</span><br><span class="line">                            num_heads=(<span class="number">6</span>, <span class="number">12</span>, <span class="number">24</span>, <span class="number">48</span>),</span><br><span class="line">                            num_classes=num_classes,</span><br><span class="line">                            **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h1><a target="_blank" rel="noopener" href="http://train.py">train.py</a></h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> swin_tiny_patch4_window7_224 <span class="keyword">as</span> create_model</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(img_size),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.143</span>)),</span><br><span class="line">                                   transforms.CenterCrop(img_size),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    model = create_model(num_classes=args.num_classes).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">assert</span> os.path.exists(args.weights), <span class="string">&quot;weights file: &#x27;&#123;&#125;&#x27; not exist.&quot;</span>.<span class="built_in">format</span>(args.weights)</span><br><span class="line">        weights_dict = torch.load(args.weights, map_location=device)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        <span class="comment"># 删除有关分类类别的权重</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">list</span>(weights_dict.keys()):</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;head&quot;</span> <span class="keyword">in</span> k:</span><br><span class="line">                <span class="keyword">del</span> weights_dict[k]</span><br><span class="line">        <span class="built_in">print</span>(model.load_state_dict(weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除head外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;head&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;training &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">    pg = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=<span class="number">5E-2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        train_loss, train_acc = train_one_epoch(model=model,</span><br><span class="line">                                                optimizer=optimizer,</span><br><span class="line">                                                data_loader=train_loader,</span><br><span class="line">                                                device=device,</span><br><span class="line">                                                epoch=epoch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        val_loss, val_acc = evaluate(model=model,</span><br><span class="line">                                     data_loader=val_loader,</span><br><span class="line">                                     device=device,</span><br><span class="line">                                     epoch=epoch)</span><br><span class="line"></span><br><span class="line">        tags = [<span class="string">&quot;train_loss&quot;</span>, <span class="string">&quot;train_acc&quot;</span>, <span class="string">&quot;val_loss&quot;</span>, <span class="string">&quot;val_acc&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], train_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], train_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], val_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">3</span>], val_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">4</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;./weights/model-&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预训练权重路径，如果不想载入就设置为空字符</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./swin_tiny_patch4_window7_224.pth&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    <span class="comment"># 是否冻结权重</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<h2 id="训练结果">训练结果</h2>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h1><a target="_blank" rel="noopener" href="http://predict.py">predict.py</a></h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> swin_tiny_patch4_window7_224 <span class="keyword">as</span> create_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.14</span>)),</span><br><span class="line">         transforms.CenterCrop(img_size),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = create_model(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/model-9.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="预测结果">预测结果</h2>
<p><img src="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="fa fa-tag"></i> 神经网络</a>
              <a href="/tags/Pytorch%E6%90%AD%E5%BB%BACNN/" rel="tag"><i class="fa fa-tag"></i> Pytorch搭建CNN</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/06/03/Swin-Transformer%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/" rel="prev" title="深度学习模型之CNN（二十三）Swin-Transformer网络结构详解">
                  <i class="fa fa-chevron-left"></i> 深度学习模型之CNN（二十三）Swin-Transformer网络结构详解
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/" rel="next" title="深度学习模型之CNN（二十五）ConvNeXt网络讲解及使用Pytorch搭建">
                  深度学习模型之CNN（二十五）ConvNeXt网络讲解及使用Pytorch搭建 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="valine-comments"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Linvil Yao</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>
-->

<div>
<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("04/21/2023 22:22:22");//在此处修改你的建站时间
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "已运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.4/jquery.min.js" integrity="sha256-oP6HI9z1XaZNBrJURtCoUT5SUnxFr8s3BzRl+cbzUq8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script src="/js/third-party/fancybox.js"></script>


  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"16p3s6fLzeTRVQeTGaUl2ZaN-gzGzoHsz","app_key":"iNfyeaWVmA11Duj7fzr0B1r1","server_url":"https://16p3s6fl.lc-cn-n1-shared.com","security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script src="https://unpkg.com/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '32px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>


<script class="next-config" data-name="valine" type="application/json">{"enable":true,"appId":"16p3s6fLzeTRVQeTGaUl2ZaN-gzGzoHsz","appKey":"iNfyeaWVmA11Duj7fzr0B1r1","serverURLs":"https://16p3s6fl.lc-cn-n1-shared.com","placeholder":"请写下您的评论","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"lang":null,"visitor":false,"comment_count":true,"recordIP":true,"enableQQ":true,"requiredFields":[],"el":"#valine-comments","path":"/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.valine.el)
    .then(() => NexT.utils.getScript(
      'https://fastly.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js',
      { condition: window.Valine }
    ))
    .then(() => {
      new Valine(CONFIG.valine);
    });
});
</script>

</body>
</html>
