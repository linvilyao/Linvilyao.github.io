<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_logosc/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_logosc/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"linvilyao.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":14,"offset":10},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础13.1和13.2》，作为随堂笔记。学习Apple 2021年发表的MobileViT。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习模型之CNN（二十六）MobileViT网络讲解及通过Pytorch搭建MobileViT网络">
<meta property="og:url" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="Linvil&#39;s Blog">
<meta property="og:description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础13.1和13.2》，作为随堂笔记。学习Apple 2021年发表的MobileViT。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E4%BB%A5%E5%8F%8A%E5%BD%93%E5%B9%B4%E6%AF%94%E8%BE%83%E4%B8%BB%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E8%BD%BB%E9%87%8F%E7%9A%84ViT%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E4%BB%A5%E5%8F%8A%E5%BD%93%E5%B9%B4%E6%AF%94%E8%BE%83%E4%B8%BB%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E8%BD%BB%E9%87%8F%E5%92%8C%E9%87%8D%E9%87%8F%E7%9A%84CNN%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E7%9A%84%E6%80%A7%E8%83%BD.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Standard_visual_transformer.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MobileViT_visual_transformer.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MV2%E5%92%8CMobile_ViT_Block.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81%E4%B8%AD%E7%9A%84Unfold%E5%92%8CFold.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Patch_size%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE-MobileViT-XXS.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MV2%E5%92%8CMobile_ViT_Block.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Mobile_ViT_Block.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE-MobileViT-XXS.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png">
<meta property="article:published_time" content="2023-06-10T00:37:30.000Z">
<meta property="article:modified_time" content="2023-06-10T13:03:27.992Z">
<meta property="article:author" content="Linvil Yao">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="CNN网络详解">
<meta property="article:tag" content="Pytorch搭建CNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E4%BB%A5%E5%8F%8A%E5%BD%93%E5%B9%B4%E6%AF%94%E8%BE%83%E4%B8%BB%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E8%BD%BB%E9%87%8F%E7%9A%84ViT%E6%A8%A1%E5%9E%8B.png">


<link rel="canonical" href="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/","path":"2023/06/10/MobileViT网络讲解及通过Pytorch搭建MobileViT网络/","title":"深度学习模型之CNN（二十六）MobileViT网络讲解及通过Pytorch搭建MobileViT网络"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>深度学习模型之CNN（二十六）MobileViT网络讲解及通过Pytorch搭建MobileViT网络 | Linvil's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Linvil's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">这是一个用来记录的博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">3</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">6</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">39</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">网络架构学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E8%A7%A3%E6%9E%90"><span class="nav-number">1.2.</span> <span class="nav-text">模型结构解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Vision-Transformer%E7%BB%93%E6%9E%84%E7%AE%80%E4%BB%8B"><span class="nav-number">1.2.1.</span> <span class="nav-text">Vision Transformer结构简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MobileViT%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.2.2.</span> <span class="nav-text">MobileViT介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">整体架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MV2"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">MV2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MobileViT-block"><span class="nav-number">1.2.2.3.</span> <span class="nav-text">MobileViT block</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81%E4%B8%AD%E7%9A%84Transformer"><span class="nav-number">1.2.2.4.</span> <span class="nav-text">全局表征中的Transformer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81%E4%B8%AD%E7%9A%84Unfold%E5%92%8CFold"><span class="nav-number">1.2.2.5.</span> <span class="nav-text">全局表征中的Unfold和Fold</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Patch-Size%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">1.2.3.</span> <span class="nav-text">Patch Size对性能的影响</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%A6%E7%BB%86%E9%85%8D%E7%BD%AE"><span class="nav-number">1.3.</span> <span class="nav-text">模型详细配置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">Pytorch搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B7%A5%E7%A8%8B%E7%9B%AE%E5%BD%95"><span class="nav-number">2.1.</span> <span class="nav-text">工程目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model"><span class="nav-number">2.2.</span> <span class="nav-text">model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ConvLayer%E7%B1%BB"><span class="nav-number">2.2.1.</span> <span class="nav-text">ConvLayer类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MV2%EF%BC%88InvertedResidual%E7%B1%BB%EF%BC%89"><span class="nav-number">2.2.2.</span> <span class="nav-text">MV2（InvertedResidual类）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MobileViTBlock"><span class="nav-number">2.2.3.</span> <span class="nav-text">MobileViTBlock</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#unfolding%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.3.1.</span> <span class="nav-text">unfolding函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#folding%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.3.2.</span> <span class="nav-text">folding函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.3.3.</span> <span class="nav-text">正向传播函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MobileViT%E7%B1%BB"><span class="nav-number">2.2.4.</span> <span class="nav-text">MobileViT类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#make-layer%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.4.1.</span> <span class="nav-text">_make_layer函数</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#make-mobilenet-layer%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.4.1.1.</span> <span class="nav-text">_make_mobilenet_layer函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#make-mit-layer%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.4.1.2.</span> <span class="nav-text">_make_mit_layer函数</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#init-parameters%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.4.2.</span> <span class="nav-text">init_parameters函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#forward%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.4.3.</span> <span class="nav-text">forward函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#transformer"><span class="nav-number">2.3.</span> <span class="nav-text">transformer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#unfold-test"><span class="nav-number">2.4.</span> <span class="nav-text">unfold_test</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model-config"><span class="nav-number">2.5.</span> <span class="nav-text">model_config</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#train"><span class="nav-number">2.6.</span> <span class="nav-text">train</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C"><span class="nav-number">2.6.1.</span> <span class="nav-text">训练结果</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#predict"><span class="nav-number">2.7.</span> <span class="nav-text">predict</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="nav-number">2.7.1.</span> <span class="nav-text">预测结果</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Linvil Yao"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Linvil Yao</p>
  <div class="site-description" itemprop="description">Welcome to Linvil's Blog!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


        </div>
      </div>


  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      最近文章
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/14/%E8%A1%A5%E5%85%85%E4%B9%8BTensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2/" title="2023&#x2F;06&#x2F;14&#x2F;补充之Tensor的维度变换&#x2F;">Tensor的维度变换</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/" title="2023&#x2F;06&#x2F;13&#x2F;Transformer中Self-Attention以及Multi-Head-Attention详解&#x2F;">Transformer中Self-Attention以及Multi-Head Attention详解</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/" title="2023&#x2F;06&#x2F;10&#x2F;MobileViT网络讲解及通过Pytorch搭建MobileViT网络&#x2F;">深度学习模型之CNN（二十六）MobileViT网络讲解及通过Pytorch搭建MobileViT网络</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/" title="2023&#x2F;06&#x2F;05&#x2F;ConvNeXt网络讲解及使用Pytorch搭建&#x2F;">深度学习模型之CNN（二十五）ConvNeXt网络讲解及使用Pytorch搭建</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/06/04/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BASwin-Transformer%E7%BD%91%E7%BB%9C/" title="2023&#x2F;06&#x2F;04&#x2F;使用Pytorch搭建Swin-Transformer网络&#x2F;">深度学习模型之CNN（二十四）使用Pytorch搭建Swin-Transformer网络</a>
        </li>
    </ul>
  </div>
    </div>


    



  </aside>






    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://linvilyao.github.io/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Linvil Yao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linvil's Blog">
      <meta itemprop="description" content="Welcome to Linvil's Blog!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="深度学习模型之CNN（二十六）MobileViT网络讲解及通过Pytorch搭建MobileViT网络 | Linvil's Blog">
      <meta itemprop="description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础13.1和13.2》，作为随堂笔记。学习Apple 2021年发表的MobileViT。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习模型之CNN（二十六）MobileViT网络讲解及通过Pytorch搭建MobileViT网络
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-06-10 08:37:30 / 修改时间：21:03:27" itemprop="dateCreated datePublished" datetime="2023-06-10T08:37:30+08:00">2023-06-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
    <span id="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/" class="post-meta-item leancloud_visitors" data-flag-title="深度学习模型之CNN（二十六）MobileViT网络讲解及通过Pytorch搭建MobileViT网络" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Valine：</span>
  
    <a title="valine" href="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>40k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>36 分钟</span>
    </span>
</div>

            <div class="post-description">本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础13.1和13.2》，作为随堂笔记。学习Apple 2021年发表的MobileViT。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>MobileViT是CNN和Transformer的混合架构模型，原论文：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2110.02178">MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer</a></p>
<h1>网络架构学习</h1>
<h2 id="前言">前言</h2>
<p>当前纯Transformer模型存在的问题：</p>
<ul>
<li>参数多，算力要求高（比如ViT-L Patch16模型，仅权重模型就有1G多）；</li>
<li>缺少空间归纳偏置；</li>
<li>迁移到其他任务比较繁琐（相对于CNN）；</li>
</ul>
<blockquote>
<p>为什么会繁琐？</p>
<p>主要由于位置偏置导致的，比如在Vision Transformer当中采用的是绝对位置偏置，那么绝对位置偏置的序列长度是和输入token的序列长度保持一致的。<strong>也就是说在训练模型的时候，在指定了输入图像尺寸之后，绝对位置偏置所对应的序列长度其实就固定了</strong>，如果后期要更改输入图片的尺寸的话，会发现通过图片生成的token序列长度和绝对位置偏置的序列长度是不一致的。这样就没法进行一个相加以及后续的处理了。</p>
<p>针对这个问题，现有的问题最简单的就是去进行一个差值。也就是说将绝对位置编码给差值到与输入token数据序列相同的一个长度，那么差值之后呢，又会引入另外一个新的问题。就是说一般我们将差值之后的模型拿来直接用的话，会发现可能会出现掉点的情况。但是对于CNN模型，比如在224x224的图片尺寸上进行训练，然后在384x384的尺寸上进行验证，一般是会出现一个长点的情况，比如在ImageNet上可能会涨一个点左右。但是对于Transformer的模型，如果简单通过差值的方式在一个相对更高的分辨率上进行验证，会发现可能会掉点。</p>
<p><strong>所以说一般对Transformer的绝对位置偏置进行差值之后，还要进行一个微调</strong>。但如果每次修改了图片尺寸之后都要重新对绝对位置偏置进行一个差值和微调，就会太麻烦了一点。</p>
<p>有人会说，可以采用像Swin Transformer当中所采用的相对位置偏执。的确如此，在Swin Transformer当中的相对位置偏执，对输入图片尺寸并不敏感，只对设置的window的大小有关。但如果训练的模型的输入图片尺寸和迁移到其他任务的图片尺寸相差比较大的话，其实一般还是会对window的尺寸进行一个调整的。比如说先在ImageNet上进行一个预训练，那么训练的时候可能输入的图片大小为224x224，假设要迁移到目标检测任务中，那么此时输入的图像分辨率可能是1280x1280，那么很明显，从224到1280，图像尺寸发生非常大的变化。<strong>如果此时不去调整window的尺寸大小的话，那么效果依旧会受到影响。所以一般针对这个情况，还是会去将window的尺寸给设置的更大一点</strong>。一旦window的尺寸发生变化，那么相对位置编码的序列长度也会发生变化，那么还是遇见更改提到的问题。</p>
<p>因此当前所采用的这些位置编码其实有很多值得优化的地方，比如在Swin TransformerV2的论文当中，其实就针对Swin Transformerv1当中所采用的相对位置编码进行了优化。</p>
</blockquote>
<ul>
<li>模型训练困难（相对于CNN）</li>
</ul>
<blockquote>
<p>根据现有的一些经验，训练一个Transformer往往需要更多训练数据和迭代更多的epoch，需要更大的L2正则，需要更多的数据增强，并且对数据增强是比较敏感的。</p>
</blockquote>
<p>针对以上提出的几点问题，现有一个很好的解决办法就是可以将CNN架构和Transformer架构进行一个混合使用。因为CNN架构本身就带有空间归纳偏置，如果使用它之后就不需要单独去加上位置偏置或者位置编码。并且加入CNN之后是能够加速网络的收敛，使整个网络的训练过程更加稳定。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E4%BB%A5%E5%8F%8A%E5%BD%93%E5%B9%B4%E6%AF%94%E8%BE%83%E4%B8%BB%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E8%BD%BB%E9%87%8F%E7%9A%84ViT%E6%A8%A1%E5%9E%8B.png" alt="对比MobileViT以及当年比较主流的一些相对轻量的ViT模型"></p>
<p>在上图中，Augmentation指数据增强的两种方式，一个是比较基础的basic，另一个是更加先进的advance。basic就代表采用的使像ResNet那样的一个比较简单的数据增强，也就是随机裁剪加一个水平方向的随机翻转。但对advance所包含的数据增强方式就非常的多。</p>
<p>根据上图（b）表可以看出，MobileViT尽管采用的Augmentation中的basic，但是Top-1还是能达到74.8和78.4，也说明MobileViT对数据增强没有那么敏感，而且学习能力也是比较强的。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E4%BB%A5%E5%8F%8A%E5%BD%93%E5%B9%B4%E6%AF%94%E8%BE%83%E4%B8%BB%E6%B5%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E8%BD%BB%E9%87%8F%E5%92%8C%E9%87%8D%E9%87%8F%E7%9A%84CNN%E6%A8%A1%E5%9E%8B.png" alt="对比MobileViT以及当年比较主流的一些相对轻量和重量的CNN模型"></p>
<p>根据上图MobileViT与比较轻量和重的模型对比，能够看出来CNN和Transformer所结合的MobileViT模型确实效果是非常不错的。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%AF%B9%E6%AF%94MobileViT%E7%9A%84%E6%80%A7%E8%83%BD.png" alt="对比MobileViT与CNN网络的训练速度"></p>
<h2 id="模型结构解析">模型结构解析</h2>
<h3 id="Vision-Transformer结构简介">Vision Transformer结构简介</h3>
<p>这是论文当中作者所给的标准的Vision Transformer视觉模型结构，和之前讲过的Vision Transformer有一点点的不一样。最主要这里并没有Vision Transformer里面所提到的class token。其实class token就是参考BERT网络，但是对于视觉任务而言，其实class token并不是必须的，所以下图所展示的是一个更加标准的针对视觉的一个Vision Transformer架构。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Standard_visual_transformer.png" alt="Standard visual transformer(ViT)"></p>
<p>首先可以看到我们是针对输入的图片划分为一个一个patch，然后将每个patch的数据进行展平，展平之后再通过一个线性映射得到针对每一个patch所对应的token（其实每一个token对应的也就是一个向量而已），那么将这些token放在一起就得到一个token序列（在网络实际搭建过程当中，其实关于这一步也就是<strong>展平加线性映射这一块</strong>是可以直接通过一个卷积操作实现的），然后再加上一个位置编码或者说位置偏置（可以采用绝对位置偏置或者相对位置偏置），接着再通过L x Transformer Block（其实可以在Transformer Block和全连接层之间加一个全局池化层），再通过一个全连接层就得到输出。</p>
<h3 id="MobileViT介绍">MobileViT介绍</h3>
<h4 id="整体架构">整体架构</h4>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MobileViT_visual_transformer.png" alt="MobileViT visual transformer"></p>
<h4 id="MV2">MV2</h4>
<p>相当于MobileNet v2当中提出的Inverted Residual Block。有些MV2会有向下的箭头，这代表这个模块是需要对特征图进行一个下采样的。</p>
<h4 id="MobileViT-block"><strong>MobileViT block</strong></h4>
<p>首先输入一个$H✖W✖C$的特征图，先做一个局部的表征或者说做一个局部的建模（<code>Local representations</code>，<strong>其实就是通过一个卷积核大小为$n✖n$的卷积层实现的。在代码当中就是一个3x3的卷积层，然后再通过一个1x1的卷积层去调整通道数</strong>）。</p>
<p>调整完之后，进行一个全局表征或者说全局的建模（<code>global representations</code>，<strong>其实就是通过一个Unfold，再通过L个Transformer Block，然后再通过Fold折叠回特征图</strong>）。</p>
<p>接着再通过一个1x1的卷积层去调整通道数，将通道数又还原回了C，也就是和输入的特征图的通道数保持一致。接着通过一个shortcut将更改得到的特征图和输入特征图进行concat拼接，拼接玩完之后通道数为2C，再通过一个$n✖n$的卷积层进行一个特征融合（在源码中，这里的n对应的是3x3）。</p>
<p>这就是整一个<code>MobileViT block</code>的结构，核心其实还是有关全局表征这部分</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MV2%E5%92%8CMobile_ViT_Block.png" alt="MV2和Mobile ViT Block"></p>
<h4 id="全局表征中的Transformer"><strong>全局表征中的Transformer</strong></h4>
<p>下图（中）为方便忽略channel，对于输入transformer block或者说transformer encoder，一般将特征图直接展平成一个序列，然后再输入到transformer block当中。</p>
<p>在做Self-Attention的时候，图中的每一个像素或者说每一个token是需要和所有的token进行一个Self-Attention的。<strong>但是在MobileViT当中，并不是这么去做的</strong>。</p>
<p>首先会将输入特征图划分成一个个patch，在下图（中）中以2x2大小的patch为例。</p>
<p><strong>划分完之后在实际做Attention时，其实是将每一个patch当中对应相同位置的token去做self Attention，也就是说，下图（中）这些颜色相同的token才会去所self Attention，那么通过这么个方式，就能减少Attention的计算量</strong>。</p>
<blockquote>
<p>对于原始的self Attention这段计算过程（也就是说每一个token都要和所有的token去进行一个Attention），假设计算某一个token与其他所有token进行Attention的计算量，记为$WHC$，因为要和每一个token都去进行self Attention；</p>
<p>但是在MobileViT当中，只是让颜色相同的这些token去做self Attention，以下图2x2的patch为例，对于每一个token做self Attention的时候，实际计算量为$\frac{HWC}{4}$，因为这里的patch大小为2x2，所以计算量缩减为原来的$\frac{1}{4}$。</p>
</blockquote>
<p>其实这样做只能减少在做self Attention时的计算量。对于transformer block或者说transformer encoder的其他部分的计算量是没有任何变化的。因为像下图（左）中这些像Norm以及MLP其实是针对token去做处理的。</p>
<blockquote>
<p>为什么可以这么做呢？</p>
<p>因为在对图像进行处理中，是存在非常多的冗余数据，特别是对于图像分辨率较高的一个情况。对于相对底层的特征图也就是说当H和W比较大的时候，相邻像素之间的一个信息差异其实是比较小的。如果在做self Attention的时候，每一个token都要去看一遍的话，还是挺浪费算力的。</p>
<p>但并不是说去看相邻的像素或者token没有意义，只是说在分辨率较高的特征图上，收益可能很低，那么增加了这些计算成本远大于ACC上的收益。而且在做全局表征之前，也就是<code>Local representations</code>，已经提前做了一个局部表征，后面做全局表征的时候其实就没必要那么细了。</p>
</blockquote>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81.png" alt="全局表征中的Transformer block"></p>
<h4 id="全局表征中的Unfold和Fold">全局表征中的Unfold和Fold</h4>
<p>在MovileViT中，只是将这些颜色相同的token去做Attention，颜色不同的token是不做信息交互的，所以在论文当中，这里的<code>Unfold</code>就是将颜色相同的这些token给拼成一个序列。比如将patch设置为2x2的话，通过Unfold可以得到4个序列。</p>
<p>之后将每个序列输入到<code>Transformer Block</code>当中进行全局建模。这里的每一个序列在输入Transformer Block时，是可以进行并行计算的，所以速度还是非常快的。</p>
<p>最后再通过<code>Fold</code>方法将这些特征折叠回原特征图的一个形式。</p>
<p><strong>所以全局表征中的Unfold和Fold就是对特征图进行一个拆分和重新折叠的过程</strong>。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81%E4%B8%AD%E7%9A%84Unfold%E5%92%8CFold.png" alt="全局表征中的Unfold和Fold"></p>
<h3 id="Patch-Size对性能的影响">Patch Size对性能的影响</h3>
<p>作者有做两组对比实验，<strong>分别对应的Patch Size时8，4，2和2，2，2</strong>。这三个数字分别对应的是针对下采样的8倍，16倍以及32倍的 特征图。并且如下图所示，分别在分类、目标检测和分割任务上进行了对比。横坐标对应的时推理时间，希望越小越好，纵坐标对应的时在各项任务上的一个指标，一般都是越大越好。所以越靠近坐标的左上方代表模型的综合性能越好。</p>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Patch_size%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D.png" alt="Patch Size对性能的影响（两组实验）"></p>
<h2 id="模型详细配置">模型详细配置</h2>
<p>一共有三类模型配置：</p>
<ul>
<li>MobileViT-S(small)；</li>
<li>MobileViT-XS(extra small)；</li>
<li>MobileViT-XXS(extra extra small)</li>
</ul>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE-MobileViT-XXS.png" alt="模型配置-MobileViT-XXS"></p>
<ul>
<li><code>out_channels</code>：每一个layer输出的一个特征图的通道数；</li>
<li><code>mv2_exp</code>：在Inverted Residual模块当中的expansion ratio；</li>
<li><code>transformer_channels</code>：输入transformer block的一个token的向量长度或者输入特征图的通道数；</li>
<li><code>ffn_dim</code>：transformer block MLP中间层的一个节点个数；</li>
<li><code>patch_h</code>和<code>patch_w</code>：patch size的大小；</li>
<li><code>num_heads</code>：transformer block当中的Muti-Head Self-Attention的header的个数。</li>
</ul>
<h1>Pytorch搭建</h1>
<h2 id="工程目录">工程目录</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">├── Test15_MobileViT</span><br><span class="line">	├── model.py（模型文件）   </span><br><span class="line">	├── my_dataset.py（数据处理文件）    </span><br><span class="line">	├── train.py（调用模型训练，自动生成class_indices.json,mobilevit.pth文件）</span><br><span class="line">	├── predict.py（调用模型进行预测）</span><br><span class="line">	├── model_config.py（三种模型的详细参数）</span><br><span class="line">	├── transformer.py</span><br><span class="line">	├── utils.py（工具文件，用得上就对了）  </span><br><span class="line">	├── tulip.jpg（用来根据前期的训练结果来predict图片类型）</span><br><span class="line">	└── mobilevit_xxs.pt（迁移学习，提前下载好mobilevit_xxs.pt权重脚本）</span><br><span class="line">└── data_set</span><br><span class="line">	└── data数据集</span><br></pre></td></tr></table></figure>
<h2 id="model">model</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">original code from apple:</span></span><br><span class="line"><span class="string">https://github.com/apple/ml-cvnets/blob/main/cvnets/models/classification/mobilevit.py</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span>, <span class="type">Tuple</span>, <span class="type">Union</span>, <span class="type">Dict</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformer <span class="keyword">import</span> TransformerEncoder</span><br><span class="line"><span class="keyword">from</span> model_config <span class="keyword">import</span> get_config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_divisible</span>(<span class="params"></span></span><br><span class="line"><span class="params">    v: <span class="type">Union</span>[<span class="built_in">float</span>, <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">    divisor: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">    min_value: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">float</span>, <span class="built_in">int</span>]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Union</span>[<span class="built_in">float</span>, <span class="built_in">int</span>]:</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        kernel_size: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">        stride: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]]] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        groups: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        bias: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        use_norm: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        use_act: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        expand_ratio: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">        skip_connection: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor, *args, **kwargs</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MobileViTBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        transformer_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        ffn_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        n_transformer_blocks: <span class="built_in">int</span> = <span class="number">2</span>,</span></span><br><span class="line"><span class="params">        head_dim: <span class="built_in">int</span> = <span class="number">32</span>,</span></span><br><span class="line"><span class="params">        attn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        ffn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        patch_h: <span class="built_in">int</span> = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        patch_w: <span class="built_in">int</span> = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        conv_ksize: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">        *args,</span></span><br><span class="line"><span class="params">        **kwargs</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">unfolding</span>(<span class="params">self, x: Tensor</span>) -&gt; <span class="type">Tuple</span>[Tensor, <span class="type">Dict</span>]:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">folding</span>(<span class="params">self, x: Tensor, info_dict: <span class="type">Dict</span></span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MobileViT</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_cfg: <span class="type">Dict</span>, num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, input_channel, cfg: <span class="type">Dict</span></span>) -&gt; <span class="type">Tuple</span>[nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_mobilenet_layer</span>(<span class="params">input_channel: <span class="built_in">int</span>, cfg: <span class="type">Dict</span></span>) -&gt; <span class="type">Tuple</span>[nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_mit_layer</span>(<span class="params">input_channel: <span class="built_in">int</span>, cfg: <span class="type">Dict</span></span>) -&gt; [nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_parameters</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mobile_vit_xx_small</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mobile_vit_x_small</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mobile_vit_small</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
<h3 id="ConvLayer类">ConvLayer类</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLayer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Applies a 2D convolution over an input</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        in_channels (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, C_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        out_channels (int): :math:`C_&#123;out&#125;` from an expected output of size :math:`(N, C_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`</span></span><br><span class="line"><span class="string">        kernel_size (Union[int, Tuple[int, int]]): Kernel size for convolution.</span></span><br><span class="line"><span class="string">        stride (Union[int, Tuple[int, int]]): Stride for convolution. Default: 1</span></span><br><span class="line"><span class="string">        groups (Optional[int]): Number of groups in convolution. Default: 1</span></span><br><span class="line"><span class="string">        bias (Optional[bool]): Use bias. Default: ``False``</span></span><br><span class="line"><span class="string">        use_norm (Optional[bool]): Use normalization layer after convolution. Default: ``True``</span></span><br><span class="line"><span class="string">        use_act (Optional[bool]): Use activation layer after convolution (or convolution and normalization).</span></span><br><span class="line"><span class="string">                                Default: ``True``</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`</span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        For depth-wise convolution, `groups=C_&#123;in&#125;=C_&#123;out&#125;`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        kernel_size: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">        stride: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">int</span>, <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]]] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        groups: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">1</span>,</span></span><br><span class="line"><span class="params">        bias: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        use_norm: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        use_act: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(kernel_size, <span class="built_in">int</span>):</span><br><span class="line">            kernel_size = (kernel_size, kernel_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(stride, <span class="built_in">int</span>):</span><br><span class="line">            stride = (stride, stride)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(kernel_size, <span class="type">Tuple</span>)</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(stride, <span class="type">Tuple</span>)</span><br><span class="line"></span><br><span class="line">        padding = (</span><br><span class="line">            <span class="built_in">int</span>((kernel_size[<span class="number">0</span>] - <span class="number">1</span>) / <span class="number">2</span>),</span><br><span class="line">            <span class="built_in">int</span>((kernel_size[<span class="number">1</span>] - <span class="number">1</span>) / <span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        block = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        conv_layer = nn.Conv2d(</span><br><span class="line">            in_channels=in_channels,</span><br><span class="line">            out_channels=out_channels,</span><br><span class="line">            kernel_size=kernel_size,</span><br><span class="line">            stride=stride,</span><br><span class="line">            groups=groups,</span><br><span class="line">            padding=padding,</span><br><span class="line">            bias=bias</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        block.add_module(name=<span class="string">&quot;conv&quot;</span>, module=conv_layer)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_norm:</span><br><span class="line">            norm_layer = nn.BatchNorm2d(num_features=out_channels, momentum=<span class="number">0.1</span>)</span><br><span class="line">            block.add_module(name=<span class="string">&quot;norm&quot;</span>, module=norm_layer)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_act:</span><br><span class="line">            act_layer = nn.SiLU()</span><br><span class="line">            block.add_module(name=<span class="string">&quot;act&quot;</span>, module=act_layer)</span><br><span class="line">		</span><br><span class="line">        <span class="comment"># 返回的Sequential的类</span></span><br><span class="line">        self.block = block</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">return</span> self.block(x)</span><br></pre></td></tr></table></figure>
<h3 id="MV2（InvertedResidual类）">MV2（InvertedResidual类）</h3>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/MV2%E5%92%8CMobile_ViT_Block.png" alt="MV2和Mobile ViT Block"></p>
<p><code>skip_connection</code>：是否使用shortcut</p>
<p><code>hidden_dim</code>：通过第一个1x1卷积层之后将特征图的通道数调整为多少</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class implements the inverted residual block, as described in `MobileNetv2 &lt;https://arxiv.org/abs/1801.04381&gt;`_ paper</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        in_channels (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, C_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        out_channels (int): :math:`C_&#123;out&#125;` from an expected output of size :math:`(N, C_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out)`</span></span><br><span class="line"><span class="string">        stride (int): Use convolutions with a stride. Default: 1</span></span><br><span class="line"><span class="string">        expand_ratio (Union[int, float]): Expand the input channels by this factor in depth-wise conv</span></span><br><span class="line"><span class="string">        skip_connection (Optional[bool]): Use skip-connection. Default: True</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`</span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        If `in_channels =! out_channels` and `stride &gt; 1`, we set `skip_connection=False`</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        stride: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        expand_ratio: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">        skip_connection: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">assert</span> stride <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">        hidden_dim = make_divisible(<span class="built_in">int</span>(<span class="built_in">round</span>(in_channels * expand_ratio)), <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        block = nn.Sequential()</span><br><span class="line">        <span class="keyword">if</span> expand_ratio != <span class="number">1</span>:</span><br><span class="line">            block.add_module(</span><br><span class="line">                name=<span class="string">&quot;exp_1x1&quot;</span>,</span><br><span class="line">                module=ConvLayer(</span><br><span class="line">                    in_channels=in_channels,</span><br><span class="line">                    out_channels=hidden_dim,</span><br><span class="line">                    kernel_size=<span class="number">1</span></span><br><span class="line">                ),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        block.add_module(</span><br><span class="line">            name=<span class="string">&quot;conv_3x3&quot;</span>,</span><br><span class="line">            module=ConvLayer(</span><br><span class="line">                in_channels=hidden_dim,</span><br><span class="line">                out_channels=hidden_dim,</span><br><span class="line">                stride=stride,</span><br><span class="line">                kernel_size=<span class="number">3</span>,</span><br><span class="line">                groups=hidden_dim</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        block.add_module(</span><br><span class="line">            <span class="comment"># dw卷积</span></span><br><span class="line">            name=<span class="string">&quot;red_1x1&quot;</span>,</span><br><span class="line">            module=ConvLayer(</span><br><span class="line">                in_channels=hidden_dim,</span><br><span class="line">                out_channels=out_channels,</span><br><span class="line">                kernel_size=<span class="number">1</span>,</span><br><span class="line">                use_act=<span class="literal">False</span>,</span><br><span class="line">                use_norm=<span class="literal">True</span>,</span><br><span class="line">            ),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.block = block</span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.out_channels = out_channels</span><br><span class="line">        self.exp = expand_ratio</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.use_res_connect = (</span><br><span class="line">            self.stride == <span class="number">1</span> <span class="keyword">and</span> in_channels == out_channels <span class="keyword">and</span> skip_connection</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor, *args, **kwargs</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">if</span> self.use_res_connect:</span><br><span class="line">            <span class="keyword">return</span> x + self.block(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.block(x)</span><br></pre></td></tr></table></figure>
<h3 id="MobileViTBlock">MobileViTBlock</h3>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/Mobile_ViT_Block.png" alt="MobileViT Block"></p>
<p><code>transformer_dim</code>：输入到Transformer Encoder Block中每个token所对应的序列长度；</p>
<p><code>ffn_dim</code>：Transformer Encoder Block中MLP结构的第一个全连接层的节点个数；</p>
<p><code>n_transformer_blocks</code>：global representations当中重复堆叠Transformer Encoder Block的次数；</p>
<p><code>head_dim</code>：在做Muti-Head Self-Attention时每个header所对应的dimension；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MobileViTBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class defines the `MobileViT block &lt;https://arxiv.org/abs/2110.02178?context=cs.LG&gt;`_</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        opts: command line arguments</span></span><br><span class="line"><span class="string">        in_channels (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, C_&#123;in&#125;, H, W)`</span></span><br><span class="line"><span class="string">        transformer_dim (int): Input dimension to the transformer unit</span></span><br><span class="line"><span class="string">        ffn_dim (int): Dimension of the FFN block</span></span><br><span class="line"><span class="string">        n_transformer_blocks (int): Number of transformer blocks. Default: 2</span></span><br><span class="line"><span class="string">        head_dim (int): Head dimension in the multi-head attention. Default: 32</span></span><br><span class="line"><span class="string">        attn_dropout (float): Dropout in multi-head attention. Default: 0.0</span></span><br><span class="line"><span class="string">        dropout (float): Dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        ffn_dropout (float): Dropout between FFN layers in transformer. Default: 0.0</span></span><br><span class="line"><span class="string">        patch_h (int): Patch height for unfolding operation. Default: 8</span></span><br><span class="line"><span class="string">        patch_w (int): Patch width for unfolding operation. Default: 8</span></span><br><span class="line"><span class="string">        transformer_norm_layer (Optional[str]): Normalization layer in the transformer block. Default: layer_norm</span></span><br><span class="line"><span class="string">        conv_ksize (int): Kernel size to learn local representations in MobileViT block. Default: 3</span></span><br><span class="line"><span class="string">        no_fusion (Optional[bool]): Do not combine the input and output feature maps. Default: False</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        transformer_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        ffn_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        n_transformer_blocks: <span class="built_in">int</span> = <span class="number">2</span>,</span></span><br><span class="line"><span class="params">        head_dim: <span class="built_in">int</span> = <span class="number">32</span>,</span></span><br><span class="line"><span class="params">        attn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        ffn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">        patch_h: <span class="built_in">int</span> = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        patch_w: <span class="built_in">int</span> = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        conv_ksize: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">        *args,</span></span><br><span class="line"><span class="params">        **kwargs</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        conv_3x3_in = ConvLayer(</span><br><span class="line">            in_channels=in_channels,</span><br><span class="line">            out_channels=in_channels,</span><br><span class="line">            kernel_size=conv_ksize,</span><br><span class="line">            stride=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        conv_1x1_in = ConvLayer(</span><br><span class="line">            in_channels=in_channels,</span><br><span class="line">            out_channels=transformer_dim,</span><br><span class="line">            kernel_size=<span class="number">1</span>,</span><br><span class="line">            stride=<span class="number">1</span>,</span><br><span class="line">            use_norm=<span class="literal">False</span>,</span><br><span class="line">            use_act=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        conv_1x1_out = ConvLayer(</span><br><span class="line">            in_channels=transformer_dim,</span><br><span class="line">            out_channels=in_channels,</span><br><span class="line">            kernel_size=<span class="number">1</span>,</span><br><span class="line">            stride=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        conv_3x3_out = ConvLayer(</span><br><span class="line">            in_channels=<span class="number">2</span> * in_channels,</span><br><span class="line">            out_channels=in_channels,</span><br><span class="line">            kernel_size=conv_ksize,</span><br><span class="line">            stride=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.local_rep = nn.Sequential()</span><br><span class="line">        self.local_rep.add_module(name=<span class="string">&quot;conv_3x3&quot;</span>, module=conv_3x3_in)</span><br><span class="line">        self.local_rep.add_module(name=<span class="string">&quot;conv_1x1&quot;</span>, module=conv_1x1_in)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> transformer_dim % head_dim == <span class="number">0</span></span><br><span class="line">        num_heads = transformer_dim // head_dim</span><br><span class="line"></span><br><span class="line">        global_rep = [</span><br><span class="line">            TransformerEncoder(</span><br><span class="line">                embed_dim=transformer_dim,</span><br><span class="line">                ffn_latent_dim=ffn_dim,</span><br><span class="line">                num_heads=num_heads,</span><br><span class="line">                attn_dropout=attn_dropout,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                ffn_dropout=ffn_dropout</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_transformer_blocks)</span><br><span class="line">        ]</span><br><span class="line">        global_rep.append(nn.LayerNorm(transformer_dim))</span><br><span class="line">        self.global_rep = nn.Sequential(*global_rep)</span><br><span class="line"></span><br><span class="line">        self.conv_proj = conv_1x1_out</span><br><span class="line">        self.fusion = conv_3x3_out</span><br><span class="line"></span><br><span class="line">        self.patch_h = patch_h</span><br><span class="line">        self.patch_w = patch_w</span><br><span class="line">        self.patch_area = self.patch_w * self.patch_h</span><br><span class="line"></span><br><span class="line">        self.cnn_in_dim = in_channels</span><br><span class="line">        self.cnn_out_dim = transformer_dim</span><br><span class="line">        self.n_heads = num_heads</span><br><span class="line">        self.ffn_dim = ffn_dim</span><br><span class="line">        self.dropout = dropout</span><br><span class="line">        self.attn_dropout = attn_dropout</span><br><span class="line">        self.ffn_dropout = ffn_dropout</span><br><span class="line">        self.n_blocks = n_transformer_blocks</span><br><span class="line">        self.conv_ksize = conv_ksize</span><br></pre></td></tr></table></figure>
<h4 id="unfolding函数">unfolding函数</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">unfolding</span>(<span class="params">self, x: Tensor</span>) -&gt; <span class="type">Tuple</span>[Tensor, <span class="type">Dict</span>]:</span><br><span class="line">    patch_w, patch_h = self.patch_w, self.patch_h</span><br><span class="line">    patch_area = patch_w * patch_h</span><br><span class="line">    batch_size, in_channels, orig_h, orig_w = x.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 向上取整</span></span><br><span class="line">    new_h = <span class="built_in">int</span>(math.ceil(orig_h / self.patch_h) * self.patch_h)</span><br><span class="line">    new_w = <span class="built_in">int</span>(math.ceil(orig_w / self.patch_w) * self.patch_w)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过差值的形式，将特征图给差值到刚刚计算得到的new_h和new_w，以保证特征图能够被patch完整划分的</span></span><br><span class="line">    interpolate = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> new_w != orig_w <span class="keyword">or</span> new_h != orig_h:</span><br><span class="line">        <span class="comment"># Note: Padding can be done, but then it needs to be handled in attention function.</span></span><br><span class="line">        x = F.interpolate(x, size=(new_h, new_w), mode=<span class="string">&quot;bilinear&quot;</span>, align_corners=<span class="literal">False</span>)</span><br><span class="line">        interpolate = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># number of patches along width and height</span></span><br><span class="line">    num_patch_w = new_w // patch_w  <span class="comment"># n_w</span></span><br><span class="line">    num_patch_h = new_h // patch_h  <span class="comment"># n_h</span></span><br><span class="line">    num_patches = num_patch_h * num_patch_w  <span class="comment"># N</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将相同颜色的token给抽离出来</span></span><br><span class="line">    <span class="comment"># [B, C, H, W] -&gt; [B * C * n_h, p_h, n_w, p_w]</span></span><br><span class="line">    x = x.reshape(batch_size * in_channels * num_patch_h, patch_h, num_patch_w, patch_w)</span><br><span class="line">    <span class="comment"># [B * C * n_h, p_h, n_w, p_w] -&gt; [B * C * n_h, n_w, p_h, p_w]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># [B * C * n_h, n_w, p_h, p_w] -&gt; [B, C, N, P] where P = p_h * p_w and N = n_h * n_w</span></span><br><span class="line">    x = x.reshape(batch_size, in_channels, num_patches, patch_area)</span><br><span class="line">    <span class="comment"># [B, C, N, P] -&gt; [B, P, N, C]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># [B, P, N, C] -&gt; [BP, N, C]</span></span><br><span class="line">    x = x.reshape(batch_size * patch_area, num_patches, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    info_dict = &#123;</span><br><span class="line">        <span class="string">&quot;orig_size&quot;</span>: (orig_h, orig_w),</span><br><span class="line">        <span class="string">&quot;batch_size&quot;</span>: batch_size,</span><br><span class="line">        <span class="string">&quot;interpolate&quot;</span>: interpolate,</span><br><span class="line">        <span class="string">&quot;total_patches&quot;</span>: num_patches,</span><br><span class="line">        <span class="string">&quot;num_patches_w&quot;</span>: num_patch_w,</span><br><span class="line">        <span class="string">&quot;num_patches_h&quot;</span>: num_patch_h,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x, info_dict</span><br></pre></td></tr></table></figure>
<h4 id="folding函数">folding函数</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">folding</span>(<span class="params">self, x: Tensor, info_dict: <span class="type">Dict</span></span>) -&gt; Tensor:</span><br><span class="line">    n_dim = x.dim()</span><br><span class="line">    <span class="keyword">assert</span> n_dim == <span class="number">3</span>, <span class="string">&quot;Tensor should be of shape BPxNxC. Got: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        x.shape</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># [BP, N, C] --&gt; [B, P, N, C]</span></span><br><span class="line">    x = x.contiguous().view(</span><br><span class="line">        info_dict[<span class="string">&quot;batch_size&quot;</span>], self.patch_area, info_dict[<span class="string">&quot;total_patches&quot;</span>], -<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    batch_size, pixels, num_patches, channels = x.size()</span><br><span class="line">    num_patch_h = info_dict[<span class="string">&quot;num_patches_h&quot;</span>]</span><br><span class="line">    num_patch_w = info_dict[<span class="string">&quot;num_patches_w&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [B, P, N, C] -&gt; [B, C, N, P]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># [B, C, N, P] -&gt; [B*C*n_h, n_w, p_h, p_w]</span></span><br><span class="line">    x = x.reshape(batch_size * channels * num_patch_h, num_patch_w, self.patch_h, self.patch_w)</span><br><span class="line">    <span class="comment"># [B*C*n_h, n_w, p_h, p_w] -&gt; [B*C*n_h, p_h, n_w, p_w]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># [B*C*n_h, p_h, n_w, p_w] -&gt; [B, C, H, W]</span></span><br><span class="line">    x = x.reshape(batch_size, channels, num_patch_h * self.patch_h, num_patch_w * self.patch_w)</span><br><span class="line">    <span class="keyword">if</span> info_dict[<span class="string">&quot;interpolate&quot;</span>]:</span><br><span class="line">        x = F.interpolate(</span><br><span class="line">            x,</span><br><span class="line">            size=info_dict[<span class="string">&quot;orig_size&quot;</span>],</span><br><span class="line">            mode=<span class="string">&quot;bilinear&quot;</span>,</span><br><span class="line">            align_corners=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="正向传播函数">正向传播函数</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">    res = x</span><br><span class="line"></span><br><span class="line">    fm = self.local_rep(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># convert feature map to patches</span></span><br><span class="line">    patches, info_dict = self.unfolding(fm)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># learn global representations</span></span><br><span class="line">    <span class="keyword">for</span> transformer_layer <span class="keyword">in</span> self.global_rep:</span><br><span class="line">        patches = transformer_layer(patches)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [B x Patch x Patches x C] -&gt; [B x C x Patches x Patch]</span></span><br><span class="line">    fm = self.folding(x=patches, info_dict=info_dict)</span><br><span class="line"></span><br><span class="line">    fm = self.conv_proj(fm)</span><br><span class="line"></span><br><span class="line">    fm = self.fusion(torch.cat((res, fm), dim=<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> fm</span><br></pre></td></tr></table></figure>
<h3 id="MobileViT类">MobileViT类</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MobileViT</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class implements the `MobileViT architecture &lt;https://arxiv.org/abs/2110.02178?context=cs.LG&gt;`_</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_cfg: <span class="type">Dict</span>, num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        image_channels = <span class="number">3</span></span><br><span class="line">        out_channels = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">        self.conv_1 = ConvLayer(</span><br><span class="line">            in_channels=image_channels,</span><br><span class="line">            out_channels=out_channels,</span><br><span class="line">            kernel_size=<span class="number">3</span>,</span><br><span class="line">            stride=<span class="number">2</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.layer_1, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer1&quot;</span>])</span><br><span class="line">        self.layer_2, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer2&quot;</span>])</span><br><span class="line">        self.layer_3, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer3&quot;</span>])</span><br><span class="line">        self.layer_4, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer4&quot;</span>])</span><br><span class="line">        self.layer_5, out_channels = self._make_layer(input_channel=out_channels, cfg=model_cfg[<span class="string">&quot;layer5&quot;</span>])</span><br><span class="line"></span><br><span class="line">        exp_channels = <span class="built_in">min</span>(model_cfg[<span class="string">&quot;last_layer_exp_factor&quot;</span>] * out_channels, <span class="number">960</span>)</span><br><span class="line">        self.conv_1x1_exp = ConvLayer(</span><br><span class="line">            in_channels=out_channels,</span><br><span class="line">            out_channels=exp_channels,</span><br><span class="line">            kernel_size=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Sequential()</span><br><span class="line">        self.classifier.add_module(name=<span class="string">&quot;global_pool&quot;</span>, module=nn.AdaptiveAvgPool2d(<span class="number">1</span>))</span><br><span class="line">        self.classifier.add_module(name=<span class="string">&quot;flatten&quot;</span>, module=nn.Flatten())</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0.0</span> &lt; model_cfg[<span class="string">&quot;cls_dropout&quot;</span>] &lt; <span class="number">1.0</span>:</span><br><span class="line">            self.classifier.add_module(name=<span class="string">&quot;dropout&quot;</span>, module=nn.Dropout(p=model_cfg[<span class="string">&quot;cls_dropout&quot;</span>]))</span><br><span class="line">        self.classifier.add_module(name=<span class="string">&quot;fc&quot;</span>, module=nn.Linear(in_features=exp_channels, out_features=num_classes))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># weight init</span></span><br><span class="line">        self.apply(self.init_parameters)</span><br></pre></td></tr></table></figure>
<h4 id="make-layer函数">_make_layer函数</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, input_channel, cfg: <span class="type">Dict</span></span>) -&gt; <span class="type">Tuple</span>[nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">    block_type = cfg.get(<span class="string">&quot;block_type&quot;</span>, <span class="string">&quot;mobilevit&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> block_type.lower() == <span class="string">&quot;mobilevit&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> self._make_mit_layer(input_channel=input_channel, cfg=cfg)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> self._make_mobilenet_layer(input_channel=input_channel, cfg=cfg)</span><br></pre></td></tr></table></figure>
<h5 id="make-mobilenet-layer函数"><strong>_make_mobilenet_layer函数</strong></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_make_mobilenet_layer</span>(<span class="params">input_channel: <span class="built_in">int</span>, cfg: <span class="type">Dict</span></span>) -&gt; <span class="type">Tuple</span>[nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">    output_channels = cfg.get(<span class="string">&quot;out_channels&quot;</span>)</span><br><span class="line">    num_blocks = cfg.get(<span class="string">&quot;num_blocks&quot;</span>, <span class="number">2</span>)</span><br><span class="line">    expand_ratio = cfg.get(<span class="string">&quot;expand_ratio&quot;</span>, <span class="number">4</span>)</span><br><span class="line">    block = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">        stride = cfg.get(<span class="string">&quot;stride&quot;</span>, <span class="number">1</span>) <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        layer = InvertedResidual(</span><br><span class="line">            in_channels=input_channel,</span><br><span class="line">            out_channels=output_channels,</span><br><span class="line">            stride=stride,</span><br><span class="line">            expand_ratio=expand_ratio</span><br><span class="line">        )</span><br><span class="line">        block.append(layer)</span><br><span class="line">        input_channel = output_channels</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*block), input_channel</span><br></pre></td></tr></table></figure>
<h5 id="make-mit-layer函数"><strong>_make_mit_layer函数</strong></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_make_mit_layer</span>(<span class="params">input_channel: <span class="built_in">int</span>, cfg: <span class="type">Dict</span></span>) -&gt; [nn.Sequential, <span class="built_in">int</span>]:</span><br><span class="line">    stride = cfg.get(<span class="string">&quot;stride&quot;</span>, <span class="number">1</span>)</span><br><span class="line">    block = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> stride == <span class="number">2</span>:</span><br><span class="line">        layer = InvertedResidual(</span><br><span class="line">            in_channels=input_channel,</span><br><span class="line">            out_channels=cfg.get(<span class="string">&quot;out_channels&quot;</span>),</span><br><span class="line">            stride=stride,</span><br><span class="line">            expand_ratio=cfg.get(<span class="string">&quot;mv_expand_ratio&quot;</span>, <span class="number">4</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        block.append(layer)</span><br><span class="line">        input_channel = cfg.get(<span class="string">&quot;out_channels&quot;</span>)</span><br><span class="line"></span><br><span class="line">    transformer_dim = cfg[<span class="string">&quot;transformer_channels&quot;</span>]</span><br><span class="line">    ffn_dim = cfg.get(<span class="string">&quot;ffn_dim&quot;</span>)</span><br><span class="line">    num_heads = cfg.get(<span class="string">&quot;num_heads&quot;</span>, <span class="number">4</span>)</span><br><span class="line">    head_dim = transformer_dim // num_heads</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> transformer_dim % head_dim != <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Transformer input dimension should be divisible by head dimension. &quot;</span></span><br><span class="line">                         <span class="string">&quot;Got &#123;&#125; and &#123;&#125;.&quot;</span>.<span class="built_in">format</span>(transformer_dim, head_dim))</span><br><span class="line"></span><br><span class="line">    block.append(MobileViTBlock(</span><br><span class="line">        in_channels=input_channel,</span><br><span class="line">        transformer_dim=transformer_dim,</span><br><span class="line">        ffn_dim=ffn_dim,</span><br><span class="line">        n_transformer_blocks=cfg.get(<span class="string">&quot;transformer_blocks&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        patch_h=cfg.get(<span class="string">&quot;patch_h&quot;</span>, <span class="number">2</span>),</span><br><span class="line">        patch_w=cfg.get(<span class="string">&quot;patch_w&quot;</span>, <span class="number">2</span>),</span><br><span class="line">        dropout=cfg.get(<span class="string">&quot;dropout&quot;</span>, <span class="number">0.1</span>),</span><br><span class="line">        ffn_dropout=cfg.get(<span class="string">&quot;ffn_dropout&quot;</span>, <span class="number">0.0</span>),</span><br><span class="line">        attn_dropout=cfg.get(<span class="string">&quot;attn_dropout&quot;</span>, <span class="number">0.1</span>),</span><br><span class="line">        head_dim=head_dim,</span><br><span class="line">        conv_ksize=<span class="number">3</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*block), input_channel</span><br></pre></td></tr></table></figure>
<h4 id="init-parameters函数">init_parameters函数</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_parameters</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">        <span class="keyword">if</span> m.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.kaiming_normal_(m.weight, mode=<span class="string">&quot;fan_out&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, (nn.LayerNorm, nn.BatchNorm2d)):</span><br><span class="line">        <span class="keyword">if</span> m.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.ones_(m.weight)</span><br><span class="line">        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, (nn.Linear,)):</span><br><span class="line">        <span class="keyword">if</span> m.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.trunc_normal_(m.weight, mean=<span class="number">0.0</span>, std=<span class="number">0.02</span>)</span><br><span class="line">        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h4 id="forward函数">forward函数</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">    x = self.conv_1(x)</span><br><span class="line">    x = self.layer_1(x)</span><br><span class="line">    x = self.layer_2(x)</span><br><span class="line"></span><br><span class="line">    x = self.layer_3(x)</span><br><span class="line">    x = self.layer_4(x)</span><br><span class="line">    x = self.layer_5(x)</span><br><span class="line">    x = self.conv_1x1_exp(x)</span><br><span class="line">    x = self.classifier(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="transformer">transformer</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This layer applies a multi-head self- or cross-attention as described in</span></span><br><span class="line"><span class="string">    `Attention is all you need &lt;https://arxiv.org/abs/1706.03762&gt;`_ paper</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        embed_dim (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, P, C_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        num_heads (int): Number of heads in multi-head attention</span></span><br><span class="line"><span class="string">        attn_dropout (float): Attention dropout. Default: 0.0</span></span><br><span class="line"><span class="string">        bias (bool): Use bias or not. Default: ``True``</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, P, C_&#123;in&#125;)` where :math:`N` is batch size, :math:`P` is number of patches,</span></span><br><span class="line"><span class="string">        and :math:`C_&#123;in&#125;` is input embedding dim</span></span><br><span class="line"><span class="string">        - Output: same shape as the input</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self,</span></span><br><span class="line"><span class="params">            embed_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">            num_heads: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">            attn_dropout: <span class="built_in">float</span> = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">            bias: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">            *args,</span></span><br><span class="line"><span class="params">            **kwargs</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> embed_dim % num_heads != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">&quot;Embedding dim must be divisible by number of heads in &#123;&#125;. Got: embed_dim=&#123;&#125; and num_heads=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                    self.__class__.__name__, embed_dim, num_heads</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        self.qkv_proj = nn.Linear(in_features=embed_dim, out_features=<span class="number">3</span> * embed_dim, bias=bias)</span><br><span class="line"></span><br><span class="line">        self.attn_dropout = nn.Dropout(p=attn_dropout)</span><br><span class="line">        self.out_proj = nn.Linear(in_features=embed_dim, out_features=embed_dim, bias=bias)</span><br><span class="line"></span><br><span class="line">        self.head_dim = embed_dim // num_heads</span><br><span class="line">        self.scaling = self.head_dim ** -<span class="number">0.5</span></span><br><span class="line">        self.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_q: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># [N, P, C]</span></span><br><span class="line">        b_sz, n_patches, in_channels = x_q.shape</span><br><span class="line"></span><br><span class="line">        <span class="comment"># self-attention</span></span><br><span class="line">        <span class="comment"># [N, P, C] -&gt; [N, P, 3C] -&gt; [N, P, 3, h, c] where C = hc</span></span><br><span class="line">        qkv = self.qkv_proj(x_q).reshape(b_sz, n_patches, <span class="number">3</span>, self.num_heads, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N, P, 3, h, c] -&gt; [N, h, 3, P, C]</span></span><br><span class="line">        qkv = qkv.transpose(<span class="number">1</span>, <span class="number">3</span>).contiguous()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N, h, 3, P, C] -&gt; [N, h, P, C] x 3</span></span><br><span class="line">        query, key, value = qkv[:, :, <span class="number">0</span>], qkv[:, :, <span class="number">1</span>], qkv[:, :, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        query = query * self.scaling</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N h, P, c] -&gt; [N, h, c, P]</span></span><br><span class="line">        key = key.transpose(-<span class="number">1</span>, -<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># QK^T</span></span><br><span class="line">        <span class="comment"># [N, h, P, c] x [N, h, c, P] -&gt; [N, h, P, P]</span></span><br><span class="line">        attn = torch.matmul(query, key)</span><br><span class="line">        attn = self.softmax(attn)</span><br><span class="line">        attn = self.attn_dropout(attn)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># weighted sum</span></span><br><span class="line">        <span class="comment"># [N, h, P, P] x [N, h, P, c] -&gt; [N, h, P, c]</span></span><br><span class="line">        out = torch.matmul(attn, value)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N, h, P, c] -&gt; [N, P, h, c] -&gt; [N, P, C]</span></span><br><span class="line">        out = out.transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(b_sz, n_patches, -<span class="number">1</span>)</span><br><span class="line">        out = self.out_proj(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerEncoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class defines the pre-norm `Transformer encoder &lt;https://arxiv.org/abs/1706.03762&gt;`_</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        embed_dim (int): :math:`C_&#123;in&#125;` from an expected input of size :math:`(N, P, C_&#123;in&#125;)`</span></span><br><span class="line"><span class="string">        ffn_latent_dim (int): Inner dimension of the FFN</span></span><br><span class="line"><span class="string">        num_heads (int) : Number of heads in multi-head attention. Default: 8</span></span><br><span class="line"><span class="string">        attn_dropout (float): Dropout rate for attention in multi-head attention. Default: 0.0</span></span><br><span class="line"><span class="string">        dropout (float): Dropout rate. Default: 0.0</span></span><br><span class="line"><span class="string">        ffn_dropout (float): Dropout between FFN layers. Default: 0.0</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, P, C_&#123;in&#125;)` where :math:`N` is batch size, :math:`P` is number of patches,</span></span><br><span class="line"><span class="string">        and :math:`C_&#123;in&#125;` is input embedding dim</span></span><br><span class="line"><span class="string">        - Output: same shape as the input</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self,</span></span><br><span class="line"><span class="params">            embed_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">            ffn_latent_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">            num_heads: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">            attn_dropout: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">            dropout: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">            ffn_dropout: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.0</span>,</span></span><br><span class="line"><span class="params">            *args,</span></span><br><span class="line"><span class="params">            **kwargs</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        attn_unit = MultiHeadAttention(</span><br><span class="line">            embed_dim,</span><br><span class="line">            num_heads,</span><br><span class="line">            attn_dropout=attn_dropout,</span><br><span class="line">            bias=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.pre_norm_mha = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(embed_dim),</span><br><span class="line">            attn_unit,</span><br><span class="line">            nn.Dropout(p=dropout)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.pre_norm_ffn = nn.Sequential(</span><br><span class="line">            nn.LayerNorm(embed_dim),</span><br><span class="line">            nn.Linear(in_features=embed_dim, out_features=ffn_latent_dim, bias=<span class="literal">True</span>),</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Dropout(p=ffn_dropout),</span><br><span class="line">            nn.Linear(in_features=ffn_latent_dim, out_features=embed_dim, bias=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=dropout)</span><br><span class="line">        )</span><br><span class="line">        self.embed_dim = embed_dim</span><br><span class="line">        self.ffn_dim = ffn_latent_dim</span><br><span class="line">        self.ffn_dropout = ffn_dropout</span><br><span class="line">        self.std_dropout = dropout</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="comment"># multi-head attention</span></span><br><span class="line">        res = x</span><br><span class="line">        x = self.pre_norm_mha(x)</span><br><span class="line">        x = x + res</span><br><span class="line"></span><br><span class="line">        <span class="comment"># feed forward network</span></span><br><span class="line">        x = x + self.pre_norm_ffn(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="unfold-test">unfold_test</h2>
<p>up将把token按照相同颜色抽离出来的那部分代码自己重新写了，会更加容易理解。（这一块看图理解了，但代码是怎么据图片那样将颜色相同的token拼接成一个向量的，还没搞明白）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">8</span></span><br><span class="line">in_channels = <span class="number">32</span></span><br><span class="line">patch_h = <span class="number">2</span></span><br><span class="line">patch_w = <span class="number">2</span></span><br><span class="line">num_patch_h = <span class="number">16</span></span><br><span class="line">num_patch_w = <span class="number">16</span></span><br><span class="line">num_patches = num_patch_h * num_patch_w</span><br><span class="line">patch_area = patch_h * patch_w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">official</span>(<span class="params">x: torch.Tensor</span>):</span><br><span class="line">    <span class="comment"># [B, C, H, W] -&gt; [B * C * n_h, p_h, n_w, p_w]</span></span><br><span class="line">    x = x.reshape(batch_size * in_channels * num_patch_h, patch_h, num_patch_w, patch_w)</span><br><span class="line">    <span class="comment"># [B * C * n_h, p_h, n_w, p_w] -&gt; [B * C * n_h, n_w, p_h, p_w]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># [B * C * n_h, n_w, p_h, p_w] -&gt; [B, C, N, P] where P = p_h * p_w and N = n_h * n_w</span></span><br><span class="line">    x = x.reshape(batch_size, in_channels, num_patches, patch_area)</span><br><span class="line">    <span class="comment"># [B, C, N, P] -&gt; [B, P, N, C]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># [B, P, N, C] -&gt; [BP, N, C]</span></span><br><span class="line">    x = x.reshape(batch_size * patch_area, num_patches, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_self</span>(<span class="params">x: torch.Tensor</span>):</span><br><span class="line">    <span class="comment"># [B, C, H, W] -&gt; [B, C, n_h, p_h, n_w, p_w]</span></span><br><span class="line">    x = x.reshape(batch_size, in_channels, num_patch_h, patch_h, num_patch_w, patch_w)</span><br><span class="line">    <span class="comment"># [B, C, n_h, p_h, n_w, p_w] -&gt; [B, C, n_h, n_w, p_h, p_w]</span></span><br><span class="line">    x = x.transpose(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="comment"># [B, C, n_h, n_w, p_h, p_w] -&gt; [B, C, N, P] where P = p_h * p_w and N = n_h * n_w</span></span><br><span class="line">    x = x.reshape(batch_size, in_channels, num_patches, patch_area)</span><br><span class="line">    <span class="comment"># [B, C, N, P] -&gt; [B, P, N, C]</span></span><br><span class="line">    x = x.transpose(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># [B, P, N, C] -&gt; [BP, N, C]</span></span><br><span class="line">    x = x.reshape(batch_size * patch_area, num_patches, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t = torch.randn(batch_size, in_channels, num_patch_h * patch_h, num_patch_w * patch_w)</span><br><span class="line">    <span class="built_in">print</span>(torch.equal(official(t), my_self(t)))</span><br><span class="line"></span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">        official(t)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;official time: <span class="subst">&#123;time.time() - t1&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">        my_self(t)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;self time: <span class="subst">&#123;time.time() - t1&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="model-config">model_config</h2>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE-MobileViT-XXS.png" alt="模型配置-MobileViT-XXS"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_config</span>(<span class="params">mode: <span class="built_in">str</span> = <span class="string">&quot;xxs&quot;</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&quot;xx_small&quot;</span>:</span><br><span class="line">        mv2_exp_mult = <span class="number">2</span></span><br><span class="line">        config = &#123;</span><br><span class="line">            <span class="string">&quot;layer1&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">16</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer2&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">24</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer3&quot;</span>: &#123;  <span class="comment"># 28x28</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">48</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">64</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">128</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,  <span class="comment"># 8,</span></span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,  <span class="comment"># 8,</span></span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer4&quot;</span>: &#123;  <span class="comment"># 14x14</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">64</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">80</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">160</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,  <span class="comment"># 4,</span></span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,  <span class="comment"># 4,</span></span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer5&quot;</span>: &#123;  <span class="comment"># 7x7</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">80</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">96</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">192</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;last_layer_exp_factor&quot;</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="string">&quot;cls_dropout&quot;</span>: <span class="number">0.1</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">&quot;x_small&quot;</span>:</span><br><span class="line">        mv2_exp_mult = <span class="number">4</span></span><br><span class="line">        config = &#123;</span><br><span class="line">            <span class="string">&quot;layer1&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">32</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer2&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">48</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer3&quot;</span>: &#123;  <span class="comment"># 28x28</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">64</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">96</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">192</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer4&quot;</span>: &#123;  <span class="comment"># 14x14</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">80</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">120</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">240</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer5&quot;</span>: &#123;  <span class="comment"># 7x7</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">96</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">144</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">288</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;last_layer_exp_factor&quot;</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="string">&quot;cls_dropout&quot;</span>: <span class="number">0.1</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">&quot;small&quot;</span>:</span><br><span class="line">        mv2_exp_mult = <span class="number">4</span></span><br><span class="line">        config = &#123;</span><br><span class="line">            <span class="string">&quot;layer1&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">32</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">1</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer2&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">64</span>,</span><br><span class="line">                <span class="string">&quot;expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mv2&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer3&quot;</span>: &#123;  <span class="comment"># 28x28</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">96</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">144</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">288</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer4&quot;</span>: &#123;  <span class="comment"># 14x14</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">128</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">192</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">384</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;layer5&quot;</span>: &#123;  <span class="comment"># 7x7</span></span><br><span class="line">                <span class="string">&quot;out_channels&quot;</span>: <span class="number">160</span>,</span><br><span class="line">                <span class="string">&quot;transformer_channels&quot;</span>: <span class="number">240</span>,</span><br><span class="line">                <span class="string">&quot;ffn_dim&quot;</span>: <span class="number">480</span>,</span><br><span class="line">                <span class="string">&quot;transformer_blocks&quot;</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">&quot;patch_h&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;patch_w&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;stride&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;mv_expand_ratio&quot;</span>: mv2_exp_mult,</span><br><span class="line">                <span class="string">&quot;num_heads&quot;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&quot;block_type&quot;</span>: <span class="string">&quot;mobilevit&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;last_layer_exp_factor&quot;</span>: <span class="number">4</span>,</span><br><span class="line">            <span class="string">&quot;cls_dropout&quot;</span>: <span class="number">0.1</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&quot;layer1&quot;</span>, <span class="string">&quot;layer2&quot;</span>, <span class="string">&quot;layer3&quot;</span>, <span class="string">&quot;layer4&quot;</span>, <span class="string">&quot;layer5&quot;</span>]:</span><br><span class="line">        config[k].update(&#123;<span class="string">&quot;dropout&quot;</span>: <span class="number">0.1</span>, <span class="string">&quot;ffn_dropout&quot;</span>: <span class="number">0.0</span>, <span class="string">&quot;attn_dropout&quot;</span>: <span class="number">0.0</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure>
<h2 id="train">train</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> my_dataset <span class="keyword">import</span> MyDataSet</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> mobile_vit_xx_small <span class="keyword">as</span> create_model</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> read_split_data, train_one_epoch, evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    device = torch.device(args.device <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&quot;./weights&quot;</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        os.makedirs(<span class="string">&quot;./weights&quot;</span>)</span><br><span class="line"></span><br><span class="line">    tb_writer = SummaryWriter()</span><br><span class="line"></span><br><span class="line">    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(img_size),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.143</span>)),</span><br><span class="line">                                   transforms.CenterCrop(img_size),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化训练数据集</span></span><br><span class="line">    train_dataset = MyDataSet(images_path=train_images_path,</span><br><span class="line">                              images_class=train_images_label,</span><br><span class="line">                              transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实例化验证数据集</span></span><br><span class="line">    val_dataset = MyDataSet(images_path=val_images_path,</span><br><span class="line">                            images_class=val_images_label,</span><br><span class="line">                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size = args.batch_size</span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw,</span><br><span class="line">                                               collate_fn=train_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    val_loader = torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                                             batch_size=batch_size,</span><br><span class="line">                                             shuffle=<span class="literal">False</span>,</span><br><span class="line">                                             pin_memory=<span class="literal">True</span>,</span><br><span class="line">                                             num_workers=nw,</span><br><span class="line">                                             collate_fn=val_dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    model = create_model(num_classes=args.num_classes).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.weights != <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">assert</span> os.path.exists(args.weights), <span class="string">&quot;weights file: &#x27;&#123;&#125;&#x27; not exist.&quot;</span>.<span class="built_in">format</span>(args.weights)</span><br><span class="line">        weights_dict = torch.load(args.weights, map_location=device)</span><br><span class="line">        weights_dict = weights_dict[<span class="string">&quot;model&quot;</span>] <span class="keyword">if</span> <span class="string">&quot;model&quot;</span> <span class="keyword">in</span> weights_dict <span class="keyword">else</span> weights_dict</span><br><span class="line">        <span class="comment"># 删除有关分类类别的权重</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">list</span>(weights_dict.keys()):</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;classifier&quot;</span> <span class="keyword">in</span> k:</span><br><span class="line">                <span class="keyword">del</span> weights_dict[k]</span><br><span class="line">        <span class="built_in">print</span>(model.load_state_dict(weights_dict, strict=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.freeze_layers:</span><br><span class="line">        <span class="keyword">for</span> name, para <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">            <span class="comment"># 除head外，其他权重全部冻结</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;classifier&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                para.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;training &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">    pg = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=<span class="number">1E-2</span>)</span><br><span class="line"></span><br><span class="line">    best_acc = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        train_loss, train_acc = train_one_epoch(model=model,</span><br><span class="line">                                                optimizer=optimizer,</span><br><span class="line">                                                data_loader=train_loader,</span><br><span class="line">                                                device=device,</span><br><span class="line">                                                epoch=epoch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        val_loss, val_acc = evaluate(model=model,</span><br><span class="line">                                     data_loader=val_loader,</span><br><span class="line">                                     device=device,</span><br><span class="line">                                     epoch=epoch)</span><br><span class="line"></span><br><span class="line">        tags = [<span class="string">&quot;train_loss&quot;</span>, <span class="string">&quot;train_acc&quot;</span>, <span class="string">&quot;val_loss&quot;</span>, <span class="string">&quot;val_acc&quot;</span>, <span class="string">&quot;learning_rate&quot;</span>]</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">0</span>], train_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">1</span>], train_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">2</span>], val_loss, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">3</span>], val_acc, epoch)</span><br><span class="line">        tb_writer.add_scalar(tags[<span class="number">4</span>], optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>], epoch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> val_acc &gt; best_acc:</span><br><span class="line">            best_acc = val_acc</span><br><span class="line">            torch.save(model.state_dict(), <span class="string">&quot;./weights/best_model.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;./weights/latest_model.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.0002</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集所在根目录</span></span><br><span class="line">    <span class="comment"># https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;D:/python_test/deep-learning-for-image-processing/data_set/flower_data/flower_photos&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预训练权重路径，如果不想载入就设置为空字符</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./mobilevit_xxs.pt&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;initial weights path&#x27;</span>)</span><br><span class="line">    <span class="comment"># 是否冻结权重</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--freeze-layers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;device id (i.e. 0 or 0,1 or cpu)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(opt)</span><br></pre></td></tr></table></figure>
<h3 id="训练结果">训练结果</h3>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="训练结果"></p>
<h2 id="predict">predict</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> mobile_vit_xx_small <span class="keyword">as</span> create_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    img_size = <span class="number">224</span></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize(<span class="built_in">int</span>(img_size * <span class="number">1.14</span>)),</span><br><span class="line">         transforms.CenterCrop(img_size),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        class_indict = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = create_model(num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    model_weight_path = <span class="string">&quot;./weights/best_model.pth&quot;</span></span><br><span class="line">    model.load_state_dict(torch.load(model_weight_path, map_location=device))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(predict)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(i)],</span><br><span class="line">                                                  predict[i].numpy()))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h3 id="预测结果">预测结果</h3>
<p><img src="/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.png" alt="预测结果"></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="fa fa-tag"></i> 神经网络</a>
              <a href="/tags/CNN%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/" rel="tag"><i class="fa fa-tag"></i> CNN网络详解</a>
              <a href="/tags/Pytorch%E6%90%AD%E5%BB%BACNN/" rel="tag"><i class="fa fa-tag"></i> Pytorch搭建CNN</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/06/05/ConvNeXt%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BA/" rel="prev" title="深度学习模型之CNN（二十五）ConvNeXt网络讲解及使用Pytorch搭建">
                  <i class="fa fa-chevron-left"></i> 深度学习模型之CNN（二十五）ConvNeXt网络讲解及使用Pytorch搭建
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/06/13/Transformer%E4%B8%ADSelf-Attention%E4%BB%A5%E5%8F%8AMulti-Head-Attention%E8%AF%A6%E8%A7%A3/" rel="next" title="Transformer中Self-Attention以及Multi-Head Attention详解">
                  Transformer中Self-Attention以及Multi-Head Attention详解 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="valine-comments"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Linvil Yao</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>
-->

<div>
<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("04/21/2023 22:22:22");//在此处修改你的建站时间
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "已运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.4/jquery.min.js" integrity="sha256-oP6HI9z1XaZNBrJURtCoUT5SUnxFr8s3BzRl+cbzUq8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script src="/js/third-party/fancybox.js"></script>


  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"16p3s6fLzeTRVQeTGaUl2ZaN-gzGzoHsz","app_key":"iNfyeaWVmA11Duj7fzr0B1r1","server_url":"https://16p3s6fl.lc-cn-n1-shared.com","security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>




<script class="next-config" data-name="valine" type="application/json">{"enable":true,"appId":"16p3s6fLzeTRVQeTGaUl2ZaN-gzGzoHsz","appKey":"iNfyeaWVmA11Duj7fzr0B1r1","serverURLs":"https://16p3s6fl.lc-cn-n1-shared.com","placeholder":"请写下您的评论","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"lang":null,"visitor":false,"comment_count":true,"recordIP":true,"enableQQ":true,"requiredFields":[],"el":"#valine-comments","path":"/2023/06/10/MobileViT%E7%BD%91%E7%BB%9C%E8%AE%B2%E8%A7%A3%E5%8F%8A%E9%80%9A%E8%BF%87Pytorch%E6%90%AD%E5%BB%BAMobileViT%E7%BD%91%E7%BB%9C/"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.valine.el)
    .then(() => NexT.utils.getScript(
      'https://fastly.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js',
      { condition: window.Valine }
    ))
    .then(() => {
      new Valine(CONFIG.valine);
    });
});
</script>
<script src="https://unpkg.com/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '32px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
