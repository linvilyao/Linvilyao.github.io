<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_logosc/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_logosc/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"linvilyao.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":14,"offset":10},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础10.1》，作为随堂笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="EfficientNetV2网络详解">
<meta property="og:url" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/index.html">
<meta property="og:site_name" content="Linvil&#39;s Blog">
<meta property="og:description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础10.1》，作为随堂笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E5%92%8C%E6%97%B6%E4%B8%8B%E6%B5%81%E8%A1%8C%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E4%B8%8EEfficientNetV1%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV1%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98-%E5%9B%BE%E7%89%87%E5%B0%BA%E5%AF%B8.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Fused-MBConv%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E5%92%8C%E5%87%86%E7%A1%AE%E7%8E%87%E5%AF%B9%E6%AF%94.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2-S%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Fused-MBConv%E6%A8%A1%E5%9D%97.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B-Dropout.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/MBConv%E6%A8%A1%E5%9D%97.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2-S%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E4%B8%89%E4%B8%AA%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B8%90%E8%BF%9B%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E5%8F%82%E6%95%B0.png">
<meta property="og:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E6%B8%90%E8%BF%9B%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E5%9C%A8%E5%90%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png">
<meta property="article:published_time" content="2023-05-29T12:09:28.000Z">
<meta property="article:modified_time" content="2023-05-29T14:54:50.124Z">
<meta property="article:author" content="Linvil Yao">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="CNN网络详解">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E5%92%8C%E6%97%B6%E4%B8%8B%E6%B5%81%E8%A1%8C%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png">


<link rel="canonical" href="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/","path":"2023/05/29/EfficientNetV2网络详解/","title":"EfficientNetV2网络详解"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>EfficientNetV2网络详解 | Linvil's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Linvil's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">这是一个用来记录的博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">3</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">5</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">30</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">EfficientNetV1中存在的问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">EfficientNetV2中做出的贡献</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">EfficientNetV2网络框架</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Fused-MBConv%E6%A8%A1%E5%9D%97"><span class="nav-number">4.1.</span> <span class="nav-text">Fused-MBConv模块</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EfficientNet%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84Dropout"><span class="nav-number">4.2.</span> <span class="nav-text">EfficientNet网络中的Dropout</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MBConv%E6%A8%A1%E5%9D%97"><span class="nav-number">4.3.</span> <span class="nav-text">MBConv模块</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EfficientNetV2-S%E7%9A%84%E8%AF%A6%E7%BB%86%E5%8F%82%E6%95%B0"><span class="nav-number">4.4.</span> <span class="nav-text">EfficientNetV2-S的详细参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EfficientNetV2-M%E7%9A%84%E8%AF%A6%E7%BB%86%E5%8F%82%E6%95%B0"><span class="nav-number">4.5.</span> <span class="nav-text">EfficientNetV2-M的详细参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EfficientNetV2-L%E7%9A%84%E8%AF%A6%E7%BB%86%E5%8F%82%E6%95%B0"><span class="nav-number">4.6.</span> <span class="nav-text">EfficientNetV2-L的详细参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EfficientNetV2%E5%85%B6%E4%BB%96%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0"><span class="nav-number">4.7.</span> <span class="nav-text">EfficientNetV2其他训练参数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">Progressive Learning渐进学习策略</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Linvil Yao"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Linvil Yao</p>
  <div class="site-description" itemprop="description">Welcome to Linvil's Blog!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


        </div>
      </div>


  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      最近文章
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/" title="2023&#x2F;05&#x2F;29&#x2F;EfficientNetV2网络详解&#x2F;">EfficientNetV2网络详解</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/05/27/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNet%E7%BD%91%E7%BB%9C/" title="2023&#x2F;05&#x2F;27&#x2F;使用Pytorch搭建EfficientNet网络&#x2F;">深度学习模型之CNN（十八）使用Pytorch搭建EfficientNet网络</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/05/26/EfficientNet%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/" title="2023&#x2F;05&#x2F;26&#x2F;EfficientNet网络详解&#x2F;">深度学习模型之CNN（十七）EfficientNet网络详解</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/05/25/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAShuffleNetv2/" title="2023&#x2F;05&#x2F;25&#x2F;使用Pytorch搭建ShuffleNetv2&#x2F;">深度学习模型之CNN（十六）使用Pytorch搭建ShuffleNetv2</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/2023/05/24/ShuffleNetv1v2%E7%90%86%E8%AE%BA%E8%AE%B2%E8%A7%A3/" title="2023&#x2F;05&#x2F;24&#x2F;ShuffleNetv1v2理论讲解&#x2F;">深度学习模型之CNN（十五）ShuffleNetv1v2理论讲解</a>
        </li>
    </ul>
  </div>
    </div>


    



  </aside>






    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://linvilyao.github.io/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Linvil Yao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Linvil's Blog">
      <meta itemprop="description" content="Welcome to Linvil's Blog!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="EfficientNetV2网络详解 | Linvil's Blog">
      <meta itemprop="description" content="本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础10.1》，作为随堂笔记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          EfficientNetV2网络详解
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-05-29 20:09:28 / 修改时间：22:54:50" itemprop="dateCreated datePublished" datetime="2023-05-29T20:09:28+08:00">2023-05-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
    <span id="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/" class="post-meta-item leancloud_visitors" data-flag-title="EfficientNetV2网络详解" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Valine：</span>
  
    <a title="valine" href="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

            <div class="post-description">本笔记跟随字母站UP主霹雳吧啦Wz《卷积神经网络基础10.1》，作为随堂笔记</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1>前言</h1>
<p>本节课讲的是EfficientNet网络的升级版EfficientNetV2，这篇论文发表在2021年的CVPR，原论文：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.00298">EfficientNetV2: Smaller Models and Faster Training </a>。</p>
<p>下图为EfficientNetV2网络和时下流行网络的性能对比，其中紫色的线对应着EfficientNetV2的S、M和L三个不同大小模型的准确率和训练速度，红色的线对应着EfficientNetV2首先在EfficientNet21K上的预训练，之后再ImageNet上进行迁移学习</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E5%92%8C%E6%97%B6%E4%B8%8B%E6%B5%81%E8%A1%8C%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="EfficientNetV2网络和时下流行网络的性能对比"></p>
<p><strong>网络创新点</strong></p>
<ul>
<li>引入Fused-MBConv模块；</li>
<li>引入渐进式学习策略（学习更快）</li>
</ul>
<p>在EfficientNetV1中作者关注的是准确率，参数数量以及FLOPS(理论计算量小不代表推理速度快)，在EfficientNetV2中作者进一步关注模型的训练速度。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E4%B8%8EEfficientNetV1%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="EfficientNetV2与EfficientNetV1性能对比"></p>
<h1>EfficientNetV1中存在的问题</h1>
<p><strong>1、训练图像的尺寸很大时，训练速度非常慢</strong></p>
<p>针对这个问题一个比较好想到的办法就是降低训练图像的尺寸，之前也有一些文章这么干过。降低训练图像的尺寸不仅能够加快训练速度，还能使用更大的batch_size。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV1%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98-%E5%9B%BE%E7%89%87%E5%B0%BA%E5%AF%B8.png" alt="EfficientNetV1存在问题-图片尺寸"></p>
<p><strong>2、在网络浅层中使用Depthwise convolutions速度会很慢</strong></p>
<p>无法充分利用现有的一些加速器(虽然理论上计算量很小，但实际使用起来并没有想象中那么快)。故引入Fused-MBConv结构。</p>
<p>下图左边分别为MBConv和Fused-MBConv结构，下图右展示了不使用Fused-MBConv结构、仅将Stage2~4中的MBConv替换为Fused-MBConv结构、仅将Stage2~6中的MBConv替换为Fused-MBConv结构和将Stage2~8的MBConv替换为Fused-MBConv结构。</p>
<p>在前二者替换效果来看，训练速度和准确率都有提高，但全部替换的形式导致准确率和训练速度都下降，由此可见，<strong>并不能无脑的将MBConv转化为Fused-MBConv</strong>。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Fused-MBConv%E7%BB%93%E6%9E%84.png" alt="Fused-MBConv结构"></p>
<p><strong>3、同等的放大每个stage是次优的</strong></p>
<p>在EfficientNetV1中每个stage的深度和宽度都是同等放大的。但<strong>每个stage对网络的训练速度以及参数数量的贡献并不相同</strong>，所以直接使用同等缩放的策略并不合理。在这篇文章中，作者<strong>采用了非均匀的缩放策略来缩放模型</strong>。</p>
<table>
<thead>
<tr>
<th style="text-align:center">Model</th>
<th style="text-align:center">input_size</th>
<th style="text-align:center">width_coefficient</th>
<th style="text-align:center">depth_coefficient</th>
<th style="text-align:center">dropout_connect_rate</th>
<th style="text-align:center">dropout_rate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">EfficientNetB0</td>
<td style="text-align:center">224x224</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.2</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB1</td>
<td style="text-align:center">240x240</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">1.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.2</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB2</td>
<td style="text-align:center">260x260</td>
<td style="text-align:center">1.1</td>
<td style="text-align:center">1.2</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.3</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB3</td>
<td style="text-align:center">300x300</td>
<td style="text-align:center">1.2</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.3</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB4</td>
<td style="text-align:center">380x380</td>
<td style="text-align:center">1.4</td>
<td style="text-align:center">1.8</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.4</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB5</td>
<td style="text-align:center">456x456</td>
<td style="text-align:center">1.6</td>
<td style="text-align:center">2.2</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.4</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB6</td>
<td style="text-align:center">528x528</td>
<td style="text-align:center">1.8</td>
<td style="text-align:center">2.6</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.5</td>
</tr>
<tr>
<td style="text-align:center">EfficientNetB7</td>
<td style="text-align:center">600x600</td>
<td style="text-align:center">2.0</td>
<td style="text-align:center">3.1</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.5</td>
</tr>
</tbody>
</table>
<h1>EfficientNetV2中做出的贡献</h1>
<p>在之前的一些研究中，主要关注的是准确率以及参数数量（注意，参数数量少并不代表推理速度更快)。但在近些年的研究中，开始关注网络的训练速度以及推理速度(可能是准确率刷不动了）。</p>
<ul>
<li>引入新的网络（EfficientNetV2），该网络在训练速度以及参数数量上都优于先前的一些网络；</li>
<li>提出了改进的渐进学习方法，该方法会<strong>根据训练图像的尺寸动态调节正则方法</strong>（提升训练速度、准确率），其中方法有Dropout、Rand Augment、Mixup；</li>
<li>通过实验与先前的一些网络相比，<strong>训练速度提升11倍</strong>，参数数量减少为1/6.8</li>
</ul>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E5%92%8C%E5%87%86%E7%A1%AE%E7%8E%87%E5%AF%B9%E6%AF%94.png" alt="EfficientNetV2训练参数和准确率对比"></p>
<h1>EfficientNetV2网络框架</h1>
<p><strong>注意，在源码中Stage6的输出Channels是等于256并不是表格中的272，Stage7的输出Channels是1280并不是表格中的1792</strong>，后续论文的版本会修正过来。</p>
<p>相比与EfficientNetV1，主要有以下不同：</p>
<ul>
<li><strong>除了使用<code>MBConv</code>模块，还使用<code>Fused-MBConv</code>模块</strong>（主要是在网络浅层中使用）；</li>
<li><strong>会使用较小的<code>expansion ratio</code></strong>（<code>MBConv</code>中第一个<code>expand conv1x1</code>或者<code>Fused-MBConv</code>中第一个<code>expand conv3x3</code>）比如<code>4</code>，在EfficientNetV1中基本都是<code>6</code>. 这样的好处是能够减少内存访问开销；</li>
<li><strong>偏向使用更小的<code>kernel_size(3x3)</code></strong>，在EfficientNetV1中使用了很多<code>5x5</code>的kernel_size。通过下表可以看到使用的kernel_size全是<code>3x3</code>的，由于<code>3x3</code>的感受野是要比<code>5x5</code>小的，所以需要堆叠更多的层结构以增加感受野；</li>
<li><strong>移除了EfficientNetV1中最后一个步距为1的stage (V1中的stage8)</strong></li>
</ul>
<p><code>Stride</code>就是步距，注意每个Stage中会重复堆叠Operator模块多次，只有第一个Opertator模块的步距是按照表格中Stride来设置的，其他的默认都是1。 <code>#Channels</code>表示该Stage输出的特征矩阵的Channels，<code>#Layers</code>表示该Stage重复堆叠Operator的次数。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2-S%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6.png" alt="EfficientNetV2-S模型框架"></p>
<h2 id="Fused-MBConv模块">Fused-MBConv模块</h2>
<p>通过上表可以看到EfficientNetV2-S分为Stage0到Stage7（EfficientNetV1中是Stage1到Stage9）。Operator表示在当前Stage中使用的模块：</p>
<ul>
<li>
<p>Conv3x3就是普通的3x3卷积 + 激活函数（SiLU）+ BN；</p>
</li>
<li>
<p>Fused-MBConv模块名称后跟的1，4表示expansion ratio，k3x3表示kenel_size为3x3，下面是结构图。</p>
</li>
</ul>
<p><strong>注意</strong>：</p>
<ul>
<li>当expansion ratio = 1时是没有expand conv的；</li>
<li>这里没有使用到SE结构的（原论文图中有SE）；</li>
<li>当stride = 1且输入输出Channels相等时才有shortcut连接；</li>
<li>当有shortcut连接时才有Dropout层，而且这里的Dropout层是Stochastic Depth，即会随机丢掉整个block的主分支（只剩捷径分支，相当于直接跳过了这个block）也可以理解为减少了网络的深度。</li>
</ul>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/Fused-MBConv%E6%A8%A1%E5%9D%97.png" alt="Fused-MBConv模块"></p>
<h2 id="EfficientNet网络中的Dropout">EfficientNet网络中的Dropout</h2>
<p>EfficientNet网络中的Dropout与前期所有网络结构的Dropout不全一样，例如原始的Dropout参数丢弃比例为0.2，但EfficientNet中给出Dropout = 0.2的参数表示该网络在0~0.2的丢弃比例下逐渐失活。引用论文为：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.09382">Deep Networks with Stochastic Depth</a></p>
<p>下图可以理解为正向传播过程中将输入的特征矩阵经历了一个又一个block，每一个block都可以认为是一个残差结构。例如主分支通过$f$函数进行输出，shortcut直接从输入引到输出，在此过程中，会以一定的概率来对主分支进行丢弃（直接放弃整个主分支，相当于直接将上一层的输出引入到下一层的输入，相当于没有这一层）。即Stochastic Depth（随即深度，指的是网络的depth，因为会随机丢弃任意一层block）。</p>
<p>下图中表示存活概率从1.0至0.5，一个渐变的过程。但在EfficientNetV2中采用drop_prob是0~0.2的丢弃比例（提升训练速度，小幅提升准确率）。</p>
<p>注意：<strong>这里的dropout层仅指Fused-MBConv模块以及MBConv模块中的dropout层，不包括最后全连接前的dropout层</strong></p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B-Dropout.png" alt="正向传播过程-Dropout"></p>
<h2 id="MBConv模块">MBConv模块</h2>
<p>MBConv模块和EfficientNetV1中是一样的，其中模块名称后跟的4、6表示expansion ratio，SE0.25表示使用了SE模块，0.25表示SE模块中第一个全连接层的节点个数是输入该MBConv模块特征矩阵channels的1/4</p>
<p>下面是MBConv模块结构图。<strong>注意当stride=1且输入输出Channels相等时才有shortcut连接</strong>。同样这里的<strong>Dropout层是Stochastic Depth</strong>。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/MBConv%E6%A8%A1%E5%9D%97.png" alt="MBConv模块"></p>
<h2 id="EfficientNetV2-S的详细参数">EfficientNetV2-S的详细参数</h2>
<p>首先在官方的源码中有个baseline config注意这个不是V2-S的配置，在efficientnetv2 -&gt; effnetv2_configs.py文件中 。</p>
<ul>
<li><code>r</code>代表当前Stage中Operator重复堆叠的次数；</li>
<li><code>k</code>代表kernel_size；</li>
<li><code>s</code>代表步距stride；</li>
<li><code>e</code>代表expansion ratio；</li>
<li><code>i</code>代表input channels；</li>
<li><code>o</code>代表output channels；</li>
<li><code>c</code>代表conv_type，1代表Fused-MBConv，0代表MBConv（默认为MBConv）；</li>
<li><code>se</code>代表使用SE模块，以及se_ratio</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#################### EfficientNet V2 configs ####################</span></span><br><span class="line">v2_base_block = [  <span class="comment"># The baseline config for v2 models.</span></span><br><span class="line">    <span class="string">&#x27;r1_k3_s1_e1_i32_o16_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r2_k3_s2_e4_i16_o32_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r2_k3_s2_e4_i32_o48_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r3_k3_s2_e4_i48_o96_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s1_e6_i96_o112_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r8_k3_s2_e6_i112_o192_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>EfficientNetV2-S的配置是在baseline的基础上采用了width倍率因子1.4， depth倍率因子1.8得到的（这两个倍率因子是EfficientNetV1-B4中采用的）。</p>
<p>注意：只针对存在MBConv模块或Fused-MBConv模块的Stage，例如<code>r2_k3_s1_e1_i24_o24_c1</code>对应<code>Stage1</code>，Operator重复堆叠2次，kernel_size等于3，stride等于1，expansion等于1，input_channels等于24，output_channels等于24，conv_type为<code>Fused-MBConv</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">v2_s_block = [  <span class="comment"># about base * (width1.4, depth1.8)</span></span><br><span class="line">    <span class="string">&#x27;r2_k3_s1_e1_i24_o24_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r4_k3_s2_e4_i24_o48_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r4_k3_s2_e4_i48_o64_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r6_k3_s2_e4_i64_o128_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r9_k3_s1_e6_i128_o160_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r15_k3_s2_e6_i160_o256_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2-S%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6.png" alt="EfficientNetV2-S模型框架"></p>
<h2 id="EfficientNetV2-M的详细参数">EfficientNetV2-M的详细参数</h2>
<p>EfficientNetV2-M的配置是在baseline的基础上采用了width倍率因子1.6， depth倍率因子2.2得到的（这两个倍率因子是EfficientNetV1-B5中采用的）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">v2_m_block = [  <span class="comment"># about base * (width1.6, depth2.2)</span></span><br><span class="line">    <span class="string">&#x27;r3_k3_s1_e1_i24_o24_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s2_e4_i24_o48_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s2_e4_i48_o80_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i80_o160_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r14_k3_s1_e6_i160_o176_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r18_k3_s2_e6_i176_o304_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r5_k3_s1_e6_i304_o512_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>通过配置文件可知Stage0的卷积核个数是24（<code>i24</code>）</p>
<h2 id="EfficientNetV2-L的详细参数">EfficientNetV2-L的详细参数</h2>
<p>EfficientNetV2-L的配置是在baseline的基础上采用了width倍率因子2.0， depth倍率因子3.1得到的（这两个倍率因子是EfficientNetV1-B7中采用的）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">v2_l_block = [  <span class="comment"># about base * (width2.0, depth3.1)</span></span><br><span class="line">    <span class="string">&#x27;r4_k3_s1_e1_i32_o32_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i32_o64_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s2_e4_i64_o96_c1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r10_k3_s2_e4_i96_o192_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r19_k3_s1_e6_i192_o224_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r25_k3_s2_e6_i224_o384_se0.25&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;r7_k3_s1_e6_i384_o640_se0.25&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>通过配置文件可知Stage0的卷积核个数是32（<code>i32</code>）</p>
<p>注意：<strong>EfficientNetV2-M和EfficientNetV2-L比EfficientNetV2-S多出一个Stage</strong></p>
<h2 id="EfficientNetV2其他训练参数">EfficientNetV2其他训练参数</h2>
<p>下面是源码中给出的关于<code>efficientnetv2-s</code>，<code>efficientnetv2-m</code>和<code>efficientnetv2-l</code>三个参数的配置信息。</p>
<p>其中的<code>v2_s_block</code>，<code>v2_m_block</code>以及<code>v2_l_block</code>就是上面刚刚讲到过的网络配置参数，剩下就关注下<code>train_size</code>, <code>eval_size</code>, <code>dropout</code>, <code>randaug</code>, <code>mixup</code>, <code>aug</code>即可。比如<code>efficientnetv2-s</code>的<code>train_size=300</code>（注意实际训练中train_size是会变化的，但最大不超过300，但在验证过程中默认为384x383，后面讲Progressive Learning中会细讲），<code>eval_size=384</code>，<code>dropout=0.2</code>（指的是最后一个Stage中池化层和全连接层之间的一个dropout_rate），<code>randaug=10，mixup=0，aug='randaug'</code>（针对迁移学习策略所使用到的参数）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">efficientnetv2_params = &#123;</span><br><span class="line">    <span class="comment"># (block, width, depth, train_size, eval_size, dropout, randaug, mixup, aug)</span></span><br><span class="line">    <span class="string">&#x27;efficientnetv2-s&#x27;</span>:  <span class="comment"># 83.9% @ 22M</span></span><br><span class="line">        (v2_s_block, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">300</span>, <span class="number">384</span>, <span class="number">0.2</span>, <span class="number">10</span>, <span class="number">0</span>, <span class="string">&#x27;randaug&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;efficientnetv2-m&#x27;</span>:  <span class="comment"># 85.2% @ 54M</span></span><br><span class="line">        (v2_m_block, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">384</span>, <span class="number">480</span>, <span class="number">0.3</span>, <span class="number">15</span>, <span class="number">0.2</span>, <span class="string">&#x27;randaug&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;efficientnetv2-l&#x27;</span>:  <span class="comment"># 85.7% @ 120M</span></span><br><span class="line">        (v2_l_block, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">384</span>, <span class="number">480</span>, <span class="number">0.4</span>, <span class="number">20</span>, <span class="number">0.5</span>, <span class="string">&#x27;randaug&#x27;</span>),</span><br></pre></td></tr></table></figure>
<h1>Progressive Learning渐进学习策略</h1>
<p>训练图像的尺寸对训练模型的效率有很大的影响。所以在之前的一些工作中很多人尝试使用动态的图像尺寸（比如一开始用很小的图像尺寸，后面再增大）来加速网络的训练，但通常会导致Accuracy降低。为什么会出现这种情况呢？</p>
<p>作者提出了一个猜想：Accuracy的降低是不平衡的正则化<code>unbalanced regularization</code>导致的。在训练不同尺寸的图像时，应该使用动态的正则方法（之前都是使用固定的正则方法）。</p>
<p>为了验证这个猜想，作者接着做了一些实验。训练模型过程中尝试使用不同的图像尺寸以及不同强度的数据增强<code>data augmentations</code>。当训练的图片尺寸较小时，使用较弱的数据增强<code>augmentation</code>能够达到更好的结果；当训练的图像尺寸较大时，使用更强的数据增强能够达到更好的接果。如下表所示，当<code>Size=128</code>，<code>RandAug magnitude=5</code>时效果最好；当<code>Size=300</code>，<code>RandAug magnitude=15</code>时效果最好：</p>
<p>![Progressive Learning渐进学习策略效果](EfficientNetV2网络详解/Progressive Learning渐进学习策略效果.png)</p>
<p>基于以上实验，作者就提出了渐进式训练策略<code>Progressive Learning</code>。如下图所示，<strong>在训练早期使用较小的训练尺寸以及较弱的正则方法<code>weak regularization</code>，这样网络能够快速的学习到一些简单的表达能力。接着逐渐提升图像尺寸，同时增强正则方法<code>adding stronger regularization</code></strong>。这里所说的<code>regularization</code>包括<code>dropout rate</code>，<code>RandAugment magnitude</code>以及<code>mixup ratio</code>。</p>
<p>![Progressive Learning渐进学习策略实验](EfficientNetV2网络详解/Progressive Learning渐进学习策略实验.png)</p>
<p>下表给出了EfficientNetV2（S，M，L）三个模型的渐进学习策略参数：</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/EfficientNetV2%E4%B8%89%E4%B8%AA%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B8%90%E8%BF%9B%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E5%8F%82%E6%95%B0.png" alt="EfficientNetV2三个模型的渐进学习策略参数"></p>
<p>通过对比可以看出使用渐进式学习策略确实能够有效提升训练速度。为了进一步验证渐进式学习策略的有效性，作者还在Resnet以及EfficientNetV1上进行了测试，如下表所示，使用了渐进式学习策略后确实能够有效提升训练速度并且能够小幅提升Accuracy。</p>
<p><img src="/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/%E6%B8%90%E8%BF%9B%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E5%9C%A8%E5%90%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="渐进学习策略在各网络模型中的性能对比"></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="fa fa-tag"></i> 神经网络</a>
              <a href="/tags/CNN%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/" rel="tag"><i class="fa fa-tag"></i> CNN网络详解</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/05/27/%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAEfficientNet%E7%BD%91%E7%BB%9C/" rel="prev" title="深度学习模型之CNN（十八）使用Pytorch搭建EfficientNet网络">
                  <i class="fa fa-chevron-left"></i> 深度学习模型之CNN（十八）使用Pytorch搭建EfficientNet网络
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="valine-comments"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Linvil Yao</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>
-->

<div>
<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("04/21/2023 22:22:22");//在此处修改你的建站时间
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "已运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.4/jquery.min.js" integrity="sha256-oP6HI9z1XaZNBrJURtCoUT5SUnxFr8s3BzRl+cbzUq8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script src="/js/third-party/fancybox.js"></script>


  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"16p3s6fLzeTRVQeTGaUl2ZaN-gzGzoHsz","app_key":"iNfyeaWVmA11Duj7fzr0B1r1","server_url":"https://16p3s6fl.lc-cn-n1-shared.com","security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script src="https://unpkg.com/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '32px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>


<script class="next-config" data-name="valine" type="application/json">{"enable":true,"appId":"16p3s6fLzeTRVQeTGaUl2ZaN-gzGzoHsz","appKey":"iNfyeaWVmA11Duj7fzr0B1r1","serverURLs":"https://16p3s6fl.lc-cn-n1-shared.com","placeholder":"请写下您的评论","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"lang":null,"visitor":false,"comment_count":true,"recordIP":true,"enableQQ":true,"requiredFields":[],"el":"#valine-comments","path":"/2023/05/29/EfficientNetV2%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.valine.el)
    .then(() => NexT.utils.getScript(
      'https://fastly.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js',
      { condition: window.Valine }
    ))
    .then(() => {
      new Valine(CONFIG.valine);
    });
});
</script>

</body>
</html>
